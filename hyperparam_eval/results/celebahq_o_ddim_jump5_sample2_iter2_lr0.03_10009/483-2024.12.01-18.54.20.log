2024-12-01-18:54:25-root-INFO: Prepare model...
2024-12-01-18:54:42-root-INFO: Loading model from ./checkpoints/celeba256_250000.pt...
2024-12-01-18:55:15-root-INFO: Start sampling
2024-12-01-18:55:24-root-INFO: step: 249 lr_xt 0.00019059
2024-12-01-18:55:24-root-INFO: grad norm: 32196.164 24085.777 21365.119
2024-12-01-18:55:25-root-INFO: Loss too large (77070.016->78612.719)! Learning rate decreased to 0.00015.
2024-12-01-18:55:26-root-INFO: grad norm: 15661.116 11248.846 10896.516
2024-12-01-18:55:26-root-INFO: Loss Change: 77070.016 -> 41352.168
2024-12-01-18:55:26-root-INFO: Regularization Change: 0.000 -> 13.469
2024-12-01-18:55:26-root-INFO: Learning rate of xt decay: 0.03000 -> 0.03036.
2024-12-01-18:55:26-root-INFO: Coefficient of regularization decay: 0.00010 -> 0.00010.
2024-12-01-18:55:27-root-INFO: step: 248 lr_xt 0.00020082
2024-12-01-18:55:27-root-INFO: grad norm: 15700.966 11445.979 10747.551
2024-12-01-18:55:27-root-INFO: Loss too large (37235.816->50508.660)! Learning rate decreased to 0.00016.
2024-12-01-18:55:28-root-INFO: grad norm: 22337.473 16895.885 14611.358
2024-12-01-18:55:29-root-INFO: Loss too large (35232.438->52900.266)! Learning rate decreased to 0.00013.
2024-12-01-18:55:29-root-INFO: Loss too large (35232.438->40695.477)! Learning rate decreased to 0.00010.
2024-12-01-18:55:30-root-INFO: Loss Change: 37235.816 -> 30679.652
2024-12-01-18:55:30-root-INFO: Regularization Change: 0.000 -> 1.727
2024-12-01-18:55:30-root-INFO: Learning rate of xt decay: 0.03036 -> 0.03072.
2024-12-01-18:55:30-root-INFO: Coefficient of regularization decay: 0.00010 -> 0.00010.
2024-12-01-18:55:30-root-INFO: step: 247 lr_xt 0.00021156
2024-12-01-18:55:30-root-INFO: grad norm: 17054.482 13055.294 10973.363
2024-12-01-18:55:31-root-INFO: Loss too large (29564.221->72510.141)! Learning rate decreased to 0.00017.
2024-12-01-18:55:31-root-INFO: Loss too large (29564.221->47836.262)! Learning rate decreased to 0.00014.
2024-12-01-18:55:31-root-INFO: Loss too large (29564.221->32722.572)! Learning rate decreased to 0.00011.
2024-12-01-18:55:32-root-INFO: grad norm: 15444.778 12359.479 9261.991
2024-12-01-18:55:33-root-INFO: Loss too large (24640.688->25551.619)! Learning rate decreased to 0.00009.
2024-12-01-18:55:33-root-INFO: Loss Change: 29564.221 -> 21262.137
2024-12-01-18:55:33-root-INFO: Regularization Change: 0.000 -> 0.904
2024-12-01-18:55:33-root-INFO: Learning rate of xt decay: 0.03072 -> 0.03109.
2024-12-01-18:55:33-root-INFO: Coefficient of regularization decay: 0.00010 -> 0.00010.
2024-12-01-18:55:34-root-INFO: step: 246 lr_xt 0.00022285
2024-12-01-18:55:34-root-INFO: grad norm: 10880.424 8797.229 6402.531
2024-12-01-18:55:34-root-INFO: Loss too large (20900.229->47108.699)! Learning rate decreased to 0.00018.
2024-12-01-18:55:35-root-INFO: Loss too large (20900.229->33635.906)! Learning rate decreased to 0.00014.
2024-12-01-18:55:35-root-INFO: Loss too large (20900.229->25658.324)! Learning rate decreased to 0.00011.
2024-12-01-18:55:36-root-INFO: Loss too large (20900.229->21201.283)! Learning rate decreased to 0.00009.
2024-12-01-18:55:37-root-INFO: grad norm: 7895.036 6381.823 4648.001
2024-12-01-18:55:37-root-INFO: Loss Change: 20900.229 -> 17923.074
2024-12-01-18:55:37-root-INFO: Regularization Change: 0.000 -> 0.234
2024-12-01-18:55:37-root-INFO: Learning rate of xt decay: 0.03109 -> 0.03147.
2024-12-01-18:55:37-root-INFO: Coefficient of regularization decay: 0.00010 -> 0.00010.
2024-12-01-18:55:38-root-INFO: step: 245 lr_xt 0.00023469
2024-12-01-18:55:38-root-INFO: grad norm: 5731.952 4690.155 3295.106
2024-12-01-18:55:38-root-INFO: Loss too large (17759.990->24839.131)! Learning rate decreased to 0.00019.
2024-12-01-18:55:39-root-INFO: Loss too large (17759.990->21057.170)! Learning rate decreased to 0.00015.
2024-12-01-18:55:39-root-INFO: Loss too large (17759.990->18875.646)! Learning rate decreased to 0.00012.
2024-12-01-18:55:40-root-INFO: grad norm: 6265.008 5056.178 3699.377
2024-12-01-18:55:40-root-INFO: Loss too large (17677.887->17738.518)! Learning rate decreased to 0.00010.
2024-12-01-18:55:41-root-INFO: Loss Change: 17759.990 -> 16976.617
2024-12-01-18:55:41-root-INFO: Regularization Change: 0.000 -> 0.104
2024-12-01-18:55:41-root-INFO: Learning rate of xt decay: 0.03147 -> 0.03184.
2024-12-01-18:55:41-root-INFO: Coefficient of regularization decay: 0.00010 -> 0.00011.
2024-12-01-18:55:41-root-INFO: step: 244 lr_xt 0.00024712
2024-12-01-18:55:42-root-INFO: grad norm: 4211.623 3512.796 2323.365
2024-12-01-18:55:42-root-INFO: Loss too large (16852.031->20499.629)! Learning rate decreased to 0.00020.
2024-12-01-18:55:43-root-INFO: Loss too large (16852.031->18477.262)! Learning rate decreased to 0.00016.
2024-12-01-18:55:43-root-INFO: Loss too large (16852.031->17324.172)! Learning rate decreased to 0.00013.
2024-12-01-18:55:44-root-INFO: grad norm: 4314.614 3500.447 2522.453
2024-12-01-18:55:45-root-INFO: Loss Change: 16852.031 -> 16621.641
2024-12-01-18:55:45-root-INFO: Regularization Change: 0.000 -> 0.085
2024-12-01-18:55:45-root-INFO: Learning rate of xt decay: 0.03184 -> 0.03223.
2024-12-01-18:55:45-root-INFO: Coefficient of regularization decay: 0.00011 -> 0.00011.
2024-12-01-18:55:45-root-INFO: step: 243 lr_xt 0.00026017
2024-12-01-18:55:45-root-INFO: grad norm: 4313.835 3569.786 2421.942
2024-12-01-18:55:46-root-INFO: Loss too large (16416.090->20528.477)! Learning rate decreased to 0.00021.
2024-12-01-18:55:46-root-INFO: Loss too large (16416.090->18257.586)! Learning rate decreased to 0.00017.
2024-12-01-18:55:46-root-INFO: Loss too large (16416.090->16962.258)! Learning rate decreased to 0.00013.
2024-12-01-18:55:47-root-INFO: grad norm: 4223.581 3475.717 2399.590
2024-12-01-18:55:48-root-INFO: Loss Change: 16416.090 -> 16161.390
2024-12-01-18:55:48-root-INFO: Regularization Change: 0.000 -> 0.059
2024-12-01-18:55:48-root-INFO: Learning rate of xt decay: 0.03223 -> 0.03261.
2024-12-01-18:55:48-root-INFO: Coefficient of regularization decay: 0.00011 -> 0.00011.
2024-12-01-18:55:48-root-INFO: step: 242 lr_xt 0.00027387
2024-12-01-18:55:49-root-INFO: grad norm: 3836.327 3190.665 2130.038
2024-12-01-18:55:49-root-INFO: Loss too large (15875.312->19101.387)! Learning rate decreased to 0.00022.
2024-12-01-18:55:49-root-INFO: Loss too large (15875.312->17278.354)! Learning rate decreased to 0.00018.
2024-12-01-18:55:50-root-INFO: Loss too large (15875.312->16245.572)! Learning rate decreased to 0.00014.
2024-12-01-18:55:51-root-INFO: grad norm: 3573.751 2970.204 1987.356
2024-12-01-18:55:51-root-INFO: Loss Change: 15875.312 -> 15558.191
2024-12-01-18:55:51-root-INFO: Regularization Change: 0.000 -> 0.055
2024-12-01-18:55:51-root-INFO: Learning rate of xt decay: 0.03261 -> 0.03300.
2024-12-01-18:55:51-root-INFO: Coefficient of regularization decay: 0.00011 -> 0.00011.
2024-12-01-18:55:52-root-INFO: step: 241 lr_xt 0.00028824
2024-12-01-18:55:52-root-INFO: grad norm: 3107.945 2576.687 1737.816
2024-12-01-18:55:53-root-INFO: Loss too large (15460.953->17477.809)! Learning rate decreased to 0.00023.
2024-12-01-18:55:53-root-INFO: Loss too large (15460.953->16297.113)! Learning rate decreased to 0.00018.
2024-12-01-18:55:53-root-INFO: Loss too large (15460.953->15633.500)! Learning rate decreased to 0.00015.
2024-12-01-18:55:54-root-INFO: grad norm: 2800.579 2360.730 1506.718
2024-12-01-18:55:55-root-INFO: Loss Change: 15460.953 -> 15139.558
2024-12-01-18:55:55-root-INFO: Regularization Change: 0.000 -> 0.061
2024-12-01-18:55:55-root-INFO: Learning rate of xt decay: 0.03300 -> 0.03340.
2024-12-01-18:55:55-root-INFO: Coefficient of regularization decay: 0.00011 -> 0.00011.
2024-12-01-18:55:55-root-INFO: step: 240 lr_xt 0.00030331
2024-12-01-18:55:56-root-INFO: grad norm: 2353.538 1951.397 1315.748
2024-12-01-18:55:56-root-INFO: Loss too large (14933.925->15914.025)! Learning rate decreased to 0.00024.
2024-12-01-18:55:56-root-INFO: Loss too large (14933.925->15286.964)! Learning rate decreased to 0.00019.
2024-12-01-18:55:57-root-INFO: Loss too large (14933.925->14941.559)! Learning rate decreased to 0.00016.
2024-12-01-18:55:58-root-INFO: grad norm: 2051.843 1762.791 1050.060
2024-12-01-18:55:58-root-INFO: Loss Change: 14933.925 -> 14626.926
2024-12-01-18:55:58-root-INFO: Regularization Change: 0.000 -> 0.070
2024-12-01-18:55:58-root-INFO: Undo step: 240
2024-12-01-18:55:58-root-INFO: Undo step: 241
2024-12-01-18:55:58-root-INFO: Undo step: 242
2024-12-01-18:55:58-root-INFO: Undo step: 243
2024-12-01-18:55:58-root-INFO: Undo step: 244
2024-12-01-18:55:59-root-INFO: step: 245 lr_xt 0.00023469
2024-12-01-18:55:59-root-INFO: grad norm: 10579.234 7614.194 7344.676
2024-12-01-18:55:59-root-INFO: Loss too large (21291.324->32775.746)! Learning rate decreased to 0.00019.
2024-12-01-18:56:00-root-INFO: Loss too large (21291.324->25301.467)! Learning rate decreased to 0.00015.
2024-12-01-18:56:01-root-INFO: grad norm: 10210.729 7295.480 7143.875
2024-12-01-18:56:01-root-INFO: Loss Change: 21291.324 -> 20301.207
2024-12-01-18:56:01-root-INFO: Regularization Change: 0.000 -> 0.324
2024-12-01-18:56:01-root-INFO: Learning rate of xt decay: 0.03147 -> 0.03184.
2024-12-01-18:56:01-root-INFO: Coefficient of regularization decay: 0.00010 -> 0.00011.
2024-12-01-18:56:02-root-INFO: step: 244 lr_xt 0.00024712
2024-12-01-18:56:02-root-INFO: grad norm: 9479.746 6982.925 6411.267
2024-12-01-18:56:02-root-INFO: Loss too large (19755.781->30490.111)! Learning rate decreased to 0.00020.
2024-12-01-18:56:03-root-INFO: Loss too large (19755.781->24060.785)! Learning rate decreased to 0.00016.
2024-12-01-18:56:03-root-INFO: Loss too large (19755.781->20041.730)! Learning rate decreased to 0.00013.
2024-12-01-18:56:04-root-INFO: grad norm: 6394.338 4751.973 4278.587
2024-12-01-18:56:05-root-INFO: Loss Change: 19755.781 -> 16699.678
2024-12-01-18:56:05-root-INFO: Regularization Change: 0.000 -> 0.297
2024-12-01-18:56:05-root-INFO: Learning rate of xt decay: 0.03184 -> 0.03223.
2024-12-01-18:56:05-root-INFO: Coefficient of regularization decay: 0.00011 -> 0.00011.
2024-12-01-18:56:05-root-INFO: step: 243 lr_xt 0.00026017
2024-12-01-18:56:06-root-INFO: grad norm: 4616.725 3558.958 2940.742
2024-12-01-18:56:06-root-INFO: Loss too large (16485.438->19670.457)! Learning rate decreased to 0.00021.
2024-12-01-18:56:06-root-INFO: Loss too large (16485.438->17778.037)! Learning rate decreased to 0.00017.
2024-12-01-18:56:07-root-INFO: Loss too large (16485.438->16665.504)! Learning rate decreased to 0.00013.
2024-12-01-18:56:08-root-INFO: grad norm: 3573.081 2701.180 2338.917
2024-12-01-18:56:08-root-INFO: Loss Change: 16485.438 -> 15723.209
2024-12-01-18:56:08-root-INFO: Regularization Change: 0.000 -> 0.100
2024-12-01-18:56:08-root-INFO: Learning rate of xt decay: 0.03223 -> 0.03261.
2024-12-01-18:56:08-root-INFO: Coefficient of regularization decay: 0.00011 -> 0.00011.
2024-12-01-18:56:09-root-INFO: step: 242 lr_xt 0.00027387
2024-12-01-18:56:09-root-INFO: grad norm: 3085.157 2501.067 1806.338
2024-12-01-18:56:09-root-INFO: Loss too large (15604.607->16993.684)! Learning rate decreased to 0.00022.
2024-12-01-18:56:10-root-INFO: Loss too large (15604.607->16109.755)! Learning rate decreased to 0.00018.
2024-12-01-18:56:10-root-INFO: Loss too large (15604.607->15608.815)! Learning rate decreased to 0.00014.
2024-12-01-18:56:11-root-INFO: grad norm: 2504.368 1928.259 1598.022
2024-12-01-18:56:12-root-INFO: Loss Change: 15604.607 -> 15143.123
2024-12-01-18:56:12-root-INFO: Regularization Change: 0.000 -> 0.087
2024-12-01-18:56:12-root-INFO: Learning rate of xt decay: 0.03261 -> 0.03300.
2024-12-01-18:56:12-root-INFO: Coefficient of regularization decay: 0.00011 -> 0.00011.
2024-12-01-18:56:12-root-INFO: step: 241 lr_xt 0.00028824
2024-12-01-18:56:12-root-INFO: grad norm: 2220.198 1879.882 1181.237
2024-12-01-18:56:13-root-INFO: Loss too large (15134.641->15755.720)! Learning rate decreased to 0.00023.
2024-12-01-18:56:13-root-INFO: Loss too large (15134.641->15312.423)! Learning rate decreased to 0.00018.
2024-12-01-18:56:14-root-INFO: grad norm: 2678.804 2104.944 1656.866
2024-12-01-18:56:15-root-INFO: Loss too large (15069.659->15082.218)! Learning rate decreased to 0.00015.
2024-12-01-18:56:15-root-INFO: Loss Change: 15134.641 -> 14861.627
2024-12-01-18:56:15-root-INFO: Regularization Change: 0.000 -> 0.097
2024-12-01-18:56:15-root-INFO: Learning rate of xt decay: 0.03300 -> 0.03340.
2024-12-01-18:56:15-root-INFO: Coefficient of regularization decay: 0.00011 -> 0.00011.
2024-12-01-18:56:16-root-INFO: step: 240 lr_xt 0.00030331
2024-12-01-18:56:16-root-INFO: grad norm: 2367.132 2023.112 1228.955
2024-12-01-18:56:16-root-INFO: Loss too large (14748.134->15537.875)! Learning rate decreased to 0.00024.
2024-12-01-18:56:17-root-INFO: Loss too large (14748.134->14990.143)! Learning rate decreased to 0.00019.
2024-12-01-18:56:18-root-INFO: grad norm: 2821.123 2247.265 1705.442
2024-12-01-18:56:18-root-INFO: Loss too large (14689.217->14709.741)! Learning rate decreased to 0.00016.
2024-12-01-18:56:19-root-INFO: Loss Change: 14748.134 -> 14449.729
2024-12-01-18:56:19-root-INFO: Regularization Change: 0.000 -> 0.106
2024-12-01-18:56:19-root-INFO: Learning rate of xt decay: 0.03340 -> 0.03380.
2024-12-01-18:56:19-root-INFO: Coefficient of regularization decay: 0.00011 -> 0.00011.
2024-12-01-18:56:19-root-INFO: step: 239 lr_xt 0.00031912
2024-12-01-18:56:19-root-INFO: grad norm: 2236.294 1928.173 1132.766
2024-12-01-18:56:20-root-INFO: Loss too large (14414.580->15168.273)! Learning rate decreased to 0.00026.
2024-12-01-18:56:20-root-INFO: Loss too large (14414.580->14649.994)! Learning rate decreased to 0.00020.
2024-12-01-18:56:21-root-INFO: grad norm: 2653.443 2114.846 1602.556
2024-12-01-18:56:21-root-INFO: Loss too large (14364.600->14365.931)! Learning rate decreased to 0.00016.
2024-12-01-18:56:22-root-INFO: Loss Change: 14414.580 -> 14131.854
2024-12-01-18:56:22-root-INFO: Regularization Change: 0.000 -> 0.100
2024-12-01-18:56:22-root-INFO: Learning rate of xt decay: 0.03380 -> 0.03421.
2024-12-01-18:56:22-root-INFO: Coefficient of regularization decay: 0.00011 -> 0.00011.
2024-12-01-18:56:22-root-INFO: step: 238 lr_xt 0.00033570
2024-12-01-18:56:23-root-INFO: grad norm: 2205.821 1891.158 1135.415
2024-12-01-18:56:23-root-INFO: Loss too large (13966.413->14632.746)! Learning rate decreased to 0.00027.
2024-12-01-18:56:23-root-INFO: Loss too large (13966.413->14136.583)! Learning rate decreased to 0.00021.
2024-12-01-18:56:24-root-INFO: grad norm: 2518.906 2040.848 1476.424
2024-12-01-18:56:25-root-INFO: Loss Change: 13966.413 -> 13834.426
2024-12-01-18:56:25-root-INFO: Regularization Change: 0.000 -> 0.156
2024-12-01-18:56:25-root-INFO: Learning rate of xt decay: 0.03421 -> 0.03462.
2024-12-01-18:56:25-root-INFO: Coefficient of regularization decay: 0.00011 -> 0.00011.
2024-12-01-18:56:25-root-INFO: step: 237 lr_xt 0.00035308
2024-12-01-18:56:26-root-INFO: grad norm: 2811.295 2429.112 1415.201
2024-12-01-18:56:26-root-INFO: Loss too large (13761.295->15227.775)! Learning rate decreased to 0.00028.
2024-12-01-18:56:27-root-INFO: Loss too large (13761.295->14270.904)! Learning rate decreased to 0.00023.
2024-12-01-18:56:28-root-INFO: grad norm: 3210.626 2631.289 1839.684
2024-12-01-18:56:28-root-INFO: Loss too large (13737.157->13758.109)! Learning rate decreased to 0.00018.
2024-12-01-18:56:29-root-INFO: Loss Change: 13761.295 -> 13371.796
2024-12-01-18:56:29-root-INFO: Regularization Change: 0.000 -> 0.121
2024-12-01-18:56:29-root-INFO: Learning rate of xt decay: 0.03462 -> 0.03503.
2024-12-01-18:56:29-root-INFO: Coefficient of regularization decay: 0.00011 -> 0.00011.
2024-12-01-18:56:29-root-INFO: step: 236 lr_xt 0.00037130
2024-12-01-18:56:29-root-INFO: grad norm: 2388.666 2065.203 1200.275
2024-12-01-18:56:30-root-INFO: Loss too large (13297.495->14305.380)! Learning rate decreased to 0.00030.
2024-12-01-18:56:30-root-INFO: Loss too large (13297.495->13612.589)! Learning rate decreased to 0.00024.
2024-12-01-18:56:31-root-INFO: grad norm: 2666.470 2194.344 1514.899
2024-12-01-18:56:32-root-INFO: Loss Change: 13297.495 -> 13185.608
2024-12-01-18:56:32-root-INFO: Regularization Change: 0.000 -> 0.148
2024-12-01-18:56:32-root-INFO: Learning rate of xt decay: 0.03503 -> 0.03545.
2024-12-01-18:56:32-root-INFO: Coefficient of regularization decay: 0.00011 -> 0.00011.
2024-12-01-18:56:32-root-INFO: step: 235 lr_xt 0.00039040
2024-12-01-18:56:32-root-INFO: grad norm: 2800.571 2415.796 1416.730
2024-12-01-18:56:33-root-INFO: Loss too large (13071.688->14596.029)! Learning rate decreased to 0.00031.
2024-12-01-18:56:33-root-INFO: Loss too large (13071.688->13573.075)! Learning rate decreased to 0.00025.
2024-12-01-18:56:34-root-INFO: grad norm: 3039.738 2528.724 1686.878
2024-12-01-18:56:35-root-INFO: Loss Change: 13071.688 -> 12955.439
2024-12-01-18:56:35-root-INFO: Regularization Change: 0.000 -> 0.162
2024-12-01-18:56:35-root-INFO: Undo step: 235
2024-12-01-18:56:35-root-INFO: Undo step: 236
2024-12-01-18:56:35-root-INFO: Undo step: 237
2024-12-01-18:56:35-root-INFO: Undo step: 238
2024-12-01-18:56:35-root-INFO: Undo step: 239
2024-12-01-18:56:35-root-INFO: step: 240 lr_xt 0.00030331
2024-12-01-18:56:36-root-INFO: grad norm: 12091.322 10256.583 6403.326
2024-12-01-18:56:36-root-INFO: Loss too large (20478.996->40172.680)! Learning rate decreased to 0.00024.
2024-12-01-18:56:36-root-INFO: Loss too large (20478.996->29248.215)! Learning rate decreased to 0.00019.
2024-12-01-18:56:37-root-INFO: Loss too large (20478.996->21915.355)! Learning rate decreased to 0.00016.
2024-12-01-18:56:38-root-INFO: grad norm: 9083.374 7380.343 5295.113
2024-12-01-18:56:38-root-INFO: Loss Change: 20478.996 -> 15273.250
2024-12-01-18:56:38-root-INFO: Regularization Change: 0.000 -> 0.858
2024-12-01-18:56:38-root-INFO: Learning rate of xt decay: 0.03340 -> 0.03380.
2024-12-01-18:56:38-root-INFO: Coefficient of regularization decay: 0.00011 -> 0.00011.
2024-12-01-18:56:39-root-INFO: step: 239 lr_xt 0.00031912
2024-12-01-18:56:39-root-INFO: grad norm: 6631.400 5601.318 3549.748
2024-12-01-18:56:39-root-INFO: Loss too large (15129.656->23713.543)! Learning rate decreased to 0.00026.
2024-12-01-18:56:40-root-INFO: Loss too large (15129.656->18971.172)! Learning rate decreased to 0.00020.
2024-12-01-18:56:40-root-INFO: Loss too large (15129.656->16012.089)! Learning rate decreased to 0.00016.
2024-12-01-18:56:41-root-INFO: grad norm: 5233.518 4290.136 2997.407
2024-12-01-18:56:42-root-INFO: Loss Change: 15129.656 -> 13638.230
2024-12-01-18:56:42-root-INFO: Regularization Change: 0.000 -> 0.153
2024-12-01-18:56:42-root-INFO: Learning rate of xt decay: 0.03380 -> 0.03421.
2024-12-01-18:56:42-root-INFO: Coefficient of regularization decay: 0.00011 -> 0.00011.
2024-12-01-18:56:42-root-INFO: step: 238 lr_xt 0.00033570
2024-12-01-18:56:43-root-INFO: grad norm: 3987.762 3355.546 2154.660
2024-12-01-18:56:43-root-INFO: Loss too large (13400.129->16544.934)! Learning rate decreased to 0.00027.
2024-12-01-18:56:43-root-INFO: Loss too large (13400.129->14642.955)! Learning rate decreased to 0.00021.
2024-12-01-18:56:44-root-INFO: Loss too large (13400.129->13542.588)! Learning rate decreased to 0.00017.
2024-12-01-18:56:45-root-INFO: grad norm: 3023.389 2490.149 1714.654
2024-12-01-18:56:45-root-INFO: Loss Change: 13400.129 -> 12640.366
2024-12-01-18:56:45-root-INFO: Regularization Change: 0.000 -> 0.119
2024-12-01-18:56:45-root-INFO: Learning rate of xt decay: 0.03421 -> 0.03462.
2024-12-01-18:56:45-root-INFO: Coefficient of regularization decay: 0.00011 -> 0.00011.
2024-12-01-18:56:46-root-INFO: step: 237 lr_xt 0.00035308
2024-12-01-18:56:46-root-INFO: grad norm: 2132.640 1824.434 1104.353
2024-12-01-18:56:46-root-INFO: Loss too large (12501.076->13205.158)! Learning rate decreased to 0.00028.
2024-12-01-18:56:47-root-INFO: Loss too large (12501.076->12701.414)! Learning rate decreased to 0.00023.
2024-12-01-18:56:48-root-INFO: grad norm: 2381.562 1955.376 1359.537
2024-12-01-18:56:48-root-INFO: Loss Change: 12501.076 -> 12381.359
2024-12-01-18:56:48-root-INFO: Regularization Change: 0.000 -> 0.129
2024-12-01-18:56:48-root-INFO: Learning rate of xt decay: 0.03462 -> 0.03503.
2024-12-01-18:56:48-root-INFO: Coefficient of regularization decay: 0.00011 -> 0.00011.
2024-12-01-18:56:49-root-INFO: step: 236 lr_xt 0.00037130
2024-12-01-18:56:49-root-INFO: grad norm: 2665.220 2273.968 1390.132
2024-12-01-18:56:49-root-INFO: Loss too large (12268.361->13621.348)! Learning rate decreased to 0.00030.
2024-12-01-18:56:50-root-INFO: Loss too large (12268.361->12728.968)! Learning rate decreased to 0.00024.
2024-12-01-18:56:51-root-INFO: grad norm: 2917.321 2415.100 1636.475
2024-12-01-18:56:52-root-INFO: Loss Change: 12268.361 -> 12201.229
2024-12-01-18:56:52-root-INFO: Regularization Change: 0.000 -> 0.124
2024-12-01-18:56:52-root-INFO: Learning rate of xt decay: 0.03503 -> 0.03545.
2024-12-01-18:56:52-root-INFO: Coefficient of regularization decay: 0.00011 -> 0.00011.
2024-12-01-18:56:52-root-INFO: step: 235 lr_xt 0.00039040
2024-12-01-18:56:52-root-INFO: grad norm: 2956.241 2520.351 1545.054
2024-12-01-18:56:53-root-INFO: Loss too large (12002.754->13735.621)! Learning rate decreased to 0.00031.
2024-12-01-18:56:53-root-INFO: Loss too large (12002.754->12588.355)! Learning rate decreased to 0.00025.
2024-12-01-18:56:54-root-INFO: grad norm: 3107.899 2588.691 1719.801
2024-12-01-18:56:55-root-INFO: Loss Change: 12002.754 -> 11891.589
2024-12-01-18:56:55-root-INFO: Regularization Change: 0.000 -> 0.122
2024-12-01-18:56:55-root-INFO: Learning rate of xt decay: 0.03545 -> 0.03588.
2024-12-01-18:56:55-root-INFO: Coefficient of regularization decay: 0.00011 -> 0.00012.
2024-12-01-18:56:55-root-INFO: step: 234 lr_xt 0.00041042
2024-12-01-18:56:55-root-INFO: grad norm: 3166.382 2701.318 1651.925
2024-12-01-18:56:56-root-INFO: Loss too large (11806.546->13835.580)! Learning rate decreased to 0.00033.
2024-12-01-18:56:56-root-INFO: Loss too large (11806.546->12476.922)! Learning rate decreased to 0.00026.
2024-12-01-18:56:57-root-INFO: grad norm: 3192.426 2668.263 1752.700
2024-12-01-18:56:58-root-INFO: Loss Change: 11806.546 -> 11612.078
2024-12-01-18:56:58-root-INFO: Regularization Change: 0.000 -> 0.117
2024-12-01-18:56:58-root-INFO: Learning rate of xt decay: 0.03588 -> 0.03631.
2024-12-01-18:56:58-root-INFO: Coefficient of regularization decay: 0.00012 -> 0.00012.
2024-12-01-18:56:58-root-INFO: step: 233 lr_xt 0.00043139
2024-12-01-18:56:59-root-INFO: grad norm: 3172.457 2698.225 1668.551
2024-12-01-18:56:59-root-INFO: Loss too large (11625.918->13592.983)! Learning rate decreased to 0.00035.
2024-12-01-18:56:59-root-INFO: Loss too large (11625.918->12217.691)! Learning rate decreased to 0.00028.
2024-12-01-18:57:00-root-INFO: grad norm: 3041.291 2561.158 1640.099
2024-12-01-18:57:01-root-INFO: Loss Change: 11625.918 -> 11292.188
2024-12-01-18:57:01-root-INFO: Regularization Change: 0.000 -> 0.134
2024-12-01-18:57:01-root-INFO: Learning rate of xt decay: 0.03631 -> 0.03674.
2024-12-01-18:57:01-root-INFO: Coefficient of regularization decay: 0.00012 -> 0.00012.
2024-12-01-18:57:01-root-INFO: step: 232 lr_xt 0.00045336
2024-12-01-18:57:02-root-INFO: grad norm: 2699.277 2315.559 1387.186
2024-12-01-18:57:02-root-INFO: Loss too large (11006.081->12345.738)! Learning rate decreased to 0.00036.
2024-12-01-18:57:02-root-INFO: Loss too large (11006.081->11344.861)! Learning rate decreased to 0.00029.
2024-12-01-18:57:03-root-INFO: grad norm: 2467.466 2092.274 1307.967
2024-12-01-18:57:04-root-INFO: Loss Change: 11006.081 -> 10630.346
2024-12-01-18:57:04-root-INFO: Regularization Change: 0.000 -> 0.137
2024-12-01-18:57:04-root-INFO: Learning rate of xt decay: 0.03674 -> 0.03719.
2024-12-01-18:57:04-root-INFO: Coefficient of regularization decay: 0.00012 -> 0.00012.
2024-12-01-18:57:05-root-INFO: step: 231 lr_xt 0.00047637
2024-12-01-18:57:05-root-INFO: grad norm: 2158.673 1867.945 1081.965
2024-12-01-18:57:05-root-INFO: Loss too large (10518.928->11335.035)! Learning rate decreased to 0.00038.
2024-12-01-18:57:06-root-INFO: Loss too large (10518.928->10689.569)! Learning rate decreased to 0.00030.
2024-12-01-18:57:07-root-INFO: grad norm: 1925.564 1638.088 1012.157
2024-12-01-18:57:07-root-INFO: Loss Change: 10518.928 -> 10190.988
2024-12-01-18:57:07-root-INFO: Regularization Change: 0.000 -> 0.125
2024-12-01-18:57:07-root-INFO: Learning rate of xt decay: 0.03719 -> 0.03763.
2024-12-01-18:57:07-root-INFO: Coefficient of regularization decay: 0.00012 -> 0.00012.
2024-12-01-18:57:08-root-INFO: step: 230 lr_xt 0.00050047
2024-12-01-18:57:08-root-INFO: grad norm: 1589.919 1382.219 785.692
2024-12-01-18:57:08-root-INFO: Loss too large (10050.844->10382.238)! Learning rate decreased to 0.00040.
2024-12-01-18:57:09-root-INFO: Loss too large (10050.844->10060.581)! Learning rate decreased to 0.00032.
2024-12-01-18:57:10-root-INFO: grad norm: 1357.512 1163.788 698.882
2024-12-01-18:57:10-root-INFO: Loss Change: 10050.844 -> 9763.930
2024-12-01-18:57:10-root-INFO: Regularization Change: 0.000 -> 0.129
2024-12-01-18:57:10-root-INFO: Undo step: 230
2024-12-01-18:57:10-root-INFO: Undo step: 231
2024-12-01-18:57:10-root-INFO: Undo step: 232
2024-12-01-18:57:10-root-INFO: Undo step: 233
2024-12-01-18:57:10-root-INFO: Undo step: 234
2024-12-01-18:57:11-root-INFO: step: 235 lr_xt 0.00039040
2024-12-01-18:57:11-root-INFO: grad norm: 10139.521 7545.776 6772.823
2024-12-01-18:57:12-root-INFO: Loss too large (21717.480->23661.957)! Learning rate decreased to 0.00031.
2024-12-01-18:57:13-root-INFO: grad norm: 7407.119 5723.169 4702.205
2024-12-01-18:57:13-root-INFO: Loss Change: 21717.480 -> 14908.242
2024-12-01-18:57:13-root-INFO: Regularization Change: 0.000 -> 2.021
2024-12-01-18:57:13-root-INFO: Learning rate of xt decay: 0.03545 -> 0.03588.
2024-12-01-18:57:13-root-INFO: Coefficient of regularization decay: 0.00011 -> 0.00012.
2024-12-01-18:57:14-root-INFO: step: 234 lr_xt 0.00041042
2024-12-01-18:57:14-root-INFO: grad norm: 6246.015 5031.153 3701.378
2024-12-01-18:57:14-root-INFO: Loss too large (14500.012->19167.531)! Learning rate decreased to 0.00033.
2024-12-01-18:57:15-root-INFO: Loss too large (14500.012->15218.552)! Learning rate decreased to 0.00026.
2024-12-01-18:57:16-root-INFO: grad norm: 4853.266 4022.757 2715.072
2024-12-01-18:57:16-root-INFO: Loss Change: 14500.012 -> 12281.301
2024-12-01-18:57:16-root-INFO: Regularization Change: 0.000 -> 0.514
2024-12-01-18:57:16-root-INFO: Learning rate of xt decay: 0.03588 -> 0.03631.
2024-12-01-18:57:16-root-INFO: Coefficient of regularization decay: 0.00012 -> 0.00012.
2024-12-01-18:57:17-root-INFO: step: 233 lr_xt 0.00043139
2024-12-01-18:57:17-root-INFO: grad norm: 4156.156 3499.949 2241.426
2024-12-01-18:57:18-root-INFO: Loss too large (12306.643->15394.840)! Learning rate decreased to 0.00035.
2024-12-01-18:57:18-root-INFO: Loss too large (12306.643->13144.979)! Learning rate decreased to 0.00028.
2024-12-01-18:57:19-root-INFO: grad norm: 3740.938 3144.842 2025.978
2024-12-01-18:57:20-root-INFO: Loss Change: 12306.643 -> 11589.234
2024-12-01-18:57:20-root-INFO: Regularization Change: 0.000 -> 0.198
2024-12-01-18:57:20-root-INFO: Learning rate of xt decay: 0.03631 -> 0.03674.
2024-12-01-18:57:20-root-INFO: Coefficient of regularization decay: 0.00012 -> 0.00012.
2024-12-01-18:57:20-root-INFO: step: 232 lr_xt 0.00045336
2024-12-01-18:57:20-root-INFO: grad norm: 3207.034 2729.650 1683.472
2024-12-01-18:57:21-root-INFO: Loss too large (11339.603->13113.861)! Learning rate decreased to 0.00036.
2024-12-01-18:57:21-root-INFO: Loss too large (11339.603->11740.283)! Learning rate decreased to 0.00029.
2024-12-01-18:57:22-root-INFO: grad norm: 2802.083 2366.309 1500.749
2024-12-01-18:57:23-root-INFO: Loss Change: 11339.603 -> 10745.650
2024-12-01-18:57:23-root-INFO: Regularization Change: 0.000 -> 0.183
2024-12-01-18:57:23-root-INFO: Learning rate of xt decay: 0.03674 -> 0.03719.
2024-12-01-18:57:23-root-INFO: Coefficient of regularization decay: 0.00012 -> 0.00012.
2024-12-01-18:57:23-root-INFO: step: 231 lr_xt 0.00047637
2024-12-01-18:57:23-root-INFO: grad norm: 2381.469 2045.935 1218.830
2024-12-01-18:57:24-root-INFO: Loss too large (10599.222->11557.023)! Learning rate decreased to 0.00038.
2024-12-01-18:57:24-root-INFO: Loss too large (10599.222->10782.030)! Learning rate decreased to 0.00030.
2024-12-01-18:57:25-root-INFO: grad norm: 2063.299 1746.511 1098.592
2024-12-01-18:57:26-root-INFO: Loss Change: 10599.222 -> 10181.943
2024-12-01-18:57:26-root-INFO: Regularization Change: 0.000 -> 0.146
2024-12-01-18:57:26-root-INFO: Learning rate of xt decay: 0.03719 -> 0.03763.
2024-12-01-18:57:26-root-INFO: Coefficient of regularization decay: 0.00012 -> 0.00012.
2024-12-01-18:57:26-root-INFO: step: 230 lr_xt 0.00050047
2024-12-01-18:57:27-root-INFO: grad norm: 1689.915 1463.042 845.765
2024-12-01-18:57:27-root-INFO: Loss too large (10049.395->10401.201)! Learning rate decreased to 0.00040.
2024-12-01-18:57:28-root-INFO: grad norm: 2087.902 1774.740 1099.833
2024-12-01-18:57:28-root-INFO: Loss too large (10045.203->10141.131)! Learning rate decreased to 0.00032.
2024-12-01-18:57:29-root-INFO: Loss Change: 10049.395 -> 9828.627
2024-12-01-18:57:29-root-INFO: Regularization Change: 0.000 -> 0.175
2024-12-01-18:57:29-root-INFO: Learning rate of xt decay: 0.03763 -> 0.03808.
2024-12-01-18:57:29-root-INFO: Coefficient of regularization decay: 0.00012 -> 0.00012.
2024-12-01-18:57:29-root-INFO: step: 229 lr_xt 0.00052570
2024-12-01-18:57:30-root-INFO: grad norm: 1703.143 1480.254 842.343
2024-12-01-18:57:30-root-INFO: Loss too large (9724.225->10056.109)! Learning rate decreased to 0.00042.
2024-12-01-18:57:31-root-INFO: grad norm: 2011.279 1725.779 1032.924
2024-12-01-18:57:31-root-INFO: Loss too large (9690.533->9740.903)! Learning rate decreased to 0.00034.
2024-12-01-18:57:32-root-INFO: Loss Change: 9724.225 -> 9451.948
2024-12-01-18:57:32-root-INFO: Regularization Change: 0.000 -> 0.189
2024-12-01-18:57:32-root-INFO: Learning rate of xt decay: 0.03808 -> 0.03854.
2024-12-01-18:57:32-root-INFO: Coefficient of regularization decay: 0.00012 -> 0.00012.
2024-12-01-18:57:33-root-INFO: step: 228 lr_xt 0.00055211
2024-12-01-18:57:33-root-INFO: grad norm: 1512.145 1317.209 742.658
2024-12-01-18:57:33-root-INFO: Loss too large (9381.150->9619.631)! Learning rate decreased to 0.00044.
2024-12-01-18:57:34-root-INFO: grad norm: 1741.149 1499.654 884.667
2024-12-01-18:57:35-root-INFO: Loss Change: 9381.150 -> 9320.624
2024-12-01-18:57:35-root-INFO: Regularization Change: 0.000 -> 0.230
2024-12-01-18:57:35-root-INFO: Learning rate of xt decay: 0.03854 -> 0.03900.
2024-12-01-18:57:35-root-INFO: Coefficient of regularization decay: 0.00012 -> 0.00012.
2024-12-01-18:57:35-root-INFO: step: 227 lr_xt 0.00057976
2024-12-01-18:57:36-root-INFO: grad norm: 1853.828 1616.035 908.356
2024-12-01-18:57:36-root-INFO: Loss too large (9250.524->9642.799)! Learning rate decreased to 0.00046.
2024-12-01-18:57:37-root-INFO: grad norm: 2020.918 1752.027 1007.230
2024-12-01-18:57:38-root-INFO: Loss Change: 9250.524 -> 9167.204
2024-12-01-18:57:38-root-INFO: Regularization Change: 0.000 -> 0.255
2024-12-01-18:57:38-root-INFO: Learning rate of xt decay: 0.03900 -> 0.03947.
2024-12-01-18:57:38-root-INFO: Coefficient of regularization decay: 0.00012 -> 0.00013.
2024-12-01-18:57:38-root-INFO: step: 226 lr_xt 0.00060869
2024-12-01-18:57:39-root-INFO: grad norm: 2128.174 1865.526 1024.176
2024-12-01-18:57:39-root-INFO: Loss too large (9053.463->9692.771)! Learning rate decreased to 0.00049.
2024-12-01-18:57:40-root-INFO: grad norm: 2300.203 1999.524 1137.031
2024-12-01-18:57:41-root-INFO: Loss Change: 9053.463 -> 9015.909
2024-12-01-18:57:41-root-INFO: Regularization Change: 0.000 -> 0.240
2024-12-01-18:57:41-root-INFO: Learning rate of xt decay: 0.03947 -> 0.03994.
2024-12-01-18:57:41-root-INFO: Coefficient of regularization decay: 0.00013 -> 0.00013.
2024-12-01-18:57:41-root-INFO: step: 225 lr_xt 0.00063896
2024-12-01-18:57:41-root-INFO: grad norm: 2282.750 2008.480 1084.877
2024-12-01-18:57:42-root-INFO: Loss too large (8847.812->9470.168)! Learning rate decreased to 0.00051.
2024-12-01-18:57:43-root-INFO: grad norm: 2286.223 2003.317 1101.608
2024-12-01-18:57:43-root-INFO: Loss Change: 8847.812 -> 8633.225
2024-12-01-18:57:43-root-INFO: Regularization Change: 0.000 -> 0.253
2024-12-01-18:57:43-root-INFO: Undo step: 225
2024-12-01-18:57:43-root-INFO: Undo step: 226
2024-12-01-18:57:43-root-INFO: Undo step: 227
2024-12-01-18:57:43-root-INFO: Undo step: 228
2024-12-01-18:57:43-root-INFO: Undo step: 229
2024-12-01-18:57:44-root-INFO: step: 230 lr_xt 0.00050047
2024-12-01-18:57:44-root-INFO: grad norm: 3464.844 2622.232 2264.739
2024-12-01-18:57:45-root-INFO: grad norm: 3546.754 2855.979 2103.056
2024-12-01-18:57:46-root-INFO: Loss too large (10841.246->11135.591)! Learning rate decreased to 0.00040.
2024-12-01-18:57:46-root-INFO: Loss Change: 11210.406 -> 9986.544
2024-12-01-18:57:46-root-INFO: Regularization Change: 0.000 -> 1.274
2024-12-01-18:57:46-root-INFO: Learning rate of xt decay: 0.03763 -> 0.03808.
2024-12-01-18:57:46-root-INFO: Coefficient of regularization decay: 0.00012 -> 0.00012.
2024-12-01-18:57:47-root-INFO: step: 229 lr_xt 0.00052570
2024-12-01-18:57:47-root-INFO: grad norm: 2846.516 2328.937 1636.676
2024-12-01-18:57:47-root-INFO: Loss too large (9797.303->10631.904)! Learning rate decreased to 0.00042.
2024-12-01-18:57:48-root-INFO: grad norm: 3026.829 2622.174 1511.918
2024-12-01-18:57:49-root-INFO: Loss too large (9650.421->9815.755)! Learning rate decreased to 0.00034.
2024-12-01-18:57:49-root-INFO: Loss Change: 9797.303 -> 9144.039
2024-12-01-18:57:49-root-INFO: Regularization Change: 0.000 -> 0.350
2024-12-01-18:57:49-root-INFO: Learning rate of xt decay: 0.03808 -> 0.03854.
2024-12-01-18:57:49-root-INFO: Coefficient of regularization decay: 0.00012 -> 0.00012.
2024-12-01-18:57:50-root-INFO: step: 228 lr_xt 0.00055211
2024-12-01-18:57:50-root-INFO: grad norm: 2139.433 1838.200 1094.622
2024-12-01-18:57:50-root-INFO: Loss too large (9042.461->9702.464)! Learning rate decreased to 0.00044.
2024-12-01-18:57:51-root-INFO: Loss too large (9042.461->9061.600)! Learning rate decreased to 0.00035.
2024-12-01-18:57:52-root-INFO: grad norm: 1605.025 1415.856 755.948
2024-12-01-18:57:53-root-INFO: Loss Change: 9042.461 -> 8528.551
2024-12-01-18:57:53-root-INFO: Regularization Change: 0.000 -> 0.186
2024-12-01-18:57:53-root-INFO: Learning rate of xt decay: 0.03854 -> 0.03900.
2024-12-01-18:57:53-root-INFO: Coefficient of regularization decay: 0.00012 -> 0.00012.
2024-12-01-18:57:53-root-INFO: step: 227 lr_xt 0.00057976
2024-12-01-18:57:53-root-INFO: grad norm: 1109.039 959.519 556.138
2024-12-01-18:57:54-root-INFO: Loss too large (8448.049->8452.400)! Learning rate decreased to 0.00046.
2024-12-01-18:57:55-root-INFO: grad norm: 1157.900 1025.504 537.656
2024-12-01-18:57:55-root-INFO: Loss Change: 8448.049 -> 8255.594
2024-12-01-18:57:55-root-INFO: Regularization Change: 0.000 -> 0.228
2024-12-01-18:57:55-root-INFO: Learning rate of xt decay: 0.03900 -> 0.03947.
2024-12-01-18:57:55-root-INFO: Coefficient of regularization decay: 0.00012 -> 0.00013.
2024-12-01-18:57:56-root-INFO: step: 226 lr_xt 0.00060869
2024-12-01-18:57:56-root-INFO: grad norm: 1213.202 1070.372 571.105
2024-12-01-18:57:56-root-INFO: Loss too large (8162.767->8259.669)! Learning rate decreased to 0.00049.
2024-12-01-18:57:57-root-INFO: grad norm: 1301.292 1154.185 601.014
2024-12-01-18:57:58-root-INFO: Loss Change: 8162.767 -> 8012.811
2024-12-01-18:57:58-root-INFO: Regularization Change: 0.000 -> 0.211
2024-12-01-18:57:58-root-INFO: Learning rate of xt decay: 0.03947 -> 0.03994.
2024-12-01-18:57:58-root-INFO: Coefficient of regularization decay: 0.00013 -> 0.00013.
2024-12-01-18:57:58-root-INFO: step: 225 lr_xt 0.00063896
2024-12-01-18:57:59-root-INFO: grad norm: 1250.646 1099.630 595.761
2024-12-01-18:57:59-root-INFO: Loss too large (7857.883->7928.083)! Learning rate decreased to 0.00051.
2024-12-01-18:58:00-root-INFO: grad norm: 1223.467 1089.244 557.153
2024-12-01-18:58:01-root-INFO: Loss Change: 7857.883 -> 7662.455
2024-12-01-18:58:01-root-INFO: Regularization Change: 0.000 -> 0.212
2024-12-01-18:58:01-root-INFO: Learning rate of xt decay: 0.03994 -> 0.04042.
2024-12-01-18:58:01-root-INFO: Coefficient of regularization decay: 0.00013 -> 0.00013.
2024-12-01-18:58:01-root-INFO: step: 224 lr_xt 0.00067063
2024-12-01-18:58:02-root-INFO: grad norm: 1146.178 1022.124 518.640
2024-12-01-18:58:02-root-INFO: Loss too large (7576.735->7643.973)! Learning rate decreased to 0.00054.
2024-12-01-18:58:03-root-INFO: grad norm: 1120.765 1007.227 491.536
2024-12-01-18:58:04-root-INFO: Loss Change: 7576.735 -> 7399.867
2024-12-01-18:58:04-root-INFO: Regularization Change: 0.000 -> 0.191
2024-12-01-18:58:04-root-INFO: Learning rate of xt decay: 0.04042 -> 0.04091.
2024-12-01-18:58:04-root-INFO: Coefficient of regularization decay: 0.00013 -> 0.00013.
2024-12-01-18:58:04-root-INFO: step: 223 lr_xt 0.00070376
2024-12-01-18:58:04-root-INFO: grad norm: 1000.203 895.815 444.884
2024-12-01-18:58:05-root-INFO: Loss too large (7329.091->7349.351)! Learning rate decreased to 0.00056.
2024-12-01-18:58:06-root-INFO: grad norm: 944.530 853.784 403.968
2024-12-01-18:58:06-root-INFO: Loss Change: 7329.091 -> 7149.153
2024-12-01-18:58:06-root-INFO: Regularization Change: 0.000 -> 0.188
2024-12-01-18:58:06-root-INFO: Learning rate of xt decay: 0.04091 -> 0.04140.
2024-12-01-18:58:06-root-INFO: Coefficient of regularization decay: 0.00013 -> 0.00013.
2024-12-01-18:58:07-root-INFO: step: 222 lr_xt 0.00073840
2024-12-01-18:58:07-root-INFO: grad norm: 869.431 782.847 378.232
2024-12-01-18:58:07-root-INFO: Loss too large (7081.843->7097.840)! Learning rate decreased to 0.00059.
2024-12-01-18:58:09-root-INFO: grad norm: 839.589 766.045 343.633
2024-12-01-18:58:09-root-INFO: Loss Change: 7081.843 -> 6928.045
2024-12-01-18:58:09-root-INFO: Regularization Change: 0.000 -> 0.169
2024-12-01-18:58:09-root-INFO: Learning rate of xt decay: 0.04140 -> 0.04190.
2024-12-01-18:58:09-root-INFO: Coefficient of regularization decay: 0.00013 -> 0.00013.
2024-12-01-18:58:10-root-INFO: step: 221 lr_xt 0.00077462
2024-12-01-18:58:10-root-INFO: grad norm: 747.710 673.982 323.757
2024-12-01-18:58:11-root-INFO: grad norm: 986.953 894.373 417.340
2024-12-01-18:58:11-root-INFO: Loss too large (6835.802->6893.292)! Learning rate decreased to 0.00062.
2024-12-01-18:58:12-root-INFO: Loss Change: 6854.987 -> 6751.454
2024-12-01-18:58:12-root-INFO: Regularization Change: 0.000 -> 0.219
2024-12-01-18:58:12-root-INFO: Learning rate of xt decay: 0.04190 -> 0.04240.
2024-12-01-18:58:12-root-INFO: Coefficient of regularization decay: 0.00013 -> 0.00013.
2024-12-01-18:58:12-root-INFO: step: 220 lr_xt 0.00081248
2024-12-01-18:58:13-root-INFO: grad norm: 802.692 723.356 347.952
2024-12-01-18:58:14-root-INFO: grad norm: 984.783 893.652 413.743
2024-12-01-18:58:14-root-INFO: Loss too large (6638.011->6681.459)! Learning rate decreased to 0.00065.
2024-12-01-18:58:15-root-INFO: Loss Change: 6685.475 -> 6539.886
2024-12-01-18:58:15-root-INFO: Regularization Change: 0.000 -> 0.267
2024-12-01-18:58:15-root-INFO: Undo step: 220
2024-12-01-18:58:15-root-INFO: Undo step: 221
2024-12-01-18:58:15-root-INFO: Undo step: 222
2024-12-01-18:58:15-root-INFO: Undo step: 223
2024-12-01-18:58:15-root-INFO: Undo step: 224
2024-12-01-18:58:15-root-INFO: step: 225 lr_xt 0.00063896
2024-12-01-18:58:16-root-INFO: grad norm: 2663.900 2270.568 1393.155
2024-12-01-18:58:16-root-INFO: Loss too large (8329.590->9104.793)! Learning rate decreased to 0.00051.
2024-12-01-18:58:17-root-INFO: grad norm: 2885.644 2683.984 1059.797
2024-12-01-18:58:17-root-INFO: Loss too large (8138.944->8214.529)! Learning rate decreased to 0.00041.
2024-12-01-18:58:18-root-INFO: Loss Change: 8329.590 -> 7507.980
2024-12-01-18:58:18-root-INFO: Regularization Change: 0.000 -> 0.679
2024-12-01-18:58:18-root-INFO: Learning rate of xt decay: 0.03994 -> 0.04042.
2024-12-01-18:58:18-root-INFO: Coefficient of regularization decay: 0.00013 -> 0.00013.
2024-12-01-18:58:18-root-INFO: step: 224 lr_xt 0.00067063
2024-12-01-18:58:19-root-INFO: grad norm: 1926.735 1714.692 878.715
2024-12-01-18:58:19-root-INFO: Loss too large (7370.852->7956.337)! Learning rate decreased to 0.00054.
2024-12-01-18:58:20-root-INFO: grad norm: 2132.443 1956.177 848.931
2024-12-01-18:58:20-root-INFO: Loss too large (7354.749->7397.784)! Learning rate decreased to 0.00043.
2024-12-01-18:58:21-root-INFO: Loss Change: 7370.852 -> 6990.629
2024-12-01-18:58:21-root-INFO: Regularization Change: 0.000 -> 0.245
2024-12-01-18:58:21-root-INFO: Learning rate of xt decay: 0.04042 -> 0.04091.
2024-12-01-18:58:21-root-INFO: Coefficient of regularization decay: 0.00013 -> 0.00013.
2024-12-01-18:58:22-root-INFO: step: 223 lr_xt 0.00070376
2024-12-01-18:58:22-root-INFO: grad norm: 1344.988 1209.356 588.602
2024-12-01-18:58:22-root-INFO: Loss too large (6889.270->7106.864)! Learning rate decreased to 0.00056.
2024-12-01-18:58:23-root-INFO: grad norm: 1420.817 1298.411 576.931
2024-12-01-18:58:24-root-INFO: Loss Change: 6889.270 -> 6797.050
2024-12-01-18:58:24-root-INFO: Regularization Change: 0.000 -> 0.212
2024-12-01-18:58:24-root-INFO: Learning rate of xt decay: 0.04091 -> 0.04140.
2024-12-01-18:58:24-root-INFO: Coefficient of regularization decay: 0.00013 -> 0.00013.
2024-12-01-18:58:24-root-INFO: step: 222 lr_xt 0.00073840
2024-12-01-18:58:25-root-INFO: grad norm: 1458.541 1318.568 623.475
2024-12-01-18:58:25-root-INFO: Loss too large (6716.929->7062.149)! Learning rate decreased to 0.00059.
2024-12-01-18:58:26-root-INFO: grad norm: 1537.399 1406.187 621.476
2024-12-01-18:58:27-root-INFO: Loss Change: 6716.929 -> 6658.529
2024-12-01-18:58:27-root-INFO: Regularization Change: 0.000 -> 0.165
2024-12-01-18:58:27-root-INFO: Learning rate of xt decay: 0.04140 -> 0.04190.
2024-12-01-18:58:27-root-INFO: Coefficient of regularization decay: 0.00013 -> 0.00013.
2024-12-01-18:58:27-root-INFO: step: 221 lr_xt 0.00077462
2024-12-01-18:58:28-root-INFO: grad norm: 1483.918 1345.445 625.933
2024-12-01-18:58:28-root-INFO: Loss too large (6554.201->6896.742)! Learning rate decreased to 0.00062.
2024-12-01-18:58:29-root-INFO: grad norm: 1492.274 1360.809 612.437
2024-12-01-18:58:30-root-INFO: Loss Change: 6554.201 -> 6446.069
2024-12-01-18:58:30-root-INFO: Regularization Change: 0.000 -> 0.152
2024-12-01-18:58:30-root-INFO: Learning rate of xt decay: 0.04190 -> 0.04240.
2024-12-01-18:58:30-root-INFO: Coefficient of regularization decay: 0.00013 -> 0.00013.
2024-12-01-18:58:30-root-INFO: step: 220 lr_xt 0.00081248
2024-12-01-18:58:30-root-INFO: grad norm: 1272.520 1163.322 515.741
2024-12-01-18:58:31-root-INFO: Loss too large (6310.667->6501.988)! Learning rate decreased to 0.00065.
2024-12-01-18:58:32-root-INFO: grad norm: 1222.526 1119.306 491.655
2024-12-01-18:58:32-root-INFO: Loss Change: 6310.667 -> 6159.874
2024-12-01-18:58:32-root-INFO: Regularization Change: 0.000 -> 0.175
2024-12-01-18:58:32-root-INFO: Learning rate of xt decay: 0.04240 -> 0.04291.
2024-12-01-18:58:32-root-INFO: Coefficient of regularization decay: 0.00013 -> 0.00013.
2024-12-01-18:58:33-root-INFO: step: 219 lr_xt 0.00085206
2024-12-01-18:58:33-root-INFO: grad norm: 1157.928 1050.919 486.176
2024-12-01-18:58:33-root-INFO: Loss too large (6124.113->6302.657)! Learning rate decreased to 0.00068.
2024-12-01-18:58:35-root-INFO: grad norm: 1107.862 1013.791 446.751
2024-12-01-18:58:35-root-INFO: Loss Change: 6124.113 -> 5986.712
2024-12-01-18:58:35-root-INFO: Regularization Change: 0.000 -> 0.142
2024-12-01-18:58:35-root-INFO: Learning rate of xt decay: 0.04291 -> 0.04342.
2024-12-01-18:58:35-root-INFO: Coefficient of regularization decay: 0.00013 -> 0.00014.
2024-12-01-18:58:36-root-INFO: step: 218 lr_xt 0.00089342
2024-12-01-18:58:36-root-INFO: grad norm: 886.508 812.286 355.087
2024-12-01-18:58:36-root-INFO: Loss too large (5900.399->5962.166)! Learning rate decreased to 0.00071.
2024-12-01-18:58:37-root-INFO: grad norm: 822.433 755.148 325.805
2024-12-01-18:58:38-root-INFO: Loss Change: 5900.399 -> 5764.207
2024-12-01-18:58:38-root-INFO: Regularization Change: 0.000 -> 0.153
2024-12-01-18:58:38-root-INFO: Learning rate of xt decay: 0.04342 -> 0.04394.
2024-12-01-18:58:38-root-INFO: Coefficient of regularization decay: 0.00014 -> 0.00014.
2024-12-01-18:58:38-root-INFO: step: 217 lr_xt 0.00093664
2024-12-01-18:58:39-root-INFO: grad norm: 654.032 601.505 256.806
2024-12-01-18:58:40-root-INFO: grad norm: 842.495 774.161 332.375
2024-12-01-18:58:40-root-INFO: Loss too large (5702.137->5764.589)! Learning rate decreased to 0.00075.
2024-12-01-18:58:41-root-INFO: Loss Change: 5714.669 -> 5634.868
2024-12-01-18:58:41-root-INFO: Regularization Change: 0.000 -> 0.208
2024-12-01-18:58:41-root-INFO: Learning rate of xt decay: 0.04394 -> 0.04447.
2024-12-01-18:58:41-root-INFO: Coefficient of regularization decay: 0.00014 -> 0.00014.
2024-12-01-18:58:41-root-INFO: step: 216 lr_xt 0.00098179
2024-12-01-18:58:41-root-INFO: grad norm: 657.606 609.401 247.137
2024-12-01-18:58:42-root-INFO: grad norm: 846.079 782.859 320.908
2024-12-01-18:58:43-root-INFO: Loss too large (5571.729->5649.148)! Learning rate decreased to 0.00079.
2024-12-01-18:58:43-root-INFO: Loss Change: 5581.351 -> 5508.146
2024-12-01-18:58:43-root-INFO: Regularization Change: 0.000 -> 0.214
2024-12-01-18:58:43-root-INFO: Learning rate of xt decay: 0.04447 -> 0.04500.
2024-12-01-18:58:43-root-INFO: Coefficient of regularization decay: 0.00014 -> 0.00014.
2024-12-01-18:58:44-root-INFO: step: 215 lr_xt 0.00102894
2024-12-01-18:58:44-root-INFO: grad norm: 737.495 679.060 287.709
2024-12-01-18:58:44-root-INFO: Loss too large (5470.517->5515.821)! Learning rate decreased to 0.00082.
2024-12-01-18:58:45-root-INFO: grad norm: 675.409 623.338 260.052
2024-12-01-18:58:46-root-INFO: Loss Change: 5470.517 -> 5355.734
2024-12-01-18:58:46-root-INFO: Regularization Change: 0.000 -> 0.141
2024-12-01-18:58:46-root-INFO: Undo step: 215
2024-12-01-18:58:46-root-INFO: Undo step: 216
2024-12-01-18:58:46-root-INFO: Undo step: 217
2024-12-01-18:58:46-root-INFO: Undo step: 218
2024-12-01-18:58:46-root-INFO: Undo step: 219
2024-12-01-18:58:47-root-INFO: step: 220 lr_xt 0.00081248
2024-12-01-18:58:47-root-INFO: grad norm: 3783.522 3086.238 2188.647
2024-12-01-18:58:48-root-INFO: grad norm: 3984.119 3704.010 1467.488
2024-12-01-18:58:48-root-INFO: Loss too large (9498.989->10360.590)! Learning rate decreased to 0.00065.
2024-12-01-18:58:49-root-INFO: Loss Change: 9727.397 -> 8322.789
2024-12-01-18:58:49-root-INFO: Regularization Change: 0.000 -> 3.508
2024-12-01-18:58:49-root-INFO: Learning rate of xt decay: 0.04240 -> 0.04291.
2024-12-01-18:58:49-root-INFO: Coefficient of regularization decay: 0.00013 -> 0.00013.
2024-12-01-18:58:49-root-INFO: step: 219 lr_xt 0.00085206
2024-12-01-18:58:50-root-INFO: grad norm: 3365.462 3111.614 1282.261
2024-12-01-18:58:50-root-INFO: Loss too large (8290.775->8670.001)! Learning rate decreased to 0.00068.
2024-12-01-18:58:51-root-INFO: grad norm: 2542.320 2325.988 1026.241
2024-12-01-18:58:52-root-INFO: Loss Change: 8290.775 -> 6756.116
2024-12-01-18:58:52-root-INFO: Regularization Change: 0.000 -> 1.677
2024-12-01-18:58:52-root-INFO: Learning rate of xt decay: 0.04291 -> 0.04342.
2024-12-01-18:58:52-root-INFO: Coefficient of regularization decay: 0.00013 -> 0.00014.
2024-12-01-18:58:52-root-INFO: step: 218 lr_xt 0.00089342
2024-12-01-18:58:53-root-INFO: grad norm: 2028.666 1857.302 816.035
2024-12-01-18:58:53-root-INFO: Loss too large (6626.979->7085.811)! Learning rate decreased to 0.00071.
2024-12-01-18:58:54-root-INFO: grad norm: 1719.166 1539.617 764.925
2024-12-01-18:58:55-root-INFO: Loss Change: 6626.979 -> 6109.558
2024-12-01-18:58:55-root-INFO: Regularization Change: 0.000 -> 0.272
2024-12-01-18:58:55-root-INFO: Learning rate of xt decay: 0.04342 -> 0.04394.
2024-12-01-18:58:55-root-INFO: Coefficient of regularization decay: 0.00014 -> 0.00014.
2024-12-01-18:58:55-root-INFO: step: 217 lr_xt 0.00093664
2024-12-01-18:58:55-root-INFO: grad norm: 1339.090 1232.510 523.526
2024-12-01-18:58:56-root-INFO: Loss too large (6056.281->6188.113)! Learning rate decreased to 0.00075.
2024-12-01-18:58:57-root-INFO: grad norm: 1103.194 989.705 487.361
2024-12-01-18:58:57-root-INFO: Loss Change: 6056.281 -> 5742.872
2024-12-01-18:58:57-root-INFO: Regularization Change: 0.000 -> 0.231
2024-12-01-18:58:57-root-INFO: Learning rate of xt decay: 0.04394 -> 0.04447.
2024-12-01-18:58:57-root-INFO: Coefficient of regularization decay: 0.00014 -> 0.00014.
2024-12-01-18:58:58-root-INFO: step: 216 lr_xt 0.00098179
2024-12-01-18:58:58-root-INFO: grad norm: 836.680 777.949 307.944
2024-12-01-18:58:59-root-INFO: grad norm: 997.063 900.982 427.043
2024-12-01-18:58:59-root-INFO: Loss too large (5677.308->5742.525)! Learning rate decreased to 0.00079.
2024-12-01-18:59:00-root-INFO: Loss Change: 5694.479 -> 5561.348
2024-12-01-18:59:00-root-INFO: Regularization Change: 0.000 -> 0.256
2024-12-01-18:59:00-root-INFO: Learning rate of xt decay: 0.04447 -> 0.04500.
2024-12-01-18:59:00-root-INFO: Coefficient of regularization decay: 0.00014 -> 0.00014.
2024-12-01-18:59:00-root-INFO: step: 215 lr_xt 0.00102894
2024-12-01-18:59:01-root-INFO: grad norm: 785.429 724.358 303.651
2024-12-01-18:59:01-root-INFO: Loss too large (5538.963->5553.491)! Learning rate decreased to 0.00082.
2024-12-01-18:59:02-root-INFO: grad norm: 643.446 585.069 267.801
2024-12-01-18:59:03-root-INFO: Loss Change: 5538.963 -> 5373.101
2024-12-01-18:59:03-root-INFO: Regularization Change: 0.000 -> 0.167
2024-12-01-18:59:03-root-INFO: Learning rate of xt decay: 0.04500 -> 0.04554.
2024-12-01-18:59:03-root-INFO: Coefficient of regularization decay: 0.00014 -> 0.00014.
2024-12-01-18:59:03-root-INFO: step: 214 lr_xt 0.00107819
2024-12-01-18:59:04-root-INFO: grad norm: 471.681 444.369 158.173
2024-12-01-18:59:05-root-INFO: grad norm: 534.028 486.644 219.917
2024-12-01-18:59:05-root-INFO: Loss Change: 5321.357 -> 5253.790
2024-12-01-18:59:05-root-INFO: Regularization Change: 0.000 -> 0.266
2024-12-01-18:59:05-root-INFO: Learning rate of xt decay: 0.04554 -> 0.04609.
2024-12-01-18:59:05-root-INFO: Coefficient of regularization decay: 0.00014 -> 0.00014.
2024-12-01-18:59:06-root-INFO: step: 213 lr_xt 0.00112961
2024-12-01-18:59:06-root-INFO: grad norm: 557.513 526.559 183.186
2024-12-01-18:59:07-root-INFO: grad norm: 638.254 586.354 252.105
2024-12-01-18:59:07-root-INFO: Loss too large (5181.060->5186.594)! Learning rate decreased to 0.00090.
2024-12-01-18:59:08-root-INFO: Loss Change: 5224.558 -> 5110.478
2024-12-01-18:59:08-root-INFO: Regularization Change: 0.000 -> 0.241
2024-12-01-18:59:08-root-INFO: Learning rate of xt decay: 0.04609 -> 0.04664.
2024-12-01-18:59:08-root-INFO: Coefficient of regularization decay: 0.00014 -> 0.00014.
2024-12-01-18:59:08-root-INFO: step: 212 lr_xt 0.00118329
2024-12-01-18:59:09-root-INFO: grad norm: 522.686 496.424 163.594
2024-12-01-18:59:10-root-INFO: grad norm: 651.841 608.585 233.497
2024-12-01-18:59:10-root-INFO: Loss too large (5076.859->5104.331)! Learning rate decreased to 0.00095.
2024-12-01-18:59:11-root-INFO: Loss Change: 5091.229 -> 5014.289
2024-12-01-18:59:11-root-INFO: Regularization Change: 0.000 -> 0.194
2024-12-01-18:59:11-root-INFO: Learning rate of xt decay: 0.04664 -> 0.04720.
2024-12-01-18:59:11-root-INFO: Coefficient of regularization decay: 0.00014 -> 0.00015.
2024-12-01-18:59:11-root-INFO: step: 211 lr_xt 0.00123933
2024-12-01-18:59:12-root-INFO: grad norm: 502.775 482.975 139.708
2024-12-01-18:59:13-root-INFO: grad norm: 652.667 619.358 205.839
2024-12-01-18:59:13-root-INFO: Loss too large (4946.213->5013.792)! Learning rate decreased to 0.00099.
2024-12-01-18:59:14-root-INFO: Loss Change: 4971.174 -> 4909.531
2024-12-01-18:59:14-root-INFO: Regularization Change: 0.000 -> 0.239
2024-12-01-18:59:14-root-INFO: Learning rate of xt decay: 0.04720 -> 0.04777.
2024-12-01-18:59:14-root-INFO: Coefficient of regularization decay: 0.00015 -> 0.00015.
2024-12-01-18:59:14-root-INFO: step: 210 lr_xt 0.00129780
2024-12-01-18:59:14-root-INFO: grad norm: 568.997 550.977 142.063
2024-12-01-18:59:15-root-INFO: Loss too large (4889.318->4906.550)! Learning rate decreased to 0.00104.
2024-12-01-18:59:16-root-INFO: grad norm: 526.509 500.099 164.659
2024-12-01-18:59:16-root-INFO: Loss Change: 4889.318 -> 4789.716
2024-12-01-18:59:16-root-INFO: Regularization Change: 0.000 -> 0.164
2024-12-01-18:59:16-root-INFO: Undo step: 210
2024-12-01-18:59:16-root-INFO: Undo step: 211
2024-12-01-18:59:16-root-INFO: Undo step: 212
2024-12-01-18:59:16-root-INFO: Undo step: 213
2024-12-01-18:59:17-root-INFO: Undo step: 214
2024-12-01-18:59:17-root-INFO: step: 215 lr_xt 0.00102894
2024-12-01-18:59:17-root-INFO: grad norm: 2777.031 2423.542 1355.858
2024-12-01-18:59:18-root-INFO: grad norm: 2409.934 2176.117 1035.518
2024-12-01-18:59:19-root-INFO: Loss Change: 7232.915 -> 6326.195
2024-12-01-18:59:19-root-INFO: Regularization Change: 0.000 -> 3.069
2024-12-01-18:59:19-root-INFO: Learning rate of xt decay: 0.04500 -> 0.04554.
2024-12-01-18:59:19-root-INFO: Coefficient of regularization decay: 0.00014 -> 0.00014.
2024-12-01-18:59:19-root-INFO: step: 214 lr_xt 0.00107819
2024-12-01-18:59:20-root-INFO: grad norm: 2157.343 1992.016 828.252
2024-12-01-18:59:20-root-INFO: Loss too large (6172.791->6723.540)! Learning rate decreased to 0.00086.
2024-12-01-18:59:21-root-INFO: grad norm: 1710.995 1574.779 669.011
2024-12-01-18:59:22-root-INFO: Loss Change: 6172.791 -> 5378.053
2024-12-01-18:59:22-root-INFO: Regularization Change: 0.000 -> 0.472
2024-12-01-18:59:22-root-INFO: Learning rate of xt decay: 0.04554 -> 0.04609.
2024-12-01-18:59:22-root-INFO: Coefficient of regularization decay: 0.00014 -> 0.00014.
2024-12-01-18:59:22-root-INFO: step: 213 lr_xt 0.00112961
2024-12-01-18:59:22-root-INFO: grad norm: 1176.006 1092.786 434.521
2024-12-01-18:59:23-root-INFO: Loss too large (5281.357->5384.106)! Learning rate decreased to 0.00090.
2024-12-01-18:59:24-root-INFO: grad norm: 938.558 867.658 357.855
2024-12-01-18:59:24-root-INFO: Loss Change: 5281.357 -> 4963.653
2024-12-01-18:59:24-root-INFO: Regularization Change: 0.000 -> 0.275
2024-12-01-18:59:24-root-INFO: Learning rate of xt decay: 0.04609 -> 0.04664.
2024-12-01-18:59:24-root-INFO: Coefficient of regularization decay: 0.00014 -> 0.00014.
2024-12-01-18:59:25-root-INFO: step: 212 lr_xt 0.00118329
2024-12-01-18:59:25-root-INFO: grad norm: 724.311 672.238 269.672
2024-12-01-18:59:25-root-INFO: Loss too large (4940.771->4943.283)! Learning rate decreased to 0.00095.
2024-12-01-18:59:26-root-INFO: grad norm: 578.062 534.792 219.439
2024-12-01-18:59:27-root-INFO: Loss Change: 4940.771 -> 4765.940
2024-12-01-18:59:27-root-INFO: Regularization Change: 0.000 -> 0.207
2024-12-01-18:59:27-root-INFO: Learning rate of xt decay: 0.04664 -> 0.04720.
2024-12-01-18:59:27-root-INFO: Coefficient of regularization decay: 0.00014 -> 0.00015.
2024-12-01-18:59:28-root-INFO: step: 211 lr_xt 0.00123933
2024-12-01-18:59:28-root-INFO: grad norm: 375.669 350.417 135.407
2024-12-01-18:59:29-root-INFO: grad norm: 392.021 357.283 161.336
2024-12-01-18:59:30-root-INFO: Loss Change: 4719.846 -> 4619.834
2024-12-01-18:59:30-root-INFO: Regularization Change: 0.000 -> 0.309
2024-12-01-18:59:30-root-INFO: Learning rate of xt decay: 0.04720 -> 0.04777.
2024-12-01-18:59:30-root-INFO: Coefficient of regularization decay: 0.00015 -> 0.00015.
2024-12-01-18:59:30-root-INFO: step: 210 lr_xt 0.00129780
2024-12-01-18:59:30-root-INFO: grad norm: 391.257 365.247 140.274
2024-12-01-18:59:31-root-INFO: grad norm: 433.122 398.646 169.340
2024-12-01-18:59:32-root-INFO: Loss Change: 4587.664 -> 4520.483
2024-12-01-18:59:32-root-INFO: Regularization Change: 0.000 -> 0.258
2024-12-01-18:59:32-root-INFO: Learning rate of xt decay: 0.04777 -> 0.04834.
2024-12-01-18:59:32-root-INFO: Coefficient of regularization decay: 0.00015 -> 0.00015.
2024-12-01-18:59:33-root-INFO: step: 209 lr_xt 0.00135882
2024-12-01-18:59:33-root-INFO: grad norm: 439.365 414.047 146.991
2024-12-01-18:59:34-root-INFO: grad norm: 479.354 442.910 183.334
2024-12-01-18:59:35-root-INFO: Loss Change: 4475.568 -> 4419.023
2024-12-01-18:59:35-root-INFO: Regularization Change: 0.000 -> 0.254
2024-12-01-18:59:35-root-INFO: Learning rate of xt decay: 0.04834 -> 0.04892.
2024-12-01-18:59:35-root-INFO: Coefficient of regularization decay: 0.00015 -> 0.00015.
2024-12-01-18:59:35-root-INFO: step: 208 lr_xt 0.00142247
2024-12-01-18:59:35-root-INFO: grad norm: 478.340 452.371 155.466
2024-12-01-18:59:36-root-INFO: grad norm: 522.199 484.790 194.089
2024-12-01-18:59:37-root-INFO: Loss Change: 4383.741 -> 4339.740
2024-12-01-18:59:37-root-INFO: Regularization Change: 0.000 -> 0.255
2024-12-01-18:59:37-root-INFO: Learning rate of xt decay: 0.04892 -> 0.04951.
2024-12-01-18:59:37-root-INFO: Coefficient of regularization decay: 0.00015 -> 0.00015.
2024-12-01-18:59:37-root-INFO: step: 207 lr_xt 0.00150141
2024-12-01-18:59:38-root-INFO: grad norm: 539.034 511.054 171.411
2024-12-01-18:59:39-root-INFO: grad norm: 573.199 535.804 203.647
2024-12-01-18:59:39-root-INFO: Loss Change: 4296.360 -> 4257.424
2024-12-01-18:59:39-root-INFO: Regularization Change: 0.000 -> 0.226
2024-12-01-18:59:39-root-INFO: Learning rate of xt decay: 0.04951 -> 0.05011.
2024-12-01-18:59:39-root-INFO: Coefficient of regularization decay: 0.00015 -> 0.00015.
2024-12-01-18:59:40-root-INFO: step: 206 lr_xt 0.00157117
2024-12-01-18:59:40-root-INFO: grad norm: 563.111 537.296 168.546
2024-12-01-18:59:41-root-INFO: grad norm: 594.843 561.691 195.811
2024-12-01-18:59:42-root-INFO: Loss Change: 4212.506 -> 4179.951
2024-12-01-18:59:42-root-INFO: Regularization Change: 0.000 -> 0.219
2024-12-01-18:59:42-root-INFO: Learning rate of xt decay: 0.05011 -> 0.05071.
2024-12-01-18:59:42-root-INFO: Coefficient of regularization decay: 0.00015 -> 0.00015.
2024-12-01-18:59:42-root-INFO: step: 205 lr_xt 0.00164390
2024-12-01-18:59:42-root-INFO: grad norm: 586.658 563.845 162.005
2024-12-01-18:59:43-root-INFO: grad norm: 625.826 599.014 181.219
2024-12-01-18:59:44-root-INFO: Loss Change: 4140.732 -> 4122.567
2024-12-01-18:59:44-root-INFO: Regularization Change: 0.000 -> 0.227
2024-12-01-18:59:44-root-INFO: Undo step: 205
2024-12-01-18:59:44-root-INFO: Undo step: 206
2024-12-01-18:59:44-root-INFO: Undo step: 207
2024-12-01-18:59:44-root-INFO: Undo step: 208
2024-12-01-18:59:44-root-INFO: Undo step: 209
2024-12-01-18:59:44-root-INFO: step: 210 lr_xt 0.00129780
2024-12-01-18:59:45-root-INFO: grad norm: 3251.088 2891.562 1486.082
2024-12-01-18:59:46-root-INFO: grad norm: 3316.987 3134.776 1084.245
2024-12-01-18:59:46-root-INFO: Loss too large (8116.089->8604.479)! Learning rate decreased to 0.00104.
2024-12-01-18:59:47-root-INFO: Loss Change: 8303.807 -> 6132.205
2024-12-01-18:59:47-root-INFO: Regularization Change: 0.000 -> 4.909
2024-12-01-18:59:47-root-INFO: Learning rate of xt decay: 0.04777 -> 0.04834.
2024-12-01-18:59:47-root-INFO: Coefficient of regularization decay: 0.00015 -> 0.00015.
2024-12-01-18:59:47-root-INFO: step: 209 lr_xt 0.00135882
2024-12-01-18:59:48-root-INFO: grad norm: 2346.024 2184.316 855.916
2024-12-01-18:59:48-root-INFO: Loss too large (6033.003->6310.007)! Learning rate decreased to 0.00109.
2024-12-01-18:59:49-root-INFO: grad norm: 1589.424 1495.238 539.009
2024-12-01-18:59:50-root-INFO: Loss Change: 6033.003 -> 4631.040
2024-12-01-18:59:50-root-INFO: Regularization Change: 0.000 -> 1.549
2024-12-01-18:59:50-root-INFO: Learning rate of xt decay: 0.04834 -> 0.04892.
2024-12-01-18:59:50-root-INFO: Coefficient of regularization decay: 0.00015 -> 0.00015.
2024-12-01-18:59:50-root-INFO: step: 208 lr_xt 0.00142247
2024-12-01-18:59:50-root-INFO: grad norm: 1038.787 989.606 315.848
2024-12-01-18:59:51-root-INFO: Loss too large (4597.180->4628.589)! Learning rate decreased to 0.00114.
2024-12-01-18:59:52-root-INFO: grad norm: 771.598 713.651 293.368
2024-12-01-18:59:52-root-INFO: Loss Change: 4597.180 -> 4229.102
2024-12-01-18:59:52-root-INFO: Regularization Change: 0.000 -> 0.440
2024-12-01-18:59:52-root-INFO: Learning rate of xt decay: 0.04892 -> 0.04951.
2024-12-01-18:59:52-root-INFO: Coefficient of regularization decay: 0.00015 -> 0.00015.
2024-12-01-18:59:53-root-INFO: step: 207 lr_xt 0.00150141
2024-12-01-18:59:53-root-INFO: grad norm: 525.477 493.891 179.440
2024-12-01-18:59:54-root-INFO: grad norm: 561.628 521.691 208.001
2024-12-01-18:59:55-root-INFO: Loss Change: 4204.311 -> 4135.422
2024-12-01-18:59:55-root-INFO: Regularization Change: 0.000 -> 0.353
2024-12-01-18:59:55-root-INFO: Learning rate of xt decay: 0.04951 -> 0.05011.
2024-12-01-18:59:55-root-INFO: Coefficient of regularization decay: 0.00015 -> 0.00015.
2024-12-01-18:59:55-root-INFO: step: 206 lr_xt 0.00157117
2024-12-01-18:59:55-root-INFO: grad norm: 559.614 528.104 185.130
2024-12-01-18:59:56-root-INFO: grad norm: 595.265 556.051 212.480
2024-12-01-18:59:57-root-INFO: Loss Change: 4091.565 -> 4047.694
2024-12-01-18:59:57-root-INFO: Regularization Change: 0.000 -> 0.273
2024-12-01-18:59:57-root-INFO: Learning rate of xt decay: 0.05011 -> 0.05071.
2024-12-01-18:59:57-root-INFO: Coefficient of regularization decay: 0.00015 -> 0.00015.
2024-12-01-18:59:58-root-INFO: step: 205 lr_xt 0.00164390
2024-12-01-18:59:58-root-INFO: grad norm: 588.413 557.662 187.730
2024-12-01-18:59:59-root-INFO: grad norm: 615.244 578.479 209.493
2024-12-01-19:00:00-root-INFO: Loss Change: 4008.374 -> 3970.140
2024-12-01-19:00:00-root-INFO: Regularization Change: 0.000 -> 0.238
2024-12-01-19:00:00-root-INFO: Learning rate of xt decay: 0.05071 -> 0.05131.
2024-12-01-19:00:00-root-INFO: Coefficient of regularization decay: 0.00015 -> 0.00016.
2024-12-01-19:00:00-root-INFO: step: 204 lr_xt 0.00171973
2024-12-01-19:00:00-root-INFO: grad norm: 607.332 579.114 182.974
2024-12-01-19:00:01-root-INFO: grad norm: 624.428 591.307 200.663
2024-12-01-19:00:02-root-INFO: Loss Change: 3944.897 -> 3900.294
2024-12-01-19:00:02-root-INFO: Regularization Change: 0.000 -> 0.244
2024-12-01-19:00:02-root-INFO: Learning rate of xt decay: 0.05131 -> 0.05193.
2024-12-01-19:00:02-root-INFO: Coefficient of regularization decay: 0.00016 -> 0.00016.
2024-12-01-19:00:02-root-INFO: step: 203 lr_xt 0.00179875
2024-12-01-19:00:03-root-INFO: grad norm: 622.832 594.863 184.549
2024-12-01-19:00:04-root-INFO: grad norm: 628.809 600.428 186.782
2024-12-01-19:00:04-root-INFO: Loss Change: 3883.405 -> 3834.764
2024-12-01-19:00:04-root-INFO: Regularization Change: 0.000 -> 0.219
2024-12-01-19:00:04-root-INFO: Learning rate of xt decay: 0.05193 -> 0.05255.
2024-12-01-19:00:04-root-INFO: Coefficient of regularization decay: 0.00016 -> 0.00016.
2024-12-01-19:00:05-root-INFO: step: 202 lr_xt 0.00188111
2024-12-01-19:00:05-root-INFO: grad norm: 616.317 592.768 168.741
2024-12-01-19:00:06-root-INFO: grad norm: 622.096 602.087 156.507
2024-12-01-19:00:07-root-INFO: Loss Change: 3819.790 -> 3766.951
2024-12-01-19:00:07-root-INFO: Regularization Change: 0.000 -> 0.270
2024-12-01-19:00:07-root-INFO: Learning rate of xt decay: 0.05255 -> 0.05318.
2024-12-01-19:00:07-root-INFO: Coefficient of regularization decay: 0.00016 -> 0.00016.
2024-12-01-19:00:07-root-INFO: step: 201 lr_xt 0.00196691
2024-12-01-19:00:08-root-INFO: grad norm: 586.074 565.670 153.295
2024-12-01-19:00:09-root-INFO: grad norm: 533.392 515.112 138.442
2024-12-01-19:00:09-root-INFO: Loss Change: 3764.780 -> 3656.129
2024-12-01-19:00:09-root-INFO: Regularization Change: 0.000 -> 0.238
2024-12-01-19:00:09-root-INFO: Learning rate of xt decay: 0.05318 -> 0.05382.
2024-12-01-19:00:09-root-INFO: Coefficient of regularization decay: 0.00016 -> 0.00016.
2024-12-01-19:00:10-root-INFO: step: 200 lr_xt 0.00205630
2024-12-01-19:00:10-root-INFO: grad norm: 513.718 492.508 146.090
2024-12-01-19:00:11-root-INFO: grad norm: 451.648 434.871 121.958
2024-12-01-19:00:12-root-INFO: Loss Change: 3658.884 -> 3549.041
2024-12-01-19:00:12-root-INFO: Regularization Change: 0.000 -> 0.248
2024-12-01-19:00:12-root-INFO: Undo step: 200
2024-12-01-19:00:12-root-INFO: Undo step: 201
2024-12-01-19:00:12-root-INFO: Undo step: 202
2024-12-01-19:00:12-root-INFO: Undo step: 203
2024-12-01-19:00:12-root-INFO: Undo step: 204
2024-12-01-19:00:12-root-INFO: step: 205 lr_xt 0.00164390
2024-12-01-19:00:12-root-INFO: grad norm: 1170.061 957.025 673.161
2024-12-01-19:00:13-root-INFO: grad norm: 616.635 569.045 237.544
2024-12-01-19:00:14-root-INFO: Loss Change: 5140.406 -> 4077.004
2024-12-01-19:00:14-root-INFO: Regularization Change: 0.000 -> 3.423
2024-12-01-19:00:14-root-INFO: Learning rate of xt decay: 0.05071 -> 0.05131.
2024-12-01-19:00:14-root-INFO: Coefficient of regularization decay: 0.00015 -> 0.00016.
2024-12-01-19:00:14-root-INFO: step: 204 lr_xt 0.00171973
2024-12-01-19:00:15-root-INFO: grad norm: 473.905 437.186 182.905
2024-12-01-19:00:16-root-INFO: grad norm: 465.322 449.695 119.579
2024-12-01-19:00:16-root-INFO: Loss Change: 4026.214 -> 3919.940
2024-12-01-19:00:16-root-INFO: Regularization Change: 0.000 -> 0.511
2024-12-01-19:00:16-root-INFO: Learning rate of xt decay: 0.05131 -> 0.05193.
2024-12-01-19:00:16-root-INFO: Coefficient of regularization decay: 0.00016 -> 0.00016.
2024-12-01-19:00:17-root-INFO: step: 203 lr_xt 0.00179875
2024-12-01-19:00:17-root-INFO: grad norm: 471.435 451.151 136.797
2024-12-01-19:00:18-root-INFO: grad norm: 514.724 498.254 129.168
2024-12-01-19:00:19-root-INFO: Loss Change: 3895.494 -> 3863.301
2024-12-01-19:00:19-root-INFO: Regularization Change: 0.000 -> 0.330
2024-12-01-19:00:19-root-INFO: Learning rate of xt decay: 0.05193 -> 0.05255.
2024-12-01-19:00:19-root-INFO: Coefficient of regularization decay: 0.00016 -> 0.00016.
2024-12-01-19:00:19-root-INFO: step: 202 lr_xt 0.00188111
2024-12-01-19:00:19-root-INFO: grad norm: 532.999 510.606 152.873
2024-12-01-19:00:20-root-INFO: grad norm: 564.896 548.222 136.237
2024-12-01-19:00:21-root-INFO: Loss Change: 3835.726 -> 3800.566
2024-12-01-19:00:21-root-INFO: Regularization Change: 0.000 -> 0.308
2024-12-01-19:00:21-root-INFO: Learning rate of xt decay: 0.05255 -> 0.05318.
2024-12-01-19:00:21-root-INFO: Coefficient of regularization decay: 0.00016 -> 0.00016.
2024-12-01-19:00:21-root-INFO: step: 201 lr_xt 0.00196691
2024-12-01-19:00:22-root-INFO: grad norm: 561.873 542.118 147.683
2024-12-01-19:00:23-root-INFO: grad norm: 567.488 548.693 144.839
2024-12-01-19:00:24-root-INFO: Loss Change: 3790.469 -> 3734.483
2024-12-01-19:00:24-root-INFO: Regularization Change: 0.000 -> 0.260
2024-12-01-19:00:24-root-INFO: Learning rate of xt decay: 0.05318 -> 0.05382.
2024-12-01-19:00:24-root-INFO: Coefficient of regularization decay: 0.00016 -> 0.00016.
2024-12-01-19:00:24-root-INFO: step: 200 lr_xt 0.00205630
2024-12-01-19:00:24-root-INFO: grad norm: 555.649 534.635 151.363
2024-12-01-19:00:25-root-INFO: grad norm: 538.747 522.605 130.889
2024-12-01-19:00:26-root-INFO: Loss Change: 3708.444 -> 3628.587
2024-12-01-19:00:26-root-INFO: Regularization Change: 0.000 -> 0.266
2024-12-01-19:00:26-root-INFO: Learning rate of xt decay: 0.05382 -> 0.05447.
2024-12-01-19:00:26-root-INFO: Coefficient of regularization decay: 0.00016 -> 0.00016.
2024-12-01-19:00:26-root-INFO: step: 199 lr_xt 0.00214940
2024-12-01-19:00:27-root-INFO: grad norm: 514.965 496.152 137.920
2024-12-01-19:00:28-root-INFO: grad norm: 483.742 469.532 116.390
2024-12-01-19:00:28-root-INFO: Loss Change: 3616.448 -> 3524.329
2024-12-01-19:00:28-root-INFO: Regularization Change: 0.000 -> 0.273
2024-12-01-19:00:28-root-INFO: Learning rate of xt decay: 0.05447 -> 0.05512.
2024-12-01-19:00:28-root-INFO: Coefficient of regularization decay: 0.00016 -> 0.00017.
2024-12-01-19:00:29-root-INFO: step: 198 lr_xt 0.00224635
2024-12-01-19:00:29-root-INFO: grad norm: 473.305 454.093 133.484
2024-12-01-19:00:30-root-INFO: grad norm: 453.540 439.928 110.279
2024-12-01-19:00:31-root-INFO: Loss Change: 3520.989 -> 3441.089
2024-12-01-19:00:31-root-INFO: Regularization Change: 0.000 -> 0.296
2024-12-01-19:00:31-root-INFO: Learning rate of xt decay: 0.05512 -> 0.05578.
2024-12-01-19:00:31-root-INFO: Coefficient of regularization decay: 0.00017 -> 0.00017.
2024-12-01-19:00:31-root-INFO: step: 197 lr_xt 0.00234729
2024-12-01-19:00:31-root-INFO: grad norm: 465.614 447.068 130.102
2024-12-01-19:00:32-root-INFO: grad norm: 444.539 428.293 119.082
2024-12-01-19:00:33-root-INFO: Loss Change: 3439.858 -> 3359.294
2024-12-01-19:00:33-root-INFO: Regularization Change: 0.000 -> 0.302
2024-12-01-19:00:33-root-INFO: Learning rate of xt decay: 0.05578 -> 0.05645.
2024-12-01-19:00:33-root-INFO: Coefficient of regularization decay: 0.00017 -> 0.00017.
2024-12-01-19:00:33-root-INFO: step: 196 lr_xt 0.00245238
2024-12-01-19:00:34-root-INFO: grad norm: 456.033 430.031 151.788
2024-12-01-19:00:35-root-INFO: grad norm: 424.169 405.213 125.385
2024-12-01-19:00:36-root-INFO: Loss Change: 3364.909 -> 3274.329
2024-12-01-19:00:36-root-INFO: Regularization Change: 0.000 -> 0.315
2024-12-01-19:00:36-root-INFO: Learning rate of xt decay: 0.05645 -> 0.05713.
2024-12-01-19:00:36-root-INFO: Coefficient of regularization decay: 0.00017 -> 0.00017.
2024-12-01-19:00:36-root-INFO: step: 195 lr_xt 0.00256175
2024-12-01-19:00:36-root-INFO: grad norm: 406.209 383.911 132.733
2024-12-01-19:00:37-root-INFO: grad norm: 363.583 343.809 118.271
2024-12-01-19:00:38-root-INFO: Loss Change: 3273.006 -> 3176.925
2024-12-01-19:00:38-root-INFO: Regularization Change: 0.000 -> 0.311
2024-12-01-19:00:38-root-INFO: Undo step: 195
2024-12-01-19:00:38-root-INFO: Undo step: 196
2024-12-01-19:00:38-root-INFO: Undo step: 197
2024-12-01-19:00:38-root-INFO: Undo step: 198
2024-12-01-19:00:38-root-INFO: Undo step: 199
2024-12-01-19:00:38-root-INFO: step: 200 lr_xt 0.00205630
2024-12-01-19:00:39-root-INFO: grad norm: 1014.898 946.417 366.486
2024-12-01-19:00:40-root-INFO: grad norm: 408.686 372.812 167.437
2024-12-01-19:00:40-root-INFO: Loss Change: 4727.121 -> 3596.601
2024-12-01-19:00:40-root-INFO: Regularization Change: 0.000 -> 4.172
2024-12-01-19:00:40-root-INFO: Learning rate of xt decay: 0.05382 -> 0.05447.
2024-12-01-19:00:40-root-INFO: Coefficient of regularization decay: 0.00016 -> 0.00016.
2024-12-01-19:00:41-root-INFO: step: 199 lr_xt 0.00214940
2024-12-01-19:00:41-root-INFO: grad norm: 286.727 268.063 101.758
2024-12-01-19:00:42-root-INFO: grad norm: 228.927 208.482 94.568
2024-12-01-19:00:43-root-INFO: Loss Change: 3579.444 -> 3416.988
2024-12-01-19:00:43-root-INFO: Regularization Change: 0.000 -> 0.727
2024-12-01-19:00:43-root-INFO: Learning rate of xt decay: 0.05447 -> 0.05512.
2024-12-01-19:00:43-root-INFO: Coefficient of regularization decay: 0.00016 -> 0.00017.
2024-12-01-19:00:43-root-INFO: step: 198 lr_xt 0.00224635
2024-12-01-19:00:44-root-INFO: grad norm: 241.283 223.199 91.651
2024-12-01-19:00:45-root-INFO: grad norm: 236.210 217.207 92.825
2024-12-01-19:00:45-root-INFO: Loss Change: 3401.719 -> 3312.972
2024-12-01-19:00:45-root-INFO: Regularization Change: 0.000 -> 0.429
2024-12-01-19:00:45-root-INFO: Learning rate of xt decay: 0.05512 -> 0.05578.
2024-12-01-19:00:45-root-INFO: Coefficient of regularization decay: 0.00017 -> 0.00017.
2024-12-01-19:00:46-root-INFO: step: 197 lr_xt 0.00234729
2024-12-01-19:00:46-root-INFO: grad norm: 271.704 252.858 99.427
2024-12-01-19:00:47-root-INFO: grad norm: 271.989 251.775 102.894
2024-12-01-19:00:48-root-INFO: Loss Change: 3301.415 -> 3226.206
2024-12-01-19:00:48-root-INFO: Regularization Change: 0.000 -> 0.372
2024-12-01-19:00:48-root-INFO: Learning rate of xt decay: 0.05578 -> 0.05645.
2024-12-01-19:00:48-root-INFO: Coefficient of regularization decay: 0.00017 -> 0.00017.
2024-12-01-19:00:48-root-INFO: step: 196 lr_xt 0.00245238
2024-12-01-19:00:48-root-INFO: grad norm: 322.004 296.180 126.349
2024-12-01-19:00:49-root-INFO: grad norm: 336.992 315.363 118.785
2024-12-01-19:00:50-root-INFO: Loss Change: 3222.769 -> 3165.826
2024-12-01-19:00:50-root-INFO: Regularization Change: 0.000 -> 0.375
2024-12-01-19:00:50-root-INFO: Learning rate of xt decay: 0.05645 -> 0.05713.
2024-12-01-19:00:50-root-INFO: Coefficient of regularization decay: 0.00017 -> 0.00017.
2024-12-01-19:00:50-root-INFO: step: 195 lr_xt 0.00256175
2024-12-01-19:00:51-root-INFO: grad norm: 378.878 353.063 137.459
2024-12-01-19:00:52-root-INFO: grad norm: 390.395 367.151 132.696
2024-12-01-19:00:52-root-INFO: Loss Change: 3162.395 -> 3110.042
2024-12-01-19:00:52-root-INFO: Regularization Change: 0.000 -> 0.362
2024-12-01-19:00:52-root-INFO: Learning rate of xt decay: 0.05713 -> 0.05782.
2024-12-01-19:00:52-root-INFO: Coefficient of regularization decay: 0.00017 -> 0.00017.
2024-12-01-19:00:53-root-INFO: step: 194 lr_xt 0.00267557
2024-12-01-19:00:53-root-INFO: grad norm: 457.286 425.185 168.310
2024-12-01-19:00:54-root-INFO: grad norm: 449.745 426.357 143.144
2024-12-01-19:00:55-root-INFO: Loss Change: 3125.911 -> 3052.981
2024-12-01-19:00:55-root-INFO: Regularization Change: 0.000 -> 0.391
2024-12-01-19:00:55-root-INFO: Learning rate of xt decay: 0.05782 -> 0.05851.
2024-12-01-19:00:55-root-INFO: Coefficient of regularization decay: 0.00017 -> 0.00017.
2024-12-01-19:00:55-root-INFO: step: 193 lr_xt 0.00279399
2024-12-01-19:00:56-root-INFO: grad norm: 458.589 428.014 164.643
2024-12-01-19:00:57-root-INFO: grad norm: 409.992 388.216 131.841
2024-12-01-19:00:57-root-INFO: Loss Change: 3062.506 -> 2949.886
2024-12-01-19:00:57-root-INFO: Regularization Change: 0.000 -> 0.404
2024-12-01-19:00:57-root-INFO: Learning rate of xt decay: 0.05851 -> 0.05921.
2024-12-01-19:00:57-root-INFO: Coefficient of regularization decay: 0.00017 -> 0.00018.
2024-12-01-19:00:58-root-INFO: step: 192 lr_xt 0.00291718
2024-12-01-19:00:58-root-INFO: grad norm: 387.509 366.128 126.940
2024-12-01-19:00:59-root-INFO: grad norm: 368.312 349.943 114.864
2024-12-01-19:01:00-root-INFO: Loss Change: 2949.164 -> 2874.066
2024-12-01-19:01:00-root-INFO: Regularization Change: 0.000 -> 0.383
2024-12-01-19:01:00-root-INFO: Learning rate of xt decay: 0.05921 -> 0.05992.
2024-12-01-19:01:00-root-INFO: Coefficient of regularization decay: 0.00018 -> 0.00018.
2024-12-01-19:01:00-root-INFO: step: 191 lr_xt 0.00304531
2024-12-01-19:01:00-root-INFO: grad norm: 479.872 457.524 144.739
2024-12-01-19:01:01-root-INFO: Loss too large (2906.216->2945.936)! Learning rate decreased to 0.00244.
2024-12-01-19:01:02-root-INFO: grad norm: 340.299 326.351 96.426
2024-12-01-19:01:02-root-INFO: Loss Change: 2906.216 -> 2746.910
2024-12-01-19:01:02-root-INFO: Regularization Change: 0.000 -> 0.446
2024-12-01-19:01:02-root-INFO: Learning rate of xt decay: 0.05992 -> 0.06064.
2024-12-01-19:01:02-root-INFO: Coefficient of regularization decay: 0.00018 -> 0.00018.
2024-12-01-19:01:03-root-INFO: step: 190 lr_xt 0.00317856
2024-12-01-19:01:03-root-INFO: grad norm: 262.772 250.328 79.907
2024-12-01-19:01:04-root-INFO: grad norm: 324.019 310.657 92.090
2024-12-01-19:01:04-root-INFO: Loss too large (2734.165->2756.312)! Learning rate decreased to 0.00254.
2024-12-01-19:01:05-root-INFO: Loss Change: 2742.613 -> 2690.859
2024-12-01-19:01:05-root-INFO: Regularization Change: 0.000 -> 0.357
2024-12-01-19:01:05-root-INFO: Undo step: 190
2024-12-01-19:01:05-root-INFO: Undo step: 191
2024-12-01-19:01:05-root-INFO: Undo step: 192
2024-12-01-19:01:05-root-INFO: Undo step: 193
2024-12-01-19:01:05-root-INFO: Undo step: 194
2024-12-01-19:01:06-root-INFO: step: 195 lr_xt 0.00256175
2024-12-01-19:01:06-root-INFO: grad norm: 1063.083 994.897 374.602
2024-12-01-19:01:07-root-INFO: grad norm: 821.177 781.417 252.427
2024-12-01-19:01:08-root-INFO: Loss Change: 4030.727 -> 3233.617
2024-12-01-19:01:08-root-INFO: Regularization Change: 0.000 -> 3.439
2024-12-01-19:01:08-root-INFO: Learning rate of xt decay: 0.05713 -> 0.05782.
2024-12-01-19:01:08-root-INFO: Coefficient of regularization decay: 0.00017 -> 0.00017.
2024-12-01-19:01:08-root-INFO: step: 194 lr_xt 0.00267557
2024-12-01-19:01:08-root-INFO: grad norm: 660.156 625.449 211.233
2024-12-01-19:01:09-root-INFO: grad norm: 488.366 467.414 141.512
2024-12-01-19:01:10-root-INFO: Loss Change: 3247.021 -> 2918.271
2024-12-01-19:01:10-root-INFO: Regularization Change: 0.000 -> 0.860
2024-12-01-19:01:10-root-INFO: Learning rate of xt decay: 0.05782 -> 0.05851.
2024-12-01-19:01:10-root-INFO: Coefficient of regularization decay: 0.00017 -> 0.00017.
2024-12-01-19:01:10-root-INFO: step: 193 lr_xt 0.00279399
2024-12-01-19:01:11-root-INFO: grad norm: 386.875 363.928 131.258
2024-12-01-19:01:12-root-INFO: grad norm: 305.389 293.484 84.440
2024-12-01-19:01:12-root-INFO: Loss Change: 2910.329 -> 2767.311
2024-12-01-19:01:12-root-INFO: Regularization Change: 0.000 -> 0.514
2024-12-01-19:01:12-root-INFO: Learning rate of xt decay: 0.05851 -> 0.05921.
2024-12-01-19:01:12-root-INFO: Coefficient of regularization decay: 0.00017 -> 0.00018.
2024-12-01-19:01:13-root-INFO: step: 192 lr_xt 0.00291718
2024-12-01-19:01:13-root-INFO: grad norm: 282.507 268.458 87.980
2024-12-01-19:01:14-root-INFO: grad norm: 267.186 258.181 68.778
2024-12-01-19:01:15-root-INFO: Loss Change: 2757.872 -> 2681.919
2024-12-01-19:01:15-root-INFO: Regularization Change: 0.000 -> 0.414
2024-12-01-19:01:15-root-INFO: Learning rate of xt decay: 0.05921 -> 0.05992.
2024-12-01-19:01:15-root-INFO: Coefficient of regularization decay: 0.00018 -> 0.00018.
2024-12-01-19:01:15-root-INFO: step: 191 lr_xt 0.00304531
2024-12-01-19:01:16-root-INFO: grad norm: 295.525 280.027 94.445
2024-12-01-19:01:17-root-INFO: grad norm: 316.820 308.436 72.405
2024-12-01-19:01:17-root-INFO: Loss Change: 2674.209 -> 2637.549
2024-12-01-19:01:17-root-INFO: Regularization Change: 0.000 -> 0.431
2024-12-01-19:01:17-root-INFO: Learning rate of xt decay: 0.05992 -> 0.06064.
2024-12-01-19:01:17-root-INFO: Coefficient of regularization decay: 0.00018 -> 0.00018.
2024-12-01-19:01:18-root-INFO: step: 190 lr_xt 0.00317856
2024-12-01-19:01:18-root-INFO: grad norm: 368.218 354.420 99.854
2024-12-01-19:01:18-root-INFO: Loss too large (2627.731->2628.531)! Learning rate decreased to 0.00254.
2024-12-01-19:01:19-root-INFO: grad norm: 283.576 277.113 60.196
2024-12-01-19:01:20-root-INFO: Loss Change: 2627.731 -> 2516.149
2024-12-01-19:01:20-root-INFO: Regularization Change: 0.000 -> 0.298
2024-12-01-19:01:20-root-INFO: Learning rate of xt decay: 0.06064 -> 0.06137.
2024-12-01-19:01:20-root-INFO: Coefficient of regularization decay: 0.00018 -> 0.00018.
2024-12-01-19:01:20-root-INFO: step: 189 lr_xt 0.00331709
2024-12-01-19:01:21-root-INFO: grad norm: 260.353 250.974 69.253
2024-12-01-19:01:21-root-INFO: Loss too large (2505.314->2509.491)! Learning rate decreased to 0.00265.
2024-12-01-19:01:22-root-INFO: grad norm: 249.348 244.215 50.336
2024-12-01-19:01:23-root-INFO: Loss Change: 2505.314 -> 2445.615
2024-12-01-19:01:23-root-INFO: Regularization Change: 0.000 -> 0.284
2024-12-01-19:01:23-root-INFO: Learning rate of xt decay: 0.06137 -> 0.06211.
2024-12-01-19:01:23-root-INFO: Coefficient of regularization decay: 0.00018 -> 0.00018.
2024-12-01-19:01:23-root-INFO: step: 188 lr_xt 0.00346111
2024-12-01-19:01:24-root-INFO: grad norm: 287.978 278.348 73.852
2024-12-01-19:01:24-root-INFO: Loss too large (2438.748->2491.190)! Learning rate decreased to 0.00277.
2024-12-01-19:01:25-root-INFO: grad norm: 339.018 334.142 57.291
2024-12-01-19:01:25-root-INFO: Loss too large (2422.772->2451.191)! Learning rate decreased to 0.00222.
2024-12-01-19:01:26-root-INFO: Loss Change: 2438.748 -> 2395.559
2024-12-01-19:01:26-root-INFO: Regularization Change: 0.000 -> 0.247
2024-12-01-19:01:26-root-INFO: Learning rate of xt decay: 0.06211 -> 0.06285.
2024-12-01-19:01:26-root-INFO: Coefficient of regularization decay: 0.00018 -> 0.00019.
2024-12-01-19:01:26-root-INFO: step: 187 lr_xt 0.00361079
2024-12-01-19:01:27-root-INFO: grad norm: 303.434 296.086 66.369
2024-12-01-19:01:27-root-INFO: Loss too large (2385.254->2595.412)! Learning rate decreased to 0.00289.
2024-12-01-19:01:27-root-INFO: Loss too large (2385.254->2461.891)! Learning rate decreased to 0.00231.
2024-12-01-19:01:28-root-INFO: grad norm: 500.267 494.978 72.555
2024-12-01-19:01:29-root-INFO: Loss too large (2383.425->2447.484)! Learning rate decreased to 0.00185.
2024-12-01-19:01:29-root-INFO: Loss too large (2383.425->2408.588)! Learning rate decreased to 0.00148.
2024-12-01-19:01:30-root-INFO: Loss Change: 2385.254 -> 2376.861
2024-12-01-19:01:30-root-INFO: Regularization Change: 0.000 -> 0.286
2024-12-01-19:01:30-root-INFO: Learning rate of xt decay: 0.06285 -> 0.06361.
2024-12-01-19:01:30-root-INFO: Coefficient of regularization decay: 0.00019 -> 0.00019.
2024-12-01-19:01:30-root-INFO: step: 186 lr_xt 0.00376634
2024-12-01-19:01:31-root-INFO: grad norm: 237.751 232.839 48.080
2024-12-01-19:01:31-root-INFO: Loss too large (2354.230->2398.588)! Learning rate decreased to 0.00301.
2024-12-01-19:01:32-root-INFO: grad norm: 438.203 432.444 70.808
2024-12-01-19:01:32-root-INFO: Loss too large (2312.976->2427.006)! Learning rate decreased to 0.00241.
2024-12-01-19:01:33-root-INFO: Loss too large (2312.976->2387.180)! Learning rate decreased to 0.00193.
2024-12-01-19:01:33-root-INFO: Loss too large (2312.976->2351.072)! Learning rate decreased to 0.00154.
2024-12-01-19:01:33-root-INFO: Loss too large (2312.976->2320.040)! Learning rate decreased to 0.00123.
2024-12-01-19:01:34-root-INFO: Loss Change: 2354.230 -> 2295.109
2024-12-01-19:01:34-root-INFO: Regularization Change: 0.000 -> 0.174
2024-12-01-19:01:34-root-INFO: Learning rate of xt decay: 0.06361 -> 0.06437.
2024-12-01-19:01:34-root-INFO: Coefficient of regularization decay: 0.00019 -> 0.00019.
2024-12-01-19:01:34-root-INFO: step: 185 lr_xt 0.00392795
2024-12-01-19:01:35-root-INFO: grad norm: 227.569 222.749 46.587
2024-12-01-19:01:35-root-INFO: Loss too large (2276.429->2487.429)! Learning rate decreased to 0.00314.
2024-12-01-19:01:35-root-INFO: Loss too large (2276.429->2363.124)! Learning rate decreased to 0.00251.
2024-12-01-19:01:36-root-INFO: Loss too large (2276.429->2283.842)! Learning rate decreased to 0.00201.
2024-12-01-19:01:37-root-INFO: grad norm: 320.466 315.243 57.626
2024-12-01-19:01:37-root-INFO: Loss too large (2243.116->2291.797)! Learning rate decreased to 0.00161.
2024-12-01-19:01:38-root-INFO: Loss too large (2243.116->2266.020)! Learning rate decreased to 0.00129.
2024-12-01-19:01:38-root-INFO: Loss too large (2243.116->2245.717)! Learning rate decreased to 0.00103.
2024-12-01-19:01:39-root-INFO: Loss Change: 2276.429 -> 2231.292
2024-12-01-19:01:39-root-INFO: Regularization Change: 0.000 -> 0.084
2024-12-01-19:01:39-root-INFO: Undo step: 185
2024-12-01-19:01:39-root-INFO: Undo step: 186
2024-12-01-19:01:39-root-INFO: Undo step: 187
2024-12-01-19:01:39-root-INFO: Undo step: 188
2024-12-01-19:01:39-root-INFO: Undo step: 189
2024-12-01-19:01:39-root-INFO: step: 190 lr_xt 0.00317856
2024-12-01-19:01:39-root-INFO: grad norm: 821.583 761.386 308.691
2024-12-01-19:01:40-root-INFO: grad norm: 978.435 940.577 269.538
2024-12-01-19:01:41-root-INFO: Loss Change: 3576.198 -> 3312.224
2024-12-01-19:01:41-root-INFO: Regularization Change: 0.000 -> 7.410
2024-12-01-19:01:41-root-INFO: Learning rate of xt decay: 0.06064 -> 0.06137.
2024-12-01-19:01:41-root-INFO: Coefficient of regularization decay: 0.00018 -> 0.00018.
2024-12-01-19:01:41-root-INFO: step: 189 lr_xt 0.00331709
2024-12-01-19:01:42-root-INFO: grad norm: 676.553 663.472 132.397
2024-12-01-19:01:43-root-INFO: grad norm: 293.018 281.294 82.058
2024-12-01-19:01:43-root-INFO: Loss Change: 3286.843 -> 2615.129
2024-12-01-19:01:43-root-INFO: Regularization Change: 0.000 -> 3.614
2024-12-01-19:01:43-root-INFO: Learning rate of xt decay: 0.06137 -> 0.06211.
2024-12-01-19:01:43-root-INFO: Coefficient of regularization decay: 0.00018 -> 0.00018.
2024-12-01-19:01:44-root-INFO: step: 188 lr_xt 0.00346111
2024-12-01-19:01:44-root-INFO: grad norm: 215.176 204.808 65.987
2024-12-01-19:01:45-root-INFO: grad norm: 215.656 207.341 59.306
2024-12-01-19:01:46-root-INFO: Loss Change: 2604.412 -> 2543.390
2024-12-01-19:01:46-root-INFO: Regularization Change: 0.000 -> 0.956
2024-12-01-19:01:46-root-INFO: Learning rate of xt decay: 0.06211 -> 0.06285.
2024-12-01-19:01:46-root-INFO: Coefficient of regularization decay: 0.00018 -> 0.00019.
2024-12-01-19:01:46-root-INFO: step: 187 lr_xt 0.00361079
2024-12-01-19:01:47-root-INFO: grad norm: 688.164 672.912 144.081
2024-12-01-19:01:47-root-INFO: Loss too large (2590.681->2738.864)! Learning rate decreased to 0.00289.
2024-12-01-19:01:47-root-INFO: Loss too large (2590.681->2685.009)! Learning rate decreased to 0.00231.
2024-12-01-19:01:48-root-INFO: Loss too large (2590.681->2633.936)! Learning rate decreased to 0.00185.
2024-12-01-19:01:49-root-INFO: grad norm: 232.311 226.066 53.503
2024-12-01-19:01:49-root-INFO: Loss Change: 2590.681 -> 2500.203
2024-12-01-19:01:49-root-INFO: Regularization Change: 0.000 -> 1.033
2024-12-01-19:01:49-root-INFO: Learning rate of xt decay: 0.06285 -> 0.06361.
2024-12-01-19:01:49-root-INFO: Coefficient of regularization decay: 0.00019 -> 0.00019.
2024-12-01-19:01:50-root-INFO: step: 186 lr_xt 0.00376634
2024-12-01-19:01:50-root-INFO: grad norm: 198.532 190.008 57.550
2024-12-01-19:01:51-root-INFO: grad norm: 205.319 197.855 54.857
2024-12-01-19:01:52-root-INFO: Loss too large (2384.872->2416.736)! Learning rate decreased to 0.00301.
2024-12-01-19:01:52-root-INFO: Loss too large (2384.872->2392.070)! Learning rate decreased to 0.00241.
2024-12-01-19:01:53-root-INFO: Loss Change: 2480.611 -> 2375.786
2024-12-01-19:01:53-root-INFO: Regularization Change: 0.000 -> 0.490
2024-12-01-19:01:53-root-INFO: Learning rate of xt decay: 0.06361 -> 0.06437.
2024-12-01-19:01:53-root-INFO: Coefficient of regularization decay: 0.00019 -> 0.00019.
2024-12-01-19:01:53-root-INFO: step: 185 lr_xt 0.00392795
2024-12-01-19:01:53-root-INFO: grad norm: 237.932 231.918 53.157
2024-12-01-19:01:54-root-INFO: Loss too large (2358.843->2601.772)! Learning rate decreased to 0.00314.
2024-12-01-19:01:54-root-INFO: Loss too large (2358.843->2477.819)! Learning rate decreased to 0.00251.
2024-12-01-19:01:54-root-INFO: Loss too large (2358.843->2394.441)! Learning rate decreased to 0.00201.
2024-12-01-19:01:55-root-INFO: grad norm: 404.625 396.597 80.200
2024-12-01-19:01:56-root-INFO: Loss too large (2345.812->2402.421)! Learning rate decreased to 0.00161.
2024-12-01-19:01:56-root-INFO: Loss too large (2345.812->2371.724)! Learning rate decreased to 0.00129.
2024-12-01-19:01:57-root-INFO: Loss Change: 2358.843 -> 2345.395
2024-12-01-19:01:57-root-INFO: Regularization Change: 0.000 -> 0.107
2024-12-01-19:01:57-root-INFO: Learning rate of xt decay: 0.06437 -> 0.06514.
2024-12-01-19:01:57-root-INFO: Coefficient of regularization decay: 0.00019 -> 0.00019.
2024-12-01-19:01:57-root-INFO: step: 184 lr_xt 0.00409583
2024-12-01-19:01:57-root-INFO: grad norm: 244.957 238.469 56.002
2024-12-01-19:01:58-root-INFO: Loss too large (2315.880->2597.424)! Learning rate decreased to 0.00328.
2024-12-01-19:01:58-root-INFO: Loss too large (2315.880->2468.886)! Learning rate decreased to 0.00262.
2024-12-01-19:01:58-root-INFO: Loss too large (2315.880->2376.083)! Learning rate decreased to 0.00210.
2024-12-01-19:01:59-root-INFO: Loss too large (2315.880->2317.217)! Learning rate decreased to 0.00168.
2024-12-01-19:02:00-root-INFO: grad norm: 311.469 304.361 66.160
2024-12-01-19:02:00-root-INFO: Loss too large (2286.024->2314.522)! Learning rate decreased to 0.00134.
2024-12-01-19:02:00-root-INFO: Loss too large (2286.024->2292.808)! Learning rate decreased to 0.00107.
2024-12-01-19:02:01-root-INFO: Loss Change: 2315.880 -> 2276.951
2024-12-01-19:02:01-root-INFO: Regularization Change: 0.000 -> 0.086
2024-12-01-19:02:01-root-INFO: Learning rate of xt decay: 0.06514 -> 0.06592.
2024-12-01-19:02:01-root-INFO: Coefficient of regularization decay: 0.00019 -> 0.00019.
2024-12-01-19:02:02-root-INFO: step: 183 lr_xt 0.00427020
2024-12-01-19:02:02-root-INFO: grad norm: 220.748 215.047 49.844
2024-12-01-19:02:02-root-INFO: Loss too large (2263.486->2577.314)! Learning rate decreased to 0.00342.
2024-12-01-19:02:03-root-INFO: Loss too large (2263.486->2458.276)! Learning rate decreased to 0.00273.
2024-12-01-19:02:03-root-INFO: Loss too large (2263.486->2368.190)! Learning rate decreased to 0.00219.
2024-12-01-19:02:03-root-INFO: Loss too large (2263.486->2306.311)! Learning rate decreased to 0.00175.
2024-12-01-19:02:04-root-INFO: Loss too large (2263.486->2268.316)! Learning rate decreased to 0.00140.
2024-12-01-19:02:05-root-INFO: grad norm: 290.660 284.598 59.055
2024-12-01-19:02:05-root-INFO: Loss too large (2248.123->2262.940)! Learning rate decreased to 0.00112.
2024-12-01-19:02:06-root-INFO: Loss Change: 2263.486 -> 2246.538
2024-12-01-19:02:06-root-INFO: Regularization Change: 0.000 -> 0.067
2024-12-01-19:02:06-root-INFO: Learning rate of xt decay: 0.06592 -> 0.06671.
2024-12-01-19:02:06-root-INFO: Coefficient of regularization decay: 0.00019 -> 0.00019.
2024-12-01-19:02:06-root-INFO: step: 182 lr_xt 0.00445127
2024-12-01-19:02:06-root-INFO: grad norm: 223.845 218.726 47.597
2024-12-01-19:02:07-root-INFO: Loss too large (2226.576->2604.560)! Learning rate decreased to 0.00356.
2024-12-01-19:02:07-root-INFO: Loss too large (2226.576->2480.701)! Learning rate decreased to 0.00285.
2024-12-01-19:02:07-root-INFO: Loss too large (2226.576->2381.393)! Learning rate decreased to 0.00228.
2024-12-01-19:02:08-root-INFO: Loss too large (2226.576->2308.239)! Learning rate decreased to 0.00182.
2024-12-01-19:02:08-root-INFO: Loss too large (2226.576->2259.072)! Learning rate decreased to 0.00146.
2024-12-01-19:02:08-root-INFO: Loss too large (2226.576->2229.318)! Learning rate decreased to 0.00117.
2024-12-01-19:02:09-root-INFO: grad norm: 268.295 262.753 54.250
2024-12-01-19:02:10-root-INFO: Loss too large (2213.566->2218.862)! Learning rate decreased to 0.00093.
2024-12-01-19:02:10-root-INFO: Loss Change: 2226.576 -> 2207.064
2024-12-01-19:02:10-root-INFO: Regularization Change: 0.000 -> 0.043
2024-12-01-19:02:10-root-INFO: Learning rate of xt decay: 0.06671 -> 0.06751.
2024-12-01-19:02:10-root-INFO: Coefficient of regularization decay: 0.00019 -> 0.00020.
2024-12-01-19:02:11-root-INFO: step: 181 lr_xt 0.00463927
2024-12-01-19:02:11-root-INFO: grad norm: 171.649 167.239 38.656
2024-12-01-19:02:12-root-INFO: Loss too large (2190.646->2441.461)! Learning rate decreased to 0.00371.
2024-12-01-19:02:12-root-INFO: Loss too large (2190.646->2354.314)! Learning rate decreased to 0.00297.
2024-12-01-19:02:12-root-INFO: Loss too large (2190.646->2288.658)! Learning rate decreased to 0.00238.
2024-12-01-19:02:13-root-INFO: Loss too large (2190.646->2242.740)! Learning rate decreased to 0.00190.
2024-12-01-19:02:13-root-INFO: Loss too large (2190.646->2212.938)! Learning rate decreased to 0.00152.
2024-12-01-19:02:13-root-INFO: Loss too large (2190.646->2195.103)! Learning rate decreased to 0.00122.
2024-12-01-19:02:14-root-INFO: grad norm: 264.055 258.818 52.332
2024-12-01-19:02:15-root-INFO: Loss too large (2185.437->2198.451)! Learning rate decreased to 0.00097.
2024-12-01-19:02:15-root-INFO: Loss Change: 2190.646 -> 2184.469
2024-12-01-19:02:15-root-INFO: Regularization Change: 0.000 -> 0.051
2024-12-01-19:02:15-root-INFO: Learning rate of xt decay: 0.06751 -> 0.06832.
2024-12-01-19:02:15-root-INFO: Coefficient of regularization decay: 0.00020 -> 0.00020.
2024-12-01-19:02:16-root-INFO: step: 180 lr_xt 0.00483443
2024-12-01-19:02:16-root-INFO: grad norm: 199.560 194.902 42.867
2024-12-01-19:02:16-root-INFO: Loss too large (2168.386->2524.111)! Learning rate decreased to 0.00387.
2024-12-01-19:02:17-root-INFO: Loss too large (2168.386->2417.879)! Learning rate decreased to 0.00309.
2024-12-01-19:02:17-root-INFO: Loss too large (2168.386->2330.833)! Learning rate decreased to 0.00248.
2024-12-01-19:02:17-root-INFO: Loss too large (2168.386->2264.752)! Learning rate decreased to 0.00198.
2024-12-01-19:02:18-root-INFO: Loss too large (2168.386->2218.286)! Learning rate decreased to 0.00158.
2024-12-01-19:02:18-root-INFO: Loss too large (2168.386->2188.070)! Learning rate decreased to 0.00127.
2024-12-01-19:02:18-root-INFO: Loss too large (2168.386->2170.055)! Learning rate decreased to 0.00101.
2024-12-01-19:02:19-root-INFO: grad norm: 258.241 252.819 52.641
2024-12-01-19:02:20-root-INFO: Loss too large (2160.433->2163.623)! Learning rate decreased to 0.00081.
2024-12-01-19:02:21-root-INFO: Loss Change: 2168.386 -> 2153.758
2024-12-01-19:02:21-root-INFO: Regularization Change: 0.000 -> 0.037
2024-12-01-19:02:21-root-INFO: Undo step: 180
2024-12-01-19:02:21-root-INFO: Undo step: 181
2024-12-01-19:02:21-root-INFO: Undo step: 182
2024-12-01-19:02:21-root-INFO: Undo step: 183
2024-12-01-19:02:21-root-INFO: Undo step: 184
2024-12-01-19:02:21-root-INFO: step: 185 lr_xt 0.00392795
2024-12-01-19:02:21-root-INFO: grad norm: 596.015 563.889 193.035
2024-12-01-19:02:22-root-INFO: grad norm: 655.298 620.921 209.458
2024-12-01-19:02:23-root-INFO: Loss Change: 3141.324 -> 3043.669
2024-12-01-19:02:23-root-INFO: Regularization Change: 0.000 -> 4.924
2024-12-01-19:02:23-root-INFO: Learning rate of xt decay: 0.06437 -> 0.06514.
2024-12-01-19:02:23-root-INFO: Coefficient of regularization decay: 0.00019 -> 0.00019.
2024-12-01-19:02:23-root-INFO: step: 184 lr_xt 0.00409583
2024-12-01-19:02:24-root-INFO: grad norm: 753.027 733.680 169.598
2024-12-01-19:02:24-root-INFO: Loss too large (2995.301->3074.219)! Learning rate decreased to 0.00328.
2024-12-01-19:02:25-root-INFO: grad norm: 490.499 470.174 139.735
2024-12-01-19:02:26-root-INFO: Loss Change: 2995.301 -> 2466.911
2024-12-01-19:02:26-root-INFO: Regularization Change: 0.000 -> 2.149
2024-12-01-19:02:26-root-INFO: Learning rate of xt decay: 0.06514 -> 0.06592.
2024-12-01-19:02:26-root-INFO: Coefficient of regularization decay: 0.00019 -> 0.00019.
2024-12-01-19:02:26-root-INFO: step: 183 lr_xt 0.00427020
2024-12-01-19:02:26-root-INFO: grad norm: 226.700 215.882 69.194
2024-12-01-19:02:27-root-INFO: grad norm: 212.152 201.195 67.299
2024-12-01-19:02:28-root-INFO: Loss Change: 2450.690 -> 2286.329
2024-12-01-19:02:28-root-INFO: Regularization Change: 0.000 -> 1.334
2024-12-01-19:02:28-root-INFO: Learning rate of xt decay: 0.06592 -> 0.06671.
2024-12-01-19:02:28-root-INFO: Coefficient of regularization decay: 0.00019 -> 0.00019.
2024-12-01-19:02:28-root-INFO: step: 182 lr_xt 0.00445127
2024-12-01-19:02:29-root-INFO: grad norm: 197.470 191.724 47.290
2024-12-01-19:02:30-root-INFO: grad norm: 449.274 438.803 96.435
2024-12-01-19:02:30-root-INFO: Loss too large (2251.671->2518.830)! Learning rate decreased to 0.00356.
2024-12-01-19:02:31-root-INFO: Loss too large (2251.671->2443.082)! Learning rate decreased to 0.00285.
2024-12-01-19:02:31-root-INFO: Loss too large (2251.671->2384.728)! Learning rate decreased to 0.00228.
2024-12-01-19:02:31-root-INFO: Loss too large (2251.671->2338.871)! Learning rate decreased to 0.00182.
2024-12-01-19:02:32-root-INFO: Loss too large (2251.671->2301.849)! Learning rate decreased to 0.00146.
2024-12-01-19:02:32-root-INFO: Loss too large (2251.671->2271.299)! Learning rate decreased to 0.00117.
2024-12-01-19:02:33-root-INFO: Loss Change: 2264.000 -> 2246.382
2024-12-01-19:02:33-root-INFO: Regularization Change: 0.000 -> 0.651
2024-12-01-19:02:33-root-INFO: Learning rate of xt decay: 0.06671 -> 0.06751.
2024-12-01-19:02:33-root-INFO: Coefficient of regularization decay: 0.00019 -> 0.00020.
2024-12-01-19:02:33-root-INFO: step: 181 lr_xt 0.00463927
2024-12-01-19:02:33-root-INFO: grad norm: 309.466 303.626 59.839
2024-12-01-19:02:34-root-INFO: Loss too large (2229.065->2749.836)! Learning rate decreased to 0.00371.
2024-12-01-19:02:34-root-INFO: Loss too large (2229.065->2592.562)! Learning rate decreased to 0.00297.
2024-12-01-19:02:34-root-INFO: Loss too large (2229.065->2454.995)! Learning rate decreased to 0.00238.
2024-12-01-19:02:35-root-INFO: Loss too large (2229.065->2338.474)! Learning rate decreased to 0.00190.
2024-12-01-19:02:35-root-INFO: Loss too large (2229.065->2248.902)! Learning rate decreased to 0.00152.
2024-12-01-19:02:36-root-INFO: grad norm: 463.510 455.686 84.801
2024-12-01-19:02:36-root-INFO: Loss too large (2191.871->2264.437)! Learning rate decreased to 0.00122.
2024-12-01-19:02:37-root-INFO: Loss too large (2191.871->2234.489)! Learning rate decreased to 0.00097.
2024-12-01-19:02:37-root-INFO: Loss too large (2191.871->2206.301)! Learning rate decreased to 0.00078.
2024-12-01-19:02:38-root-INFO: Loss Change: 2229.065 -> 2182.737
2024-12-01-19:02:38-root-INFO: Regularization Change: 0.000 -> 0.069
2024-12-01-19:02:38-root-INFO: Learning rate of xt decay: 0.06751 -> 0.06832.
2024-12-01-19:02:38-root-INFO: Coefficient of regularization decay: 0.00020 -> 0.00020.
2024-12-01-19:02:38-root-INFO: step: 180 lr_xt 0.00483443
2024-12-01-19:02:38-root-INFO: grad norm: 273.526 268.598 51.689
2024-12-01-19:02:39-root-INFO: Loss too large (2161.030->2748.322)! Learning rate decreased to 0.00387.
2024-12-01-19:02:39-root-INFO: Loss too large (2161.030->2610.352)! Learning rate decreased to 0.00309.
2024-12-01-19:02:39-root-INFO: Loss too large (2161.030->2488.337)! Learning rate decreased to 0.00248.
2024-12-01-19:02:40-root-INFO: Loss too large (2161.030->2382.072)! Learning rate decreased to 0.00198.
2024-12-01-19:02:40-root-INFO: Loss too large (2161.030->2293.848)! Learning rate decreased to 0.00158.
2024-12-01-19:02:40-root-INFO: Loss too large (2161.030->2226.281)! Learning rate decreased to 0.00127.
2024-12-01-19:02:41-root-INFO: Loss too large (2161.030->2180.150)! Learning rate decreased to 0.00101.
2024-12-01-19:02:42-root-INFO: grad norm: 386.312 379.313 73.202
2024-12-01-19:02:42-root-INFO: Loss too large (2152.974->2178.240)! Learning rate decreased to 0.00081.
2024-12-01-19:02:43-root-INFO: Loss too large (2152.974->2156.964)! Learning rate decreased to 0.00065.
2024-12-01-19:02:43-root-INFO: Loss Change: 2161.030 -> 2141.723
2024-12-01-19:02:43-root-INFO: Regularization Change: 0.000 -> 0.028
2024-12-01-19:02:43-root-INFO: Learning rate of xt decay: 0.06832 -> 0.06914.
2024-12-01-19:02:43-root-INFO: Coefficient of regularization decay: 0.00020 -> 0.00020.
2024-12-01-19:02:44-root-INFO: step: 179 lr_xt 0.00503698
2024-12-01-19:02:44-root-INFO: grad norm: 200.818 196.852 39.713
2024-12-01-19:02:44-root-INFO: Loss too large (2124.286->2555.044)! Learning rate decreased to 0.00403.
2024-12-01-19:02:45-root-INFO: Loss too large (2124.286->2448.996)! Learning rate decreased to 0.00322.
2024-12-01-19:02:45-root-INFO: Loss too large (2124.286->2356.846)! Learning rate decreased to 0.00258.
2024-12-01-19:02:45-root-INFO: Loss too large (2124.286->2279.961)! Learning rate decreased to 0.00206.
2024-12-01-19:02:46-root-INFO: Loss too large (2124.286->2219.584)! Learning rate decreased to 0.00165.
2024-12-01-19:02:46-root-INFO: Loss too large (2124.286->2175.696)! Learning rate decreased to 0.00132.
2024-12-01-19:02:46-root-INFO: Loss too large (2124.286->2146.514)! Learning rate decreased to 0.00106.
2024-12-01-19:02:47-root-INFO: Loss too large (2124.286->2128.899)! Learning rate decreased to 0.00085.
2024-12-01-19:02:48-root-INFO: grad norm: 272.711 267.072 55.171
2024-12-01-19:02:48-root-INFO: Loss too large (2119.369->2125.300)! Learning rate decreased to 0.00068.
2024-12-01-19:02:49-root-INFO: Loss Change: 2124.286 -> 2115.454
2024-12-01-19:02:49-root-INFO: Regularization Change: 0.000 -> 0.023
2024-12-01-19:02:49-root-INFO: Learning rate of xt decay: 0.06914 -> 0.06997.
2024-12-01-19:02:49-root-INFO: Coefficient of regularization decay: 0.00020 -> 0.00020.
2024-12-01-19:02:49-root-INFO: step: 178 lr_xt 0.00524717
2024-12-01-19:02:49-root-INFO: grad norm: 162.959 158.509 37.821
2024-12-01-19:02:50-root-INFO: Loss too large (2104.721->2387.659)! Learning rate decreased to 0.00420.
2024-12-01-19:02:50-root-INFO: Loss too large (2104.721->2307.303)! Learning rate decreased to 0.00336.
2024-12-01-19:02:50-root-INFO: Loss too large (2104.721->2241.374)! Learning rate decreased to 0.00269.
2024-12-01-19:02:51-root-INFO: Loss too large (2104.721->2190.105)! Learning rate decreased to 0.00215.
2024-12-01-19:02:51-root-INFO: Loss too large (2104.721->2152.836)! Learning rate decreased to 0.00172.
2024-12-01-19:02:52-root-INFO: Loss too large (2104.721->2127.723)! Learning rate decreased to 0.00138.
2024-12-01-19:02:52-root-INFO: Loss too large (2104.721->2112.116)! Learning rate decreased to 0.00110.
2024-12-01-19:02:53-root-INFO: grad norm: 326.724 320.822 61.819
2024-12-01-19:02:53-root-INFO: Loss too large (2103.246->2143.182)! Learning rate decreased to 0.00088.
2024-12-01-19:02:54-root-INFO: Loss too large (2103.246->2121.560)! Learning rate decreased to 0.00070.
2024-12-01-19:02:54-root-INFO: Loss too large (2103.246->2105.429)! Learning rate decreased to 0.00056.
2024-12-01-19:02:55-root-INFO: Loss Change: 2104.721 -> 2094.924
2024-12-01-19:02:55-root-INFO: Regularization Change: 0.000 -> 0.034
2024-12-01-19:02:55-root-INFO: Learning rate of xt decay: 0.06997 -> 0.07081.
2024-12-01-19:02:55-root-INFO: Coefficient of regularization decay: 0.00020 -> 0.00020.
2024-12-01-19:02:55-root-INFO: step: 177 lr_xt 0.00546525
2024-12-01-19:02:55-root-INFO: grad norm: 187.164 182.932 39.574
2024-12-01-19:02:56-root-INFO: Loss too large (2082.990->2501.198)! Learning rate decreased to 0.00437.
2024-12-01-19:02:56-root-INFO: Loss too large (2082.990->2404.548)! Learning rate decreased to 0.00350.
2024-12-01-19:02:56-root-INFO: Loss too large (2082.990->2319.888)! Learning rate decreased to 0.00280.
2024-12-01-19:02:57-root-INFO: Loss too large (2082.990->2248.187)! Learning rate decreased to 0.00224.
2024-12-01-19:02:57-root-INFO: Loss too large (2082.990->2190.459)! Learning rate decreased to 0.00179.
2024-12-01-19:02:57-root-INFO: Loss too large (2082.990->2146.889)! Learning rate decreased to 0.00143.
2024-12-01-19:02:58-root-INFO: Loss too large (2082.990->2116.367)! Learning rate decreased to 0.00115.
2024-12-01-19:02:58-root-INFO: Loss too large (2082.990->2096.640)! Learning rate decreased to 0.00092.
2024-12-01-19:02:58-root-INFO: Loss too large (2082.990->2084.939)! Learning rate decreased to 0.00073.
2024-12-01-19:02:59-root-INFO: grad norm: 255.809 250.609 51.315
2024-12-01-19:03:00-root-INFO: Loss too large (2078.669->2081.914)! Learning rate decreased to 0.00059.
2024-12-01-19:03:01-root-INFO: Loss Change: 2082.990 -> 2074.367
2024-12-01-19:03:01-root-INFO: Regularization Change: 0.000 -> 0.019
2024-12-01-19:03:01-root-INFO: Learning rate of xt decay: 0.07081 -> 0.07166.
2024-12-01-19:03:01-root-INFO: Coefficient of regularization decay: 0.00020 -> 0.00021.
2024-12-01-19:03:01-root-INFO: step: 176 lr_xt 0.00569148
2024-12-01-19:03:01-root-INFO: grad norm: 114.909 109.236 35.662
2024-12-01-19:03:02-root-INFO: grad norm: 247.454 244.176 40.145
2024-12-01-19:03:03-root-INFO: Loss too large (2028.723->2262.899)! Learning rate decreased to 0.00455.
2024-12-01-19:03:03-root-INFO: Loss too large (2028.723->2221.393)! Learning rate decreased to 0.00364.
2024-12-01-19:03:03-root-INFO: Loss too large (2028.723->2188.482)! Learning rate decreased to 0.00291.
2024-12-01-19:03:04-root-INFO: Loss too large (2028.723->2159.261)! Learning rate decreased to 0.00233.
2024-12-01-19:03:04-root-INFO: Loss too large (2028.723->2131.167)! Learning rate decreased to 0.00186.
2024-12-01-19:03:04-root-INFO: Loss too large (2028.723->2103.744)! Learning rate decreased to 0.00149.
2024-12-01-19:03:05-root-INFO: Loss too large (2028.723->2078.283)! Learning rate decreased to 0.00119.
2024-12-01-19:03:05-root-INFO: Loss too large (2028.723->2056.682)! Learning rate decreased to 0.00095.
2024-12-01-19:03:05-root-INFO: Loss too large (2028.723->2040.221)! Learning rate decreased to 0.00076.
2024-12-01-19:03:06-root-INFO: Loss too large (2028.723->2029.035)! Learning rate decreased to 0.00061.
2024-12-01-19:03:06-root-INFO: Loss Change: 2065.649 -> 2022.337
2024-12-01-19:03:06-root-INFO: Regularization Change: 0.000 -> 0.447
2024-12-01-19:03:06-root-INFO: Learning rate of xt decay: 0.07166 -> 0.07252.
2024-12-01-19:03:06-root-INFO: Coefficient of regularization decay: 0.00021 -> 0.00021.
2024-12-01-19:03:07-root-INFO: step: 175 lr_xt 0.00592610
2024-12-01-19:03:07-root-INFO: grad norm: 107.054 103.917 25.724
2024-12-01-19:03:07-root-INFO: Loss too large (2003.551->2120.660)! Learning rate decreased to 0.00474.
2024-12-01-19:03:08-root-INFO: Loss too large (2003.551->2076.665)! Learning rate decreased to 0.00379.
2024-12-01-19:03:08-root-INFO: Loss too large (2003.551->2045.974)! Learning rate decreased to 0.00303.
2024-12-01-19:03:09-root-INFO: Loss too large (2003.551->2025.582)! Learning rate decreased to 0.00243.
2024-12-01-19:03:09-root-INFO: Loss too large (2003.551->2012.754)! Learning rate decreased to 0.00194.
2024-12-01-19:03:09-root-INFO: Loss too large (2003.551->2005.175)! Learning rate decreased to 0.00155.
2024-12-01-19:03:10-root-INFO: grad norm: 290.823 286.678 48.925
2024-12-01-19:03:11-root-INFO: Loss too large (2001.047->2100.925)! Learning rate decreased to 0.00124.
2024-12-01-19:03:11-root-INFO: Loss too large (2001.047->2072.130)! Learning rate decreased to 0.00099.
2024-12-01-19:03:11-root-INFO: Loss too large (2001.047->2045.512)! Learning rate decreased to 0.00080.
2024-12-01-19:03:12-root-INFO: Loss too large (2001.047->2023.722)! Learning rate decreased to 0.00064.
2024-12-01-19:03:12-root-INFO: Loss too large (2001.047->2007.979)! Learning rate decreased to 0.00051.
2024-12-01-19:03:13-root-INFO: Loss Change: 2003.551 -> 1997.964
2024-12-01-19:03:13-root-INFO: Regularization Change: 0.000 -> 0.036
2024-12-01-19:03:13-root-INFO: Undo step: 175
2024-12-01-19:03:13-root-INFO: Undo step: 176
2024-12-01-19:03:13-root-INFO: Undo step: 177
2024-12-01-19:03:13-root-INFO: Undo step: 178
2024-12-01-19:03:13-root-INFO: Undo step: 179
2024-12-01-19:03:13-root-INFO: step: 180 lr_xt 0.00483443
2024-12-01-19:03:14-root-INFO: grad norm: 1010.219 992.304 189.405
2024-12-01-19:03:15-root-INFO: grad norm: 644.980 625.285 158.171
2024-12-01-19:03:15-root-INFO: Loss Change: 3287.012 -> 2580.878
2024-12-01-19:03:15-root-INFO: Regularization Change: 0.000 -> 15.411
2024-12-01-19:03:15-root-INFO: Learning rate of xt decay: 0.06832 -> 0.06914.
2024-12-01-19:03:15-root-INFO: Coefficient of regularization decay: 0.00020 -> 0.00020.
2024-12-01-19:03:16-root-INFO: step: 179 lr_xt 0.00503698
2024-12-01-19:03:16-root-INFO: grad norm: 352.518 344.502 74.748
2024-12-01-19:03:17-root-INFO: grad norm: 348.723 339.311 80.475
2024-12-01-19:03:18-root-INFO: Loss Change: 2561.158 -> 2444.089
2024-12-01-19:03:18-root-INFO: Regularization Change: 0.000 -> 1.450
2024-12-01-19:03:18-root-INFO: Learning rate of xt decay: 0.06914 -> 0.06997.
2024-12-01-19:03:18-root-INFO: Coefficient of regularization decay: 0.00020 -> 0.00020.
2024-12-01-19:03:18-root-INFO: step: 178 lr_xt 0.00524717
2024-12-01-19:03:18-root-INFO: grad norm: 314.372 308.051 62.725
2024-12-01-19:03:19-root-INFO: grad norm: 306.929 298.209 72.642
2024-12-01-19:03:20-root-INFO: Loss Change: 2409.089 -> 2305.438
2024-12-01-19:03:20-root-INFO: Regularization Change: 0.000 -> 0.979
2024-12-01-19:03:20-root-INFO: Learning rate of xt decay: 0.06997 -> 0.07081.
2024-12-01-19:03:20-root-INFO: Coefficient of regularization decay: 0.00020 -> 0.00020.
2024-12-01-19:03:20-root-INFO: step: 177 lr_xt 0.00546525
2024-12-01-19:03:21-root-INFO: grad norm: 295.182 288.574 62.110
2024-12-01-19:03:22-root-INFO: grad norm: 301.735 294.665 64.932
2024-12-01-19:03:22-root-INFO: Loss Change: 2284.278 -> 2164.056
2024-12-01-19:03:22-root-INFO: Regularization Change: 0.000 -> 1.257
2024-12-01-19:03:22-root-INFO: Learning rate of xt decay: 0.07081 -> 0.07166.
2024-12-01-19:03:22-root-INFO: Coefficient of regularization decay: 0.00020 -> 0.00021.
2024-12-01-19:03:23-root-INFO: step: 176 lr_xt 0.00569148
2024-12-01-19:03:23-root-INFO: grad norm: 286.132 280.657 55.705
2024-12-01-19:03:24-root-INFO: grad norm: 448.904 443.626 68.631
2024-12-01-19:03:25-root-INFO: Loss too large (2125.125->2247.891)! Learning rate decreased to 0.00455.
2024-12-01-19:03:25-root-INFO: Loss too large (2125.125->2172.456)! Learning rate decreased to 0.00364.
2024-12-01-19:03:26-root-INFO: Loss Change: 2138.365 -> 2118.545
2024-12-01-19:03:26-root-INFO: Regularization Change: 0.000 -> 1.692
2024-12-01-19:03:26-root-INFO: Learning rate of xt decay: 0.07166 -> 0.07252.
2024-12-01-19:03:26-root-INFO: Coefficient of regularization decay: 0.00021 -> 0.00021.
2024-12-01-19:03:26-root-INFO: step: 175 lr_xt 0.00592610
2024-12-01-19:03:26-root-INFO: grad norm: 180.721 177.316 34.917
2024-12-01-19:03:27-root-INFO: grad norm: 178.155 176.313 25.549
2024-12-01-19:03:28-root-INFO: Loss Change: 2105.719 -> 1955.377
2024-12-01-19:03:28-root-INFO: Regularization Change: 0.000 -> 2.500
2024-12-01-19:03:28-root-INFO: Learning rate of xt decay: 0.07252 -> 0.07339.
2024-12-01-19:03:28-root-INFO: Coefficient of regularization decay: 0.00021 -> 0.00021.
2024-12-01-19:03:28-root-INFO: step: 174 lr_xt 0.00616941
2024-12-01-19:03:29-root-INFO: grad norm: 463.979 461.002 52.480
2024-12-01-19:03:29-root-INFO: Loss too large (1964.203->2082.623)! Learning rate decreased to 0.00494.
2024-12-01-19:03:29-root-INFO: Loss too large (1964.203->2067.277)! Learning rate decreased to 0.00395.
2024-12-01-19:03:30-root-INFO: Loss too large (1964.203->2048.849)! Learning rate decreased to 0.00316.
2024-12-01-19:03:30-root-INFO: Loss too large (1964.203->2024.664)! Learning rate decreased to 0.00253.
2024-12-01-19:03:30-root-INFO: Loss too large (1964.203->1994.718)! Learning rate decreased to 0.00202.
2024-12-01-19:03:31-root-INFO: grad norm: 215.047 211.574 38.491
2024-12-01-19:03:32-root-INFO: Loss Change: 1964.203 -> 1876.944
2024-12-01-19:03:32-root-INFO: Regularization Change: 0.000 -> 0.475
2024-12-01-19:03:32-root-INFO: Learning rate of xt decay: 0.07339 -> 0.07427.
2024-12-01-19:03:32-root-INFO: Coefficient of regularization decay: 0.00021 -> 0.00021.
2024-12-01-19:03:32-root-INFO: step: 173 lr_xt 0.00642166
2024-12-01-19:03:33-root-INFO: grad norm: 141.979 139.509 26.368
2024-12-01-19:03:33-root-INFO: Loss too large (1864.496->2032.887)! Learning rate decreased to 0.00514.
2024-12-01-19:03:33-root-INFO: Loss too large (1864.496->1947.030)! Learning rate decreased to 0.00411.
2024-12-01-19:03:34-root-INFO: Loss too large (1864.496->1892.264)! Learning rate decreased to 0.00329.
2024-12-01-19:03:35-root-INFO: grad norm: 325.848 322.598 45.902
2024-12-01-19:03:35-root-INFO: Loss too large (1861.915->1956.711)! Learning rate decreased to 0.00263.
2024-12-01-19:03:35-root-INFO: Loss too large (1861.915->1922.007)! Learning rate decreased to 0.00210.
2024-12-01-19:03:36-root-INFO: Loss too large (1861.915->1889.457)! Learning rate decreased to 0.00168.
2024-12-01-19:03:36-root-INFO: Loss too large (1861.915->1862.128)! Learning rate decreased to 0.00135.
2024-12-01-19:03:37-root-INFO: Loss Change: 1864.496 -> 1842.105
2024-12-01-19:03:37-root-INFO: Regularization Change: 0.000 -> 0.158
2024-12-01-19:03:37-root-INFO: Learning rate of xt decay: 0.07427 -> 0.07517.
2024-12-01-19:03:37-root-INFO: Coefficient of regularization decay: 0.00021 -> 0.00022.
2024-12-01-19:03:37-root-INFO: step: 172 lr_xt 0.00668315
2024-12-01-19:03:38-root-INFO: grad norm: 208.679 206.312 31.345
2024-12-01-19:03:38-root-INFO: Loss too large (1833.762->2362.752)! Learning rate decreased to 0.00535.
2024-12-01-19:03:38-root-INFO: Loss too large (1833.762->2197.953)! Learning rate decreased to 0.00428.
2024-12-01-19:03:39-root-INFO: Loss too large (1833.762->2063.794)! Learning rate decreased to 0.00342.
2024-12-01-19:03:39-root-INFO: Loss too large (1833.762->1960.047)! Learning rate decreased to 0.00274.
2024-12-01-19:03:39-root-INFO: Loss too large (1833.762->1886.426)! Learning rate decreased to 0.00219.
2024-12-01-19:03:40-root-INFO: Loss too large (1833.762->1840.122)! Learning rate decreased to 0.00175.
2024-12-01-19:03:41-root-INFO: grad norm: 257.143 254.426 37.285
2024-12-01-19:03:41-root-INFO: Loss too large (1815.379->1834.313)! Learning rate decreased to 0.00140.
2024-12-01-19:03:41-root-INFO: Loss too large (1815.379->1815.961)! Learning rate decreased to 0.00112.
2024-12-01-19:03:42-root-INFO: Loss Change: 1833.762 -> 1803.921
2024-12-01-19:03:42-root-INFO: Regularization Change: 0.000 -> 0.053
2024-12-01-19:03:42-root-INFO: Learning rate of xt decay: 0.07517 -> 0.07607.
2024-12-01-19:03:42-root-INFO: Coefficient of regularization decay: 0.00022 -> 0.00022.
2024-12-01-19:03:42-root-INFO: step: 171 lr_xt 0.00695416
2024-12-01-19:03:43-root-INFO: grad norm: 169.616 167.090 29.164
2024-12-01-19:03:43-root-INFO: Loss too large (1791.365->2229.012)! Learning rate decreased to 0.00556.
2024-12-01-19:03:43-root-INFO: Loss too large (1791.365->2108.215)! Learning rate decreased to 0.00445.
2024-12-01-19:03:44-root-INFO: Loss too large (1791.365->2007.106)! Learning rate decreased to 0.00356.
2024-12-01-19:03:44-root-INFO: Loss too large (1791.365->1926.446)! Learning rate decreased to 0.00285.
2024-12-01-19:03:44-root-INFO: Loss too large (1791.365->1866.543)! Learning rate decreased to 0.00228.
2024-12-01-19:03:45-root-INFO: Loss too large (1791.365->1825.744)! Learning rate decreased to 0.00182.
2024-12-01-19:03:45-root-INFO: Loss too large (1791.365->1800.539)! Learning rate decreased to 0.00146.
2024-12-01-19:03:46-root-INFO: grad norm: 258.401 256.037 34.876
2024-12-01-19:03:47-root-INFO: Loss too large (1786.639->1806.403)! Learning rate decreased to 0.00117.
2024-12-01-19:03:47-root-INFO: Loss too large (1786.639->1789.289)! Learning rate decreased to 0.00093.
2024-12-01-19:03:48-root-INFO: Loss Change: 1791.365 -> 1778.085
2024-12-01-19:03:48-root-INFO: Regularization Change: 0.000 -> 0.039
2024-12-01-19:03:48-root-INFO: Learning rate of xt decay: 0.07607 -> 0.07698.
2024-12-01-19:03:48-root-INFO: Coefficient of regularization decay: 0.00022 -> 0.00022.
2024-12-01-19:03:48-root-INFO: step: 170 lr_xt 0.00723499
2024-12-01-19:03:48-root-INFO: grad norm: 171.279 168.644 29.928
2024-12-01-19:03:49-root-INFO: Loss too large (1771.126->2232.955)! Learning rate decreased to 0.00579.
2024-12-01-19:03:49-root-INFO: Loss too large (1771.126->2115.607)! Learning rate decreased to 0.00463.
2024-12-01-19:03:49-root-INFO: Loss too large (1771.126->2016.764)! Learning rate decreased to 0.00370.
2024-12-01-19:03:50-root-INFO: Loss too large (1771.126->1935.726)! Learning rate decreased to 0.00296.
2024-12-01-19:03:50-root-INFO: Loss too large (1771.126->1872.682)! Learning rate decreased to 0.00237.
2024-12-01-19:03:50-root-INFO: Loss too large (1771.126->1826.939)! Learning rate decreased to 0.00190.
2024-12-01-19:03:51-root-INFO: Loss too large (1771.126->1796.278)! Learning rate decreased to 0.00152.
2024-12-01-19:03:51-root-INFO: Loss too large (1771.126->1777.441)! Learning rate decreased to 0.00121.
2024-12-01-19:03:52-root-INFO: grad norm: 246.220 243.868 33.951
2024-12-01-19:03:52-root-INFO: Loss too large (1766.990->1778.031)! Learning rate decreased to 0.00097.
2024-12-01-19:03:53-root-INFO: Loss Change: 1771.126 -> 1765.016
2024-12-01-19:03:53-root-INFO: Regularization Change: 0.000 -> 0.037
2024-12-01-19:03:53-root-INFO: Undo step: 170
2024-12-01-19:03:53-root-INFO: Undo step: 171
2024-12-01-19:03:53-root-INFO: Undo step: 172
2024-12-01-19:03:53-root-INFO: Undo step: 173
2024-12-01-19:03:53-root-INFO: Undo step: 174
2024-12-01-19:03:54-root-INFO: step: 175 lr_xt 0.00592610
2024-12-01-19:03:54-root-INFO: grad norm: 583.213 554.839 179.696
2024-12-01-19:03:55-root-INFO: grad norm: 736.676 703.090 219.901
2024-12-01-19:03:55-root-INFO: Loss too large (2566.329->2622.723)! Learning rate decreased to 0.00474.
2024-12-01-19:03:56-root-INFO: Loss Change: 2808.622 -> 2435.134
2024-12-01-19:03:56-root-INFO: Regularization Change: 0.000 -> 9.769
2024-12-01-19:03:56-root-INFO: Learning rate of xt decay: 0.07252 -> 0.07339.
2024-12-01-19:03:56-root-INFO: Coefficient of regularization decay: 0.00021 -> 0.00021.
2024-12-01-19:03:56-root-INFO: step: 174 lr_xt 0.00616941
2024-12-01-19:03:57-root-INFO: grad norm: 340.379 328.440 89.362
2024-12-01-19:03:58-root-INFO: grad norm: 393.609 386.007 76.986
2024-12-01-19:03:58-root-INFO: Loss too large (2222.726->2686.861)! Learning rate decreased to 0.00494.
2024-12-01-19:03:58-root-INFO: Loss too large (2222.726->2423.484)! Learning rate decreased to 0.00395.
2024-12-01-19:03:59-root-INFO: Loss too large (2222.726->2248.917)! Learning rate decreased to 0.00316.
2024-12-01-19:03:59-root-INFO: Loss Change: 2437.426 -> 2144.728
2024-12-01-19:03:59-root-INFO: Regularization Change: 0.000 -> 3.655
2024-12-01-19:03:59-root-INFO: Learning rate of xt decay: 0.07339 -> 0.07427.
2024-12-01-19:03:59-root-INFO: Coefficient of regularization decay: 0.00021 -> 0.00021.
2024-12-01-19:04:00-root-INFO: step: 173 lr_xt 0.00642166
2024-12-01-19:04:00-root-INFO: grad norm: 367.892 363.125 59.030
2024-12-01-19:04:00-root-INFO: Loss too large (2157.802->2485.666)! Learning rate decreased to 0.00514.
2024-12-01-19:04:01-root-INFO: Loss too large (2157.802->2299.089)! Learning rate decreased to 0.00411.
2024-12-01-19:04:01-root-INFO: Loss too large (2157.802->2162.078)! Learning rate decreased to 0.00329.
2024-12-01-19:04:02-root-INFO: grad norm: 298.707 293.898 53.383
2024-12-01-19:04:03-root-INFO: Loss Change: 2157.802 -> 2008.497
2024-12-01-19:04:03-root-INFO: Regularization Change: 0.000 -> 0.593
2024-12-01-19:04:03-root-INFO: Learning rate of xt decay: 0.07427 -> 0.07517.
2024-12-01-19:04:03-root-INFO: Coefficient of regularization decay: 0.00021 -> 0.00022.
2024-12-01-19:04:03-root-INFO: step: 172 lr_xt 0.00668315
2024-12-01-19:04:04-root-INFO: grad norm: 258.556 254.916 43.230
2024-12-01-19:04:04-root-INFO: Loss too large (2011.909->2083.281)! Learning rate decreased to 0.00535.
2024-12-01-19:04:05-root-INFO: grad norm: 389.325 383.595 66.550
2024-12-01-19:04:05-root-INFO: Loss too large (1996.026->2132.949)! Learning rate decreased to 0.00428.
2024-12-01-19:04:06-root-INFO: Loss Change: 2011.909 -> 1949.485
2024-12-01-19:04:06-root-INFO: Regularization Change: 0.000 -> 2.121
2024-12-01-19:04:06-root-INFO: Learning rate of xt decay: 0.07517 -> 0.07607.
2024-12-01-19:04:06-root-INFO: Coefficient of regularization decay: 0.00022 -> 0.00022.
2024-12-01-19:04:06-root-INFO: step: 171 lr_xt 0.00695416
2024-12-01-19:04:07-root-INFO: grad norm: 465.408 460.541 67.134
2024-12-01-19:04:07-root-INFO: Loss too large (1975.860->2209.569)! Learning rate decreased to 0.00556.
2024-12-01-19:04:07-root-INFO: Loss too large (1975.860->2080.664)! Learning rate decreased to 0.00445.
2024-12-01-19:04:08-root-INFO: Loss too large (1975.860->1986.603)! Learning rate decreased to 0.00356.
2024-12-01-19:04:09-root-INFO: grad norm: 191.604 187.725 38.362
2024-12-01-19:04:09-root-INFO: Loss Change: 1975.860 -> 1809.237
2024-12-01-19:04:09-root-INFO: Regularization Change: 0.000 -> 1.403
2024-12-01-19:04:09-root-INFO: Learning rate of xt decay: 0.07607 -> 0.07698.
2024-12-01-19:04:09-root-INFO: Coefficient of regularization decay: 0.00022 -> 0.00022.
2024-12-01-19:04:10-root-INFO: step: 170 lr_xt 0.00723499
2024-12-01-19:04:10-root-INFO: grad norm: 187.397 184.223 34.348
2024-12-01-19:04:10-root-INFO: Loss too large (1805.497->1935.079)! Learning rate decreased to 0.00579.
2024-12-01-19:04:11-root-INFO: Loss too large (1805.497->1836.993)! Learning rate decreased to 0.00463.
2024-12-01-19:04:12-root-INFO: grad norm: 322.286 318.831 47.061
2024-12-01-19:04:12-root-INFO: Loss too large (1774.071->1876.171)! Learning rate decreased to 0.00370.
2024-12-01-19:04:13-root-INFO: Loss too large (1774.071->1838.840)! Learning rate decreased to 0.00296.
2024-12-01-19:04:13-root-INFO: Loss too large (1774.071->1801.991)! Learning rate decreased to 0.00237.
2024-12-01-19:04:14-root-INFO: Loss Change: 1805.497 -> 1769.200
2024-12-01-19:04:14-root-INFO: Regularization Change: 0.000 -> 0.355
2024-12-01-19:04:14-root-INFO: Learning rate of xt decay: 0.07698 -> 0.07790.
2024-12-01-19:04:14-root-INFO: Coefficient of regularization decay: 0.00022 -> 0.00022.
2024-12-01-19:04:14-root-INFO: step: 169 lr_xt 0.00752595
2024-12-01-19:04:14-root-INFO: grad norm: 210.781 206.959 39.959
2024-12-01-19:04:15-root-INFO: Loss too large (1757.564->2075.565)! Learning rate decreased to 0.00602.
2024-12-01-19:04:15-root-INFO: Loss too large (1757.564->1929.854)! Learning rate decreased to 0.00482.
2024-12-01-19:04:15-root-INFO: Loss too large (1757.564->1823.854)! Learning rate decreased to 0.00385.
2024-12-01-19:04:16-root-INFO: grad norm: 353.833 350.340 49.601
2024-12-01-19:04:17-root-INFO: Loss too large (1752.024->1825.740)! Learning rate decreased to 0.00308.
2024-12-01-19:04:17-root-INFO: Loss too large (1752.024->1785.578)! Learning rate decreased to 0.00247.
2024-12-01-19:04:18-root-INFO: Loss Change: 1757.564 -> 1747.762
2024-12-01-19:04:18-root-INFO: Regularization Change: 0.000 -> 0.186
2024-12-01-19:04:18-root-INFO: Learning rate of xt decay: 0.07790 -> 0.07884.
2024-12-01-19:04:18-root-INFO: Coefficient of regularization decay: 0.00022 -> 0.00022.
2024-12-01-19:04:18-root-INFO: step: 168 lr_xt 0.00782735
2024-12-01-19:04:18-root-INFO: grad norm: 212.983 209.284 39.524
2024-12-01-19:04:19-root-INFO: Loss too large (1741.886->2031.059)! Learning rate decreased to 0.00626.
2024-12-01-19:04:19-root-INFO: Loss too large (1741.886->1884.661)! Learning rate decreased to 0.00501.
2024-12-01-19:04:19-root-INFO: Loss too large (1741.886->1779.804)! Learning rate decreased to 0.00401.
2024-12-01-19:04:20-root-INFO: grad norm: 315.927 312.815 44.235
2024-12-01-19:04:21-root-INFO: Loss too large (1710.476->1788.248)! Learning rate decreased to 0.00321.
2024-12-01-19:04:21-root-INFO: Loss too large (1710.476->1748.363)! Learning rate decreased to 0.00256.
2024-12-01-19:04:21-root-INFO: Loss too large (1710.476->1712.167)! Learning rate decreased to 0.00205.
2024-12-01-19:04:22-root-INFO: Loss Change: 1741.886 -> 1683.022
2024-12-01-19:04:22-root-INFO: Regularization Change: 0.000 -> 0.180
2024-12-01-19:04:22-root-INFO: Learning rate of xt decay: 0.07884 -> 0.07979.
2024-12-01-19:04:22-root-INFO: Coefficient of regularization decay: 0.00022 -> 0.00023.
2024-12-01-19:04:22-root-INFO: step: 167 lr_xt 0.00813950
2024-12-01-19:04:23-root-INFO: grad norm: 197.365 194.484 33.596
2024-12-01-19:04:23-root-INFO: Loss too large (1672.674->2048.534)! Learning rate decreased to 0.00651.
2024-12-01-19:04:24-root-INFO: Loss too large (1672.674->1914.344)! Learning rate decreased to 0.00521.
2024-12-01-19:04:24-root-INFO: Loss too large (1672.674->1811.928)! Learning rate decreased to 0.00417.
2024-12-01-19:04:24-root-INFO: Loss too large (1672.674->1735.985)! Learning rate decreased to 0.00333.
2024-12-01-19:04:25-root-INFO: Loss too large (1672.674->1683.410)! Learning rate decreased to 0.00267.
2024-12-01-19:04:26-root-INFO: grad norm: 242.545 240.166 33.887
2024-12-01-19:04:26-root-INFO: Loss too large (1651.324->1677.458)! Learning rate decreased to 0.00213.
2024-12-01-19:04:26-root-INFO: Loss too large (1651.324->1652.705)! Learning rate decreased to 0.00171.
2024-12-01-19:04:27-root-INFO: Loss Change: 1672.674 -> 1635.320
2024-12-01-19:04:27-root-INFO: Regularization Change: 0.000 -> 0.095
2024-12-01-19:04:27-root-INFO: Learning rate of xt decay: 0.07979 -> 0.08074.
2024-12-01-19:04:27-root-INFO: Coefficient of regularization decay: 0.00023 -> 0.00023.
2024-12-01-19:04:27-root-INFO: step: 166 lr_xt 0.00846273
2024-12-01-19:04:28-root-INFO: grad norm: 165.067 162.586 28.513
2024-12-01-19:04:28-root-INFO: Loss too large (1624.139->1955.296)! Learning rate decreased to 0.00677.
2024-12-01-19:04:28-root-INFO: Loss too large (1624.139->1852.255)! Learning rate decreased to 0.00542.
2024-12-01-19:04:29-root-INFO: Loss too large (1624.139->1771.998)! Learning rate decreased to 0.00433.
2024-12-01-19:04:29-root-INFO: Loss too large (1624.139->1711.047)! Learning rate decreased to 0.00347.
2024-12-01-19:04:29-root-INFO: Loss too large (1624.139->1666.985)! Learning rate decreased to 0.00277.
2024-12-01-19:04:30-root-INFO: Loss too large (1624.139->1637.388)! Learning rate decreased to 0.00222.
2024-12-01-19:04:31-root-INFO: grad norm: 223.023 221.066 29.479
2024-12-01-19:04:31-root-INFO: Loss too large (1619.410->1632.724)! Learning rate decreased to 0.00177.
2024-12-01-19:04:32-root-INFO: Loss Change: 1624.139 -> 1614.004
2024-12-01-19:04:32-root-INFO: Regularization Change: 0.000 -> 0.081
2024-12-01-19:04:32-root-INFO: Learning rate of xt decay: 0.08074 -> 0.08171.
2024-12-01-19:04:32-root-INFO: Coefficient of regularization decay: 0.00023 -> 0.00023.
2024-12-01-19:04:32-root-INFO: step: 165 lr_xt 0.00879737
2024-12-01-19:04:32-root-INFO: grad norm: 207.505 204.821 33.266
2024-12-01-19:04:33-root-INFO: Loss too large (1607.420->2117.288)! Learning rate decreased to 0.00704.
2024-12-01-19:04:33-root-INFO: Loss too large (1607.420->1972.697)! Learning rate decreased to 0.00563.
2024-12-01-19:04:33-root-INFO: Loss too large (1607.420->1860.581)! Learning rate decreased to 0.00450.
2024-12-01-19:04:34-root-INFO: Loss too large (1607.420->1773.554)! Learning rate decreased to 0.00360.
2024-12-01-19:04:34-root-INFO: Loss too large (1607.420->1706.816)! Learning rate decreased to 0.00288.
2024-12-01-19:04:35-root-INFO: Loss too large (1607.420->1657.467)! Learning rate decreased to 0.00231.
2024-12-01-19:04:35-root-INFO: Loss too large (1607.420->1623.221)! Learning rate decreased to 0.00184.
2024-12-01-19:04:36-root-INFO: grad norm: 233.524 231.692 29.200
2024-12-01-19:04:36-root-INFO: Loss too large (1601.576->1602.775)! Learning rate decreased to 0.00148.
2024-12-01-19:04:37-root-INFO: Loss Change: 1607.420 -> 1587.157
2024-12-01-19:04:37-root-INFO: Regularization Change: 0.000 -> 0.050
2024-12-01-19:04:37-root-INFO: Undo step: 165
2024-12-01-19:04:37-root-INFO: Undo step: 166
2024-12-01-19:04:37-root-INFO: Undo step: 167
2024-12-01-19:04:37-root-INFO: Undo step: 168
2024-12-01-19:04:37-root-INFO: Undo step: 169
2024-12-01-19:04:37-root-INFO: step: 170 lr_xt 0.00723499
2024-12-01-19:04:38-root-INFO: grad norm: 423.037 413.572 88.988
2024-12-01-19:04:39-root-INFO: grad norm: 429.952 422.606 79.136
2024-12-01-19:04:39-root-INFO: Loss Change: 2416.510 -> 2244.611
2024-12-01-19:04:39-root-INFO: Regularization Change: 0.000 -> 9.263
2024-12-01-19:04:39-root-INFO: Learning rate of xt decay: 0.07698 -> 0.07790.
2024-12-01-19:04:39-root-INFO: Coefficient of regularization decay: 0.00022 -> 0.00022.
2024-12-01-19:04:40-root-INFO: step: 169 lr_xt 0.00752595
2024-12-01-19:04:40-root-INFO: grad norm: 555.229 548.934 83.371
2024-12-01-19:04:41-root-INFO: grad norm: 298.372 292.640 58.206
2024-12-01-19:04:42-root-INFO: Loss Change: 2257.276 -> 1877.874
2024-12-01-19:04:42-root-INFO: Regularization Change: 0.000 -> 10.186
2024-12-01-19:04:42-root-INFO: Learning rate of xt decay: 0.07790 -> 0.07884.
2024-12-01-19:04:42-root-INFO: Coefficient of regularization decay: 0.00022 -> 0.00022.
2024-12-01-19:04:42-root-INFO: step: 168 lr_xt 0.00782735
2024-12-01-19:04:42-root-INFO: grad norm: 292.714 286.911 57.998
2024-12-01-19:04:43-root-INFO: Loss too large (1865.438->2110.361)! Learning rate decreased to 0.00626.
2024-12-01-19:04:43-root-INFO: Loss too large (1865.438->1928.415)! Learning rate decreased to 0.00501.
2024-12-01-19:04:44-root-INFO: grad norm: 382.359 379.537 46.365
2024-12-01-19:04:44-root-INFO: Loss too large (1817.405->1822.793)! Learning rate decreased to 0.00401.
2024-12-01-19:04:45-root-INFO: Loss Change: 1865.438 -> 1787.162
2024-12-01-19:04:45-root-INFO: Regularization Change: 0.000 -> 1.467
2024-12-01-19:04:45-root-INFO: Learning rate of xt decay: 0.07884 -> 0.07979.
2024-12-01-19:04:45-root-INFO: Coefficient of regularization decay: 0.00022 -> 0.00023.
2024-12-01-19:04:46-root-INFO: step: 167 lr_xt 0.00813950
2024-12-01-19:04:46-root-INFO: grad norm: 172.336 167.551 40.331
2024-12-01-19:04:47-root-INFO: grad norm: 255.257 251.138 45.671
2024-12-01-19:04:47-root-INFO: Loss too large (1669.841->1842.659)! Learning rate decreased to 0.00651.
2024-12-01-19:04:48-root-INFO: Loss too large (1669.841->1780.480)! Learning rate decreased to 0.00521.
2024-12-01-19:04:48-root-INFO: Loss too large (1669.841->1722.724)! Learning rate decreased to 0.00417.
2024-12-01-19:04:48-root-INFO: Loss too large (1669.841->1674.137)! Learning rate decreased to 0.00333.
2024-12-01-19:04:49-root-INFO: Loss Change: 1782.816 -> 1638.715
2024-12-01-19:04:49-root-INFO: Regularization Change: 0.000 -> 0.917
2024-12-01-19:04:49-root-INFO: Learning rate of xt decay: 0.07979 -> 0.08074.
2024-12-01-19:04:49-root-INFO: Coefficient of regularization decay: 0.00023 -> 0.00023.
2024-12-01-19:04:49-root-INFO: step: 166 lr_xt 0.00846273
2024-12-01-19:04:50-root-INFO: grad norm: 202.690 197.918 43.724
2024-12-01-19:04:50-root-INFO: Loss too large (1626.066->1904.767)! Learning rate decreased to 0.00677.
2024-12-01-19:04:50-root-INFO: Loss too large (1626.066->1783.032)! Learning rate decreased to 0.00542.
2024-12-01-19:04:51-root-INFO: Loss too large (1626.066->1697.243)! Learning rate decreased to 0.00433.
2024-12-01-19:04:51-root-INFO: Loss too large (1626.066->1638.366)! Learning rate decreased to 0.00347.
2024-12-01-19:04:52-root-INFO: grad norm: 222.957 220.444 33.381
2024-12-01-19:04:52-root-INFO: Loss too large (1601.101->1611.520)! Learning rate decreased to 0.00277.
2024-12-01-19:04:53-root-INFO: Loss Change: 1626.066 -> 1584.810
2024-12-01-19:04:53-root-INFO: Regularization Change: 0.000 -> 0.184
2024-12-01-19:04:53-root-INFO: Learning rate of xt decay: 0.08074 -> 0.08171.
2024-12-01-19:04:53-root-INFO: Coefficient of regularization decay: 0.00023 -> 0.00023.
2024-12-01-19:04:53-root-INFO: step: 165 lr_xt 0.00879737
2024-12-01-19:04:54-root-INFO: grad norm: 199.517 195.311 40.750
2024-12-01-19:04:54-root-INFO: Loss too large (1579.460->1913.234)! Learning rate decreased to 0.00704.
2024-12-01-19:04:54-root-INFO: Loss too large (1579.460->1791.506)! Learning rate decreased to 0.00563.
2024-12-01-19:04:55-root-INFO: Loss too large (1579.460->1703.003)! Learning rate decreased to 0.00450.
2024-12-01-19:04:55-root-INFO: Loss too large (1579.460->1639.253)! Learning rate decreased to 0.00360.
2024-12-01-19:04:55-root-INFO: Loss too large (1579.460->1594.907)! Learning rate decreased to 0.00288.
2024-12-01-19:04:56-root-INFO: grad norm: 210.172 207.869 31.030
2024-12-01-19:04:57-root-INFO: Loss Change: 1579.460 -> 1562.817
2024-12-01-19:04:57-root-INFO: Regularization Change: 0.000 -> 0.140
2024-12-01-19:04:57-root-INFO: Learning rate of xt decay: 0.08171 -> 0.08269.
2024-12-01-19:04:57-root-INFO: Coefficient of regularization decay: 0.00023 -> 0.00023.
2024-12-01-19:04:58-root-INFO: step: 164 lr_xt 0.00914377
2024-12-01-19:04:58-root-INFO: grad norm: 208.145 203.923 41.709
2024-12-01-19:04:58-root-INFO: Loss too large (1553.893->1923.690)! Learning rate decreased to 0.00732.
2024-12-01-19:04:59-root-INFO: Loss too large (1553.893->1792.664)! Learning rate decreased to 0.00585.
2024-12-01-19:04:59-root-INFO: Loss too large (1553.893->1697.354)! Learning rate decreased to 0.00468.
2024-12-01-19:04:59-root-INFO: Loss too large (1553.893->1628.396)! Learning rate decreased to 0.00375.
2024-12-01-19:05:00-root-INFO: Loss too large (1553.893->1579.562)! Learning rate decreased to 0.00300.
2024-12-01-19:05:01-root-INFO: grad norm: 222.661 220.413 31.561
2024-12-01-19:05:01-root-INFO: Loss Change: 1553.893 -> 1539.786
2024-12-01-19:05:01-root-INFO: Regularization Change: 0.000 -> 0.150
2024-12-01-19:05:01-root-INFO: Learning rate of xt decay: 0.08269 -> 0.08368.
2024-12-01-19:05:01-root-INFO: Coefficient of regularization decay: 0.00023 -> 0.00024.
2024-12-01-19:05:02-root-INFO: step: 163 lr_xt 0.00950228
2024-12-01-19:05:02-root-INFO: grad norm: 215.510 211.218 42.796
2024-12-01-19:05:02-root-INFO: Loss too large (1529.900->1921.553)! Learning rate decreased to 0.00760.
2024-12-01-19:05:03-root-INFO: Loss too large (1529.900->1781.261)! Learning rate decreased to 0.00608.
2024-12-01-19:05:03-root-INFO: Loss too large (1529.900->1679.956)! Learning rate decreased to 0.00487.
2024-12-01-19:05:03-root-INFO: Loss too large (1529.900->1607.210)! Learning rate decreased to 0.00389.
2024-12-01-19:05:04-root-INFO: Loss too large (1529.900->1555.783)! Learning rate decreased to 0.00311.
2024-12-01-19:05:05-root-INFO: grad norm: 216.202 214.189 29.432
2024-12-01-19:05:05-root-INFO: Loss Change: 1529.900 -> 1508.053
2024-12-01-19:05:05-root-INFO: Regularization Change: 0.000 -> 0.145
2024-12-01-19:05:06-root-INFO: Learning rate of xt decay: 0.08368 -> 0.08469.
2024-12-01-19:05:06-root-INFO: Coefficient of regularization decay: 0.00024 -> 0.00024.
2024-12-01-19:05:06-root-INFO: step: 162 lr_xt 0.00987325
2024-12-01-19:05:06-root-INFO: grad norm: 202.714 198.670 40.291
2024-12-01-19:05:07-root-INFO: Loss too large (1502.513->1866.755)! Learning rate decreased to 0.00790.
2024-12-01-19:05:07-root-INFO: Loss too large (1502.513->1736.240)! Learning rate decreased to 0.00632.
2024-12-01-19:05:07-root-INFO: Loss too large (1502.513->1642.680)! Learning rate decreased to 0.00506.
2024-12-01-19:05:08-root-INFO: Loss too large (1502.513->1576.039)! Learning rate decreased to 0.00404.
2024-12-01-19:05:08-root-INFO: Loss too large (1502.513->1529.338)! Learning rate decreased to 0.00324.
2024-12-01-19:05:09-root-INFO: grad norm: 207.146 204.938 30.160
2024-12-01-19:05:10-root-INFO: Loss Change: 1502.513 -> 1481.371
2024-12-01-19:05:10-root-INFO: Regularization Change: 0.000 -> 0.167
2024-12-01-19:05:10-root-INFO: Learning rate of xt decay: 0.08469 -> 0.08571.
2024-12-01-19:05:10-root-INFO: Coefficient of regularization decay: 0.00024 -> 0.00024.
2024-12-01-19:05:10-root-INFO: step: 161 lr_xt 0.01025704
2024-12-01-19:05:10-root-INFO: grad norm: 192.248 188.312 38.706
2024-12-01-19:05:11-root-INFO: Loss too large (1472.497->1809.815)! Learning rate decreased to 0.00821.
2024-12-01-19:05:11-root-INFO: Loss too large (1472.497->1688.322)! Learning rate decreased to 0.00656.
2024-12-01-19:05:11-root-INFO: Loss too large (1472.497->1601.814)! Learning rate decreased to 0.00525.
2024-12-01-19:05:12-root-INFO: Loss too large (1472.497->1540.606)! Learning rate decreased to 0.00420.
2024-12-01-19:05:12-root-INFO: Loss too large (1472.497->1497.994)! Learning rate decreased to 0.00336.
2024-12-01-19:05:13-root-INFO: grad norm: 190.768 188.886 26.734
2024-12-01-19:05:14-root-INFO: Loss Change: 1472.497 -> 1449.476
2024-12-01-19:05:14-root-INFO: Regularization Change: 0.000 -> 0.156
2024-12-01-19:05:14-root-INFO: Learning rate of xt decay: 0.08571 -> 0.08673.
2024-12-01-19:05:14-root-INFO: Coefficient of regularization decay: 0.00024 -> 0.00024.
2024-12-01-19:05:14-root-INFO: step: 160 lr_xt 0.01065404
2024-12-01-19:05:15-root-INFO: grad norm: 168.652 165.192 33.986
2024-12-01-19:05:15-root-INFO: Loss too large (1443.519->1717.074)! Learning rate decreased to 0.00852.
2024-12-01-19:05:15-root-INFO: Loss too large (1443.519->1617.517)! Learning rate decreased to 0.00682.
2024-12-01-19:05:16-root-INFO: Loss too large (1443.519->1547.170)! Learning rate decreased to 0.00545.
2024-12-01-19:05:16-root-INFO: Loss too large (1443.519->1497.794)! Learning rate decreased to 0.00436.
2024-12-01-19:05:16-root-INFO: Loss too large (1443.519->1463.843)! Learning rate decreased to 0.00349.
2024-12-01-19:05:17-root-INFO: grad norm: 171.146 169.213 25.654
2024-12-01-19:05:18-root-INFO: Loss Change: 1443.519 -> 1423.226
2024-12-01-19:05:18-root-INFO: Regularization Change: 0.000 -> 0.161
2024-12-01-19:05:18-root-INFO: Undo step: 160
2024-12-01-19:05:18-root-INFO: Undo step: 161
2024-12-01-19:05:18-root-INFO: Undo step: 162
2024-12-01-19:05:18-root-INFO: Undo step: 163
2024-12-01-19:05:18-root-INFO: Undo step: 164
2024-12-01-19:05:18-root-INFO: step: 165 lr_xt 0.00879737
2024-12-01-19:05:19-root-INFO: grad norm: 358.225 349.705 77.663
2024-12-01-19:05:20-root-INFO: grad norm: 491.890 479.815 108.321
2024-12-01-19:05:20-root-INFO: Loss too large (1922.372->2166.186)! Learning rate decreased to 0.00704.
2024-12-01-19:05:21-root-INFO: Loss too large (1922.372->2035.384)! Learning rate decreased to 0.00563.
2024-12-01-19:05:21-root-INFO: Loss too large (1922.372->1934.598)! Learning rate decreased to 0.00450.
2024-12-01-19:05:22-root-INFO: Loss Change: 2159.664 -> 1855.305
2024-12-01-19:05:22-root-INFO: Regularization Change: 0.000 -> 8.991
2024-12-01-19:05:22-root-INFO: Learning rate of xt decay: 0.08171 -> 0.08269.
2024-12-01-19:05:22-root-INFO: Coefficient of regularization decay: 0.00023 -> 0.00023.
2024-12-01-19:05:22-root-INFO: step: 164 lr_xt 0.00914377
2024-12-01-19:05:22-root-INFO: grad norm: 243.604 237.129 55.791
2024-12-01-19:05:23-root-INFO: grad norm: 345.456 339.318 64.831
2024-12-01-19:05:24-root-INFO: Loss too large (1678.507->1723.612)! Learning rate decreased to 0.00732.
2024-12-01-19:05:24-root-INFO: Loss Change: 1849.723 -> 1631.485
2024-12-01-19:05:24-root-INFO: Regularization Change: 0.000 -> 3.976
2024-12-01-19:05:24-root-INFO: Learning rate of xt decay: 0.08269 -> 0.08368.
2024-12-01-19:05:24-root-INFO: Coefficient of regularization decay: 0.00023 -> 0.00024.
2024-12-01-19:05:25-root-INFO: step: 163 lr_xt 0.00950228
2024-12-01-19:05:25-root-INFO: grad norm: 391.117 379.701 93.805
2024-12-01-19:05:25-root-INFO: Loss too large (1613.531->2576.013)! Learning rate decreased to 0.00760.
2024-12-01-19:05:26-root-INFO: Loss too large (1613.531->2261.997)! Learning rate decreased to 0.00608.
2024-12-01-19:05:26-root-INFO: Loss too large (1613.531->2039.107)! Learning rate decreased to 0.00487.
2024-12-01-19:05:26-root-INFO: Loss too large (1613.531->1881.578)! Learning rate decreased to 0.00389.
2024-12-01-19:05:27-root-INFO: Loss too large (1613.531->1769.178)! Learning rate decreased to 0.00311.
2024-12-01-19:05:27-root-INFO: Loss too large (1613.531->1687.683)! Learning rate decreased to 0.00249.
2024-12-01-19:05:27-root-INFO: Loss too large (1613.531->1628.212)! Learning rate decreased to 0.00199.
2024-12-01-19:05:28-root-INFO: grad norm: 340.722 335.090 61.690
2024-12-01-19:05:29-root-INFO: Loss Change: 1613.531 -> 1484.686
2024-12-01-19:05:29-root-INFO: Regularization Change: 0.000 -> 0.448
2024-12-01-19:05:29-root-INFO: Learning rate of xt decay: 0.08368 -> 0.08469.
2024-12-01-19:05:29-root-INFO: Coefficient of regularization decay: 0.00024 -> 0.00024.
2024-12-01-19:05:29-root-INFO: step: 162 lr_xt 0.00987325
2024-12-01-19:05:30-root-INFO: grad norm: 221.137 216.041 47.201
2024-12-01-19:05:30-root-INFO: Loss too large (1469.690->1920.846)! Learning rate decreased to 0.00790.
2024-12-01-19:05:30-root-INFO: Loss too large (1469.690->1774.885)! Learning rate decreased to 0.00632.
2024-12-01-19:05:31-root-INFO: Loss too large (1469.690->1670.933)! Learning rate decreased to 0.00506.
2024-12-01-19:05:31-root-INFO: Loss too large (1469.690->1596.160)! Learning rate decreased to 0.00404.
2024-12-01-19:05:31-root-INFO: Loss too large (1469.690->1542.190)! Learning rate decreased to 0.00324.
2024-12-01-19:05:32-root-INFO: Loss too large (1469.690->1503.761)! Learning rate decreased to 0.00259.
2024-12-01-19:05:32-root-INFO: Loss too large (1469.690->1477.394)! Learning rate decreased to 0.00207.
2024-12-01-19:05:33-root-INFO: grad norm: 228.392 223.467 47.174
2024-12-01-19:05:34-root-INFO: Loss Change: 1469.690 -> 1435.154
2024-12-01-19:05:34-root-INFO: Regularization Change: 0.000 -> 0.192
2024-12-01-19:05:34-root-INFO: Learning rate of xt decay: 0.08469 -> 0.08571.
2024-12-01-19:05:34-root-INFO: Coefficient of regularization decay: 0.00024 -> 0.00024.
2024-12-01-19:05:34-root-INFO: step: 161 lr_xt 0.01025704
2024-12-01-19:05:35-root-INFO: grad norm: 203.053 198.440 43.037
2024-12-01-19:05:35-root-INFO: Loss too large (1424.155->1862.562)! Learning rate decreased to 0.00821.
2024-12-01-19:05:35-root-INFO: Loss too large (1424.155->1728.112)! Learning rate decreased to 0.00656.
2024-12-01-19:05:36-root-INFO: Loss too large (1424.155->1630.891)! Learning rate decreased to 0.00525.
2024-12-01-19:05:36-root-INFO: Loss too large (1424.155->1559.714)! Learning rate decreased to 0.00420.
2024-12-01-19:05:36-root-INFO: Loss too large (1424.155->1507.331)! Learning rate decreased to 0.00336.
2024-12-01-19:05:37-root-INFO: Loss too large (1424.155->1469.206)! Learning rate decreased to 0.00269.
2024-12-01-19:05:37-root-INFO: Loss too large (1424.155->1442.335)! Learning rate decreased to 0.00215.
2024-12-01-19:05:37-root-INFO: Loss too large (1424.155->1424.406)! Learning rate decreased to 0.00172.
2024-12-01-19:05:38-root-INFO: grad norm: 164.635 160.600 36.227
2024-12-01-19:05:39-root-INFO: Loss Change: 1424.155 -> 1394.321
2024-12-01-19:05:39-root-INFO: Regularization Change: 0.000 -> 0.076
2024-12-01-19:05:39-root-INFO: Learning rate of xt decay: 0.08571 -> 0.08673.
2024-12-01-19:05:39-root-INFO: Coefficient of regularization decay: 0.00024 -> 0.00024.
2024-12-01-19:05:39-root-INFO: step: 160 lr_xt 0.01065404
2024-12-01-19:05:40-root-INFO: grad norm: 82.637 79.914 21.035
2024-12-01-19:05:40-root-INFO: Loss too large (1391.092->1392.614)! Learning rate decreased to 0.00852.
2024-12-01-19:05:41-root-INFO: grad norm: 200.430 197.186 35.916
2024-12-01-19:05:41-root-INFO: Loss too large (1383.604->1579.650)! Learning rate decreased to 0.00682.
2024-12-01-19:05:42-root-INFO: Loss too large (1383.604->1554.764)! Learning rate decreased to 0.00545.
2024-12-01-19:05:42-root-INFO: Loss too large (1383.604->1517.624)! Learning rate decreased to 0.00436.
2024-12-01-19:05:42-root-INFO: Loss too large (1383.604->1467.930)! Learning rate decreased to 0.00349.
2024-12-01-19:05:43-root-INFO: Loss too large (1383.604->1415.247)! Learning rate decreased to 0.00279.
2024-12-01-19:05:43-root-INFO: Loss Change: 1391.092 -> 1375.387
2024-12-01-19:05:43-root-INFO: Regularization Change: 0.000 -> 0.643
2024-12-01-19:05:43-root-INFO: Learning rate of xt decay: 0.08673 -> 0.08777.
2024-12-01-19:05:43-root-INFO: Coefficient of regularization decay: 0.00024 -> 0.00024.
2024-12-01-19:05:44-root-INFO: step: 159 lr_xt 0.01106461
2024-12-01-19:05:44-root-INFO: grad norm: 260.013 254.525 53.139
2024-12-01-19:05:44-root-INFO: Loss too large (1366.858->2058.760)! Learning rate decreased to 0.00885.
2024-12-01-19:05:45-root-INFO: Loss too large (1366.858->1842.728)! Learning rate decreased to 0.00708.
2024-12-01-19:05:45-root-INFO: Loss too large (1366.858->1688.739)! Learning rate decreased to 0.00567.
2024-12-01-19:05:46-root-INFO: Loss too large (1366.858->1579.141)! Learning rate decreased to 0.00453.
2024-12-01-19:05:46-root-INFO: Loss too large (1366.858->1500.388)! Learning rate decreased to 0.00363.
2024-12-01-19:05:46-root-INFO: Loss too large (1366.858->1443.306)! Learning rate decreased to 0.00290.
2024-12-01-19:05:47-root-INFO: Loss too large (1366.858->1402.114)! Learning rate decreased to 0.00232.
2024-12-01-19:05:47-root-INFO: Loss too large (1366.858->1373.193)! Learning rate decreased to 0.00186.
2024-12-01-19:05:48-root-INFO: grad norm: 166.915 163.986 31.132
2024-12-01-19:05:49-root-INFO: Loss Change: 1366.858 -> 1327.782
2024-12-01-19:05:49-root-INFO: Regularization Change: 0.000 -> 0.080
2024-12-01-19:05:49-root-INFO: Learning rate of xt decay: 0.08777 -> 0.08883.
2024-12-01-19:05:49-root-INFO: Coefficient of regularization decay: 0.00024 -> 0.00025.
2024-12-01-19:05:49-root-INFO: step: 158 lr_xt 0.01148915
2024-12-01-19:05:49-root-INFO: grad norm: 63.850 60.913 19.143
2024-12-01-19:05:50-root-INFO: grad norm: 100.100 97.840 21.151
2024-12-01-19:05:51-root-INFO: Loss too large (1295.677->1465.958)! Learning rate decreased to 0.00919.
2024-12-01-19:05:51-root-INFO: Loss too large (1295.677->1427.831)! Learning rate decreased to 0.00735.
2024-12-01-19:05:51-root-INFO: Loss too large (1295.677->1386.086)! Learning rate decreased to 0.00588.
2024-12-01-19:05:52-root-INFO: Loss too large (1295.677->1347.806)! Learning rate decreased to 0.00471.
2024-12-01-19:05:52-root-INFO: Loss too large (1295.677->1319.240)! Learning rate decreased to 0.00376.
2024-12-01-19:05:52-root-INFO: Loss too large (1295.677->1301.484)! Learning rate decreased to 0.00301.
2024-12-01-19:05:53-root-INFO: Loss Change: 1326.381 -> 1291.991
2024-12-01-19:05:53-root-INFO: Regularization Change: 0.000 -> 0.723
2024-12-01-19:05:53-root-INFO: Learning rate of xt decay: 0.08883 -> 0.08989.
2024-12-01-19:05:53-root-INFO: Coefficient of regularization decay: 0.00025 -> 0.00025.
2024-12-01-19:05:53-root-INFO: step: 157 lr_xt 0.01192805
2024-12-01-19:05:54-root-INFO: grad norm: 92.518 90.643 18.531
2024-12-01-19:05:54-root-INFO: Loss too large (1282.246->1387.052)! Learning rate decreased to 0.00954.
2024-12-01-19:05:54-root-INFO: Loss too large (1282.246->1350.467)! Learning rate decreased to 0.00763.
2024-12-01-19:05:55-root-INFO: Loss too large (1282.246->1324.336)! Learning rate decreased to 0.00611.
2024-12-01-19:05:55-root-INFO: Loss too large (1282.246->1305.932)! Learning rate decreased to 0.00489.
2024-12-01-19:05:55-root-INFO: Loss too large (1282.246->1293.351)! Learning rate decreased to 0.00391.
2024-12-01-19:05:56-root-INFO: Loss too large (1282.246->1285.136)! Learning rate decreased to 0.00313.
2024-12-01-19:05:57-root-INFO: grad norm: 115.230 112.794 23.567
2024-12-01-19:05:58-root-INFO: Loss Change: 1282.246 -> 1277.005
2024-12-01-19:05:58-root-INFO: Regularization Change: 0.000 -> 0.108
2024-12-01-19:05:58-root-INFO: Learning rate of xt decay: 0.08989 -> 0.09097.
2024-12-01-19:05:58-root-INFO: Coefficient of regularization decay: 0.00025 -> 0.00025.
2024-12-01-19:05:58-root-INFO: step: 156 lr_xt 0.01238172
2024-12-01-19:05:58-root-INFO: grad norm: 132.772 130.578 24.037
2024-12-01-19:05:59-root-INFO: Loss too large (1267.998->1495.773)! Learning rate decreased to 0.00991.
2024-12-01-19:05:59-root-INFO: Loss too large (1267.998->1421.289)! Learning rate decreased to 0.00792.
2024-12-01-19:05:59-root-INFO: Loss too large (1267.998->1368.989)! Learning rate decreased to 0.00634.
2024-12-01-19:06:00-root-INFO: Loss too large (1267.998->1331.742)! Learning rate decreased to 0.00507.
2024-12-01-19:06:00-root-INFO: Loss too large (1267.998->1305.153)! Learning rate decreased to 0.00406.
2024-12-01-19:06:00-root-INFO: Loss too large (1267.998->1286.455)! Learning rate decreased to 0.00325.
2024-12-01-19:06:01-root-INFO: Loss too large (1267.998->1273.758)! Learning rate decreased to 0.00260.
2024-12-01-19:06:02-root-INFO: grad norm: 118.436 116.179 23.016
2024-12-01-19:06:02-root-INFO: Loss Change: 1267.998 -> 1251.642
2024-12-01-19:06:02-root-INFO: Regularization Change: 0.000 -> 0.067
2024-12-01-19:06:02-root-INFO: Learning rate of xt decay: 0.09097 -> 0.09206.
2024-12-01-19:06:02-root-INFO: Coefficient of regularization decay: 0.00025 -> 0.00025.
2024-12-01-19:06:03-root-INFO: step: 155 lr_xt 0.01285057
2024-12-01-19:06:03-root-INFO: grad norm: 61.428 59.253 16.201
2024-12-01-19:06:03-root-INFO: Loss too large (1247.287->1250.944)! Learning rate decreased to 0.01028.
2024-12-01-19:06:04-root-INFO: grad norm: 138.939 137.016 23.036
2024-12-01-19:06:05-root-INFO: Loss too large (1244.396->1436.632)! Learning rate decreased to 0.00822.
2024-12-01-19:06:05-root-INFO: Loss too large (1244.396->1394.566)! Learning rate decreased to 0.00658.
2024-12-01-19:06:05-root-INFO: Loss too large (1244.396->1340.174)! Learning rate decreased to 0.00526.
2024-12-01-19:06:06-root-INFO: Loss too large (1244.396->1284.865)! Learning rate decreased to 0.00421.
2024-12-01-19:06:06-root-INFO: Loss too large (1244.396->1245.230)! Learning rate decreased to 0.00337.
2024-12-01-19:06:07-root-INFO: Loss Change: 1247.287 -> 1225.229
2024-12-01-19:06:07-root-INFO: Regularization Change: 0.000 -> 0.468
2024-12-01-19:06:07-root-INFO: Undo step: 155
2024-12-01-19:06:07-root-INFO: Undo step: 156
2024-12-01-19:06:07-root-INFO: Undo step: 157
2024-12-01-19:06:07-root-INFO: Undo step: 158
2024-12-01-19:06:07-root-INFO: Undo step: 159
2024-12-01-19:06:07-root-INFO: step: 160 lr_xt 0.01065404
2024-12-01-19:06:07-root-INFO: grad norm: 337.590 330.623 68.228
2024-12-01-19:06:08-root-INFO: Loss too large (1717.885->2227.189)! Learning rate decreased to 0.00852.
2024-12-01-19:06:08-root-INFO: Loss too large (1717.885->2003.198)! Learning rate decreased to 0.00682.
2024-12-01-19:06:09-root-INFO: Loss too large (1717.885->1855.830)! Learning rate decreased to 0.00545.
2024-12-01-19:06:09-root-INFO: Loss too large (1717.885->1759.654)! Learning rate decreased to 0.00436.
2024-12-01-19:06:10-root-INFO: grad norm: 324.400 318.907 59.442
2024-12-01-19:06:11-root-INFO: Loss Change: 1717.885 -> 1531.259
2024-12-01-19:06:11-root-INFO: Regularization Change: 0.000 -> 2.243
2024-12-01-19:06:11-root-INFO: Learning rate of xt decay: 0.08673 -> 0.08777.
2024-12-01-19:06:11-root-INFO: Coefficient of regularization decay: 0.00024 -> 0.00024.
2024-12-01-19:06:11-root-INFO: step: 159 lr_xt 0.01106461
2024-12-01-19:06:11-root-INFO: grad norm: 330.579 325.237 59.190
2024-12-01-19:06:12-root-INFO: Loss too large (1521.367->2239.759)! Learning rate decreased to 0.00885.
2024-12-01-19:06:12-root-INFO: Loss too large (1521.367->1993.699)! Learning rate decreased to 0.00708.
2024-12-01-19:06:12-root-INFO: Loss too large (1521.367->1814.012)! Learning rate decreased to 0.00567.
2024-12-01-19:06:13-root-INFO: Loss too large (1521.367->1685.591)! Learning rate decreased to 0.00453.
2024-12-01-19:06:13-root-INFO: Loss too large (1521.367->1594.917)! Learning rate decreased to 0.00363.
2024-12-01-19:06:13-root-INFO: Loss too large (1521.367->1530.802)! Learning rate decreased to 0.00290.
2024-12-01-19:06:14-root-INFO: grad norm: 236.121 232.127 43.249
2024-12-01-19:06:15-root-INFO: Loss Change: 1521.367 -> 1397.989
2024-12-01-19:06:15-root-INFO: Regularization Change: 0.000 -> 0.428
2024-12-01-19:06:15-root-INFO: Learning rate of xt decay: 0.08777 -> 0.08883.
2024-12-01-19:06:15-root-INFO: Coefficient of regularization decay: 0.00024 -> 0.00025.
2024-12-01-19:06:15-root-INFO: step: 158 lr_xt 0.01148915
2024-12-01-19:06:16-root-INFO: grad norm: 115.626 112.648 26.073
2024-12-01-19:06:16-root-INFO: Loss too large (1387.796->1426.015)! Learning rate decreased to 0.00919.
2024-12-01-19:06:16-root-INFO: Loss too large (1387.796->1400.807)! Learning rate decreased to 0.00735.
2024-12-01-19:06:17-root-INFO: grad norm: 202.356 199.993 30.835
2024-12-01-19:06:18-root-INFO: Loss too large (1384.450->1515.186)! Learning rate decreased to 0.00588.
2024-12-01-19:06:18-root-INFO: Loss too large (1384.450->1473.034)! Learning rate decreased to 0.00471.
2024-12-01-19:06:18-root-INFO: Loss too large (1384.450->1418.838)! Learning rate decreased to 0.00376.
2024-12-01-19:06:19-root-INFO: Loss Change: 1387.796 -> 1364.154
2024-12-01-19:06:19-root-INFO: Regularization Change: 0.000 -> 0.871
2024-12-01-19:06:19-root-INFO: Learning rate of xt decay: 0.08883 -> 0.08989.
2024-12-01-19:06:19-root-INFO: Coefficient of regularization decay: 0.00025 -> 0.00025.
2024-12-01-19:06:20-root-INFO: step: 157 lr_xt 0.01192805
2024-12-01-19:06:20-root-INFO: grad norm: 257.233 254.890 34.638
2024-12-01-19:06:20-root-INFO: Loss too large (1340.426->1984.332)! Learning rate decreased to 0.00954.
2024-12-01-19:06:21-root-INFO: Loss too large (1340.426->1781.721)! Learning rate decreased to 0.00763.
2024-12-01-19:06:21-root-INFO: Loss too large (1340.426->1633.642)! Learning rate decreased to 0.00611.
2024-12-01-19:06:21-root-INFO: Loss too large (1340.426->1529.222)! Learning rate decreased to 0.00489.
2024-12-01-19:06:22-root-INFO: Loss too large (1340.426->1456.214)! Learning rate decreased to 0.00391.
2024-12-01-19:06:22-root-INFO: Loss too large (1340.426->1404.780)! Learning rate decreased to 0.00313.
2024-12-01-19:06:22-root-INFO: Loss too large (1340.426->1368.370)! Learning rate decreased to 0.00250.
2024-12-01-19:06:23-root-INFO: Loss too large (1340.426->1342.994)! Learning rate decreased to 0.00200.
2024-12-01-19:06:24-root-INFO: grad norm: 150.572 148.078 27.291
2024-12-01-19:06:24-root-INFO: Loss Change: 1340.426 -> 1297.125
2024-12-01-19:06:24-root-INFO: Regularization Change: 0.000 -> 0.117
2024-12-01-19:06:24-root-INFO: Learning rate of xt decay: 0.08989 -> 0.09097.
2024-12-01-19:06:24-root-INFO: Coefficient of regularization decay: 0.00025 -> 0.00025.
2024-12-01-19:06:25-root-INFO: step: 156 lr_xt 0.01238172
2024-12-01-19:06:25-root-INFO: grad norm: 70.264 67.293 20.213
2024-12-01-19:06:25-root-INFO: Loss too large (1294.769->1309.890)! Learning rate decreased to 0.00991.
2024-12-01-19:06:26-root-INFO: grad norm: 285.972 283.196 39.751
2024-12-01-19:06:27-root-INFO: Loss too large (1292.484->1843.021)! Learning rate decreased to 0.00792.
2024-12-01-19:06:27-root-INFO: Loss too large (1292.484->1659.914)! Learning rate decreased to 0.00634.
2024-12-01-19:06:27-root-INFO: Loss too large (1292.484->1529.743)! Learning rate decreased to 0.00507.
2024-12-01-19:06:28-root-INFO: Loss too large (1292.484->1439.477)! Learning rate decreased to 0.00406.
2024-12-01-19:06:28-root-INFO: Loss too large (1292.484->1376.956)! Learning rate decreased to 0.00325.
2024-12-01-19:06:28-root-INFO: Loss too large (1292.484->1333.275)! Learning rate decreased to 0.00260.
2024-12-01-19:06:29-root-INFO: Loss too large (1292.484->1302.737)! Learning rate decreased to 0.00208.
2024-12-01-19:06:29-root-INFO: Loss Change: 1294.769 -> 1281.881
2024-12-01-19:06:29-root-INFO: Regularization Change: 0.000 -> 0.607
2024-12-01-19:06:29-root-INFO: Learning rate of xt decay: 0.09097 -> 0.09206.
2024-12-01-19:06:29-root-INFO: Coefficient of regularization decay: 0.00025 -> 0.00025.
2024-12-01-19:06:30-root-INFO: step: 155 lr_xt 0.01285057
2024-12-01-19:06:30-root-INFO: grad norm: 158.654 156.779 24.320
2024-12-01-19:06:30-root-INFO: Loss too large (1287.455->1492.463)! Learning rate decreased to 0.01028.
2024-12-01-19:06:31-root-INFO: Loss too large (1287.455->1464.327)! Learning rate decreased to 0.00822.
2024-12-01-19:06:31-root-INFO: Loss too large (1287.455->1422.287)! Learning rate decreased to 0.00658.
2024-12-01-19:06:31-root-INFO: Loss too large (1287.455->1364.639)! Learning rate decreased to 0.00526.
2024-12-01-19:06:32-root-INFO: Loss too large (1287.455->1300.621)! Learning rate decreased to 0.00421.
2024-12-01-19:06:33-root-INFO: grad norm: 218.657 216.731 28.955
2024-12-01-19:06:33-root-INFO: Loss too large (1258.294->1307.565)! Learning rate decreased to 0.00337.
2024-12-01-19:06:33-root-INFO: Loss too large (1258.294->1279.434)! Learning rate decreased to 0.00269.
2024-12-01-19:06:34-root-INFO: Loss too large (1258.294->1260.067)! Learning rate decreased to 0.00216.
2024-12-01-19:06:34-root-INFO: Loss Change: 1287.455 -> 1247.341
2024-12-01-19:06:34-root-INFO: Regularization Change: 0.000 -> 0.148
2024-12-01-19:06:34-root-INFO: Learning rate of xt decay: 0.09206 -> 0.09317.
2024-12-01-19:06:35-root-INFO: Coefficient of regularization decay: 0.00025 -> 0.00026.
2024-12-01-19:06:35-root-INFO: step: 154 lr_xt 0.01333503
2024-12-01-19:06:35-root-INFO: grad norm: 129.164 127.245 22.184
2024-12-01-19:06:36-root-INFO: Loss too large (1251.637->1456.623)! Learning rate decreased to 0.01067.
2024-12-01-19:06:36-root-INFO: Loss too large (1251.637->1420.695)! Learning rate decreased to 0.00853.
2024-12-01-19:06:36-root-INFO: Loss too large (1251.637->1371.330)! Learning rate decreased to 0.00683.
2024-12-01-19:06:37-root-INFO: Loss too large (1251.637->1311.439)! Learning rate decreased to 0.00546.
2024-12-01-19:06:37-root-INFO: Loss too large (1251.637->1260.129)! Learning rate decreased to 0.00437.
2024-12-01-19:06:38-root-INFO: grad norm: 178.103 176.530 23.620
2024-12-01-19:06:38-root-INFO: Loss too large (1232.601->1259.832)! Learning rate decreased to 0.00350.
2024-12-01-19:06:39-root-INFO: Loss too large (1232.601->1240.904)! Learning rate decreased to 0.00280.
2024-12-01-19:06:39-root-INFO: Loss Change: 1251.637 -> 1228.340
2024-12-01-19:06:39-root-INFO: Regularization Change: 0.000 -> 0.146
2024-12-01-19:06:39-root-INFO: Learning rate of xt decay: 0.09317 -> 0.09429.
2024-12-01-19:06:39-root-INFO: Coefficient of regularization decay: 0.00026 -> 0.00026.
2024-12-01-19:06:40-root-INFO: step: 153 lr_xt 0.01383551
2024-12-01-19:06:40-root-INFO: grad norm: 126.031 124.158 21.649
2024-12-01-19:06:40-root-INFO: Loss too large (1232.758->1433.138)! Learning rate decreased to 0.01107.
2024-12-01-19:06:41-root-INFO: Loss too large (1232.758->1392.235)! Learning rate decreased to 0.00885.
2024-12-01-19:06:41-root-INFO: Loss too large (1232.758->1335.459)! Learning rate decreased to 0.00708.
2024-12-01-19:06:41-root-INFO: Loss too large (1232.758->1270.629)! Learning rate decreased to 0.00567.
2024-12-01-19:06:42-root-INFO: grad norm: 250.433 248.410 31.774
2024-12-01-19:06:43-root-INFO: Loss too large (1224.312->1320.652)! Learning rate decreased to 0.00453.
2024-12-01-19:06:43-root-INFO: Loss too large (1224.312->1272.404)! Learning rate decreased to 0.00363.
2024-12-01-19:06:43-root-INFO: Loss too large (1224.312->1239.770)! Learning rate decreased to 0.00290.
2024-12-01-19:06:44-root-INFO: Loss Change: 1232.758 -> 1217.850
2024-12-01-19:06:44-root-INFO: Regularization Change: 0.000 -> 0.212
2024-12-01-19:06:44-root-INFO: Learning rate of xt decay: 0.09429 -> 0.09542.
2024-12-01-19:06:44-root-INFO: Coefficient of regularization decay: 0.00026 -> 0.00026.
2024-12-01-19:06:44-root-INFO: step: 152 lr_xt 0.01435246
2024-12-01-19:06:45-root-INFO: grad norm: 132.401 130.847 20.226
2024-12-01-19:06:45-root-INFO: Loss too large (1221.431->1411.265)! Learning rate decreased to 0.01148.
2024-12-01-19:06:45-root-INFO: Loss too large (1221.431->1365.079)! Learning rate decreased to 0.00919.
2024-12-01-19:06:46-root-INFO: Loss too large (1221.431->1298.742)! Learning rate decreased to 0.00735.
2024-12-01-19:06:46-root-INFO: Loss too large (1221.431->1227.356)! Learning rate decreased to 0.00588.
2024-12-01-19:06:47-root-INFO: grad norm: 167.955 166.493 22.115
2024-12-01-19:06:47-root-INFO: Loss too large (1187.066->1224.999)! Learning rate decreased to 0.00470.
2024-12-01-19:06:48-root-INFO: Loss too large (1187.066->1201.740)! Learning rate decreased to 0.00376.
2024-12-01-19:06:48-root-INFO: Loss Change: 1221.431 -> 1186.349
2024-12-01-19:06:48-root-INFO: Regularization Change: 0.000 -> 0.236
2024-12-01-19:06:49-root-INFO: Learning rate of xt decay: 0.09542 -> 0.09656.
2024-12-01-19:06:49-root-INFO: Coefficient of regularization decay: 0.00026 -> 0.00027.
2024-12-01-19:06:49-root-INFO: step: 151 lr_xt 0.01488633
2024-12-01-19:06:49-root-INFO: grad norm: 116.646 115.071 19.104
2024-12-01-19:06:50-root-INFO: Loss too large (1191.557->1369.364)! Learning rate decreased to 0.01191.
2024-12-01-19:06:50-root-INFO: Loss too large (1191.557->1313.184)! Learning rate decreased to 0.00953.
2024-12-01-19:06:50-root-INFO: Loss too large (1191.557->1239.862)! Learning rate decreased to 0.00762.
2024-12-01-19:06:51-root-INFO: grad norm: 248.012 246.126 30.522
2024-12-01-19:06:52-root-INFO: Loss too large (1181.727->1326.724)! Learning rate decreased to 0.00610.
2024-12-01-19:06:52-root-INFO: Loss too large (1181.727->1257.393)! Learning rate decreased to 0.00488.
2024-12-01-19:06:52-root-INFO: Loss too large (1181.727->1212.090)! Learning rate decreased to 0.00390.
2024-12-01-19:06:53-root-INFO: Loss too large (1181.727->1182.480)! Learning rate decreased to 0.00312.
2024-12-01-19:06:53-root-INFO: Loss Change: 1191.557 -> 1163.382
2024-12-01-19:06:53-root-INFO: Regularization Change: 0.000 -> 0.274
2024-12-01-19:06:53-root-INFO: Learning rate of xt decay: 0.09656 -> 0.09772.
2024-12-01-19:06:53-root-INFO: Coefficient of regularization decay: 0.00027 -> 0.00027.
2024-12-01-19:06:54-root-INFO: step: 150 lr_xt 0.01543756
2024-12-01-19:06:54-root-INFO: grad norm: 107.888 106.493 17.298
2024-12-01-19:06:54-root-INFO: Loss too large (1165.088->1330.771)! Learning rate decreased to 0.01235.
2024-12-01-19:06:55-root-INFO: Loss too large (1165.088->1267.723)! Learning rate decreased to 0.00988.
2024-12-01-19:06:55-root-INFO: Loss too large (1165.088->1193.856)! Learning rate decreased to 0.00790.
2024-12-01-19:06:56-root-INFO: grad norm: 190.849 189.380 23.635
2024-12-01-19:06:56-root-INFO: Loss too large (1146.951->1229.079)! Learning rate decreased to 0.00632.
2024-12-01-19:06:57-root-INFO: Loss too large (1146.951->1186.167)! Learning rate decreased to 0.00506.
2024-12-01-19:06:57-root-INFO: Loss too large (1146.951->1158.284)! Learning rate decreased to 0.00405.
2024-12-01-19:06:58-root-INFO: Loss Change: 1165.088 -> 1140.346
2024-12-01-19:06:58-root-INFO: Regularization Change: 0.000 -> 0.282
2024-12-01-19:06:58-root-INFO: Undo step: 150
2024-12-01-19:06:58-root-INFO: Undo step: 151
2024-12-01-19:06:58-root-INFO: Undo step: 152
2024-12-01-19:06:58-root-INFO: Undo step: 153
2024-12-01-19:06:58-root-INFO: Undo step: 154
2024-12-01-19:06:58-root-INFO: step: 155 lr_xt 0.01285057
2024-12-01-19:06:58-root-INFO: grad norm: 331.984 324.528 69.962
2024-12-01-19:06:59-root-INFO: Loss too large (1727.446->1984.222)! Learning rate decreased to 0.01028.
2024-12-01-19:06:59-root-INFO: Loss too large (1727.446->1774.698)! Learning rate decreased to 0.00822.
2024-12-01-19:07:00-root-INFO: grad norm: 282.923 280.850 34.181
2024-12-01-19:07:01-root-INFO: Loss Change: 1727.446 -> 1435.678
2024-12-01-19:07:01-root-INFO: Regularization Change: 0.000 -> 5.579
2024-12-01-19:07:01-root-INFO: Learning rate of xt decay: 0.09206 -> 0.09317.
2024-12-01-19:07:01-root-INFO: Coefficient of regularization decay: 0.00025 -> 0.00026.
2024-12-01-19:07:01-root-INFO: step: 154 lr_xt 0.01333503
2024-12-01-19:07:02-root-INFO: grad norm: 364.267 359.059 61.378
2024-12-01-19:07:02-root-INFO: Loss too large (1416.686->2275.722)! Learning rate decreased to 0.01067.
2024-12-01-19:07:02-root-INFO: Loss too large (1416.686->1954.106)! Learning rate decreased to 0.00853.
2024-12-01-19:07:03-root-INFO: Loss too large (1416.686->1722.912)! Learning rate decreased to 0.00683.
2024-12-01-19:07:03-root-INFO: Loss too large (1416.686->1562.199)! Learning rate decreased to 0.00546.
2024-12-01-19:07:03-root-INFO: Loss too large (1416.686->1455.178)! Learning rate decreased to 0.00437.
2024-12-01-19:07:04-root-INFO: grad norm: 196.092 194.423 25.533
2024-12-01-19:07:05-root-INFO: Loss Change: 1416.686 -> 1256.583
2024-12-01-19:07:05-root-INFO: Regularization Change: 0.000 -> 1.046
2024-12-01-19:07:05-root-INFO: Learning rate of xt decay: 0.09317 -> 0.09429.
2024-12-01-19:07:05-root-INFO: Coefficient of regularization decay: 0.00026 -> 0.00026.
2024-12-01-19:07:05-root-INFO: step: 153 lr_xt 0.01383551
2024-12-01-19:07:06-root-INFO: grad norm: 100.351 97.986 21.659
2024-12-01-19:07:06-root-INFO: Loss too large (1254.511->1371.729)! Learning rate decreased to 0.01107.
2024-12-01-19:07:06-root-INFO: Loss too large (1254.511->1313.914)! Learning rate decreased to 0.00885.
2024-12-01-19:07:07-root-INFO: Loss too large (1254.511->1264.942)! Learning rate decreased to 0.00708.
2024-12-01-19:07:08-root-INFO: grad norm: 196.467 193.371 34.741
2024-12-01-19:07:08-root-INFO: Loss too large (1238.608->1304.307)! Learning rate decreased to 0.00567.
2024-12-01-19:07:08-root-INFO: Loss too large (1238.608->1267.027)! Learning rate decreased to 0.00453.
2024-12-01-19:07:09-root-INFO: Loss too large (1238.608->1242.454)! Learning rate decreased to 0.00363.
2024-12-01-19:07:09-root-INFO: Loss Change: 1254.511 -> 1226.596
2024-12-01-19:07:09-root-INFO: Regularization Change: 0.000 -> 0.480
2024-12-01-19:07:09-root-INFO: Learning rate of xt decay: 0.09429 -> 0.09542.
2024-12-01-19:07:09-root-INFO: Coefficient of regularization decay: 0.00026 -> 0.00026.
2024-12-01-19:07:10-root-INFO: step: 152 lr_xt 0.01435246
2024-12-01-19:07:10-root-INFO: grad norm: 115.680 114.040 19.411
2024-12-01-19:07:10-root-INFO: Loss too large (1226.609->1375.947)! Learning rate decreased to 0.01148.
2024-12-01-19:07:11-root-INFO: Loss too large (1226.609->1309.116)! Learning rate decreased to 0.00919.
2024-12-01-19:07:11-root-INFO: Loss too large (1226.609->1237.578)! Learning rate decreased to 0.00735.
2024-12-01-19:07:12-root-INFO: grad norm: 174.943 171.843 32.789
2024-12-01-19:07:13-root-INFO: Loss too large (1198.019->1245.764)! Learning rate decreased to 0.00588.
2024-12-01-19:07:13-root-INFO: Loss too large (1198.019->1215.705)! Learning rate decreased to 0.00470.
2024-12-01-19:07:14-root-INFO: Loss Change: 1226.609 -> 1196.270
2024-12-01-19:07:14-root-INFO: Regularization Change: 0.000 -> 0.439
2024-12-01-19:07:14-root-INFO: Learning rate of xt decay: 0.09542 -> 0.09656.
2024-12-01-19:07:14-root-INFO: Coefficient of regularization decay: 0.00026 -> 0.00027.
2024-12-01-19:07:14-root-INFO: step: 151 lr_xt 0.01488633
2024-12-01-19:07:14-root-INFO: grad norm: 116.902 115.175 20.018
2024-12-01-19:07:15-root-INFO: Loss too large (1200.771->1337.538)! Learning rate decreased to 0.01191.
2024-12-01-19:07:15-root-INFO: Loss too large (1200.771->1253.018)! Learning rate decreased to 0.00953.
2024-12-01-19:07:16-root-INFO: grad norm: 243.138 237.647 51.380
2024-12-01-19:07:16-root-INFO: Loss too large (1181.329->1358.583)! Learning rate decreased to 0.00762.
2024-12-01-19:07:17-root-INFO: Loss too large (1181.329->1273.353)! Learning rate decreased to 0.00610.
2024-12-01-19:07:17-root-INFO: Loss too large (1181.329->1218.379)! Learning rate decreased to 0.00488.
2024-12-01-19:07:17-root-INFO: Loss too large (1181.329->1183.249)! Learning rate decreased to 0.00390.
2024-12-01-19:07:18-root-INFO: Loss Change: 1200.771 -> 1161.157
2024-12-01-19:07:18-root-INFO: Regularization Change: 0.000 -> 0.486
2024-12-01-19:07:18-root-INFO: Learning rate of xt decay: 0.09656 -> 0.09772.
2024-12-01-19:07:18-root-INFO: Coefficient of regularization decay: 0.00027 -> 0.00027.
2024-12-01-19:07:18-root-INFO: step: 150 lr_xt 0.01543756
2024-12-01-19:07:19-root-INFO: grad norm: 103.828 102.081 18.966
2024-12-01-19:07:19-root-INFO: Loss too large (1161.305->1268.272)! Learning rate decreased to 0.01235.
2024-12-01-19:07:19-root-INFO: Loss too large (1161.305->1182.719)! Learning rate decreased to 0.00988.
2024-12-01-19:07:20-root-INFO: grad norm: 166.710 161.802 40.152
2024-12-01-19:07:21-root-INFO: Loss too large (1132.392->1205.997)! Learning rate decreased to 0.00790.
2024-12-01-19:07:21-root-INFO: Loss too large (1132.392->1164.956)! Learning rate decreased to 0.00632.
2024-12-01-19:07:21-root-INFO: Loss too large (1132.392->1138.683)! Learning rate decreased to 0.00506.
2024-12-01-19:07:22-root-INFO: Loss Change: 1161.305 -> 1122.242
2024-12-01-19:07:22-root-INFO: Regularization Change: 0.000 -> 0.480
2024-12-01-19:07:22-root-INFO: Learning rate of xt decay: 0.09772 -> 0.09889.
2024-12-01-19:07:22-root-INFO: Coefficient of regularization decay: 0.00027 -> 0.00027.
2024-12-01-19:07:23-root-INFO: step: 149 lr_xt 0.01600663
2024-12-01-19:07:23-root-INFO: grad norm: 95.280 93.226 19.678
2024-12-01-19:07:23-root-INFO: Loss too large (1125.710->1211.042)! Learning rate decreased to 0.01281.
2024-12-01-19:07:24-root-INFO: Loss too large (1125.710->1130.637)! Learning rate decreased to 0.01024.
2024-12-01-19:07:25-root-INFO: grad norm: 121.880 117.245 33.292
2024-12-01-19:07:25-root-INFO: Loss too large (1095.572->1120.764)! Learning rate decreased to 0.00820.
2024-12-01-19:07:25-root-INFO: Loss too large (1095.572->1100.016)! Learning rate decreased to 0.00656.
2024-12-01-19:07:26-root-INFO: Loss Change: 1125.710 -> 1087.379
2024-12-01-19:07:26-root-INFO: Regularization Change: 0.000 -> 0.527
2024-12-01-19:07:26-root-INFO: Learning rate of xt decay: 0.09889 -> 0.10008.
2024-12-01-19:07:26-root-INFO: Coefficient of regularization decay: 0.00027 -> 0.00027.
2024-12-01-19:07:26-root-INFO: step: 148 lr_xt 0.01659399
2024-12-01-19:07:27-root-INFO: grad norm: 84.548 82.267 19.508
2024-12-01-19:07:27-root-INFO: Loss too large (1089.691->1136.980)! Learning rate decreased to 0.01328.
2024-12-01-19:07:28-root-INFO: grad norm: 182.431 172.860 58.313
2024-12-01-19:07:28-root-INFO: Loss too large (1079.623->1222.789)! Learning rate decreased to 0.01062.
2024-12-01-19:07:29-root-INFO: Loss too large (1079.623->1150.887)! Learning rate decreased to 0.00850.
2024-12-01-19:07:29-root-INFO: Loss too large (1079.623->1105.380)! Learning rate decreased to 0.00680.
2024-12-01-19:07:30-root-INFO: Loss Change: 1089.691 -> 1077.010
2024-12-01-19:07:30-root-INFO: Regularization Change: 0.000 -> 0.723
2024-12-01-19:07:30-root-INFO: Learning rate of xt decay: 0.10008 -> 0.10128.
2024-12-01-19:07:30-root-INFO: Coefficient of regularization decay: 0.00027 -> 0.00028.
2024-12-01-19:07:30-root-INFO: step: 147 lr_xt 0.01720013
2024-12-01-19:07:30-root-INFO: grad norm: 98.610 96.326 21.105
2024-12-01-19:07:31-root-INFO: Loss too large (1077.270->1089.711)! Learning rate decreased to 0.01376.
2024-12-01-19:07:32-root-INFO: grad norm: 112.609 106.527 36.507
2024-12-01-19:07:32-root-INFO: Loss too large (1037.609->1062.280)! Learning rate decreased to 0.01101.
2024-12-01-19:07:32-root-INFO: Loss too large (1037.609->1037.625)! Learning rate decreased to 0.00881.
2024-12-01-19:07:33-root-INFO: Loss Change: 1077.270 -> 1023.545
2024-12-01-19:07:33-root-INFO: Regularization Change: 0.000 -> 0.821
2024-12-01-19:07:33-root-INFO: Learning rate of xt decay: 0.10128 -> 0.10250.
2024-12-01-19:07:33-root-INFO: Coefficient of regularization decay: 0.00028 -> 0.00028.
2024-12-01-19:07:34-root-INFO: step: 146 lr_xt 0.01782554
2024-12-01-19:07:34-root-INFO: grad norm: 73.063 70.643 18.648
2024-12-01-19:07:35-root-INFO: grad norm: 140.622 132.000 48.482
2024-12-01-19:07:35-root-INFO: Loss too large (1013.676->1133.263)! Learning rate decreased to 0.01426.
2024-12-01-19:07:36-root-INFO: Loss too large (1013.676->1065.990)! Learning rate decreased to 0.01141.
2024-12-01-19:07:36-root-INFO: Loss too large (1013.676->1025.064)! Learning rate decreased to 0.00913.
2024-12-01-19:07:37-root-INFO: Loss Change: 1024.247 -> 1000.989
2024-12-01-19:07:37-root-INFO: Regularization Change: 0.000 -> 0.884
2024-12-01-19:07:37-root-INFO: Learning rate of xt decay: 0.10250 -> 0.10373.
2024-12-01-19:07:37-root-INFO: Coefficient of regularization decay: 0.00028 -> 0.00028.
2024-12-01-19:07:37-root-INFO: step: 145 lr_xt 0.01847071
2024-12-01-19:07:37-root-INFO: grad norm: 85.783 83.367 20.219
2024-12-01-19:07:38-root-INFO: grad norm: 122.107 117.204 34.256
2024-12-01-19:07:39-root-INFO: Loss too large (992.265->1046.047)! Learning rate decreased to 0.01478.
2024-12-01-19:07:39-root-INFO: Loss too large (992.265->998.039)! Learning rate decreased to 0.01182.
2024-12-01-19:07:40-root-INFO: Loss Change: 1005.197 -> 971.680
2024-12-01-19:07:40-root-INFO: Regularization Change: 0.000 -> 1.007
2024-12-01-19:07:40-root-INFO: Undo step: 145
2024-12-01-19:07:40-root-INFO: Undo step: 146
2024-12-01-19:07:40-root-INFO: Undo step: 147
2024-12-01-19:07:40-root-INFO: Undo step: 148
2024-12-01-19:07:40-root-INFO: Undo step: 149
2024-12-01-19:07:40-root-INFO: step: 150 lr_xt 0.01543756
2024-12-01-19:07:40-root-INFO: grad norm: 219.931 215.956 41.626
2024-12-01-19:07:41-root-INFO: grad norm: 305.009 282.710 114.479
2024-12-01-19:07:42-root-INFO: Loss too large (1284.894->1695.329)! Learning rate decreased to 0.01235.
2024-12-01-19:07:42-root-INFO: Loss too large (1284.894->1476.019)! Learning rate decreased to 0.00988.
2024-12-01-19:07:43-root-INFO: Loss too large (1284.894->1341.862)! Learning rate decreased to 0.00790.
2024-12-01-19:07:43-root-INFO: Loss Change: 1411.816 -> 1262.035
2024-12-01-19:07:43-root-INFO: Regularization Change: 0.000 -> 10.176
2024-12-01-19:07:43-root-INFO: Learning rate of xt decay: 0.09772 -> 0.09889.
2024-12-01-19:07:43-root-INFO: Coefficient of regularization decay: 0.00027 -> 0.00027.
2024-12-01-19:07:44-root-INFO: step: 149 lr_xt 0.01600663
2024-12-01-19:07:44-root-INFO: grad norm: 183.240 179.748 35.600
2024-12-01-19:07:45-root-INFO: grad norm: 264.940 250.665 85.793
2024-12-01-19:07:45-root-INFO: Loss too large (1149.507->1440.677)! Learning rate decreased to 0.01281.
2024-12-01-19:07:46-root-INFO: Loss too large (1149.507->1269.510)! Learning rate decreased to 0.01024.
2024-12-01-19:07:46-root-INFO: Loss too large (1149.507->1167.233)! Learning rate decreased to 0.00820.
2024-12-01-19:07:47-root-INFO: Loss Change: 1269.367 -> 1108.101
2024-12-01-19:07:47-root-INFO: Regularization Change: 0.000 -> 3.400
2024-12-01-19:07:47-root-INFO: Learning rate of xt decay: 0.09889 -> 0.10008.
2024-12-01-19:07:47-root-INFO: Coefficient of regularization decay: 0.00027 -> 0.00027.
2024-12-01-19:07:47-root-INFO: step: 148 lr_xt 0.01659399
2024-12-01-19:07:47-root-INFO: grad norm: 122.309 118.682 29.567
2024-12-01-19:07:48-root-INFO: grad norm: 81.235 79.289 17.676
2024-12-01-19:07:49-root-INFO: Loss Change: 1109.218 -> 990.231
2024-12-01-19:07:49-root-INFO: Regularization Change: 0.000 -> 3.118
2024-12-01-19:07:49-root-INFO: Learning rate of xt decay: 0.10008 -> 0.10128.
2024-12-01-19:07:49-root-INFO: Coefficient of regularization decay: 0.00027 -> 0.00028.
2024-12-01-19:07:49-root-INFO: step: 147 lr_xt 0.01720013
2024-12-01-19:07:50-root-INFO: grad norm: 72.422 70.168 17.928
2024-12-01-19:07:51-root-INFO: grad norm: 79.608 77.880 16.495
2024-12-01-19:07:51-root-INFO: Loss too large (960.503->961.834)! Learning rate decreased to 0.01376.
2024-12-01-19:07:52-root-INFO: Loss Change: 988.443 -> 948.172
2024-12-01-19:07:52-root-INFO: Regularization Change: 0.000 -> 1.372
2024-12-01-19:07:52-root-INFO: Learning rate of xt decay: 0.10128 -> 0.10250.
2024-12-01-19:07:52-root-INFO: Coefficient of regularization decay: 0.00028 -> 0.00028.
2024-12-01-19:07:52-root-INFO: step: 146 lr_xt 0.01782554
2024-12-01-19:07:53-root-INFO: grad norm: 71.027 69.236 15.848
2024-12-01-19:07:54-root-INFO: grad norm: 84.726 83.222 15.894
2024-12-01-19:07:54-root-INFO: Loss too large (930.243->934.539)! Learning rate decreased to 0.01426.
2024-12-01-19:07:55-root-INFO: Loss Change: 947.776 -> 917.765
2024-12-01-19:07:55-root-INFO: Regularization Change: 0.000 -> 1.015
2024-12-01-19:07:55-root-INFO: Learning rate of xt decay: 0.10250 -> 0.10373.
2024-12-01-19:07:55-root-INFO: Coefficient of regularization decay: 0.00028 -> 0.00028.
2024-12-01-19:07:55-root-INFO: step: 145 lr_xt 0.01847071
2024-12-01-19:07:55-root-INFO: grad norm: 71.009 69.271 15.614
2024-12-01-19:07:56-root-INFO: grad norm: 80.286 79.035 14.118
2024-12-01-19:07:57-root-INFO: Loss too large (899.915->903.761)! Learning rate decreased to 0.01478.
2024-12-01-19:07:57-root-INFO: Loss Change: 918.605 -> 887.130
2024-12-01-19:07:57-root-INFO: Regularization Change: 0.000 -> 0.951
2024-12-01-19:07:57-root-INFO: Learning rate of xt decay: 0.10373 -> 0.10497.
2024-12-01-19:07:57-root-INFO: Coefficient of regularization decay: 0.00028 -> 0.00028.
2024-12-01-19:07:58-root-INFO: step: 144 lr_xt 0.01913614
2024-12-01-19:07:58-root-INFO: grad norm: 67.802 66.260 14.376
2024-12-01-19:07:59-root-INFO: grad norm: 78.590 77.500 13.042
2024-12-01-19:07:59-root-INFO: Loss too large (873.109->878.490)! Learning rate decreased to 0.01531.
2024-12-01-19:08:00-root-INFO: Loss Change: 887.725 -> 860.512
2024-12-01-19:08:00-root-INFO: Regularization Change: 0.000 -> 0.884
2024-12-01-19:08:00-root-INFO: Learning rate of xt decay: 0.10497 -> 0.10623.
2024-12-01-19:08:00-root-INFO: Coefficient of regularization decay: 0.00028 -> 0.00029.
2024-12-01-19:08:00-root-INFO: step: 143 lr_xt 0.01982236
2024-12-01-19:08:01-root-INFO: grad norm: 67.805 66.471 13.383
2024-12-01-19:08:02-root-INFO: grad norm: 81.288 80.267 12.840
2024-12-01-19:08:02-root-INFO: Loss too large (850.829->857.227)! Learning rate decreased to 0.01586.
2024-12-01-19:08:03-root-INFO: Loss Change: 860.497 -> 837.254
2024-12-01-19:08:03-root-INFO: Regularization Change: 0.000 -> 0.834
2024-12-01-19:08:03-root-INFO: Learning rate of xt decay: 0.10623 -> 0.10751.
2024-12-01-19:08:03-root-INFO: Coefficient of regularization decay: 0.00029 -> 0.00029.
2024-12-01-19:08:03-root-INFO: step: 142 lr_xt 0.02052986
2024-12-01-19:08:04-root-INFO: grad norm: 68.945 67.593 13.584
2024-12-01-19:08:05-root-INFO: grad norm: 79.667 78.732 12.172
2024-12-01-19:08:05-root-INFO: Loss too large (826.813->834.144)! Learning rate decreased to 0.01642.
2024-12-01-19:08:06-root-INFO: Loss Change: 839.143 -> 813.681
2024-12-01-19:08:06-root-INFO: Regularization Change: 0.000 -> 0.852
2024-12-01-19:08:06-root-INFO: Learning rate of xt decay: 0.10751 -> 0.10880.
2024-12-01-19:08:06-root-INFO: Coefficient of regularization decay: 0.00029 -> 0.00029.
2024-12-01-19:08:06-root-INFO: step: 141 lr_xt 0.02125920
2024-12-01-19:08:06-root-INFO: grad norm: 65.952 64.797 12.290
2024-12-01-19:08:07-root-INFO: grad norm: 76.657 75.780 11.561
2024-12-01-19:08:08-root-INFO: Loss too large (804.610->808.707)! Learning rate decreased to 0.01701.
2024-12-01-19:08:08-root-INFO: Loss Change: 813.682 -> 790.271
2024-12-01-19:08:08-root-INFO: Regularization Change: 0.000 -> 0.805
2024-12-01-19:08:08-root-INFO: Learning rate of xt decay: 0.10880 -> 0.11010.
2024-12-01-19:08:08-root-INFO: Coefficient of regularization decay: 0.00029 -> 0.00030.
2024-12-01-19:08:09-root-INFO: step: 140 lr_xt 0.02201089
2024-12-01-19:08:09-root-INFO: grad norm: 61.995 60.913 11.530
2024-12-01-19:08:10-root-INFO: grad norm: 70.787 70.017 10.410
2024-12-01-19:08:10-root-INFO: Loss too large (779.250->785.819)! Learning rate decreased to 0.01761.
2024-12-01-19:08:11-root-INFO: Loss Change: 791.842 -> 768.711
2024-12-01-19:08:11-root-INFO: Regularization Change: 0.000 -> 0.818
2024-12-01-19:08:11-root-INFO: Undo step: 140
2024-12-01-19:08:11-root-INFO: Undo step: 141
2024-12-01-19:08:11-root-INFO: Undo step: 142
2024-12-01-19:08:11-root-INFO: Undo step: 143
2024-12-01-19:08:11-root-INFO: Undo step: 144
2024-12-01-19:08:12-root-INFO: step: 145 lr_xt 0.01847071
2024-12-01-19:08:12-root-INFO: grad norm: 167.659 163.063 38.986
2024-12-01-19:08:13-root-INFO: grad norm: 96.159 92.893 24.851
2024-12-01-19:08:14-root-INFO: Loss Change: 1147.843 -> 904.525
2024-12-01-19:08:14-root-INFO: Regularization Change: 0.000 -> 10.351
2024-12-01-19:08:14-root-INFO: Learning rate of xt decay: 0.10373 -> 0.10497.
2024-12-01-19:08:14-root-INFO: Coefficient of regularization decay: 0.00028 -> 0.00028.
2024-12-01-19:08:14-root-INFO: step: 144 lr_xt 0.01913614
2024-12-01-19:08:14-root-INFO: grad norm: 86.212 83.735 20.515
2024-12-01-19:08:15-root-INFO: grad norm: 92.531 90.312 20.143
2024-12-01-19:08:16-root-INFO: Loss Change: 894.979 -> 847.503
2024-12-01-19:08:16-root-INFO: Regularization Change: 0.000 -> 3.066
2024-12-01-19:08:16-root-INFO: Learning rate of xt decay: 0.10497 -> 0.10623.
2024-12-01-19:08:16-root-INFO: Coefficient of regularization decay: 0.00028 -> 0.00029.
2024-12-01-19:08:16-root-INFO: step: 143 lr_xt 0.01982236
2024-12-01-19:08:17-root-INFO: grad norm: 98.799 96.701 20.252
2024-12-01-19:08:18-root-INFO: grad norm: 110.254 108.558 19.260
2024-12-01-19:08:19-root-INFO: Loss Change: 838.119 -> 827.068
2024-12-01-19:08:19-root-INFO: Regularization Change: 0.000 -> 1.690
2024-12-01-19:08:19-root-INFO: Learning rate of xt decay: 0.10623 -> 0.10751.
2024-12-01-19:08:19-root-INFO: Coefficient of regularization decay: 0.00029 -> 0.00029.
2024-12-01-19:08:19-root-INFO: step: 142 lr_xt 0.02052986
2024-12-01-19:08:19-root-INFO: grad norm: 99.182 97.587 17.716
2024-12-01-19:08:20-root-INFO: grad norm: 94.454 93.027 16.357
2024-12-01-19:08:21-root-INFO: Loss Change: 815.706 -> 780.201
2024-12-01-19:08:21-root-INFO: Regularization Change: 0.000 -> 1.383
2024-12-01-19:08:21-root-INFO: Learning rate of xt decay: 0.10751 -> 0.10880.
2024-12-01-19:08:21-root-INFO: Coefficient of regularization decay: 0.00029 -> 0.00029.
2024-12-01-19:08:21-root-INFO: step: 141 lr_xt 0.02125920
2024-12-01-19:08:22-root-INFO: grad norm: 83.605 82.220 15.154
2024-12-01-19:08:23-root-INFO: grad norm: 82.491 81.243 14.295
2024-12-01-19:08:23-root-INFO: Loss Change: 772.934 -> 750.914
2024-12-01-19:08:23-root-INFO: Regularization Change: 0.000 -> 0.990
2024-12-01-19:08:23-root-INFO: Learning rate of xt decay: 0.10880 -> 0.11010.
2024-12-01-19:08:23-root-INFO: Coefficient of regularization decay: 0.00029 -> 0.00030.
2024-12-01-19:08:24-root-INFO: step: 140 lr_xt 0.02201089
2024-12-01-19:08:24-root-INFO: grad norm: 73.254 71.991 13.544
2024-12-01-19:08:25-root-INFO: grad norm: 77.255 76.006 13.839
2024-12-01-19:08:25-root-INFO: Loss too large (728.627->731.414)! Learning rate decreased to 0.01761.
2024-12-01-19:08:26-root-INFO: Loss Change: 744.012 -> 714.644
2024-12-01-19:08:26-root-INFO: Regularization Change: 0.000 -> 0.882
2024-12-01-19:08:26-root-INFO: Learning rate of xt decay: 0.11010 -> 0.11142.
2024-12-01-19:08:26-root-INFO: Coefficient of regularization decay: 0.00030 -> 0.00030.
2024-12-01-19:08:26-root-INFO: step: 139 lr_xt 0.02278550
2024-12-01-19:08:27-root-INFO: grad norm: 50.590 49.347 11.148
2024-12-01-19:08:28-root-INFO: grad norm: 52.918 51.919 10.236
2024-12-01-19:08:28-root-INFO: Loss too large (695.628->697.458)! Learning rate decreased to 0.01823.
2024-12-01-19:08:29-root-INFO: Loss Change: 712.203 -> 689.540
2024-12-01-19:08:29-root-INFO: Regularization Change: 0.000 -> 0.731
2024-12-01-19:08:29-root-INFO: Learning rate of xt decay: 0.11142 -> 0.11276.
2024-12-01-19:08:29-root-INFO: Coefficient of regularization decay: 0.00030 -> 0.00030.
2024-12-01-19:08:29-root-INFO: step: 138 lr_xt 0.02358356
2024-12-01-19:08:29-root-INFO: grad norm: 41.556 40.435 9.587
2024-12-01-19:08:30-root-INFO: grad norm: 52.115 51.210 9.667
2024-12-01-19:08:31-root-INFO: Loss too large (677.570->681.598)! Learning rate decreased to 0.01887.
2024-12-01-19:08:32-root-INFO: Loss Change: 687.504 -> 674.287
2024-12-01-19:08:32-root-INFO: Regularization Change: 0.000 -> 0.669
2024-12-01-19:08:32-root-INFO: Learning rate of xt decay: 0.11276 -> 0.11411.
2024-12-01-19:08:32-root-INFO: Coefficient of regularization decay: 0.00030 -> 0.00030.
2024-12-01-19:08:32-root-INFO: step: 137 lr_xt 0.02440563
2024-12-01-19:08:32-root-INFO: grad norm: 41.209 40.158 9.251
2024-12-01-19:08:33-root-INFO: grad norm: 43.989 43.294 7.790
2024-12-01-19:08:34-root-INFO: Loss too large (658.695->659.992)! Learning rate decreased to 0.01952.
2024-12-01-19:08:34-root-INFO: Loss Change: 672.969 -> 654.481
2024-12-01-19:08:34-root-INFO: Regularization Change: 0.000 -> 0.715
2024-12-01-19:08:34-root-INFO: Learning rate of xt decay: 0.11411 -> 0.11548.
2024-12-01-19:08:34-root-INFO: Coefficient of regularization decay: 0.00030 -> 0.00031.
2024-12-01-19:08:35-root-INFO: step: 136 lr_xt 0.02525230
2024-12-01-19:08:35-root-INFO: grad norm: 37.299 36.438 7.971
2024-12-01-19:08:36-root-INFO: grad norm: 48.009 47.304 8.197
2024-12-01-19:08:36-root-INFO: Loss too large (645.043->648.941)! Learning rate decreased to 0.02020.
2024-12-01-19:08:37-root-INFO: Loss Change: 653.526 -> 642.387
2024-12-01-19:08:37-root-INFO: Regularization Change: 0.000 -> 0.656
2024-12-01-19:08:37-root-INFO: Learning rate of xt decay: 0.11548 -> 0.11687.
2024-12-01-19:08:37-root-INFO: Coefficient of regularization decay: 0.00031 -> 0.00031.
2024-12-01-19:08:38-root-INFO: step: 135 lr_xt 0.02612413
2024-12-01-19:08:38-root-INFO: grad norm: 38.241 37.448 7.748
2024-12-01-19:08:39-root-INFO: grad norm: 40.412 39.834 6.811
2024-12-01-19:08:39-root-INFO: Loss too large (628.120->629.138)! Learning rate decreased to 0.02090.
2024-12-01-19:08:40-root-INFO: Loss Change: 641.234 -> 623.933
2024-12-01-19:08:40-root-INFO: Regularization Change: 0.000 -> 0.674
2024-12-01-19:08:40-root-INFO: Undo step: 135
2024-12-01-19:08:40-root-INFO: Undo step: 136
2024-12-01-19:08:40-root-INFO: Undo step: 137
2024-12-01-19:08:40-root-INFO: Undo step: 138
2024-12-01-19:08:40-root-INFO: Undo step: 139
2024-12-01-19:08:40-root-INFO: step: 140 lr_xt 0.02201089
2024-12-01-19:08:41-root-INFO: grad norm: 144.274 140.583 32.426
2024-12-01-19:08:42-root-INFO: grad norm: 113.967 111.496 23.605
2024-12-01-19:08:42-root-INFO: Loss Change: 989.556 -> 772.779
2024-12-01-19:08:42-root-INFO: Regularization Change: 0.000 -> 11.228
2024-12-01-19:08:42-root-INFO: Learning rate of xt decay: 0.11010 -> 0.11142.
2024-12-01-19:08:42-root-INFO: Coefficient of regularization decay: 0.00030 -> 0.00030.
2024-12-01-19:08:43-root-INFO: step: 139 lr_xt 0.02278550
2024-12-01-19:08:43-root-INFO: grad norm: 83.668 81.467 19.065
2024-12-01-19:08:44-root-INFO: grad norm: 77.157 75.379 16.469
2024-12-01-19:08:45-root-INFO: Loss Change: 772.098 -> 706.848
2024-12-01-19:08:45-root-INFO: Regularization Change: 0.000 -> 4.048
2024-12-01-19:08:45-root-INFO: Learning rate of xt decay: 0.11142 -> 0.11276.
2024-12-01-19:08:45-root-INFO: Coefficient of regularization decay: 0.00030 -> 0.00030.
2024-12-01-19:08:45-root-INFO: step: 138 lr_xt 0.02358356
2024-12-01-19:08:45-root-INFO: grad norm: 87.233 85.855 15.442
2024-12-01-19:08:46-root-INFO: Loss too large (710.216->714.068)! Learning rate decreased to 0.01887.
2024-12-01-19:08:47-root-INFO: grad norm: 76.369 74.594 16.370
2024-12-01-19:08:48-root-INFO: Loss Change: 710.216 -> 673.021
2024-12-01-19:08:48-root-INFO: Regularization Change: 0.000 -> 1.134
2024-12-01-19:08:48-root-INFO: Learning rate of xt decay: 0.11276 -> 0.11411.
2024-12-01-19:08:48-root-INFO: Coefficient of regularization decay: 0.00030 -> 0.00030.
2024-12-01-19:08:48-root-INFO: step: 137 lr_xt 0.02440563
2024-12-01-19:08:48-root-INFO: grad norm: 74.487 73.272 13.396
2024-12-01-19:08:49-root-INFO: grad norm: 97.916 96.076 18.891
2024-12-01-19:08:50-root-INFO: Loss too large (669.950->707.084)! Learning rate decreased to 0.01952.
2024-12-01-19:08:50-root-INFO: Loss Change: 678.454 -> 666.830
2024-12-01-19:08:50-root-INFO: Regularization Change: 0.000 -> 1.113
2024-12-01-19:08:50-root-INFO: Learning rate of xt decay: 0.11411 -> 0.11548.
2024-12-01-19:08:50-root-INFO: Coefficient of regularization decay: 0.00030 -> 0.00031.
2024-12-01-19:08:51-root-INFO: step: 136 lr_xt 0.02525230
2024-12-01-19:08:51-root-INFO: grad norm: 80.973 79.932 12.943
2024-12-01-19:08:52-root-INFO: grad norm: 82.695 81.469 14.187
2024-12-01-19:08:52-root-INFO: Loss too large (651.254->662.867)! Learning rate decreased to 0.02020.
2024-12-01-19:08:53-root-INFO: Loss Change: 670.017 -> 633.318
2024-12-01-19:08:53-root-INFO: Regularization Change: 0.000 -> 1.082
2024-12-01-19:08:53-root-INFO: Learning rate of xt decay: 0.11548 -> 0.11687.
2024-12-01-19:08:53-root-INFO: Coefficient of regularization decay: 0.00031 -> 0.00031.
2024-12-01-19:08:53-root-INFO: step: 135 lr_xt 0.02612413
2024-12-01-19:08:54-root-INFO: grad norm: 73.304 72.246 12.413
2024-12-01-19:08:54-root-INFO: Loss too large (636.707->641.956)! Learning rate decreased to 0.02090.
2024-12-01-19:08:55-root-INFO: grad norm: 50.289 49.496 8.892
2024-12-01-19:08:56-root-INFO: Loss Change: 636.707 -> 601.144
2024-12-01-19:08:56-root-INFO: Regularization Change: 0.000 -> 1.082
2024-12-01-19:08:56-root-INFO: Learning rate of xt decay: 0.11687 -> 0.11827.
2024-12-01-19:08:56-root-INFO: Coefficient of regularization decay: 0.00031 -> 0.00031.
2024-12-01-19:08:56-root-INFO: step: 134 lr_xt 0.02702170
2024-12-01-19:08:57-root-INFO: grad norm: 39.457 38.761 7.375
2024-12-01-19:08:58-root-INFO: grad norm: 46.031 45.471 7.160
2024-12-01-19:08:58-root-INFO: Loss too large (597.860->598.029)! Learning rate decreased to 0.02162.
2024-12-01-19:08:59-root-INFO: Loss Change: 602.763 -> 589.080
2024-12-01-19:08:59-root-INFO: Regularization Change: 0.000 -> 0.722
2024-12-01-19:08:59-root-INFO: Learning rate of xt decay: 0.11827 -> 0.11969.
2024-12-01-19:08:59-root-INFO: Coefficient of regularization decay: 0.00031 -> 0.00032.
2024-12-01-19:08:59-root-INFO: step: 133 lr_xt 0.02794561
2024-12-01-19:08:59-root-INFO: grad norm: 45.569 44.895 7.809
2024-12-01-19:09:00-root-INFO: Loss too large (591.461->593.796)! Learning rate decreased to 0.02236.
2024-12-01-19:09:01-root-INFO: grad norm: 43.635 43.031 7.238
2024-12-01-19:09:01-root-INFO: Loss Change: 591.461 -> 582.385
2024-12-01-19:09:01-root-INFO: Regularization Change: 0.000 -> 0.601
2024-12-01-19:09:01-root-INFO: Learning rate of xt decay: 0.11969 -> 0.12113.
2024-12-01-19:09:01-root-INFO: Coefficient of regularization decay: 0.00032 -> 0.00032.
2024-12-01-19:09:02-root-INFO: step: 132 lr_xt 0.02889645
2024-12-01-19:09:02-root-INFO: grad norm: 61.738 61.024 9.364
2024-12-01-19:09:03-root-INFO: Loss too large (585.012->600.615)! Learning rate decreased to 0.02312.
2024-12-01-19:09:03-root-INFO: Loss too large (585.012->587.881)! Learning rate decreased to 0.01849.
2024-12-01-19:09:04-root-INFO: grad norm: 39.501 38.823 7.287
2024-12-01-19:09:05-root-INFO: Loss Change: 585.012 -> 562.108
2024-12-01-19:09:05-root-INFO: Regularization Change: 0.000 -> 0.580
2024-12-01-19:09:05-root-INFO: Learning rate of xt decay: 0.12113 -> 0.12258.
2024-12-01-19:09:05-root-INFO: Coefficient of regularization decay: 0.00032 -> 0.00032.
2024-12-01-19:09:05-root-INFO: step: 131 lr_xt 0.02987484
2024-12-01-19:09:05-root-INFO: grad norm: 25.262 24.611 5.700
2024-12-01-19:09:06-root-INFO: grad norm: 32.085 31.586 5.638
2024-12-01-19:09:07-root-INFO: Loss too large (558.125->560.741)! Learning rate decreased to 0.02390.
2024-12-01-19:09:07-root-INFO: Loss Change: 563.363 -> 555.020
2024-12-01-19:09:07-root-INFO: Regularization Change: 0.000 -> 0.730
2024-12-01-19:09:07-root-INFO: Learning rate of xt decay: 0.12258 -> 0.12405.
2024-12-01-19:09:07-root-INFO: Coefficient of regularization decay: 0.00032 -> 0.00033.
2024-12-01-19:09:08-root-INFO: step: 130 lr_xt 0.03088137
2024-12-01-19:09:08-root-INFO: grad norm: 42.354 41.802 6.812
2024-12-01-19:09:08-root-INFO: Loss too large (556.607->569.132)! Learning rate decreased to 0.02471.
2024-12-01-19:09:09-root-INFO: Loss too large (556.607->557.598)! Learning rate decreased to 0.01976.
2024-12-01-19:09:10-root-INFO: grad norm: 37.211 36.651 6.435
2024-12-01-19:09:11-root-INFO: Loss Change: 556.607 -> 545.686
2024-12-01-19:09:11-root-INFO: Regularization Change: 0.000 -> 0.382
2024-12-01-19:09:11-root-INFO: Undo step: 130
2024-12-01-19:09:11-root-INFO: Undo step: 131
2024-12-01-19:09:11-root-INFO: Undo step: 132
2024-12-01-19:09:11-root-INFO: Undo step: 133
2024-12-01-19:09:11-root-INFO: Undo step: 134
2024-12-01-19:09:11-root-INFO: step: 135 lr_xt 0.02612413
2024-12-01-19:09:11-root-INFO: grad norm: 139.128 135.248 32.626
2024-12-01-19:09:12-root-INFO: grad norm: 92.128 90.132 19.076
2024-12-01-19:09:13-root-INFO: Loss Change: 897.658 -> 667.150
2024-12-01-19:09:13-root-INFO: Regularization Change: 0.000 -> 16.276
2024-12-01-19:09:13-root-INFO: Learning rate of xt decay: 0.11687 -> 0.11827.
2024-12-01-19:09:13-root-INFO: Coefficient of regularization decay: 0.00031 -> 0.00031.
2024-12-01-19:09:13-root-INFO: step: 134 lr_xt 0.02702170
2024-12-01-19:09:14-root-INFO: grad norm: 64.457 62.638 15.206
2024-12-01-19:09:15-root-INFO: grad norm: 58.285 56.794 13.097
2024-12-01-19:09:15-root-INFO: Loss Change: 667.268 -> 603.829
2024-12-01-19:09:15-root-INFO: Regularization Change: 0.000 -> 4.174
2024-12-01-19:09:15-root-INFO: Learning rate of xt decay: 0.11827 -> 0.11969.
2024-12-01-19:09:15-root-INFO: Coefficient of regularization decay: 0.00031 -> 0.00032.
2024-12-01-19:09:16-root-INFO: step: 133 lr_xt 0.02794561
2024-12-01-19:09:16-root-INFO: grad norm: 63.086 61.771 12.817
2024-12-01-19:09:17-root-INFO: grad norm: 65.660 64.602 11.738
2024-12-01-19:09:18-root-INFO: Loss Change: 606.899 -> 590.024
2024-12-01-19:09:18-root-INFO: Regularization Change: 0.000 -> 1.573
2024-12-01-19:09:18-root-INFO: Learning rate of xt decay: 0.11969 -> 0.12113.
2024-12-01-19:09:18-root-INFO: Coefficient of regularization decay: 0.00032 -> 0.00032.
2024-12-01-19:09:18-root-INFO: step: 132 lr_xt 0.02889645
2024-12-01-19:09:19-root-INFO: grad norm: 67.350 66.282 11.945
2024-12-01-19:09:20-root-INFO: grad norm: 58.406 57.400 10.791
2024-12-01-19:09:20-root-INFO: Loss Change: 593.601 -> 563.080
2024-12-01-19:09:20-root-INFO: Regularization Change: 0.000 -> 1.172
2024-12-01-19:09:20-root-INFO: Learning rate of xt decay: 0.12113 -> 0.12258.
2024-12-01-19:09:20-root-INFO: Coefficient of regularization decay: 0.00032 -> 0.00032.
2024-12-01-19:09:21-root-INFO: step: 131 lr_xt 0.02987484
2024-12-01-19:09:21-root-INFO: grad norm: 54.093 53.068 10.481
2024-12-01-19:09:22-root-INFO: grad norm: 48.604 47.625 9.710
2024-12-01-19:09:23-root-INFO: Loss Change: 566.947 -> 545.479
2024-12-01-19:09:23-root-INFO: Regularization Change: 0.000 -> 0.957
2024-12-01-19:09:23-root-INFO: Learning rate of xt decay: 0.12258 -> 0.12405.
2024-12-01-19:09:23-root-INFO: Coefficient of regularization decay: 0.00032 -> 0.00033.
2024-12-01-19:09:23-root-INFO: step: 130 lr_xt 0.03088137
2024-12-01-19:09:23-root-INFO: grad norm: 49.153 48.260 9.327
2024-12-01-19:09:24-root-INFO: grad norm: 48.122 47.240 9.173
2024-12-01-19:09:25-root-INFO: Loss Change: 547.411 -> 534.228
2024-12-01-19:09:25-root-INFO: Regularization Change: 0.000 -> 0.819
2024-12-01-19:09:25-root-INFO: Learning rate of xt decay: 0.12405 -> 0.12554.
2024-12-01-19:09:25-root-INFO: Coefficient of regularization decay: 0.00033 -> 0.00033.
2024-12-01-19:09:25-root-INFO: step: 129 lr_xt 0.03191668
2024-12-01-19:09:26-root-INFO: grad norm: 52.762 51.877 9.620
2024-12-01-19:09:27-root-INFO: grad norm: 51.123 50.328 8.979
2024-12-01-19:09:27-root-INFO: Loss Change: 537.645 -> 524.081
2024-12-01-19:09:28-root-INFO: Regularization Change: 0.000 -> 0.792
2024-12-01-19:09:28-root-INFO: Learning rate of xt decay: 0.12554 -> 0.12705.
2024-12-01-19:09:28-root-INFO: Coefficient of regularization decay: 0.00033 -> 0.00033.
2024-12-01-19:09:28-root-INFO: step: 128 lr_xt 0.03298138
2024-12-01-19:09:28-root-INFO: grad norm: 52.519 51.709 9.189
2024-12-01-19:09:29-root-INFO: grad norm: 48.967 48.258 8.301
2024-12-01-19:09:30-root-INFO: Loss Change: 527.246 -> 511.226
2024-12-01-19:09:30-root-INFO: Regularization Change: 0.000 -> 0.772
2024-12-01-19:09:30-root-INFO: Learning rate of xt decay: 0.12705 -> 0.12857.
2024-12-01-19:09:30-root-INFO: Coefficient of regularization decay: 0.00033 -> 0.00034.
2024-12-01-19:09:30-root-INFO: step: 127 lr_xt 0.03407612
2024-12-01-19:09:31-root-INFO: grad norm: 48.943 48.249 8.212
2024-12-01-19:09:32-root-INFO: grad norm: 46.821 46.163 7.822
2024-12-01-19:09:32-root-INFO: Loss Change: 514.057 -> 500.983
2024-12-01-19:09:32-root-INFO: Regularization Change: 0.000 -> 0.740
2024-12-01-19:09:32-root-INFO: Learning rate of xt decay: 0.12857 -> 0.13011.
2024-12-01-19:09:32-root-INFO: Coefficient of regularization decay: 0.00034 -> 0.00034.
2024-12-01-19:09:33-root-INFO: step: 126 lr_xt 0.03520152
2024-12-01-19:09:33-root-INFO: grad norm: 47.580 46.949 7.724
2024-12-01-19:09:34-root-INFO: grad norm: 47.273 46.666 7.551
2024-12-01-19:09:35-root-INFO: Loss Change: 502.507 -> 492.883
2024-12-01-19:09:35-root-INFO: Regularization Change: 0.000 -> 0.730
2024-12-01-19:09:35-root-INFO: Learning rate of xt decay: 0.13011 -> 0.13168.
2024-12-01-19:09:35-root-INFO: Coefficient of regularization decay: 0.00034 -> 0.00034.
2024-12-01-19:09:35-root-INFO: step: 125 lr_xt 0.03635823
2024-12-01-19:09:35-root-INFO: grad norm: 50.740 50.103 8.017
2024-12-01-19:09:36-root-INFO: grad norm: 49.854 49.237 7.817
2024-12-01-19:09:37-root-INFO: Loss Change: 495.174 -> 484.528
2024-12-01-19:09:37-root-INFO: Regularization Change: 0.000 -> 0.739
2024-12-01-19:09:37-root-INFO: Undo step: 125
2024-12-01-19:09:37-root-INFO: Undo step: 126
2024-12-01-19:09:37-root-INFO: Undo step: 127
2024-12-01-19:09:37-root-INFO: Undo step: 128
2024-12-01-19:09:37-root-INFO: Undo step: 129
2024-12-01-19:09:38-root-INFO: step: 130 lr_xt 0.03088137
2024-12-01-19:09:38-root-INFO: grad norm: 117.398 115.507 20.984
2024-12-01-19:09:39-root-INFO: grad norm: 60.402 58.840 13.646
2024-12-01-19:09:40-root-INFO: Loss Change: 829.052 -> 561.480
2024-12-01-19:09:40-root-INFO: Regularization Change: 0.000 -> 17.684
2024-12-01-19:09:40-root-INFO: Learning rate of xt decay: 0.12405 -> 0.12554.
2024-12-01-19:09:40-root-INFO: Coefficient of regularization decay: 0.00033 -> 0.00033.
2024-12-01-19:09:40-root-INFO: step: 129 lr_xt 0.03191668
2024-12-01-19:09:40-root-INFO: grad norm: 42.336 41.320 9.217
2024-12-01-19:09:41-root-INFO: grad norm: 40.660 39.795 8.344
2024-12-01-19:09:42-root-INFO: Loss Change: 559.614 -> 526.924
2024-12-01-19:09:42-root-INFO: Regularization Change: 0.000 -> 2.690
2024-12-01-19:09:42-root-INFO: Learning rate of xt decay: 0.12554 -> 0.12705.
2024-12-01-19:09:42-root-INFO: Coefficient of regularization decay: 0.00033 -> 0.00033.
2024-12-01-19:09:43-root-INFO: step: 128 lr_xt 0.03298138
2024-12-01-19:09:43-root-INFO: grad norm: 45.672 44.879 8.475
2024-12-01-19:09:44-root-INFO: grad norm: 52.248 51.593 8.252
2024-12-01-19:09:44-root-INFO: Loss too large (517.669->519.002)! Learning rate decreased to 0.02639.
2024-12-01-19:09:45-root-INFO: Loss Change: 528.112 -> 506.950
2024-12-01-19:09:45-root-INFO: Regularization Change: 0.000 -> 1.249
2024-12-01-19:09:45-root-INFO: Learning rate of xt decay: 0.12705 -> 0.12857.
2024-12-01-19:09:45-root-INFO: Coefficient of regularization decay: 0.00033 -> 0.00034.
2024-12-01-19:09:45-root-INFO: step: 127 lr_xt 0.03407612
2024-12-01-19:09:46-root-INFO: grad norm: 42.660 42.061 7.122
2024-12-01-19:09:47-root-INFO: grad norm: 49.692 49.219 6.839
2024-12-01-19:09:47-root-INFO: Loss too large (500.364->505.240)! Learning rate decreased to 0.02726.
2024-12-01-19:09:48-root-INFO: Loss Change: 507.984 -> 492.231
2024-12-01-19:09:48-root-INFO: Regularization Change: 0.000 -> 0.923
2024-12-01-19:09:48-root-INFO: Learning rate of xt decay: 0.12857 -> 0.13011.
2024-12-01-19:09:48-root-INFO: Coefficient of regularization decay: 0.00034 -> 0.00034.
2024-12-01-19:09:48-root-INFO: step: 126 lr_xt 0.03520152
2024-12-01-19:09:48-root-INFO: grad norm: 42.620 42.121 6.506
2024-12-01-19:09:49-root-INFO: grad norm: 49.670 49.257 6.391
2024-12-01-19:09:50-root-INFO: Loss too large (488.784->493.374)! Learning rate decreased to 0.02816.
2024-12-01-19:09:50-root-INFO: Loss Change: 493.782 -> 479.882
2024-12-01-19:09:50-root-INFO: Regularization Change: 0.000 -> 0.763
2024-12-01-19:09:50-root-INFO: Learning rate of xt decay: 0.13011 -> 0.13168.
2024-12-01-19:09:50-root-INFO: Coefficient of regularization decay: 0.00034 -> 0.00034.
2024-12-01-19:09:51-root-INFO: step: 125 lr_xt 0.03635823
2024-12-01-19:09:51-root-INFO: grad norm: 41.916 41.429 6.371
2024-12-01-19:09:52-root-INFO: grad norm: 46.580 46.181 6.086
2024-12-01-19:09:52-root-INFO: Loss too large (476.453->478.922)! Learning rate decreased to 0.02909.
2024-12-01-19:09:53-root-INFO: Loss Change: 481.884 -> 466.818
2024-12-01-19:09:53-root-INFO: Regularization Change: 0.000 -> 0.712
2024-12-01-19:09:53-root-INFO: Learning rate of xt decay: 0.13168 -> 0.13326.
2024-12-01-19:09:53-root-INFO: Coefficient of regularization decay: 0.00034 -> 0.00035.
2024-12-01-19:09:54-root-INFO: step: 124 lr_xt 0.03773645
2024-12-01-19:09:54-root-INFO: grad norm: 40.773 40.260 6.446
2024-12-01-19:09:55-root-INFO: grad norm: 45.116 44.721 5.955
2024-12-01-19:09:55-root-INFO: Loss too large (465.770->467.770)! Learning rate decreased to 0.03019.
2024-12-01-19:09:56-root-INFO: Loss Change: 470.477 -> 455.963
2024-12-01-19:09:56-root-INFO: Regularization Change: 0.000 -> 0.714
2024-12-01-19:09:56-root-INFO: Learning rate of xt decay: 0.13326 -> 0.13485.
2024-12-01-19:09:56-root-INFO: Coefficient of regularization decay: 0.00035 -> 0.00035.
2024-12-01-19:09:56-root-INFO: step: 123 lr_xt 0.03896235
2024-12-01-19:09:57-root-INFO: grad norm: 36.515 36.104 5.469
2024-12-01-19:09:58-root-INFO: grad norm: 41.385 41.046 5.285
2024-12-01-19:09:58-root-INFO: Loss too large (454.066->456.481)! Learning rate decreased to 0.03117.
2024-12-01-19:09:59-root-INFO: Loss Change: 457.862 -> 445.895
2024-12-01-19:09:59-root-INFO: Regularization Change: 0.000 -> 0.642
2024-12-01-19:09:59-root-INFO: Learning rate of xt decay: 0.13485 -> 0.13647.
2024-12-01-19:09:59-root-INFO: Coefficient of regularization decay: 0.00035 -> 0.00035.
2024-12-01-19:09:59-root-INFO: step: 122 lr_xt 0.04022160
2024-12-01-19:09:59-root-INFO: grad norm: 34.732 34.350 5.133
2024-12-01-19:10:00-root-INFO: grad norm: 40.102 39.789 5.000
2024-12-01-19:10:01-root-INFO: Loss too large (444.793->447.348)! Learning rate decreased to 0.03218.
2024-12-01-19:10:01-root-INFO: Loss Change: 447.492 -> 436.983
2024-12-01-19:10:01-root-INFO: Regularization Change: 0.000 -> 0.622
2024-12-01-19:10:01-root-INFO: Learning rate of xt decay: 0.13647 -> 0.13811.
2024-12-01-19:10:01-root-INFO: Coefficient of regularization decay: 0.00035 -> 0.00036.
2024-12-01-19:10:02-root-INFO: step: 121 lr_xt 0.04151486
2024-12-01-19:10:02-root-INFO: grad norm: 34.089 33.735 4.903
2024-12-01-19:10:03-root-INFO: grad norm: 39.598 39.312 4.753
2024-12-01-19:10:03-root-INFO: Loss too large (436.229->439.117)! Learning rate decreased to 0.03321.
2024-12-01-19:10:04-root-INFO: Loss Change: 438.490 -> 428.583
2024-12-01-19:10:04-root-INFO: Regularization Change: 0.000 -> 0.610
2024-12-01-19:10:04-root-INFO: Learning rate of xt decay: 0.13811 -> 0.13977.
2024-12-01-19:10:04-root-INFO: Coefficient of regularization decay: 0.00036 -> 0.00036.
2024-12-01-19:10:05-root-INFO: step: 120 lr_xt 0.04284282
2024-12-01-19:10:05-root-INFO: grad norm: 34.023 33.688 4.763
2024-12-01-19:10:06-root-INFO: grad norm: 39.459 39.190 4.593
2024-12-01-19:10:06-root-INFO: Loss too large (428.852->431.868)! Learning rate decreased to 0.03427.
2024-12-01-19:10:07-root-INFO: Loss Change: 430.817 -> 421.018
2024-12-01-19:10:07-root-INFO: Regularization Change: 0.000 -> 0.612
2024-12-01-19:10:07-root-INFO: Undo step: 120
2024-12-01-19:10:07-root-INFO: Undo step: 121
2024-12-01-19:10:07-root-INFO: Undo step: 122
2024-12-01-19:10:07-root-INFO: Undo step: 123
2024-12-01-19:10:07-root-INFO: Undo step: 124
2024-12-01-19:10:07-root-INFO: step: 125 lr_xt 0.03635823
2024-12-01-19:10:08-root-INFO: grad norm: 102.731 101.395 16.517
2024-12-01-19:10:09-root-INFO: grad norm: 71.283 70.157 12.616
2024-12-01-19:10:09-root-INFO: Loss Change: 712.340 -> 526.416
2024-12-01-19:10:09-root-INFO: Regularization Change: 0.000 -> 14.728
2024-12-01-19:10:09-root-INFO: Learning rate of xt decay: 0.13168 -> 0.13326.
2024-12-01-19:10:09-root-INFO: Coefficient of regularization decay: 0.00034 -> 0.00035.
2024-12-01-19:10:10-root-INFO: step: 124 lr_xt 0.03773645
2024-12-01-19:10:10-root-INFO: grad norm: 53.888 53.040 9.523
2024-12-01-19:10:11-root-INFO: grad norm: 46.316 45.604 8.091
2024-12-01-19:10:12-root-INFO: Loss Change: 520.706 -> 469.312
2024-12-01-19:10:12-root-INFO: Regularization Change: 0.000 -> 3.898
2024-12-01-19:10:12-root-INFO: Learning rate of xt decay: 0.13326 -> 0.13485.
2024-12-01-19:10:12-root-INFO: Coefficient of regularization decay: 0.00035 -> 0.00035.
2024-12-01-19:10:12-root-INFO: step: 123 lr_xt 0.03896235
2024-12-01-19:10:12-root-INFO: grad norm: 42.076 41.458 7.183
2024-12-01-19:10:13-root-INFO: grad norm: 41.441 40.884 6.771
2024-12-01-19:10:14-root-INFO: Loss Change: 466.734 -> 449.964
2024-12-01-19:10:14-root-INFO: Regularization Change: 0.000 -> 1.440
2024-12-01-19:10:14-root-INFO: Learning rate of xt decay: 0.13485 -> 0.13647.
2024-12-01-19:10:14-root-INFO: Coefficient of regularization decay: 0.00035 -> 0.00035.
2024-12-01-19:10:15-root-INFO: step: 122 lr_xt 0.04022160
2024-12-01-19:10:15-root-INFO: grad norm: 40.030 39.574 6.026
2024-12-01-19:10:16-root-INFO: grad norm: 40.631 40.161 6.165
2024-12-01-19:10:17-root-INFO: Loss Change: 447.320 -> 436.857
2024-12-01-19:10:17-root-INFO: Regularization Change: 0.000 -> 1.075
2024-12-01-19:10:17-root-INFO: Learning rate of xt decay: 0.13647 -> 0.13811.
2024-12-01-19:10:17-root-INFO: Coefficient of regularization decay: 0.00035 -> 0.00036.
2024-12-01-19:10:17-root-INFO: step: 121 lr_xt 0.04151486
2024-12-01-19:10:17-root-INFO: grad norm: 41.033 40.661 5.517
2024-12-01-19:10:18-root-INFO: grad norm: 40.547 40.095 6.041
2024-12-01-19:10:19-root-INFO: Loss Change: 434.633 -> 424.184
2024-12-01-19:10:19-root-INFO: Regularization Change: 0.000 -> 0.955
2024-12-01-19:10:19-root-INFO: Learning rate of xt decay: 0.13811 -> 0.13977.
2024-12-01-19:10:19-root-INFO: Coefficient of regularization decay: 0.00036 -> 0.00036.
2024-12-01-19:10:19-root-INFO: step: 120 lr_xt 0.04284282
2024-12-01-19:10:20-root-INFO: grad norm: 38.268 37.956 4.877
2024-12-01-19:10:20-root-INFO: Loss too large (422.341->422.989)! Learning rate decreased to 0.03427.
2024-12-01-19:10:21-root-INFO: grad norm: 29.053 28.708 4.463
2024-12-01-19:10:22-root-INFO: Loss Change: 422.341 -> 405.549
2024-12-01-19:10:22-root-INFO: Regularization Change: 0.000 -> 0.667
2024-12-01-19:10:22-root-INFO: Learning rate of xt decay: 0.13977 -> 0.14145.
2024-12-01-19:10:22-root-INFO: Coefficient of regularization decay: 0.00036 -> 0.00036.
2024-12-01-19:10:22-root-INFO: step: 119 lr_xt 0.04420613
2024-12-01-19:10:23-root-INFO: grad norm: 22.686 22.336 3.969
2024-12-01-19:10:24-root-INFO: grad norm: 27.215 26.849 4.452
2024-12-01-19:10:24-root-INFO: Loss Change: 404.602 -> 402.422
2024-12-01-19:10:24-root-INFO: Regularization Change: 0.000 -> 0.878
2024-12-01-19:10:24-root-INFO: Learning rate of xt decay: 0.14145 -> 0.14314.
2024-12-01-19:10:24-root-INFO: Coefficient of regularization decay: 0.00036 -> 0.00037.
2024-12-01-19:10:25-root-INFO: step: 118 lr_xt 0.04560549
2024-12-01-19:10:25-root-INFO: grad norm: 35.297 34.942 4.994
2024-12-01-19:10:25-root-INFO: Loss too large (402.576->407.529)! Learning rate decreased to 0.03648.
2024-12-01-19:10:26-root-INFO: grad norm: 30.020 29.655 4.667
2024-12-01-19:10:27-root-INFO: Loss Change: 402.576 -> 390.683
2024-12-01-19:10:27-root-INFO: Regularization Change: 0.000 -> 0.537
2024-12-01-19:10:27-root-INFO: Learning rate of xt decay: 0.14314 -> 0.14486.
2024-12-01-19:10:27-root-INFO: Coefficient of regularization decay: 0.00037 -> 0.00037.
2024-12-01-19:10:27-root-INFO: step: 117 lr_xt 0.04704158
2024-12-01-19:10:28-root-INFO: grad norm: 25.503 25.170 4.113
2024-12-01-19:10:28-root-INFO: Loss too large (390.580->391.545)! Learning rate decreased to 0.03763.
2024-12-01-19:10:29-root-INFO: grad norm: 23.441 23.142 3.729
2024-12-01-19:10:30-root-INFO: Loss Change: 390.580 -> 382.622
2024-12-01-19:10:30-root-INFO: Regularization Change: 0.000 -> 0.518
2024-12-01-19:10:30-root-INFO: Learning rate of xt decay: 0.14486 -> 0.14660.
2024-12-01-19:10:30-root-INFO: Coefficient of regularization decay: 0.00037 -> 0.00038.
2024-12-01-19:10:30-root-INFO: step: 116 lr_xt 0.04851508
2024-12-01-19:10:31-root-INFO: grad norm: 22.575 22.274 3.672
2024-12-01-19:10:31-root-INFO: Loss too large (382.509->383.039)! Learning rate decreased to 0.03881.
2024-12-01-19:10:32-root-INFO: grad norm: 21.494 21.209 3.486
2024-12-01-19:10:33-root-INFO: Loss Change: 382.509 -> 375.700
2024-12-01-19:10:33-root-INFO: Regularization Change: 0.000 -> 0.502
2024-12-01-19:10:33-root-INFO: Learning rate of xt decay: 0.14660 -> 0.14836.
2024-12-01-19:10:33-root-INFO: Coefficient of regularization decay: 0.00038 -> 0.00038.
2024-12-01-19:10:33-root-INFO: step: 115 lr_xt 0.05002669
2024-12-01-19:10:33-root-INFO: grad norm: 21.602 21.305 3.573
2024-12-01-19:10:34-root-INFO: Loss too large (375.882->376.396)! Learning rate decreased to 0.04002.
2024-12-01-19:10:35-root-INFO: grad norm: 20.851 20.574 3.384
2024-12-01-19:10:35-root-INFO: Loss Change: 375.882 -> 369.506
2024-12-01-19:10:35-root-INFO: Regularization Change: 0.000 -> 0.505
2024-12-01-19:10:35-root-INFO: Undo step: 115
2024-12-01-19:10:35-root-INFO: Undo step: 116
2024-12-01-19:10:36-root-INFO: Undo step: 117
2024-12-01-19:10:36-root-INFO: Undo step: 118
2024-12-01-19:10:36-root-INFO: Undo step: 119
2024-12-01-19:10:36-root-INFO: step: 120 lr_xt 0.04284282
2024-12-01-19:10:36-root-INFO: grad norm: 95.252 93.173 19.791
2024-12-01-19:10:37-root-INFO: grad norm: 53.117 52.420 8.577
2024-12-01-19:10:38-root-INFO: Loss Change: 646.448 -> 452.391
2024-12-01-19:10:38-root-INFO: Regularization Change: 0.000 -> 19.544
2024-12-01-19:10:38-root-INFO: Learning rate of xt decay: 0.13977 -> 0.14145.
2024-12-01-19:10:38-root-INFO: Coefficient of regularization decay: 0.00036 -> 0.00036.
2024-12-01-19:10:38-root-INFO: step: 119 lr_xt 0.04420613
2024-12-01-19:10:39-root-INFO: grad norm: 45.084 44.452 7.518
2024-12-01-19:10:40-root-INFO: grad norm: 43.038 42.673 5.597
2024-12-01-19:10:40-root-INFO: Loss Change: 450.822 -> 420.458
2024-12-01-19:10:40-root-INFO: Regularization Change: 0.000 -> 3.266
2024-12-01-19:10:40-root-INFO: Learning rate of xt decay: 0.14145 -> 0.14314.
2024-12-01-19:10:40-root-INFO: Coefficient of regularization decay: 0.00036 -> 0.00037.
2024-12-01-19:10:41-root-INFO: step: 118 lr_xt 0.04560549
2024-12-01-19:10:41-root-INFO: grad norm: 41.701 41.292 5.825
2024-12-01-19:10:42-root-INFO: grad norm: 40.371 40.079 4.843
2024-12-01-19:10:43-root-INFO: Loss Change: 420.006 -> 402.840
2024-12-01-19:10:43-root-INFO: Regularization Change: 0.000 -> 1.619
2024-12-01-19:10:43-root-INFO: Learning rate of xt decay: 0.14314 -> 0.14486.
2024-12-01-19:10:43-root-INFO: Coefficient of regularization decay: 0.00037 -> 0.00037.
2024-12-01-19:10:43-root-INFO: step: 117 lr_xt 0.04704158
2024-12-01-19:10:43-root-INFO: grad norm: 39.277 38.956 5.008
2024-12-01-19:10:45-root-INFO: grad norm: 39.994 39.731 4.581
2024-12-01-19:10:45-root-INFO: Loss Change: 401.770 -> 392.431
2024-12-01-19:10:45-root-INFO: Regularization Change: 0.000 -> 1.200
2024-12-01-19:10:45-root-INFO: Learning rate of xt decay: 0.14486 -> 0.14660.
2024-12-01-19:10:45-root-INFO: Coefficient of regularization decay: 0.00037 -> 0.00038.
2024-12-01-19:10:46-root-INFO: step: 116 lr_xt 0.04851508
2024-12-01-19:10:46-root-INFO: grad norm: 40.875 40.599 4.740
2024-12-01-19:10:47-root-INFO: grad norm: 41.877 41.643 4.420
2024-12-01-19:10:48-root-INFO: Loss Change: 392.104 -> 385.426
2024-12-01-19:10:48-root-INFO: Regularization Change: 0.000 -> 0.997
2024-12-01-19:10:48-root-INFO: Learning rate of xt decay: 0.14660 -> 0.14836.
2024-12-01-19:10:48-root-INFO: Coefficient of regularization decay: 0.00038 -> 0.00038.
2024-12-01-19:10:48-root-INFO: step: 115 lr_xt 0.05002669
2024-12-01-19:10:48-root-INFO: grad norm: 42.586 42.358 4.402
2024-12-01-19:10:49-root-INFO: grad norm: 42.972 42.771 4.149
2024-12-01-19:10:50-root-INFO: Loss Change: 385.252 -> 378.276
2024-12-01-19:10:50-root-INFO: Regularization Change: 0.000 -> 0.910
2024-12-01-19:10:50-root-INFO: Learning rate of xt decay: 0.14836 -> 0.15014.
2024-12-01-19:10:50-root-INFO: Coefficient of regularization decay: 0.00038 -> 0.00038.
2024-12-01-19:10:50-root-INFO: step: 114 lr_xt 0.05157710
2024-12-01-19:10:51-root-INFO: grad norm: 42.740 42.554 3.978
2024-12-01-19:10:52-root-INFO: grad norm: 42.686 42.511 3.862
2024-12-01-19:10:53-root-INFO: Loss Change: 378.313 -> 371.177
2024-12-01-19:10:53-root-INFO: Regularization Change: 0.000 -> 0.833
2024-12-01-19:10:53-root-INFO: Learning rate of xt decay: 0.15014 -> 0.15194.
2024-12-01-19:10:53-root-INFO: Coefficient of regularization decay: 0.00038 -> 0.00039.
2024-12-01-19:10:53-root-INFO: step: 113 lr_xt 0.05316701
2024-12-01-19:10:53-root-INFO: grad norm: 42.110 41.959 3.553
2024-12-01-19:10:54-root-INFO: grad norm: 41.520 41.354 3.711
2024-12-01-19:10:55-root-INFO: Loss Change: 371.252 -> 363.618
2024-12-01-19:10:55-root-INFO: Regularization Change: 0.000 -> 0.801
2024-12-01-19:10:55-root-INFO: Learning rate of xt decay: 0.15194 -> 0.15376.
2024-12-01-19:10:55-root-INFO: Coefficient of regularization decay: 0.00039 -> 0.00039.
2024-12-01-19:10:55-root-INFO: step: 112 lr_xt 0.05479712
2024-12-01-19:10:56-root-INFO: grad norm: 41.022 40.854 3.704
2024-12-01-19:10:57-root-INFO: grad norm: 40.433 40.213 4.213
2024-12-01-19:10:57-root-INFO: Loss Change: 364.136 -> 356.969
2024-12-01-19:10:57-root-INFO: Regularization Change: 0.000 -> 0.823
2024-12-01-19:10:57-root-INFO: Learning rate of xt decay: 0.15376 -> 0.15561.
2024-12-01-19:10:57-root-INFO: Coefficient of regularization decay: 0.00039 -> 0.00039.
2024-12-01-19:10:58-root-INFO: step: 111 lr_xt 0.05646812
2024-12-01-19:10:58-root-INFO: grad norm: 40.206 39.976 4.294
2024-12-01-19:10:59-root-INFO: grad norm: 39.754 39.426 5.094
2024-12-01-19:11:00-root-INFO: Loss Change: 357.141 -> 350.083
2024-12-01-19:11:00-root-INFO: Regularization Change: 0.000 -> 0.788
2024-12-01-19:11:00-root-INFO: Learning rate of xt decay: 0.15561 -> 0.15748.
2024-12-01-19:11:00-root-INFO: Coefficient of regularization decay: 0.00039 -> 0.00040.
2024-12-01-19:11:00-root-INFO: step: 110 lr_xt 0.05818072
2024-12-01-19:11:00-root-INFO: grad norm: 39.340 39.063 4.661
2024-12-01-19:11:02-root-INFO: grad norm: 38.298 37.952 5.138
2024-12-01-19:11:02-root-INFO: Loss Change: 350.627 -> 342.397
2024-12-01-19:11:02-root-INFO: Regularization Change: 0.000 -> 0.763
2024-12-01-19:11:02-root-INFO: Undo step: 110
2024-12-01-19:11:02-root-INFO: Undo step: 111
2024-12-01-19:11:02-root-INFO: Undo step: 112
2024-12-01-19:11:02-root-INFO: Undo step: 113
2024-12-01-19:11:02-root-INFO: Undo step: 114
2024-12-01-19:11:03-root-INFO: step: 115 lr_xt 0.05002669
2024-12-01-19:11:03-root-INFO: grad norm: 94.154 92.898 15.327
2024-12-01-19:11:04-root-INFO: grad norm: 59.389 58.679 9.156
2024-12-01-19:11:05-root-INFO: Loss Change: 600.215 -> 401.918
2024-12-01-19:11:05-root-INFO: Regularization Change: 0.000 -> 20.200
2024-12-01-19:11:05-root-INFO: Learning rate of xt decay: 0.14836 -> 0.15014.
2024-12-01-19:11:05-root-INFO: Coefficient of regularization decay: 0.00038 -> 0.00038.
2024-12-01-19:11:05-root-INFO: step: 114 lr_xt 0.05157710
2024-12-01-19:11:05-root-INFO: grad norm: 43.234 42.554 7.634
2024-12-01-19:11:06-root-INFO: grad norm: 40.826 40.345 6.248
2024-12-01-19:11:07-root-INFO: Loss Change: 398.938 -> 372.154
2024-12-01-19:11:07-root-INFO: Regularization Change: 0.000 -> 3.146
2024-12-01-19:11:07-root-INFO: Learning rate of xt decay: 0.15014 -> 0.15194.
2024-12-01-19:11:07-root-INFO: Coefficient of regularization decay: 0.00038 -> 0.00039.
2024-12-01-19:11:08-root-INFO: step: 113 lr_xt 0.05316701
2024-12-01-19:11:08-root-INFO: grad norm: 38.193 37.745 5.833
2024-12-01-19:11:09-root-INFO: grad norm: 37.090 36.693 5.412
2024-12-01-19:11:10-root-INFO: Loss Change: 369.794 -> 355.773
2024-12-01-19:11:10-root-INFO: Regularization Change: 0.000 -> 1.512
2024-12-01-19:11:10-root-INFO: Learning rate of xt decay: 0.15194 -> 0.15376.
2024-12-01-19:11:10-root-INFO: Coefficient of regularization decay: 0.00039 -> 0.00039.
2024-12-01-19:11:10-root-INFO: step: 112 lr_xt 0.05479712
2024-12-01-19:11:10-root-INFO: grad norm: 35.034 34.698 4.845
2024-12-01-19:11:11-root-INFO: grad norm: 35.388 35.044 4.923
2024-12-01-19:11:12-root-INFO: Loss Change: 353.243 -> 345.514
2024-12-01-19:11:12-root-INFO: Regularization Change: 0.000 -> 1.086
2024-12-01-19:11:12-root-INFO: Learning rate of xt decay: 0.15376 -> 0.15561.
2024-12-01-19:11:12-root-INFO: Coefficient of regularization decay: 0.00039 -> 0.00039.
2024-12-01-19:11:13-root-INFO: step: 111 lr_xt 0.05646812
2024-12-01-19:11:13-root-INFO: grad norm: 34.686 34.399 4.456
2024-12-01-19:11:14-root-INFO: grad norm: 35.788 35.489 4.612
2024-12-01-19:11:15-root-INFO: Loss Change: 343.659 -> 339.065
2024-12-01-19:11:15-root-INFO: Regularization Change: 0.000 -> 0.920
2024-12-01-19:11:15-root-INFO: Learning rate of xt decay: 0.15561 -> 0.15748.
2024-12-01-19:11:15-root-INFO: Coefficient of regularization decay: 0.00039 -> 0.00040.
2024-12-01-19:11:15-root-INFO: step: 110 lr_xt 0.05818072
2024-12-01-19:11:15-root-INFO: grad norm: 35.636 35.401 4.086
2024-12-01-19:11:16-root-INFO: grad norm: 37.716 37.456 4.417
2024-12-01-19:11:17-root-INFO: Loss Change: 337.301 -> 335.751
2024-12-01-19:11:17-root-INFO: Regularization Change: 0.000 -> 0.867
2024-12-01-19:11:17-root-INFO: Learning rate of xt decay: 0.15748 -> 0.15937.
2024-12-01-19:11:17-root-INFO: Coefficient of regularization decay: 0.00040 -> 0.00040.
2024-12-01-19:11:17-root-INFO: step: 109 lr_xt 0.05993563
2024-12-01-19:11:18-root-INFO: grad norm: 37.325 37.141 3.707
2024-12-01-19:11:19-root-INFO: grad norm: 38.452 38.222 4.199
2024-12-01-19:11:19-root-INFO: Loss Change: 333.718 -> 330.255
2024-12-01-19:11:19-root-INFO: Regularization Change: 0.000 -> 0.807
2024-12-01-19:11:19-root-INFO: Learning rate of xt decay: 0.15937 -> 0.16128.
2024-12-01-19:11:19-root-INFO: Coefficient of regularization decay: 0.00040 -> 0.00041.
2024-12-01-19:11:20-root-INFO: step: 108 lr_xt 0.06173354
2024-12-01-19:11:20-root-INFO: grad norm: 36.729 36.559 3.523
2024-12-01-19:11:21-root-INFO: grad norm: 36.167 35.958 3.883
2024-12-01-19:11:22-root-INFO: Loss Change: 328.094 -> 321.282
2024-12-01-19:11:22-root-INFO: Regularization Change: 0.000 -> 0.742
2024-12-01-19:11:22-root-INFO: Learning rate of xt decay: 0.16128 -> 0.16321.
2024-12-01-19:11:22-root-INFO: Coefficient of regularization decay: 0.00041 -> 0.00041.
2024-12-01-19:11:22-root-INFO: step: 107 lr_xt 0.06357517
2024-12-01-19:11:23-root-INFO: grad norm: 33.370 33.225 3.100
2024-12-01-19:11:24-root-INFO: grad norm: 33.434 33.253 3.474
2024-12-01-19:11:24-root-INFO: Loss Change: 319.024 -> 313.839
2024-12-01-19:11:24-root-INFO: Regularization Change: 0.000 -> 0.729
2024-12-01-19:11:24-root-INFO: Learning rate of xt decay: 0.16321 -> 0.16517.
2024-12-01-19:11:24-root-INFO: Coefficient of regularization decay: 0.00041 -> 0.00041.
2024-12-01-19:11:25-root-INFO: step: 106 lr_xt 0.06546120
2024-12-01-19:11:25-root-INFO: grad norm: 31.677 31.538 2.966
2024-12-01-19:11:26-root-INFO: grad norm: 32.116 31.938 3.371
2024-12-01-19:11:27-root-INFO: Loss Change: 311.602 -> 307.438
2024-12-01-19:11:27-root-INFO: Regularization Change: 0.000 -> 0.725
2024-12-01-19:11:27-root-INFO: Learning rate of xt decay: 0.16517 -> 0.16715.
2024-12-01-19:11:27-root-INFO: Coefficient of regularization decay: 0.00041 -> 0.00042.
2024-12-01-19:11:27-root-INFO: step: 105 lr_xt 0.06739236
2024-12-01-19:11:28-root-INFO: grad norm: 31.157 31.026 2.856
2024-12-01-19:11:29-root-INFO: grad norm: 31.784 31.611 3.308
2024-12-01-19:11:29-root-INFO: Loss Change: 306.314 -> 302.742
2024-12-01-19:11:29-root-INFO: Regularization Change: 0.000 -> 0.712
2024-12-01-19:11:29-root-INFO: Undo step: 105
2024-12-01-19:11:29-root-INFO: Undo step: 106
2024-12-01-19:11:29-root-INFO: Undo step: 107
2024-12-01-19:11:29-root-INFO: Undo step: 108
2024-12-01-19:11:29-root-INFO: Undo step: 109
2024-12-01-19:11:30-root-INFO: step: 110 lr_xt 0.05818072
2024-12-01-19:11:30-root-INFO: grad norm: 68.880 67.911 11.511
2024-12-01-19:11:31-root-INFO: grad norm: 41.934 41.262 7.477
2024-12-01-19:11:32-root-INFO: Loss Change: 498.971 -> 353.546
2024-12-01-19:11:32-root-INFO: Regularization Change: 0.000 -> 16.644
2024-12-01-19:11:32-root-INFO: Learning rate of xt decay: 0.15748 -> 0.15937.
2024-12-01-19:11:32-root-INFO: Coefficient of regularization decay: 0.00040 -> 0.00040.
2024-12-01-19:11:32-root-INFO: step: 109 lr_xt 0.05993563
2024-12-01-19:11:32-root-INFO: grad norm: 32.843 32.321 5.830
2024-12-01-19:11:33-root-INFO: grad norm: 29.572 29.249 4.356
2024-12-01-19:11:34-root-INFO: Loss Change: 352.365 -> 326.845
2024-12-01-19:11:34-root-INFO: Regularization Change: 0.000 -> 3.173
2024-12-01-19:11:34-root-INFO: Learning rate of xt decay: 0.15937 -> 0.16128.
2024-12-01-19:11:34-root-INFO: Coefficient of regularization decay: 0.00040 -> 0.00041.
2024-12-01-19:11:34-root-INFO: step: 108 lr_xt 0.06173354
2024-12-01-19:11:35-root-INFO: grad norm: 27.605 27.341 3.809
2024-12-01-19:11:36-root-INFO: grad norm: 27.844 27.628 3.460
2024-12-01-19:11:37-root-INFO: Loss Change: 325.107 -> 314.560
2024-12-01-19:11:37-root-INFO: Regularization Change: 0.000 -> 1.608
2024-12-01-19:11:37-root-INFO: Learning rate of xt decay: 0.16128 -> 0.16321.
2024-12-01-19:11:37-root-INFO: Coefficient of regularization decay: 0.00041 -> 0.00041.
2024-12-01-19:11:37-root-INFO: step: 107 lr_xt 0.06357517
2024-12-01-19:11:37-root-INFO: grad norm: 27.622 27.425 3.296
2024-12-01-19:11:38-root-INFO: grad norm: 28.572 28.393 3.193
2024-12-01-19:11:39-root-INFO: Loss Change: 313.649 -> 307.354
2024-12-01-19:11:39-root-INFO: Regularization Change: 0.000 -> 1.207
2024-12-01-19:11:39-root-INFO: Learning rate of xt decay: 0.16321 -> 0.16517.
2024-12-01-19:11:39-root-INFO: Coefficient of regularization decay: 0.00041 -> 0.00041.
2024-12-01-19:11:39-root-INFO: step: 106 lr_xt 0.06546120
2024-12-01-19:11:40-root-INFO: grad norm: 28.287 28.139 2.885
2024-12-01-19:11:41-root-INFO: grad norm: 29.521 29.352 3.152
2024-12-01-19:11:41-root-INFO: Loss Change: 305.502 -> 301.356
2024-12-01-19:11:41-root-INFO: Regularization Change: 0.000 -> 1.038
2024-12-01-19:11:41-root-INFO: Learning rate of xt decay: 0.16517 -> 0.16715.
2024-12-01-19:11:41-root-INFO: Coefficient of regularization decay: 0.00041 -> 0.00042.
2024-12-01-19:11:42-root-INFO: step: 105 lr_xt 0.06739236
2024-12-01-19:11:42-root-INFO: grad norm: 29.607 29.464 2.908
2024-12-01-19:11:43-root-INFO: grad norm: 30.854 30.685 3.225
2024-12-01-19:11:43-root-INFO: Loss too large (297.121->297.297)! Learning rate decreased to 0.05391.
2024-12-01-19:11:44-root-INFO: Loss Change: 300.600 -> 287.452
2024-12-01-19:11:44-root-INFO: Regularization Change: 0.000 -> 0.837
2024-12-01-19:11:44-root-INFO: Learning rate of xt decay: 0.16715 -> 0.16916.
2024-12-01-19:11:44-root-INFO: Coefficient of regularization decay: 0.00042 -> 0.00042.
2024-12-01-19:11:44-root-INFO: step: 104 lr_xt 0.06936934
2024-12-01-19:11:45-root-INFO: grad norm: 19.967 19.837 2.272
2024-12-01-19:11:46-root-INFO: grad norm: 21.610 21.475 2.407
2024-12-01-19:11:47-root-INFO: Loss Change: 286.232 -> 283.268
2024-12-01-19:11:47-root-INFO: Regularization Change: 0.000 -> 0.860
2024-12-01-19:11:47-root-INFO: Learning rate of xt decay: 0.16916 -> 0.17119.
2024-12-01-19:11:47-root-INFO: Coefficient of regularization decay: 0.00042 -> 0.00043.
2024-12-01-19:11:47-root-INFO: step: 103 lr_xt 0.07139284
2024-12-01-19:11:47-root-INFO: grad norm: 22.479 22.352 2.385
2024-12-01-19:11:48-root-INFO: grad norm: 24.485 24.342 2.636
2024-12-01-19:11:49-root-INFO: Loss too large (280.281->280.879)! Learning rate decreased to 0.05711.
2024-12-01-19:11:49-root-INFO: Loss Change: 282.329 -> 274.102
2024-12-01-19:11:49-root-INFO: Regularization Change: 0.000 -> 0.670
2024-12-01-19:11:49-root-INFO: Learning rate of xt decay: 0.17119 -> 0.17324.
2024-12-01-19:11:49-root-INFO: Coefficient of regularization decay: 0.00043 -> 0.00043.
2024-12-01-19:11:50-root-INFO: step: 102 lr_xt 0.07346356
2024-12-01-19:11:50-root-INFO: grad norm: 17.326 17.194 2.134
2024-12-01-19:11:51-root-INFO: grad norm: 19.450 19.311 2.319
2024-12-01-19:11:51-root-INFO: Loss too large (271.499->271.669)! Learning rate decreased to 0.05877.
2024-12-01-19:11:52-root-INFO: Loss Change: 273.323 -> 267.284
2024-12-01-19:11:52-root-INFO: Regularization Change: 0.000 -> 0.641
2024-12-01-19:11:52-root-INFO: Learning rate of xt decay: 0.17324 -> 0.17532.
2024-12-01-19:11:52-root-INFO: Coefficient of regularization decay: 0.00043 -> 0.00044.
2024-12-01-19:11:52-root-INFO: step: 101 lr_xt 0.07558219
2024-12-01-19:11:53-root-INFO: grad norm: 13.969 13.831 1.961
2024-12-01-19:11:54-root-INFO: grad norm: 16.092 15.959 2.068
2024-12-01-19:11:54-root-INFO: Loss Change: 266.654 -> 264.724
2024-12-01-19:11:54-root-INFO: Regularization Change: 0.000 -> 0.784
2024-12-01-19:11:54-root-INFO: Learning rate of xt decay: 0.17532 -> 0.17743.
2024-12-01-19:11:54-root-INFO: Coefficient of regularization decay: 0.00044 -> 0.00044.
2024-12-01-19:11:55-root-INFO: step: 100 lr_xt 0.07774943
2024-12-01-19:11:55-root-INFO: grad norm: 17.894 17.750 2.262
2024-12-01-19:11:56-root-INFO: grad norm: 20.590 20.439 2.484
2024-12-01-19:11:57-root-INFO: Loss too large (263.333->264.250)! Learning rate decreased to 0.06220.
2024-12-01-19:11:57-root-INFO: Loss Change: 264.227 -> 258.853
2024-12-01-19:11:57-root-INFO: Regularization Change: 0.000 -> 0.607
2024-12-01-19:11:57-root-INFO: Undo step: 100
2024-12-01-19:11:57-root-INFO: Undo step: 101
2024-12-01-19:11:57-root-INFO: Undo step: 102
2024-12-01-19:11:57-root-INFO: Undo step: 103
2024-12-01-19:11:57-root-INFO: Undo step: 104
2024-12-01-19:11:58-root-INFO: step: 105 lr_xt 0.06739236
2024-12-01-19:11:58-root-INFO: grad norm: 65.073 63.894 12.330
2024-12-01-19:11:59-root-INFO: grad norm: 35.525 34.924 6.508
2024-12-01-19:12:00-root-INFO: Loss Change: 488.391 -> 322.732
2024-12-01-19:12:00-root-INFO: Regularization Change: 0.000 -> 23.922
2024-12-01-19:12:00-root-INFO: Learning rate of xt decay: 0.16715 -> 0.16916.
2024-12-01-19:12:00-root-INFO: Coefficient of regularization decay: 0.00042 -> 0.00042.
2024-12-01-19:12:00-root-INFO: step: 104 lr_xt 0.06936934
2024-12-01-19:12:00-root-INFO: grad norm: 27.318 26.903 4.746
2024-12-01-19:12:01-root-INFO: grad norm: 26.676 26.350 4.159
2024-12-01-19:12:02-root-INFO: Loss Change: 322.246 -> 300.011
2024-12-01-19:12:02-root-INFO: Regularization Change: 0.000 -> 4.041
2024-12-01-19:12:02-root-INFO: Learning rate of xt decay: 0.16916 -> 0.17119.
2024-12-01-19:12:02-root-INFO: Coefficient of regularization decay: 0.00042 -> 0.00043.
2024-12-01-19:12:03-root-INFO: step: 103 lr_xt 0.07139284
2024-12-01-19:12:03-root-INFO: grad norm: 29.575 29.316 3.907
2024-12-01-19:12:04-root-INFO: grad norm: 31.223 30.959 4.048
2024-12-01-19:12:05-root-INFO: Loss Change: 300.964 -> 292.884
2024-12-01-19:12:05-root-INFO: Regularization Change: 0.000 -> 2.116
2024-12-01-19:12:05-root-INFO: Learning rate of xt decay: 0.17119 -> 0.17324.
2024-12-01-19:12:05-root-INFO: Coefficient of regularization decay: 0.00043 -> 0.00043.
2024-12-01-19:12:05-root-INFO: step: 102 lr_xt 0.07346356
2024-12-01-19:12:05-root-INFO: grad norm: 34.023 33.747 4.329
2024-12-01-19:12:06-root-INFO: grad norm: 34.205 33.918 4.419
2024-12-01-19:12:07-root-INFO: Loss Change: 294.913 -> 287.552
2024-12-01-19:12:07-root-INFO: Regularization Change: 0.000 -> 1.602
2024-12-01-19:12:07-root-INFO: Learning rate of xt decay: 0.17324 -> 0.17532.
2024-12-01-19:12:07-root-INFO: Coefficient of regularization decay: 0.00043 -> 0.00044.
2024-12-01-19:12:07-root-INFO: step: 101 lr_xt 0.07558219
2024-12-01-19:12:08-root-INFO: grad norm: 36.435 36.098 4.946
2024-12-01-19:12:09-root-INFO: grad norm: 35.780 35.441 4.907
2024-12-01-19:12:09-root-INFO: Loss Change: 291.213 -> 283.393
2024-12-01-19:12:09-root-INFO: Regularization Change: 0.000 -> 1.358
2024-12-01-19:12:09-root-INFO: Learning rate of xt decay: 0.17532 -> 0.17743.
2024-12-01-19:12:09-root-INFO: Coefficient of regularization decay: 0.00044 -> 0.00044.
2024-12-01-19:12:10-root-INFO: step: 100 lr_xt 0.07774943
2024-12-01-19:12:10-root-INFO: grad norm: 38.006 37.634 5.305
2024-12-01-19:12:11-root-INFO: grad norm: 37.166 36.814 5.107
2024-12-01-19:12:12-root-INFO: Loss Change: 287.500 -> 279.876
2024-12-01-19:12:12-root-INFO: Regularization Change: 0.000 -> 1.218
2024-12-01-19:12:12-root-INFO: Learning rate of xt decay: 0.17743 -> 0.17956.
2024-12-01-19:12:12-root-INFO: Coefficient of regularization decay: 0.00044 -> 0.00044.
2024-12-01-19:12:12-root-INFO: step: 99 lr_xt 0.07996596
2024-12-01-19:12:13-root-INFO: grad norm: 38.383 38.041 5.114
2024-12-01-19:12:14-root-INFO: grad norm: 36.509 36.201 4.732
2024-12-01-19:12:14-root-INFO: Loss Change: 283.514 -> 272.823
2024-12-01-19:12:14-root-INFO: Regularization Change: 0.000 -> 1.061
2024-12-01-19:12:14-root-INFO: Learning rate of xt decay: 0.17956 -> 0.18171.
2024-12-01-19:12:14-root-INFO: Coefficient of regularization decay: 0.00044 -> 0.00045.
2024-12-01-19:12:15-root-INFO: step: 98 lr_xt 0.08223248
2024-12-01-19:12:15-root-INFO: grad norm: 36.446 36.131 4.779
2024-12-01-19:12:16-root-INFO: grad norm: 33.988 33.714 4.307
2024-12-01-19:12:17-root-INFO: Loss Change: 276.842 -> 265.203
2024-12-01-19:12:17-root-INFO: Regularization Change: 0.000 -> 0.935
2024-12-01-19:12:17-root-INFO: Learning rate of xt decay: 0.18171 -> 0.18389.
2024-12-01-19:12:17-root-INFO: Coefficient of regularization decay: 0.00045 -> 0.00045.
2024-12-01-19:12:17-root-INFO: step: 97 lr_xt 0.08454965
2024-12-01-19:12:17-root-INFO: grad norm: 33.400 33.115 4.351
2024-12-01-19:12:18-root-INFO: grad norm: 30.926 30.677 3.919
2024-12-01-19:12:19-root-INFO: Loss Change: 268.467 -> 257.605
2024-12-01-19:12:19-root-INFO: Regularization Change: 0.000 -> 0.861
2024-12-01-19:12:19-root-INFO: Learning rate of xt decay: 0.18389 -> 0.18610.
2024-12-01-19:12:19-root-INFO: Coefficient of regularization decay: 0.00045 -> 0.00046.
2024-12-01-19:12:19-root-INFO: step: 96 lr_xt 0.08691815
2024-12-01-19:12:20-root-INFO: grad norm: 30.420 30.158 3.986
2024-12-01-19:12:21-root-INFO: grad norm: 28.462 28.236 3.583
2024-12-01-19:12:21-root-INFO: Loss Change: 260.245 -> 251.304
2024-12-01-19:12:21-root-INFO: Regularization Change: 0.000 -> 0.800
2024-12-01-19:12:22-root-INFO: Learning rate of xt decay: 0.18610 -> 0.18833.
2024-12-01-19:12:22-root-INFO: Coefficient of regularization decay: 0.00046 -> 0.00046.
2024-12-01-19:12:22-root-INFO: step: 95 lr_xt 0.08933865
2024-12-01-19:12:22-root-INFO: grad norm: 29.007 28.747 3.871
2024-12-01-19:12:23-root-INFO: grad norm: 27.392 27.172 3.465
2024-12-01-19:12:24-root-INFO: Loss Change: 254.469 -> 246.655
2024-12-01-19:12:24-root-INFO: Regularization Change: 0.000 -> 0.775
2024-12-01-19:12:24-root-INFO: Undo step: 95
2024-12-01-19:12:24-root-INFO: Undo step: 96
2024-12-01-19:12:24-root-INFO: Undo step: 97
2024-12-01-19:12:24-root-INFO: Undo step: 98
2024-12-01-19:12:24-root-INFO: Undo step: 99
2024-12-01-19:12:24-root-INFO: step: 100 lr_xt 0.07774943
2024-12-01-19:12:25-root-INFO: grad norm: 54.991 54.123 9.735
2024-12-01-19:12:26-root-INFO: grad norm: 32.464 32.001 5.465
2024-12-01-19:12:26-root-INFO: Loss Change: 422.299 -> 291.832
2024-12-01-19:12:26-root-INFO: Regularization Change: 0.000 -> 22.014
2024-12-01-19:12:26-root-INFO: Learning rate of xt decay: 0.17743 -> 0.17956.
2024-12-01-19:12:26-root-INFO: Coefficient of regularization decay: 0.00044 -> 0.00044.
2024-12-01-19:12:27-root-INFO: step: 99 lr_xt 0.07996596
2024-12-01-19:12:27-root-INFO: grad norm: 30.053 29.712 4.512
2024-12-01-19:12:28-root-INFO: grad norm: 28.173 27.899 3.923
2024-12-01-19:12:29-root-INFO: Loss Change: 293.436 -> 272.890
2024-12-01-19:12:29-root-INFO: Regularization Change: 0.000 -> 3.477
2024-12-01-19:12:29-root-INFO: Learning rate of xt decay: 0.17956 -> 0.18171.
2024-12-01-19:12:29-root-INFO: Coefficient of regularization decay: 0.00044 -> 0.00045.
2024-12-01-19:12:29-root-INFO: step: 98 lr_xt 0.08223248
2024-12-01-19:12:29-root-INFO: grad norm: 28.464 28.199 3.878
2024-12-01-19:12:30-root-INFO: grad norm: 27.233 26.993 3.609
2024-12-01-19:12:31-root-INFO: Loss Change: 275.222 -> 262.820
2024-12-01-19:12:31-root-INFO: Regularization Change: 0.000 -> 1.906
2024-12-01-19:12:31-root-INFO: Learning rate of xt decay: 0.18171 -> 0.18389.
2024-12-01-19:12:31-root-INFO: Coefficient of regularization decay: 0.00045 -> 0.00045.
2024-12-01-19:12:32-root-INFO: step: 97 lr_xt 0.08454965
2024-12-01-19:12:32-root-INFO: grad norm: 27.955 27.701 3.759
2024-12-01-19:12:33-root-INFO: grad norm: 26.648 26.408 3.566
2024-12-01-19:12:34-root-INFO: Loss Change: 265.108 -> 255.158
2024-12-01-19:12:34-root-INFO: Regularization Change: 0.000 -> 1.351
2024-12-01-19:12:34-root-INFO: Learning rate of xt decay: 0.18389 -> 0.18610.
2024-12-01-19:12:34-root-INFO: Coefficient of regularization decay: 0.00045 -> 0.00046.
2024-12-01-19:12:34-root-INFO: step: 96 lr_xt 0.08691815
2024-12-01-19:12:34-root-INFO: grad norm: 26.865 26.616 3.650
2024-12-01-19:12:35-root-INFO: grad norm: 25.450 25.213 3.466
2024-12-01-19:12:36-root-INFO: Loss Change: 257.182 -> 248.418
2024-12-01-19:12:36-root-INFO: Regularization Change: 0.000 -> 1.104
2024-12-01-19:12:36-root-INFO: Learning rate of xt decay: 0.18610 -> 0.18833.
2024-12-01-19:12:36-root-INFO: Coefficient of regularization decay: 0.00046 -> 0.00046.
2024-12-01-19:12:36-root-INFO: step: 95 lr_xt 0.08933865
2024-12-01-19:12:37-root-INFO: grad norm: 26.890 26.624 3.775
2024-12-01-19:12:38-root-INFO: grad norm: 25.830 25.579 3.592
2024-12-01-19:12:38-root-INFO: Loss Change: 251.605 -> 244.425
2024-12-01-19:12:38-root-INFO: Regularization Change: 0.000 -> 0.998
2024-12-01-19:12:38-root-INFO: Learning rate of xt decay: 0.18833 -> 0.19059.
2024-12-01-19:12:38-root-INFO: Coefficient of regularization decay: 0.00046 -> 0.00047.
2024-12-01-19:12:39-root-INFO: step: 94 lr_xt 0.09181181
2024-12-01-19:12:39-root-INFO: grad norm: 27.317 27.052 3.794
2024-12-01-19:12:40-root-INFO: grad norm: 26.728 26.466 3.731
2024-12-01-19:12:41-root-INFO: Loss Change: 246.913 -> 241.269
2024-12-01-19:12:41-root-INFO: Regularization Change: 0.000 -> 0.946
2024-12-01-19:12:41-root-INFO: Learning rate of xt decay: 0.19059 -> 0.19288.
2024-12-01-19:12:41-root-INFO: Coefficient of regularization decay: 0.00047 -> 0.00047.
2024-12-01-19:12:41-root-INFO: step: 93 lr_xt 0.09433829
2024-12-01-19:12:42-root-INFO: grad norm: 28.523 28.255 3.901
2024-12-01-19:12:43-root-INFO: grad norm: 27.517 27.259 3.762
2024-12-01-19:12:43-root-INFO: Loss Change: 244.447 -> 237.752
2024-12-01-19:12:43-root-INFO: Regularization Change: 0.000 -> 0.890
2024-12-01-19:12:43-root-INFO: Learning rate of xt decay: 0.19288 -> 0.19519.
2024-12-01-19:12:43-root-INFO: Coefficient of regularization decay: 0.00047 -> 0.00048.
2024-12-01-19:12:44-root-INFO: step: 92 lr_xt 0.09691873
2024-12-01-19:12:44-root-INFO: grad norm: 28.105 27.847 3.801
2024-12-01-19:12:45-root-INFO: grad norm: 26.600 26.349 3.645
2024-12-01-19:12:46-root-INFO: Loss Change: 240.648 -> 232.869
2024-12-01-19:12:46-root-INFO: Regularization Change: 0.000 -> 0.846
2024-12-01-19:12:46-root-INFO: Learning rate of xt decay: 0.19519 -> 0.19753.
2024-12-01-19:12:46-root-INFO: Coefficient of regularization decay: 0.00048 -> 0.00048.
2024-12-01-19:12:46-root-INFO: step: 91 lr_xt 0.09955376
2024-12-01-19:12:46-root-INFO: grad norm: 26.738 26.495 3.598
2024-12-01-19:12:47-root-INFO: grad norm: 25.203 24.963 3.470
2024-12-01-19:12:48-root-INFO: Loss Change: 235.421 -> 227.880
2024-12-01-19:12:48-root-INFO: Regularization Change: 0.000 -> 0.802
2024-12-01-19:12:48-root-INFO: Learning rate of xt decay: 0.19753 -> 0.19990.
2024-12-01-19:12:48-root-INFO: Coefficient of regularization decay: 0.00048 -> 0.00049.
2024-12-01-19:12:48-root-INFO: step: 90 lr_xt 0.10224402
2024-12-01-19:12:49-root-INFO: grad norm: 25.483 25.245 3.473
2024-12-01-19:12:50-root-INFO: grad norm: 23.864 23.641 3.255
2024-12-01-19:12:51-root-INFO: Loss Change: 230.484 -> 222.992
2024-12-01-19:12:51-root-INFO: Regularization Change: 0.000 -> 0.799
2024-12-01-19:12:51-root-INFO: Undo step: 90
2024-12-01-19:12:51-root-INFO: Undo step: 91
2024-12-01-19:12:51-root-INFO: Undo step: 92
2024-12-01-19:12:51-root-INFO: Undo step: 93
2024-12-01-19:12:51-root-INFO: Undo step: 94
2024-12-01-19:12:51-root-INFO: step: 95 lr_xt 0.08933865
2024-12-01-19:12:51-root-INFO: grad norm: 49.276 48.449 8.990
2024-12-01-19:12:52-root-INFO: grad norm: 33.953 33.520 5.401
2024-12-01-19:12:53-root-INFO: Loss Change: 389.829 -> 277.843
2024-12-01-19:12:53-root-INFO: Regularization Change: 0.000 -> 24.409
2024-12-01-19:12:53-root-INFO: Learning rate of xt decay: 0.18833 -> 0.19059.
2024-12-01-19:12:53-root-INFO: Coefficient of regularization decay: 0.00046 -> 0.00047.
2024-12-01-19:12:53-root-INFO: step: 94 lr_xt 0.09181181
2024-12-01-19:12:54-root-INFO: grad norm: 32.853 32.534 4.564
2024-12-01-19:12:55-root-INFO: grad norm: 30.697 30.449 3.898
2024-12-01-19:12:55-root-INFO: Loss Change: 278.993 -> 255.354
2024-12-01-19:12:55-root-INFO: Regularization Change: 0.000 -> 4.319
2024-12-01-19:12:55-root-INFO: Learning rate of xt decay: 0.19059 -> 0.19288.
2024-12-01-19:12:55-root-INFO: Coefficient of regularization decay: 0.00047 -> 0.00047.
2024-12-01-19:12:56-root-INFO: step: 93 lr_xt 0.09433829
2024-12-01-19:12:56-root-INFO: grad norm: 29.609 29.381 3.665
2024-12-01-19:12:57-root-INFO: grad norm: 27.044 26.835 3.356
2024-12-01-19:12:58-root-INFO: Loss Change: 256.829 -> 240.841
2024-12-01-19:12:58-root-INFO: Regularization Change: 0.000 -> 2.167
2024-12-01-19:12:58-root-INFO: Learning rate of xt decay: 0.19288 -> 0.19519.
2024-12-01-19:12:58-root-INFO: Coefficient of regularization decay: 0.00047 -> 0.00048.
2024-12-01-19:12:58-root-INFO: step: 92 lr_xt 0.09691873
2024-12-01-19:12:59-root-INFO: grad norm: 26.976 26.768 3.349
2024-12-01-19:13:00-root-INFO: grad norm: 25.280 25.060 3.321
2024-12-01-19:13:00-root-INFO: Loss Change: 243.088 -> 232.439
2024-12-01-19:13:00-root-INFO: Regularization Change: 0.000 -> 1.502
2024-12-01-19:13:00-root-INFO: Learning rate of xt decay: 0.19519 -> 0.19753.
2024-12-01-19:13:00-root-INFO: Coefficient of regularization decay: 0.00048 -> 0.00048.
2024-12-01-19:13:01-root-INFO: step: 91 lr_xt 0.09955376
2024-12-01-19:13:01-root-INFO: grad norm: 26.058 25.847 3.307
2024-12-01-19:13:02-root-INFO: grad norm: 24.817 24.567 3.512
2024-12-01-19:13:03-root-INFO: Loss Change: 234.544 -> 226.431
2024-12-01-19:13:03-root-INFO: Regularization Change: 0.000 -> 1.236
2024-12-01-19:13:03-root-INFO: Learning rate of xt decay: 0.19753 -> 0.19990.
2024-12-01-19:13:03-root-INFO: Coefficient of regularization decay: 0.00048 -> 0.00049.
2024-12-01-19:13:03-root-INFO: step: 90 lr_xt 0.10224402
2024-12-01-19:13:03-root-INFO: grad norm: 25.922 25.698 3.402
2024-12-01-19:13:04-root-INFO: grad norm: 24.755 24.484 3.651
2024-12-01-19:13:05-root-INFO: Loss Change: 228.857 -> 221.752
2024-12-01-19:13:05-root-INFO: Regularization Change: 0.000 -> 1.138
2024-12-01-19:13:05-root-INFO: Learning rate of xt decay: 0.19990 -> 0.20230.
2024-12-01-19:13:05-root-INFO: Coefficient of regularization decay: 0.00049 -> 0.00049.
2024-12-01-19:13:06-root-INFO: step: 89 lr_xt 0.10499012
2024-12-01-19:13:06-root-INFO: grad norm: 26.203 25.938 3.717
2024-12-01-19:13:07-root-INFO: grad norm: 25.399 25.067 4.094
2024-12-01-19:13:07-root-INFO: Loss Change: 224.706 -> 218.918
2024-12-01-19:13:07-root-INFO: Regularization Change: 0.000 -> 1.069
2024-12-01-19:13:08-root-INFO: Learning rate of xt decay: 0.20230 -> 0.20473.
2024-12-01-19:13:08-root-INFO: Coefficient of regularization decay: 0.00049 -> 0.00050.
2024-12-01-19:13:08-root-INFO: step: 88 lr_xt 0.10779268
2024-12-01-19:13:08-root-INFO: grad norm: 26.010 25.660 4.248
2024-12-01-19:13:09-root-INFO: grad norm: 24.930 24.581 4.155
2024-12-01-19:13:10-root-INFO: Loss Change: 221.520 -> 215.048
2024-12-01-19:13:10-root-INFO: Regularization Change: 0.000 -> 0.979
2024-12-01-19:13:10-root-INFO: Learning rate of xt decay: 0.20473 -> 0.20719.
2024-12-01-19:13:10-root-INFO: Coefficient of regularization decay: 0.00050 -> 0.00050.
2024-12-01-19:13:10-root-INFO: step: 87 lr_xt 0.11065228
2024-12-01-19:13:11-root-INFO: grad norm: 25.229 24.875 4.212
2024-12-01-19:13:12-root-INFO: grad norm: 23.588 23.249 3.984
2024-12-01-19:13:12-root-INFO: Loss Change: 217.432 -> 209.663
2024-12-01-19:13:12-root-INFO: Regularization Change: 0.000 -> 0.899
2024-12-01-19:13:12-root-INFO: Learning rate of xt decay: 0.20719 -> 0.20967.
2024-12-01-19:13:12-root-INFO: Coefficient of regularization decay: 0.00050 -> 0.00051.
2024-12-01-19:13:13-root-INFO: step: 86 lr_xt 0.11356952
2024-12-01-19:13:13-root-INFO: grad norm: 23.375 23.032 3.987
2024-12-01-19:13:14-root-INFO: grad norm: 21.826 21.514 3.677
2024-12-01-19:13:15-root-INFO: Loss Change: 212.032 -> 204.869
2024-12-01-19:13:15-root-INFO: Regularization Change: 0.000 -> 0.842
2024-12-01-19:13:15-root-INFO: Learning rate of xt decay: 0.20967 -> 0.21219.
2024-12-01-19:13:15-root-INFO: Coefficient of regularization decay: 0.00051 -> 0.00051.
2024-12-01-19:13:15-root-INFO: step: 85 lr_xt 0.11654496
2024-12-01-19:13:15-root-INFO: grad norm: 21.757 21.452 3.626
2024-12-01-19:13:16-root-INFO: grad norm: 20.427 20.144 3.388
2024-12-01-19:13:17-root-INFO: Loss Change: 206.736 -> 200.374
2024-12-01-19:13:17-root-INFO: Regularization Change: 0.000 -> 0.817
2024-12-01-19:13:17-root-INFO: Undo step: 85
2024-12-01-19:13:17-root-INFO: Undo step: 86
2024-12-01-19:13:17-root-INFO: Undo step: 87
2024-12-01-19:13:17-root-INFO: Undo step: 88
2024-12-01-19:13:17-root-INFO: Undo step: 89
2024-12-01-19:13:18-root-INFO: step: 90 lr_xt 0.10224402
2024-12-01-19:13:18-root-INFO: grad norm: 44.195 43.132 9.637
2024-12-01-19:13:19-root-INFO: grad norm: 25.018 24.522 4.958
2024-12-01-19:13:20-root-INFO: Loss Change: 345.502 -> 234.848
2024-12-01-19:13:20-root-INFO: Regularization Change: 0.000 -> 25.250
2024-12-01-19:13:20-root-INFO: Learning rate of xt decay: 0.19990 -> 0.20230.
2024-12-01-19:13:20-root-INFO: Coefficient of regularization decay: 0.00049 -> 0.00049.
2024-12-01-19:13:20-root-INFO: step: 89 lr_xt 0.10499012
2024-12-01-19:13:20-root-INFO: grad norm: 21.277 20.990 3.480
2024-12-01-19:13:21-root-INFO: grad norm: 20.484 20.256 3.045
2024-12-01-19:13:22-root-INFO: Loss Change: 235.880 -> 220.369
2024-12-01-19:13:22-root-INFO: Regularization Change: 0.000 -> 4.039
2024-12-01-19:13:22-root-INFO: Learning rate of xt decay: 0.20230 -> 0.20473.
2024-12-01-19:13:22-root-INFO: Coefficient of regularization decay: 0.00049 -> 0.00050.
2024-12-01-19:13:22-root-INFO: step: 88 lr_xt 0.10779268
2024-12-01-19:13:23-root-INFO: grad norm: 21.969 21.745 3.126
2024-12-01-19:13:24-root-INFO: grad norm: 21.929 21.727 2.972
2024-12-01-19:13:24-root-INFO: Loss Change: 221.963 -> 214.268
2024-12-01-19:13:24-root-INFO: Regularization Change: 0.000 -> 2.096
2024-12-01-19:13:24-root-INFO: Learning rate of xt decay: 0.20473 -> 0.20719.
2024-12-01-19:13:24-root-INFO: Coefficient of regularization decay: 0.00050 -> 0.00050.
2024-12-01-19:13:25-root-INFO: step: 87 lr_xt 0.11065228
2024-12-01-19:13:25-root-INFO: grad norm: 23.615 23.390 3.255
2024-12-01-19:13:26-root-INFO: grad norm: 23.279 23.077 3.063
2024-12-01-19:13:27-root-INFO: Loss Change: 216.031 -> 209.698
2024-12-01-19:13:27-root-INFO: Regularization Change: 0.000 -> 1.483
2024-12-01-19:13:27-root-INFO: Learning rate of xt decay: 0.20719 -> 0.20967.
2024-12-01-19:13:27-root-INFO: Coefficient of regularization decay: 0.00050 -> 0.00051.
2024-12-01-19:13:27-root-INFO: step: 86 lr_xt 0.11356952
2024-12-01-19:13:28-root-INFO: grad norm: 24.370 24.142 3.323
2024-12-01-19:13:29-root-INFO: grad norm: 23.567 23.368 3.058
2024-12-01-19:13:29-root-INFO: Loss Change: 211.920 -> 205.317
2024-12-01-19:13:29-root-INFO: Regularization Change: 0.000 -> 1.160
2024-12-01-19:13:29-root-INFO: Learning rate of xt decay: 0.20967 -> 0.21219.
2024-12-01-19:13:29-root-INFO: Coefficient of regularization decay: 0.00051 -> 0.00051.
2024-12-01-19:13:30-root-INFO: step: 85 lr_xt 0.11654496
2024-12-01-19:13:30-root-INFO: grad norm: 23.913 23.696 3.209
2024-12-01-19:13:31-root-INFO: grad norm: 22.596 22.401 2.967
2024-12-01-19:13:32-root-INFO: Loss Change: 207.302 -> 199.949
2024-12-01-19:13:32-root-INFO: Regularization Change: 0.000 -> 1.022
2024-12-01-19:13:32-root-INFO: Learning rate of xt decay: 0.21219 -> 0.21474.
2024-12-01-19:13:32-root-INFO: Coefficient of regularization decay: 0.00051 -> 0.00052.
2024-12-01-19:13:32-root-INFO: step: 84 lr_xt 0.11957917
2024-12-01-19:13:32-root-INFO: grad norm: 22.317 22.119 2.967
2024-12-01-19:13:33-root-INFO: grad norm: 21.070 20.880 2.824
2024-12-01-19:13:34-root-INFO: Loss Change: 201.454 -> 194.828
2024-12-01-19:13:34-root-INFO: Regularization Change: 0.000 -> 0.912
2024-12-01-19:13:34-root-INFO: Learning rate of xt decay: 0.21474 -> 0.21731.
2024-12-01-19:13:34-root-INFO: Coefficient of regularization decay: 0.00052 -> 0.00052.
2024-12-01-19:13:34-root-INFO: step: 83 lr_xt 0.12267269
2024-12-01-19:13:35-root-INFO: grad norm: 21.442 21.235 2.973
2024-12-01-19:13:36-root-INFO: grad norm: 20.224 20.033 2.770
2024-12-01-19:13:37-root-INFO: Loss Change: 196.905 -> 190.662
2024-12-01-19:13:37-root-INFO: Regularization Change: 0.000 -> 0.868
2024-12-01-19:13:37-root-INFO: Learning rate of xt decay: 0.21731 -> 0.21992.
2024-12-01-19:13:37-root-INFO: Coefficient of regularization decay: 0.00052 -> 0.00053.
2024-12-01-19:13:37-root-INFO: step: 82 lr_xt 0.12582604
2024-12-01-19:13:37-root-INFO: grad norm: 20.104 19.911 2.776
2024-12-01-19:13:38-root-INFO: grad norm: 18.989 18.811 2.597
2024-12-01-19:13:39-root-INFO: Loss Change: 192.272 -> 186.603
2024-12-01-19:13:39-root-INFO: Regularization Change: 0.000 -> 0.827
2024-12-01-19:13:39-root-INFO: Learning rate of xt decay: 0.21992 -> 0.22256.
2024-12-01-19:13:39-root-INFO: Coefficient of regularization decay: 0.00053 -> 0.00053.
2024-12-01-19:13:39-root-INFO: step: 81 lr_xt 0.12903975
2024-12-01-19:13:40-root-INFO: grad norm: 19.340 19.140 2.775
2024-12-01-19:13:41-root-INFO: grad norm: 18.219 18.043 2.533
2024-12-01-19:13:41-root-INFO: Loss Change: 188.246 -> 182.734
2024-12-01-19:13:41-root-INFO: Regularization Change: 0.000 -> 0.815
2024-12-01-19:13:41-root-INFO: Learning rate of xt decay: 0.22256 -> 0.22523.
2024-12-01-19:13:41-root-INFO: Coefficient of regularization decay: 0.00053 -> 0.00054.
2024-12-01-19:13:42-root-INFO: step: 80 lr_xt 0.13231432
2024-12-01-19:13:42-root-INFO: grad norm: 18.899 18.676 2.898
2024-12-01-19:13:43-root-INFO: grad norm: 17.822 17.639 2.543
2024-12-01-19:13:44-root-INFO: Loss Change: 185.043 -> 179.736
2024-12-01-19:13:44-root-INFO: Regularization Change: 0.000 -> 0.813
2024-12-01-19:13:44-root-INFO: Undo step: 80
2024-12-01-19:13:44-root-INFO: Undo step: 81
2024-12-01-19:13:44-root-INFO: Undo step: 82
2024-12-01-19:13:44-root-INFO: Undo step: 83
2024-12-01-19:13:44-root-INFO: Undo step: 84
2024-12-01-19:13:44-root-INFO: step: 85 lr_xt 0.11654496
2024-12-01-19:13:44-root-INFO: grad norm: 39.355 38.874 6.138
2024-12-01-19:13:46-root-INFO: grad norm: 23.984 23.677 3.822
2024-12-01-19:13:46-root-INFO: Loss Change: 327.658 -> 221.525
2024-12-01-19:13:46-root-INFO: Regularization Change: 0.000 -> 27.545
2024-12-01-19:13:46-root-INFO: Learning rate of xt decay: 0.21219 -> 0.21474.
2024-12-01-19:13:46-root-INFO: Coefficient of regularization decay: 0.00051 -> 0.00052.
2024-12-01-19:13:47-root-INFO: step: 84 lr_xt 0.11957917
2024-12-01-19:13:47-root-INFO: grad norm: 21.283 21.095 2.825
2024-12-01-19:13:48-root-INFO: grad norm: 19.817 19.677 2.353
2024-12-01-19:13:49-root-INFO: Loss Change: 221.368 -> 202.924
2024-12-01-19:13:49-root-INFO: Regularization Change: 0.000 -> 4.881
2024-12-01-19:13:49-root-INFO: Learning rate of xt decay: 0.21474 -> 0.21731.
2024-12-01-19:13:49-root-INFO: Coefficient of regularization decay: 0.00052 -> 0.00052.
2024-12-01-19:13:49-root-INFO: step: 83 lr_xt 0.12267269
2024-12-01-19:13:49-root-INFO: grad norm: 19.495 19.360 2.289
2024-12-01-19:13:50-root-INFO: grad norm: 17.990 17.872 2.052
2024-12-01-19:13:51-root-INFO: Loss Change: 203.097 -> 191.772
2024-12-01-19:13:51-root-INFO: Regularization Change: 0.000 -> 2.380
2024-12-01-19:13:51-root-INFO: Learning rate of xt decay: 0.21731 -> 0.21992.
2024-12-01-19:13:51-root-INFO: Coefficient of regularization decay: 0.00052 -> 0.00053.
2024-12-01-19:13:51-root-INFO: step: 82 lr_xt 0.12582604
2024-12-01-19:13:52-root-INFO: grad norm: 17.403 17.280 2.062
2024-12-01-19:13:53-root-INFO: grad norm: 16.052 15.946 1.842
2024-12-01-19:13:53-root-INFO: Loss Change: 192.662 -> 184.512
2024-12-01-19:13:53-root-INFO: Regularization Change: 0.000 -> 1.557
2024-12-01-19:13:53-root-INFO: Learning rate of xt decay: 0.21992 -> 0.22256.
2024-12-01-19:13:53-root-INFO: Coefficient of regularization decay: 0.00053 -> 0.00053.
2024-12-01-19:13:54-root-INFO: step: 81 lr_xt 0.12903975
2024-12-01-19:13:54-root-INFO: grad norm: 15.625 15.503 1.951
2024-12-01-19:13:55-root-INFO: grad norm: 14.451 14.350 1.705
2024-12-01-19:13:56-root-INFO: Loss Change: 184.894 -> 178.515
2024-12-01-19:13:56-root-INFO: Regularization Change: 0.000 -> 1.215
2024-12-01-19:13:56-root-INFO: Learning rate of xt decay: 0.22256 -> 0.22523.
2024-12-01-19:13:56-root-INFO: Coefficient of regularization decay: 0.00053 -> 0.00054.
2024-12-01-19:13:56-root-INFO: step: 80 lr_xt 0.13231432
2024-12-01-19:13:56-root-INFO: grad norm: 14.766 14.636 1.954
2024-12-01-19:13:58-root-INFO: grad norm: 13.918 13.816 1.680
2024-12-01-19:13:58-root-INFO: Loss Change: 179.676 -> 174.639
2024-12-01-19:13:58-root-INFO: Regularization Change: 0.000 -> 1.034
2024-12-01-19:13:58-root-INFO: Learning rate of xt decay: 0.22523 -> 0.22793.
2024-12-01-19:13:58-root-INFO: Coefficient of regularization decay: 0.00054 -> 0.00054.
2024-12-01-19:13:59-root-INFO: step: 79 lr_xt 0.13565022
2024-12-01-19:13:59-root-INFO: grad norm: 14.172 14.050 1.856
2024-12-01-19:14:00-root-INFO: grad norm: 13.677 13.579 1.634
2024-12-01-19:14:01-root-INFO: Loss Change: 175.225 -> 171.279
2024-12-01-19:14:01-root-INFO: Regularization Change: 0.000 -> 0.939
2024-12-01-19:14:01-root-INFO: Learning rate of xt decay: 0.22793 -> 0.23067.
2024-12-01-19:14:01-root-INFO: Coefficient of regularization decay: 0.00054 -> 0.00055.
2024-12-01-19:14:01-root-INFO: step: 78 lr_xt 0.13904792
2024-12-01-19:14:01-root-INFO: grad norm: 14.330 14.213 1.832
2024-12-01-19:14:02-root-INFO: grad norm: 14.232 14.141 1.606
2024-12-01-19:14:03-root-INFO: Loss Change: 172.385 -> 169.447
2024-12-01-19:14:03-root-INFO: Regularization Change: 0.000 -> 0.881
2024-12-01-19:14:03-root-INFO: Learning rate of xt decay: 0.23067 -> 0.23344.
2024-12-01-19:14:03-root-INFO: Coefficient of regularization decay: 0.00055 -> 0.00055.
2024-12-01-19:14:03-root-INFO: step: 77 lr_xt 0.14250787
2024-12-01-19:14:04-root-INFO: grad norm: 14.834 14.722 1.825
2024-12-01-19:14:05-root-INFO: grad norm: 14.318 14.230 1.586
2024-12-01-19:14:06-root-INFO: Loss Change: 170.152 -> 166.448
2024-12-01-19:14:06-root-INFO: Regularization Change: 0.000 -> 0.842
2024-12-01-19:14:06-root-INFO: Learning rate of xt decay: 0.23344 -> 0.23624.
2024-12-01-19:14:06-root-INFO: Coefficient of regularization decay: 0.00055 -> 0.00056.
2024-12-01-19:14:06-root-INFO: step: 76 lr_xt 0.14603050
2024-12-01-19:14:06-root-INFO: grad norm: 14.733 14.624 1.783
2024-12-01-19:14:07-root-INFO: grad norm: 13.896 13.809 1.549
2024-12-01-19:14:08-root-INFO: Loss Change: 167.559 -> 163.316
2024-12-01-19:14:08-root-INFO: Regularization Change: 0.000 -> 0.823
2024-12-01-19:14:08-root-INFO: Learning rate of xt decay: 0.23624 -> 0.23907.
2024-12-01-19:14:08-root-INFO: Coefficient of regularization decay: 0.00056 -> 0.00056.
2024-12-01-19:14:08-root-INFO: step: 75 lr_xt 0.14961620
2024-12-01-19:14:09-root-INFO: grad norm: 14.074 13.965 1.753
2024-12-01-19:14:10-root-INFO: grad norm: 13.352 13.266 1.519
2024-12-01-19:14:10-root-INFO: Loss Change: 164.229 -> 160.350
2024-12-01-19:14:10-root-INFO: Regularization Change: 0.000 -> 0.806
2024-12-01-19:14:10-root-INFO: Undo step: 75
2024-12-01-19:14:10-root-INFO: Undo step: 76
2024-12-01-19:14:10-root-INFO: Undo step: 77
2024-12-01-19:14:11-root-INFO: Undo step: 78
2024-12-01-19:14:11-root-INFO: Undo step: 79
2024-12-01-19:14:11-root-INFO: step: 80 lr_xt 0.13231432
2024-12-01-19:14:11-root-INFO: grad norm: 35.790 35.482 4.687
2024-12-01-19:14:12-root-INFO: grad norm: 16.455 16.238 2.662
2024-12-01-19:14:13-root-INFO: Loss Change: 299.661 -> 188.864
2024-12-01-19:14:13-root-INFO: Regularization Change: 0.000 -> 29.889
2024-12-01-19:14:13-root-INFO: Learning rate of xt decay: 0.22523 -> 0.22793.
2024-12-01-19:14:13-root-INFO: Coefficient of regularization decay: 0.00054 -> 0.00054.
2024-12-01-19:14:13-root-INFO: step: 79 lr_xt 0.13565022
2024-12-01-19:14:14-root-INFO: grad norm: 11.810 11.655 1.907
2024-12-01-19:14:15-root-INFO: grad norm: 11.094 10.968 1.669
2024-12-01-19:14:15-root-INFO: Loss Change: 188.337 -> 175.549
2024-12-01-19:14:15-root-INFO: Regularization Change: 0.000 -> 4.165
2024-12-01-19:14:15-root-INFO: Learning rate of xt decay: 0.22793 -> 0.23067.
2024-12-01-19:14:15-root-INFO: Coefficient of regularization decay: 0.00054 -> 0.00055.
2024-12-01-19:14:16-root-INFO: step: 78 lr_xt 0.13904792
2024-12-01-19:14:16-root-INFO: grad norm: 11.812 11.692 1.678
2024-12-01-19:14:17-root-INFO: grad norm: 12.740 12.653 1.485
2024-12-01-19:14:18-root-INFO: Loss Change: 175.892 -> 171.159
2024-12-01-19:14:18-root-INFO: Regularization Change: 0.000 -> 2.092
2024-12-01-19:14:18-root-INFO: Learning rate of xt decay: 0.23067 -> 0.23344.
2024-12-01-19:14:18-root-INFO: Coefficient of regularization decay: 0.00055 -> 0.00055.
2024-12-01-19:14:18-root-INFO: step: 77 lr_xt 0.14250787
2024-12-01-19:14:18-root-INFO: grad norm: 13.623 13.517 1.696
2024-12-01-19:14:19-root-INFO: grad norm: 13.701 13.624 1.448
2024-12-01-19:14:20-root-INFO: Loss Change: 171.309 -> 166.884
2024-12-01-19:14:20-root-INFO: Regularization Change: 0.000 -> 1.465
2024-12-01-19:14:20-root-INFO: Learning rate of xt decay: 0.23344 -> 0.23624.
2024-12-01-19:14:20-root-INFO: Coefficient of regularization decay: 0.00055 -> 0.00056.
2024-12-01-19:14:20-root-INFO: step: 76 lr_xt 0.14603050
2024-12-01-19:14:21-root-INFO: grad norm: 14.484 14.377 1.759
2024-12-01-19:14:22-root-INFO: grad norm: 14.225 14.141 1.547
2024-12-01-19:14:23-root-INFO: Loss Change: 167.714 -> 163.492
2024-12-01-19:14:23-root-INFO: Regularization Change: 0.000 -> 1.204
2024-12-01-19:14:23-root-INFO: Learning rate of xt decay: 0.23624 -> 0.23907.
2024-12-01-19:14:23-root-INFO: Coefficient of regularization decay: 0.00056 -> 0.00056.
2024-12-01-19:14:23-root-INFO: step: 75 lr_xt 0.14961620
2024-12-01-19:14:23-root-INFO: grad norm: 14.974 14.852 1.907
2024-12-01-19:14:24-root-INFO: grad norm: 14.510 14.407 1.723
2024-12-01-19:14:25-root-INFO: Loss Change: 164.552 -> 160.299
2024-12-01-19:14:25-root-INFO: Regularization Change: 0.000 -> 1.069
2024-12-01-19:14:25-root-INFO: Learning rate of xt decay: 0.23907 -> 0.24194.
2024-12-01-19:14:25-root-INFO: Coefficient of regularization decay: 0.00056 -> 0.00057.
2024-12-01-19:14:25-root-INFO: step: 74 lr_xt 0.15326538
2024-12-01-19:14:26-root-INFO: grad norm: 15.000 14.871 1.966
2024-12-01-19:14:27-root-INFO: grad norm: 14.122 14.012 1.761
2024-12-01-19:14:28-root-INFO: Loss Change: 161.489 -> 156.660
2024-12-01-19:14:28-root-INFO: Regularization Change: 0.000 -> 0.983
2024-12-01-19:14:28-root-INFO: Learning rate of xt decay: 0.24194 -> 0.24485.
2024-12-01-19:14:28-root-INFO: Coefficient of regularization decay: 0.00057 -> 0.00058.
2024-12-01-19:14:28-root-INFO: step: 73 lr_xt 0.15697839
2024-12-01-19:14:28-root-INFO: grad norm: 14.382 14.248 1.957
2024-12-01-19:14:29-root-INFO: grad norm: 13.362 13.253 1.706
2024-12-01-19:14:30-root-INFO: Loss Change: 157.867 -> 153.023
2024-12-01-19:14:30-root-INFO: Regularization Change: 0.000 -> 0.943
2024-12-01-19:14:30-root-INFO: Learning rate of xt decay: 0.24485 -> 0.24778.
2024-12-01-19:14:30-root-INFO: Coefficient of regularization decay: 0.00058 -> 0.00058.
2024-12-01-19:14:30-root-INFO: step: 72 lr_xt 0.16075558
2024-12-01-19:14:31-root-INFO: grad norm: 13.554 13.423 1.877
2024-12-01-19:14:32-root-INFO: grad norm: 12.581 12.475 1.628
2024-12-01-19:14:32-root-INFO: Loss Change: 154.112 -> 149.617
2024-12-01-19:14:32-root-INFO: Regularization Change: 0.000 -> 0.905
2024-12-01-19:14:32-root-INFO: Learning rate of xt decay: 0.24778 -> 0.25076.
2024-12-01-19:14:32-root-INFO: Coefficient of regularization decay: 0.00058 -> 0.00059.
2024-12-01-19:14:33-root-INFO: step: 71 lr_xt 0.16459726
2024-12-01-19:14:33-root-INFO: grad norm: 12.564 12.450 1.685
2024-12-01-19:14:34-root-INFO: grad norm: 11.758 11.663 1.492
2024-12-01-19:14:35-root-INFO: Loss Change: 150.549 -> 146.612
2024-12-01-19:14:35-root-INFO: Regularization Change: 0.000 -> 0.853
2024-12-01-19:14:35-root-INFO: Learning rate of xt decay: 0.25076 -> 0.25377.
2024-12-01-19:14:35-root-INFO: Coefficient of regularization decay: 0.00059 -> 0.00059.
2024-12-01-19:14:35-root-INFO: step: 70 lr_xt 0.16850375
2024-12-01-19:14:35-root-INFO: grad norm: 12.415 12.290 1.763
2024-12-01-19:14:37-root-INFO: grad norm: 11.469 11.373 1.479
2024-12-01-19:14:37-root-INFO: Loss Change: 147.727 -> 143.603
2024-12-01-19:14:37-root-INFO: Regularization Change: 0.000 -> 0.878
2024-12-01-19:14:37-root-INFO: Undo step: 70
2024-12-01-19:14:37-root-INFO: Undo step: 71
2024-12-01-19:14:37-root-INFO: Undo step: 72
2024-12-01-19:14:37-root-INFO: Undo step: 73
2024-12-01-19:14:37-root-INFO: Undo step: 74
2024-12-01-19:14:38-root-INFO: step: 75 lr_xt 0.14961620
2024-12-01-19:14:38-root-INFO: grad norm: 33.075 32.798 4.277
2024-12-01-19:14:39-root-INFO: grad norm: 14.557 14.322 2.608
2024-12-01-19:14:40-root-INFO: Loss Change: 272.830 -> 170.382
2024-12-01-19:14:40-root-INFO: Regularization Change: 0.000 -> 32.421
2024-12-01-19:14:40-root-INFO: Learning rate of xt decay: 0.23907 -> 0.24194.
2024-12-01-19:14:40-root-INFO: Coefficient of regularization decay: 0.00056 -> 0.00057.
2024-12-01-19:14:40-root-INFO: step: 74 lr_xt 0.15326538
2024-12-01-19:14:40-root-INFO: grad norm: 9.601 9.418 1.866
2024-12-01-19:14:41-root-INFO: grad norm: 7.764 7.610 1.540
2024-12-01-19:14:42-root-INFO: Loss Change: 170.404 -> 157.408
2024-12-01-19:14:42-root-INFO: Regularization Change: 0.000 -> 4.300
2024-12-01-19:14:42-root-INFO: Learning rate of xt decay: 0.24194 -> 0.24485.
2024-12-01-19:14:42-root-INFO: Coefficient of regularization decay: 0.00057 -> 0.00058.
2024-12-01-19:14:42-root-INFO: step: 73 lr_xt 0.15697839
2024-12-01-19:14:43-root-INFO: grad norm: 8.429 8.283 1.564
2024-12-01-19:14:44-root-INFO: grad norm: 9.630 9.533 1.360
2024-12-01-19:14:45-root-INFO: Loss Change: 157.708 -> 153.945
2024-12-01-19:14:45-root-INFO: Regularization Change: 0.000 -> 2.350
2024-12-01-19:14:45-root-INFO: Learning rate of xt decay: 0.24485 -> 0.24778.
2024-12-01-19:14:45-root-INFO: Coefficient of regularization decay: 0.00058 -> 0.00058.
2024-12-01-19:14:45-root-INFO: step: 72 lr_xt 0.16075558
2024-12-01-19:14:45-root-INFO: grad norm: 12.740 12.607 1.838
2024-12-01-19:14:46-root-INFO: grad norm: 13.072 12.965 1.669
2024-12-01-19:14:47-root-INFO: Loss Change: 154.746 -> 151.048
2024-12-01-19:14:47-root-INFO: Regularization Change: 0.000 -> 1.796
2024-12-01-19:14:47-root-INFO: Learning rate of xt decay: 0.24778 -> 0.25076.
2024-12-01-19:14:47-root-INFO: Coefficient of regularization decay: 0.00058 -> 0.00059.
2024-12-01-19:14:47-root-INFO: step: 71 lr_xt 0.16459726
2024-12-01-19:14:48-root-INFO: grad norm: 13.736 13.586 2.021
2024-12-01-19:14:49-root-INFO: grad norm: 14.138 14.004 1.939
2024-12-01-19:14:49-root-INFO: Loss Change: 152.000 -> 149.379
2024-12-01-19:14:49-root-INFO: Regularization Change: 0.000 -> 1.334
2024-12-01-19:14:49-root-INFO: Learning rate of xt decay: 0.25076 -> 0.25377.
2024-12-01-19:14:49-root-INFO: Coefficient of regularization decay: 0.00059 -> 0.00059.
2024-12-01-19:14:50-root-INFO: step: 70 lr_xt 0.16850375
2024-12-01-19:14:50-root-INFO: grad norm: 15.841 15.651 2.443
2024-12-01-19:14:51-root-INFO: grad norm: 15.180 15.026 2.161
2024-12-01-19:14:52-root-INFO: Loss Change: 151.102 -> 146.452
2024-12-01-19:14:52-root-INFO: Regularization Change: 0.000 -> 1.178
2024-12-01-19:14:52-root-INFO: Learning rate of xt decay: 0.25377 -> 0.25681.
2024-12-01-19:14:52-root-INFO: Coefficient of regularization decay: 0.00059 -> 0.00060.
2024-12-01-19:14:52-root-INFO: step: 69 lr_xt 0.17247530
2024-12-01-19:14:52-root-INFO: grad norm: 15.129 14.964 2.230
2024-12-01-19:14:54-root-INFO: grad norm: 14.228 14.088 1.993
2024-12-01-19:14:54-root-INFO: Loss Change: 147.878 -> 143.012
2024-12-01-19:14:54-root-INFO: Regularization Change: 0.000 -> 1.065
2024-12-01-19:14:54-root-INFO: Learning rate of xt decay: 0.25681 -> 0.25989.
2024-12-01-19:14:54-root-INFO: Coefficient of regularization decay: 0.00060 -> 0.00061.
2024-12-01-19:14:55-root-INFO: step: 68 lr_xt 0.17651217
2024-12-01-19:14:55-root-INFO: grad norm: 15.220 15.047 2.290
2024-12-01-19:14:56-root-INFO: grad norm: 13.450 13.312 1.922
2024-12-01-19:14:57-root-INFO: Loss Change: 144.694 -> 139.063
2024-12-01-19:14:57-root-INFO: Regularization Change: 0.000 -> 1.296
2024-12-01-19:14:57-root-INFO: Learning rate of xt decay: 0.25989 -> 0.26301.
2024-12-01-19:14:57-root-INFO: Coefficient of regularization decay: 0.00061 -> 0.00061.
2024-12-01-19:14:57-root-INFO: step: 67 lr_xt 0.18061458
2024-12-01-19:14:57-root-INFO: grad norm: 12.870 12.738 1.842
2024-12-01-19:14:58-root-INFO: grad norm: 11.703 11.590 1.622
2024-12-01-19:14:59-root-INFO: Loss Change: 140.010 -> 135.014
2024-12-01-19:14:59-root-INFO: Regularization Change: 0.000 -> 1.188
2024-12-01-19:14:59-root-INFO: Learning rate of xt decay: 0.26301 -> 0.26617.
2024-12-01-19:14:59-root-INFO: Coefficient of regularization decay: 0.00061 -> 0.00062.
2024-12-01-19:14:59-root-INFO: step: 66 lr_xt 0.18478272
2024-12-01-19:15:00-root-INFO: grad norm: 12.078 11.949 1.759
2024-12-01-19:15:01-root-INFO: grad norm: 10.985 10.877 1.540
2024-12-01-19:15:01-root-INFO: Loss Change: 136.021 -> 132.018
2024-12-01-19:15:01-root-INFO: Regularization Change: 0.000 -> 0.994
2024-12-01-19:15:01-root-INFO: Learning rate of xt decay: 0.26617 -> 0.26936.
2024-12-01-19:15:01-root-INFO: Coefficient of regularization decay: 0.00062 -> 0.00062.
2024-12-01-19:15:02-root-INFO: step: 65 lr_xt 0.18901677
2024-12-01-19:15:02-root-INFO: grad norm: 11.158 11.039 1.630
2024-12-01-19:15:03-root-INFO: grad norm: 10.091 9.995 1.384
2024-12-01-19:15:04-root-INFO: Loss Change: 133.161 -> 129.000
2024-12-01-19:15:04-root-INFO: Regularization Change: 0.000 -> 1.030
2024-12-01-19:15:04-root-INFO: Undo step: 65
2024-12-01-19:15:04-root-INFO: Undo step: 66
2024-12-01-19:15:04-root-INFO: Undo step: 67
2024-12-01-19:15:04-root-INFO: Undo step: 68
2024-12-01-19:15:04-root-INFO: Undo step: 69
2024-12-01-19:15:04-root-INFO: step: 70 lr_xt 0.16850375
2024-12-01-19:15:05-root-INFO: grad norm: 30.622 30.364 3.968
2024-12-01-19:15:06-root-INFO: grad norm: 14.239 14.044 2.347
2024-12-01-19:15:06-root-INFO: Loss Change: 256.854 -> 156.382
2024-12-01-19:15:06-root-INFO: Regularization Change: 0.000 -> 35.906
2024-12-01-19:15:06-root-INFO: Learning rate of xt decay: 0.25377 -> 0.25681.
2024-12-01-19:15:06-root-INFO: Coefficient of regularization decay: 0.00059 -> 0.00060.
2024-12-01-19:15:07-root-INFO: step: 69 lr_xt 0.17247530
2024-12-01-19:15:07-root-INFO: grad norm: 10.000 9.864 1.643
2024-12-01-19:15:08-root-INFO: grad norm: 9.046 8.949 1.323
2024-12-01-19:15:09-root-INFO: Loss Change: 156.027 -> 144.344
2024-12-01-19:15:09-root-INFO: Regularization Change: 0.000 -> 4.712
2024-12-01-19:15:09-root-INFO: Learning rate of xt decay: 0.25681 -> 0.25989.
2024-12-01-19:15:09-root-INFO: Coefficient of regularization decay: 0.00060 -> 0.00061.
2024-12-01-19:15:09-root-INFO: step: 68 lr_xt 0.17651217
2024-12-01-19:15:09-root-INFO: grad norm: 9.265 9.194 1.143
2024-12-01-19:15:10-root-INFO: grad norm: 9.531 9.471 1.068
2024-12-01-19:15:11-root-INFO: Loss Change: 143.797 -> 138.827
2024-12-01-19:15:11-root-INFO: Regularization Change: 0.000 -> 2.290
2024-12-01-19:15:11-root-INFO: Learning rate of xt decay: 0.25989 -> 0.26301.
2024-12-01-19:15:11-root-INFO: Coefficient of regularization decay: 0.00061 -> 0.00061.
2024-12-01-19:15:12-root-INFO: step: 67 lr_xt 0.18061458
2024-12-01-19:15:12-root-INFO: grad norm: 9.828 9.778 0.994
2024-12-01-19:15:13-root-INFO: grad norm: 9.873 9.825 0.971
2024-12-01-19:15:14-root-INFO: Loss Change: 138.658 -> 134.880
2024-12-01-19:15:14-root-INFO: Regularization Change: 0.000 -> 1.590
2024-12-01-19:15:14-root-INFO: Learning rate of xt decay: 0.26301 -> 0.26617.
2024-12-01-19:15:14-root-INFO: Coefficient of regularization decay: 0.00061 -> 0.00062.
2024-12-01-19:15:14-root-INFO: step: 66 lr_xt 0.18478272
2024-12-01-19:15:14-root-INFO: grad norm: 9.538 9.495 0.907
2024-12-01-19:15:15-root-INFO: grad norm: 9.238 9.195 0.889
2024-12-01-19:15:16-root-INFO: Loss Change: 134.940 -> 131.319
2024-12-01-19:15:16-root-INFO: Regularization Change: 0.000 -> 1.264
2024-12-01-19:15:16-root-INFO: Learning rate of xt decay: 0.26617 -> 0.26936.
2024-12-01-19:15:16-root-INFO: Coefficient of regularization decay: 0.00062 -> 0.00062.
2024-12-01-19:15:16-root-INFO: step: 65 lr_xt 0.18901677
2024-12-01-19:15:17-root-INFO: grad norm: 8.874 8.831 0.873
2024-12-01-19:15:18-root-INFO: grad norm: 8.410 8.369 0.825
2024-12-01-19:15:18-root-INFO: Loss Change: 131.251 -> 127.788
2024-12-01-19:15:18-root-INFO: Regularization Change: 0.000 -> 1.125
2024-12-01-19:15:18-root-INFO: Learning rate of xt decay: 0.26936 -> 0.27259.
2024-12-01-19:15:18-root-INFO: Coefficient of regularization decay: 0.00062 -> 0.00063.
2024-12-01-19:15:19-root-INFO: step: 64 lr_xt 0.19331686
2024-12-01-19:15:19-root-INFO: grad norm: 8.306 8.265 0.822
2024-12-01-19:15:20-root-INFO: grad norm: 8.146 8.106 0.805
2024-12-01-19:15:21-root-INFO: Loss Change: 127.846 -> 125.129
2024-12-01-19:15:21-root-INFO: Regularization Change: 0.000 -> 1.026
2024-12-01-19:15:21-root-INFO: Learning rate of xt decay: 0.27259 -> 0.27586.
2024-12-01-19:15:21-root-INFO: Coefficient of regularization decay: 0.00063 -> 0.00064.
2024-12-01-19:15:21-root-INFO: step: 63 lr_xt 0.19768311
2024-12-01-19:15:22-root-INFO: grad norm: 8.168 8.122 0.867
2024-12-01-19:15:23-root-INFO: grad norm: 7.747 7.702 0.831
2024-12-01-19:15:23-root-INFO: Loss Change: 125.409 -> 122.380
2024-12-01-19:15:23-root-INFO: Regularization Change: 0.000 -> 1.007
2024-12-01-19:15:23-root-INFO: Learning rate of xt decay: 0.27586 -> 0.27918.
2024-12-01-19:15:23-root-INFO: Coefficient of regularization decay: 0.00064 -> 0.00064.
2024-12-01-19:15:24-root-INFO: step: 62 lr_xt 0.20211560
2024-12-01-19:15:24-root-INFO: grad norm: 8.150 8.096 0.936
2024-12-01-19:15:25-root-INFO: grad norm: 8.042 7.994 0.873
2024-12-01-19:15:26-root-INFO: Loss Change: 122.436 -> 120.026
2024-12-01-19:15:26-root-INFO: Regularization Change: 0.000 -> 1.033
2024-12-01-19:15:26-root-INFO: Learning rate of xt decay: 0.27918 -> 0.28253.
2024-12-01-19:15:26-root-INFO: Coefficient of regularization decay: 0.00064 -> 0.00065.
2024-12-01-19:15:26-root-INFO: step: 61 lr_xt 0.20661437
2024-12-01-19:15:26-root-INFO: grad norm: 7.752 7.703 0.867
2024-12-01-19:15:27-root-INFO: grad norm: 7.027 6.977 0.834
2024-12-01-19:15:28-root-INFO: Loss Change: 120.315 -> 116.961
2024-12-01-19:15:28-root-INFO: Regularization Change: 0.000 -> 1.001
2024-12-01-19:15:28-root-INFO: Learning rate of xt decay: 0.28253 -> 0.28592.
2024-12-01-19:15:28-root-INFO: Coefficient of regularization decay: 0.00065 -> 0.00066.
2024-12-01-19:15:28-root-INFO: step: 60 lr_xt 0.21117946
2024-12-01-19:15:29-root-INFO: grad norm: 7.264 7.208 0.899
2024-12-01-19:15:30-root-INFO: grad norm: 7.160 7.110 0.840
2024-12-01-19:15:30-root-INFO: Loss Change: 117.260 -> 115.081
2024-12-01-19:15:30-root-INFO: Regularization Change: 0.000 -> 0.992
2024-12-01-19:15:30-root-INFO: Undo step: 60
2024-12-01-19:15:30-root-INFO: Undo step: 61
2024-12-01-19:15:30-root-INFO: Undo step: 62
2024-12-01-19:15:30-root-INFO: Undo step: 63
2024-12-01-19:15:30-root-INFO: Undo step: 64
2024-12-01-19:15:31-root-INFO: step: 65 lr_xt 0.18901677
2024-12-01-19:15:31-root-INFO: grad norm: 26.345 26.148 3.211
2024-12-01-19:15:32-root-INFO: grad norm: 11.730 11.546 2.069
2024-12-01-19:15:33-root-INFO: Loss Change: 228.206 -> 140.140
2024-12-01-19:15:33-root-INFO: Regularization Change: 0.000 -> 35.965
2024-12-01-19:15:33-root-INFO: Learning rate of xt decay: 0.26936 -> 0.27259.
2024-12-01-19:15:33-root-INFO: Coefficient of regularization decay: 0.00062 -> 0.00063.
2024-12-01-19:15:33-root-INFO: step: 64 lr_xt 0.19331686
2024-12-01-19:15:34-root-INFO: grad norm: 8.403 8.293 1.358
2024-12-01-19:15:35-root-INFO: grad norm: 7.452 7.367 1.121
2024-12-01-19:15:35-root-INFO: Loss Change: 139.919 -> 129.141
2024-12-01-19:15:35-root-INFO: Regularization Change: 0.000 -> 4.715
2024-12-01-19:15:35-root-INFO: Learning rate of xt decay: 0.27259 -> 0.27586.
2024-12-01-19:15:35-root-INFO: Coefficient of regularization decay: 0.00063 -> 0.00064.
2024-12-01-19:15:36-root-INFO: step: 63 lr_xt 0.19768311
2024-12-01-19:15:36-root-INFO: grad norm: 7.905 7.829 1.092
2024-12-01-19:15:37-root-INFO: grad norm: 7.496 7.438 0.936
2024-12-01-19:15:38-root-INFO: Loss Change: 129.319 -> 123.745
2024-12-01-19:15:38-root-INFO: Regularization Change: 0.000 -> 2.486
2024-12-01-19:15:38-root-INFO: Learning rate of xt decay: 0.27586 -> 0.27918.
2024-12-01-19:15:38-root-INFO: Coefficient of regularization decay: 0.00064 -> 0.00064.
2024-12-01-19:15:38-root-INFO: step: 62 lr_xt 0.20211560
2024-12-01-19:15:38-root-INFO: grad norm: 7.834 7.753 1.124
2024-12-01-19:15:39-root-INFO: grad norm: 8.162 8.097 1.031
2024-12-01-19:15:40-root-INFO: Loss Change: 123.797 -> 120.695
2024-12-01-19:15:40-root-INFO: Regularization Change: 0.000 -> 1.832
2024-12-01-19:15:40-root-INFO: Learning rate of xt decay: 0.27918 -> 0.28253.
2024-12-01-19:15:40-root-INFO: Coefficient of regularization decay: 0.00064 -> 0.00065.
2024-12-01-19:15:40-root-INFO: step: 61 lr_xt 0.20661437
2024-12-01-19:15:41-root-INFO: grad norm: 9.384 9.298 1.265
2024-12-01-19:15:42-root-INFO: grad norm: 9.046 8.969 1.173
2024-12-01-19:15:42-root-INFO: Loss Change: 121.119 -> 117.695
2024-12-01-19:15:42-root-INFO: Regularization Change: 0.000 -> 1.509
2024-12-01-19:15:42-root-INFO: Learning rate of xt decay: 0.28253 -> 0.28592.
2024-12-01-19:15:42-root-INFO: Coefficient of regularization decay: 0.00065 -> 0.00066.
2024-12-01-19:15:43-root-INFO: step: 60 lr_xt 0.21117946
2024-12-01-19:15:43-root-INFO: grad norm: 9.241 9.145 1.328
2024-12-01-19:15:44-root-INFO: grad norm: 9.118 9.043 1.172
2024-12-01-19:15:45-root-INFO: Loss Change: 118.374 -> 115.564
2024-12-01-19:15:45-root-INFO: Regularization Change: 0.000 -> 1.339
2024-12-01-19:15:45-root-INFO: Learning rate of xt decay: 0.28592 -> 0.28935.
2024-12-01-19:15:45-root-INFO: Coefficient of regularization decay: 0.00066 -> 0.00066.
2024-12-01-19:15:45-root-INFO: step: 59 lr_xt 0.21581084
2024-12-01-19:15:46-root-INFO: grad norm: 10.335 10.232 1.453
2024-12-01-19:15:47-root-INFO: grad norm: 9.677 9.592 1.285
2024-12-01-19:15:47-root-INFO: Loss Change: 116.320 -> 112.930
2024-12-01-19:15:47-root-INFO: Regularization Change: 0.000 -> 1.285
2024-12-01-19:15:47-root-INFO: Learning rate of xt decay: 0.28935 -> 0.29282.
2024-12-01-19:15:47-root-INFO: Coefficient of regularization decay: 0.00066 -> 0.00067.
2024-12-01-19:15:48-root-INFO: step: 58 lr_xt 0.22050848
2024-12-01-19:15:48-root-INFO: grad norm: 9.623 9.525 1.367
2024-12-01-19:15:49-root-INFO: grad norm: 8.947 8.866 1.200
2024-12-01-19:15:50-root-INFO: Loss Change: 113.492 -> 109.845
2024-12-01-19:15:50-root-INFO: Regularization Change: 0.000 -> 1.195
2024-12-01-19:15:50-root-INFO: Learning rate of xt decay: 0.29282 -> 0.29633.
2024-12-01-19:15:50-root-INFO: Coefficient of regularization decay: 0.00067 -> 0.00068.
2024-12-01-19:15:50-root-INFO: step: 57 lr_xt 0.22527231
2024-12-01-19:15:50-root-INFO: grad norm: 9.207 9.113 1.313
2024-12-01-19:15:51-root-INFO: grad norm: 8.830 8.744 1.231
2024-12-01-19:15:52-root-INFO: Loss Change: 110.295 -> 107.519
2024-12-01-19:15:52-root-INFO: Regularization Change: 0.000 -> 1.126
2024-12-01-19:15:52-root-INFO: Learning rate of xt decay: 0.29633 -> 0.29989.
2024-12-01-19:15:52-root-INFO: Coefficient of regularization decay: 0.00068 -> 0.00068.
2024-12-01-19:15:52-root-INFO: step: 56 lr_xt 0.23010221
2024-12-01-19:15:53-root-INFO: grad norm: 9.868 9.769 1.392
2024-12-01-19:15:54-root-INFO: grad norm: 8.499 8.413 1.205
2024-12-01-19:15:55-root-INFO: Loss Change: 108.261 -> 104.749
2024-12-01-19:15:55-root-INFO: Regularization Change: 0.000 -> 1.494
2024-12-01-19:15:55-root-INFO: Learning rate of xt decay: 0.29989 -> 0.30349.
2024-12-01-19:15:55-root-INFO: Coefficient of regularization decay: 0.00068 -> 0.00069.
2024-12-01-19:15:55-root-INFO: step: 55 lr_xt 0.23499803
2024-12-01-19:15:55-root-INFO: grad norm: 8.359 8.274 1.187
2024-12-01-19:15:56-root-INFO: grad norm: 7.545 7.476 1.016
2024-12-01-19:15:57-root-INFO: Loss Change: 105.233 -> 101.618
2024-12-01-19:15:57-root-INFO: Regularization Change: 0.000 -> 1.197
2024-12-01-19:15:57-root-INFO: Undo step: 55
2024-12-01-19:15:57-root-INFO: Undo step: 56
2024-12-01-19:15:57-root-INFO: Undo step: 57
2024-12-01-19:15:57-root-INFO: Undo step: 58
2024-12-01-19:15:57-root-INFO: Undo step: 59
2024-12-01-19:15:57-root-INFO: step: 60 lr_xt 0.21117946
2024-12-01-19:15:58-root-INFO: grad norm: 23.263 22.994 3.524
2024-12-01-19:15:59-root-INFO: grad norm: 10.741 10.606 1.700
2024-12-01-19:15:59-root-INFO: Loss Change: 201.509 -> 124.952
2024-12-01-19:15:59-root-INFO: Regularization Change: 0.000 -> 34.201
2024-12-01-19:15:59-root-INFO: Learning rate of xt decay: 0.28592 -> 0.28935.
2024-12-01-19:15:59-root-INFO: Coefficient of regularization decay: 0.00066 -> 0.00066.
2024-12-01-19:16:00-root-INFO: step: 59 lr_xt 0.21581084
2024-12-01-19:16:00-root-INFO: grad norm: 7.051 6.944 1.225
2024-12-01-19:16:01-root-INFO: grad norm: 5.807 5.732 0.927
2024-12-01-19:16:02-root-INFO: Loss Change: 124.568 -> 113.995
2024-12-01-19:16:02-root-INFO: Regularization Change: 0.000 -> 5.014
2024-12-01-19:16:02-root-INFO: Learning rate of xt decay: 0.28935 -> 0.29282.
2024-12-01-19:16:02-root-INFO: Coefficient of regularization decay: 0.00066 -> 0.00067.
2024-12-01-19:16:02-root-INFO: step: 58 lr_xt 0.22050848
2024-12-01-19:16:03-root-INFO: grad norm: 5.353 5.288 0.835
2024-12-01-19:16:04-root-INFO: grad norm: 6.113 6.066 0.762
2024-12-01-19:16:04-root-INFO: Loss Change: 113.595 -> 109.219
2024-12-01-19:16:04-root-INFO: Regularization Change: 0.000 -> 2.741
2024-12-01-19:16:04-root-INFO: Learning rate of xt decay: 0.29282 -> 0.29633.
2024-12-01-19:16:04-root-INFO: Coefficient of regularization decay: 0.00067 -> 0.00068.
2024-12-01-19:16:05-root-INFO: step: 57 lr_xt 0.22527231
2024-12-01-19:16:05-root-INFO: grad norm: 4.837 4.787 0.691
2024-12-01-19:16:06-root-INFO: grad norm: 4.849 4.799 0.692
2024-12-01-19:16:07-root-INFO: Loss Change: 108.659 -> 104.439
2024-12-01-19:16:07-root-INFO: Regularization Change: 0.000 -> 2.421
2024-12-01-19:16:07-root-INFO: Learning rate of xt decay: 0.29633 -> 0.29989.
2024-12-01-19:16:07-root-INFO: Coefficient of regularization decay: 0.00068 -> 0.00068.
2024-12-01-19:16:07-root-INFO: step: 56 lr_xt 0.23010221
2024-12-01-19:16:07-root-INFO: grad norm: 4.912 4.859 0.720
2024-12-01-19:16:08-root-INFO: grad norm: 4.780 4.725 0.722
2024-12-01-19:16:09-root-INFO: Loss Change: 104.335 -> 101.331
2024-12-01-19:16:09-root-INFO: Regularization Change: 0.000 -> 1.584
2024-12-01-19:16:09-root-INFO: Learning rate of xt decay: 0.29989 -> 0.30349.
2024-12-01-19:16:09-root-INFO: Coefficient of regularization decay: 0.00068 -> 0.00069.
2024-12-01-19:16:09-root-INFO: step: 55 lr_xt 0.23499803
2024-12-01-19:16:10-root-INFO: grad norm: 6.292 6.223 0.926
2024-12-01-19:16:11-root-INFO: grad norm: 5.814 5.752 0.850
2024-12-01-19:16:11-root-INFO: Loss Change: 101.454 -> 98.760
2024-12-01-19:16:11-root-INFO: Regularization Change: 0.000 -> 1.570
2024-12-01-19:16:11-root-INFO: Learning rate of xt decay: 0.30349 -> 0.30713.
2024-12-01-19:16:11-root-INFO: Coefficient of regularization decay: 0.00069 -> 0.00070.
2024-12-01-19:16:12-root-INFO: step: 54 lr_xt 0.23995961
2024-12-01-19:16:12-root-INFO: grad norm: 5.396 5.315 0.928
2024-12-01-19:16:13-root-INFO: grad norm: 4.786 4.729 0.741
2024-12-01-19:16:14-root-INFO: Loss Change: 98.748 -> 95.587
2024-12-01-19:16:14-root-INFO: Regularization Change: 0.000 -> 1.382
2024-12-01-19:16:14-root-INFO: Learning rate of xt decay: 0.30713 -> 0.31081.
2024-12-01-19:16:14-root-INFO: Coefficient of regularization decay: 0.00070 -> 0.00070.
2024-12-01-19:16:14-root-INFO: step: 53 lr_xt 0.24498673
2024-12-01-19:16:15-root-INFO: grad norm: 5.329 5.253 0.896
2024-12-01-19:16:16-root-INFO: grad norm: 5.993 5.933 0.844
2024-12-01-19:16:16-root-INFO: Loss Change: 95.727 -> 94.678
2024-12-01-19:16:16-root-INFO: Regularization Change: 0.000 -> 1.259
2024-12-01-19:16:16-root-INFO: Learning rate of xt decay: 0.31081 -> 0.31454.
2024-12-01-19:16:16-root-INFO: Coefficient of regularization decay: 0.00070 -> 0.00071.
2024-12-01-19:16:17-root-INFO: step: 52 lr_xt 0.25007913
2024-12-01-19:16:17-root-INFO: grad norm: 7.579 7.505 1.052
2024-12-01-19:16:18-root-INFO: grad norm: 6.262 6.189 0.952
2024-12-01-19:16:19-root-INFO: Loss Change: 95.016 -> 91.781
2024-12-01-19:16:19-root-INFO: Regularization Change: 0.000 -> 1.606
2024-12-01-19:16:19-root-INFO: Learning rate of xt decay: 0.31454 -> 0.31832.
2024-12-01-19:16:19-root-INFO: Coefficient of regularization decay: 0.00071 -> 0.00072.
2024-12-01-19:16:19-root-INFO: step: 51 lr_xt 0.25523653
2024-12-01-19:16:19-root-INFO: grad norm: 6.240 6.165 0.967
2024-12-01-19:16:20-root-INFO: grad norm: 5.834 5.781 0.785
2024-12-01-19:16:21-root-INFO: Loss Change: 92.035 -> 89.398
2024-12-01-19:16:21-root-INFO: Regularization Change: 0.000 -> 1.304
2024-12-01-19:16:21-root-INFO: Learning rate of xt decay: 0.31832 -> 0.32214.
2024-12-01-19:16:21-root-INFO: Coefficient of regularization decay: 0.00072 -> 0.00072.
2024-12-01-19:16:21-root-INFO: step: 50 lr_xt 0.26045862
2024-12-01-19:16:22-root-INFO: grad norm: 6.016 5.957 0.843
2024-12-01-19:16:23-root-INFO: grad norm: 5.937 5.886 0.778
2024-12-01-19:16:23-root-INFO: Loss Change: 89.372 -> 87.403
2024-12-01-19:16:23-root-INFO: Regularization Change: 0.000 -> 1.200
2024-12-01-19:16:23-root-INFO: Undo step: 50
2024-12-01-19:16:23-root-INFO: Undo step: 51
2024-12-01-19:16:23-root-INFO: Undo step: 52
2024-12-01-19:16:23-root-INFO: Undo step: 53
2024-12-01-19:16:23-root-INFO: Undo step: 54
2024-12-01-19:16:24-root-INFO: step: 55 lr_xt 0.23499803
2024-12-01-19:16:24-root-INFO: grad norm: 21.420 21.274 2.498
2024-12-01-19:16:25-root-INFO: grad norm: 9.436 9.299 1.600
2024-12-01-19:16:26-root-INFO: Loss Change: 183.394 -> 110.527
2024-12-01-19:16:26-root-INFO: Regularization Change: 0.000 -> 36.759
2024-12-01-19:16:26-root-INFO: Learning rate of xt decay: 0.30349 -> 0.30713.
2024-12-01-19:16:26-root-INFO: Coefficient of regularization decay: 0.00069 -> 0.00070.
2024-12-01-19:16:26-root-INFO: step: 54 lr_xt 0.23995961
2024-12-01-19:16:27-root-INFO: grad norm: 6.874 6.790 1.072
2024-12-01-19:16:28-root-INFO: grad norm: 6.197 6.121 0.969
2024-12-01-19:16:28-root-INFO: Loss Change: 110.068 -> 100.308
2024-12-01-19:16:28-root-INFO: Regularization Change: 0.000 -> 5.373
2024-12-01-19:16:28-root-INFO: Learning rate of xt decay: 0.30713 -> 0.31081.
2024-12-01-19:16:28-root-INFO: Coefficient of regularization decay: 0.00070 -> 0.00070.
2024-12-01-19:16:29-root-INFO: step: 53 lr_xt 0.24498673
2024-12-01-19:16:29-root-INFO: grad norm: 5.377 5.315 0.814
2024-12-01-19:16:30-root-INFO: grad norm: 4.586 4.515 0.803
2024-12-01-19:16:31-root-INFO: Loss Change: 100.065 -> 94.240
2024-12-01-19:16:31-root-INFO: Regularization Change: 0.000 -> 2.761
2024-12-01-19:16:31-root-INFO: Learning rate of xt decay: 0.31081 -> 0.31454.
2024-12-01-19:16:31-root-INFO: Coefficient of regularization decay: 0.00070 -> 0.00071.
2024-12-01-19:16:31-root-INFO: step: 52 lr_xt 0.25007913
2024-12-01-19:16:31-root-INFO: grad norm: 4.678 4.598 0.859
2024-12-01-19:16:32-root-INFO: grad norm: 5.070 4.985 0.922
2024-12-01-19:16:33-root-INFO: Loss Change: 94.105 -> 91.289
2024-12-01-19:16:33-root-INFO: Regularization Change: 0.000 -> 1.937
2024-12-01-19:16:33-root-INFO: Learning rate of xt decay: 0.31454 -> 0.31832.
2024-12-01-19:16:33-root-INFO: Coefficient of regularization decay: 0.00071 -> 0.00072.
2024-12-01-19:16:33-root-INFO: step: 51 lr_xt 0.25523653
2024-12-01-19:16:34-root-INFO: grad norm: 5.449 5.359 0.986
2024-12-01-19:16:35-root-INFO: grad norm: 5.528 5.412 1.123
2024-12-01-19:16:36-root-INFO: Loss Change: 91.203 -> 88.609
2024-12-01-19:16:36-root-INFO: Regularization Change: 0.000 -> 1.540
2024-12-01-19:16:36-root-INFO: Learning rate of xt decay: 0.31832 -> 0.32214.
2024-12-01-19:16:36-root-INFO: Coefficient of regularization decay: 0.00072 -> 0.00072.
2024-12-01-19:16:36-root-INFO: step: 50 lr_xt 0.26045862
2024-12-01-19:16:36-root-INFO: grad norm: 6.160 6.068 1.059
2024-12-01-19:16:37-root-INFO: grad norm: 6.099 5.983 1.181
2024-12-01-19:16:38-root-INFO: Loss Change: 88.432 -> 85.931
2024-12-01-19:16:38-root-INFO: Regularization Change: 0.000 -> 1.392
2024-12-01-19:16:38-root-INFO: Learning rate of xt decay: 0.32214 -> 0.32600.
2024-12-01-19:16:38-root-INFO: Coefficient of regularization decay: 0.00072 -> 0.00073.
2024-12-01-19:16:38-root-INFO: step: 49 lr_xt 0.26574501
2024-12-01-19:16:39-root-INFO: grad norm: 6.152 6.062 1.048
2024-12-01-19:16:40-root-INFO: grad norm: 5.845 5.744 1.080
2024-12-01-19:16:40-root-INFO: Loss Change: 86.025 -> 83.333
2024-12-01-19:16:40-root-INFO: Regularization Change: 0.000 -> 1.281
2024-12-01-19:16:40-root-INFO: Learning rate of xt decay: 0.32600 -> 0.32992.
2024-12-01-19:16:40-root-INFO: Coefficient of regularization decay: 0.00073 -> 0.00074.
2024-12-01-19:16:41-root-INFO: step: 48 lr_xt 0.27109532
2024-12-01-19:16:41-root-INFO: grad norm: 5.966 5.892 0.932
2024-12-01-19:16:42-root-INFO: grad norm: 5.750 5.683 0.873
2024-12-01-19:16:43-root-INFO: Loss Change: 83.368 -> 80.983
2024-12-01-19:16:43-root-INFO: Regularization Change: 0.000 -> 1.203
2024-12-01-19:16:43-root-INFO: Learning rate of xt decay: 0.32992 -> 0.33388.
2024-12-01-19:16:43-root-INFO: Coefficient of regularization decay: 0.00074 -> 0.00075.
2024-12-01-19:16:43-root-INFO: step: 47 lr_xt 0.27650911
2024-12-01-19:16:44-root-INFO: grad norm: 6.001 5.935 0.889
2024-12-01-19:16:45-root-INFO: grad norm: 5.765 5.712 0.785
2024-12-01-19:16:45-root-INFO: Loss Change: 81.171 -> 78.839
2024-12-01-19:16:45-root-INFO: Regularization Change: 0.000 -> 1.177
2024-12-01-19:16:45-root-INFO: Learning rate of xt decay: 0.33388 -> 0.33788.
2024-12-01-19:16:45-root-INFO: Coefficient of regularization decay: 0.00075 -> 0.00075.
2024-12-01-19:16:46-root-INFO: step: 46 lr_xt 0.28198590
2024-12-01-19:16:46-root-INFO: grad norm: 5.990 5.934 0.818
2024-12-01-19:16:47-root-INFO: grad norm: 5.781 5.733 0.746
2024-12-01-19:16:48-root-INFO: Loss Change: 78.962 -> 76.735
2024-12-01-19:16:48-root-INFO: Regularization Change: 0.000 -> 1.149
2024-12-01-19:16:48-root-INFO: Learning rate of xt decay: 0.33788 -> 0.34194.
2024-12-01-19:16:48-root-INFO: Coefficient of regularization decay: 0.00075 -> 0.00076.
2024-12-01-19:16:48-root-INFO: step: 45 lr_xt 0.28752516
2024-12-01-19:16:48-root-INFO: grad norm: 6.005 5.951 0.801
2024-12-01-19:16:49-root-INFO: grad norm: 5.752 5.704 0.740
2024-12-01-19:16:50-root-INFO: Loss Change: 76.813 -> 74.546
2024-12-01-19:16:50-root-INFO: Regularization Change: 0.000 -> 1.147
2024-12-01-19:16:50-root-INFO: Undo step: 45
2024-12-01-19:16:50-root-INFO: Undo step: 46
2024-12-01-19:16:50-root-INFO: Undo step: 47
2024-12-01-19:16:50-root-INFO: Undo step: 48
2024-12-01-19:16:50-root-INFO: Undo step: 49
2024-12-01-19:16:50-root-INFO: step: 50 lr_xt 0.26045862
2024-12-01-19:16:51-root-INFO: grad norm: 20.365 20.247 2.182
2024-12-01-19:16:52-root-INFO: grad norm: 10.469 10.372 1.420
2024-12-01-19:16:52-root-INFO: Loss Change: 164.401 -> 99.053
2024-12-01-19:16:53-root-INFO: Regularization Change: 0.000 -> 36.238
2024-12-01-19:16:53-root-INFO: Learning rate of xt decay: 0.32214 -> 0.32600.
2024-12-01-19:16:53-root-INFO: Coefficient of regularization decay: 0.00072 -> 0.00073.
2024-12-01-19:16:53-root-INFO: step: 49 lr_xt 0.26574501
2024-12-01-19:16:53-root-INFO: grad norm: 7.293 7.223 1.012
2024-12-01-19:16:54-root-INFO: grad norm: 6.471 6.389 1.028
2024-12-01-19:16:55-root-INFO: Loss Change: 98.286 -> 88.899
2024-12-01-19:16:55-root-INFO: Regularization Change: 0.000 -> 5.459
2024-12-01-19:16:55-root-INFO: Learning rate of xt decay: 0.32600 -> 0.32992.
2024-12-01-19:16:55-root-INFO: Coefficient of regularization decay: 0.00073 -> 0.00074.
2024-12-01-19:16:55-root-INFO: step: 48 lr_xt 0.27109532
2024-12-01-19:16:56-root-INFO: grad norm: 6.207 6.145 0.870
2024-12-01-19:16:57-root-INFO: grad norm: 6.392 6.312 1.009
2024-12-01-19:16:57-root-INFO: Loss Change: 88.614 -> 84.327
2024-12-01-19:16:57-root-INFO: Regularization Change: 0.000 -> 3.076
2024-12-01-19:16:57-root-INFO: Learning rate of xt decay: 0.32992 -> 0.33388.
2024-12-01-19:16:57-root-INFO: Coefficient of regularization decay: 0.00074 -> 0.00075.
2024-12-01-19:16:58-root-INFO: step: 47 lr_xt 0.27650911
2024-12-01-19:16:58-root-INFO: grad norm: 6.570 6.502 0.945
2024-12-01-19:16:59-root-INFO: grad norm: 7.435 7.353 1.101
2024-12-01-19:17:00-root-INFO: Loss Change: 83.908 -> 81.743
2024-12-01-19:17:00-root-INFO: Regularization Change: 0.000 -> 2.384
2024-12-01-19:17:00-root-INFO: Learning rate of xt decay: 0.33388 -> 0.33788.
2024-12-01-19:17:00-root-INFO: Coefficient of regularization decay: 0.00075 -> 0.00075.
2024-12-01-19:17:00-root-INFO: step: 46 lr_xt 0.28198590
2024-12-01-19:17:00-root-INFO: grad norm: 6.494 6.418 0.990
2024-12-01-19:17:02-root-INFO: grad norm: 5.661 5.570 1.012
2024-12-01-19:17:02-root-INFO: Loss Change: 81.266 -> 76.433
2024-12-01-19:17:02-root-INFO: Regularization Change: 0.000 -> 2.231
2024-12-01-19:17:02-root-INFO: Learning rate of xt decay: 0.33788 -> 0.34194.
2024-12-01-19:17:02-root-INFO: Coefficient of regularization decay: 0.00075 -> 0.00076.
2024-12-01-19:17:03-root-INFO: step: 45 lr_xt 0.28752516
2024-12-01-19:17:03-root-INFO: grad norm: 5.374 5.304 0.860
2024-12-01-19:17:04-root-INFO: grad norm: 5.701 5.622 0.943
2024-12-01-19:17:05-root-INFO: Loss Change: 75.989 -> 74.275
2024-12-01-19:17:05-root-INFO: Regularization Change: 0.000 -> 1.606
2024-12-01-19:17:05-root-INFO: Learning rate of xt decay: 0.34194 -> 0.34604.
2024-12-01-19:17:05-root-INFO: Coefficient of regularization decay: 0.00076 -> 0.00077.
2024-12-01-19:17:05-root-INFO: step: 44 lr_xt 0.29312635
2024-12-01-19:17:05-root-INFO: grad norm: 6.006 5.943 0.868
2024-12-01-19:17:06-root-INFO: grad norm: 6.714 6.647 0.947
2024-12-01-19:17:07-root-INFO: Loss Change: 74.046 -> 72.961
2024-12-01-19:17:07-root-INFO: Regularization Change: 0.000 -> 1.574
2024-12-01-19:17:07-root-INFO: Learning rate of xt decay: 0.34604 -> 0.35019.
2024-12-01-19:17:07-root-INFO: Coefficient of regularization decay: 0.00077 -> 0.00078.
2024-12-01-19:17:08-root-INFO: step: 43 lr_xt 0.29878886
2024-12-01-19:17:08-root-INFO: grad norm: 6.032 5.974 0.835
2024-12-01-19:17:09-root-INFO: grad norm: 5.405 5.349 0.777
2024-12-01-19:17:10-root-INFO: Loss Change: 72.392 -> 68.953
2024-12-01-19:17:10-root-INFO: Regularization Change: 0.000 -> 1.540
2024-12-01-19:17:10-root-INFO: Learning rate of xt decay: 0.35019 -> 0.35439.
2024-12-01-19:17:10-root-INFO: Coefficient of regularization decay: 0.00078 -> 0.00078.
2024-12-01-19:17:10-root-INFO: step: 42 lr_xt 0.30451205
2024-12-01-19:17:10-root-INFO: grad norm: 5.313 5.264 0.722
2024-12-01-19:17:11-root-INFO: grad norm: 5.713 5.667 0.727
2024-12-01-19:17:12-root-INFO: Loss Change: 68.681 -> 67.421
2024-12-01-19:17:12-root-INFO: Regularization Change: 0.000 -> 1.382
2024-12-01-19:17:12-root-INFO: Learning rate of xt decay: 0.35439 -> 0.35865.
2024-12-01-19:17:12-root-INFO: Coefficient of regularization decay: 0.00078 -> 0.00079.
2024-12-01-19:17:12-root-INFO: step: 41 lr_xt 0.31082203
2024-12-01-19:17:13-root-INFO: grad norm: 5.506 5.465 0.670
2024-12-01-19:17:14-root-INFO: grad norm: 5.321 5.281 0.647
2024-12-01-19:17:14-root-INFO: Loss Change: 66.963 -> 64.706
2024-12-01-19:17:14-root-INFO: Regularization Change: 0.000 -> 1.309
2024-12-01-19:17:14-root-INFO: Learning rate of xt decay: 0.35865 -> 0.36295.
2024-12-01-19:17:14-root-INFO: Coefficient of regularization decay: 0.00079 -> 0.00080.
2024-12-01-19:17:15-root-INFO: step: 40 lr_xt 0.31666177
2024-12-01-19:17:15-root-INFO: grad norm: 5.267 5.229 0.632
2024-12-01-19:17:16-root-INFO: grad norm: 5.359 5.323 0.618
2024-12-01-19:17:17-root-INFO: Loss Change: 64.362 -> 62.622
2024-12-01-19:17:17-root-INFO: Regularization Change: 0.000 -> 1.290
2024-12-01-19:17:17-root-INFO: Undo step: 40
2024-12-01-19:17:17-root-INFO: Undo step: 41
2024-12-01-19:17:17-root-INFO: Undo step: 42
2024-12-01-19:17:17-root-INFO: Undo step: 43
2024-12-01-19:17:17-root-INFO: Undo step: 44
2024-12-01-19:17:17-root-INFO: step: 45 lr_xt 0.28752516
2024-12-01-19:17:18-root-INFO: grad norm: 20.468 20.338 2.305
2024-12-01-19:17:19-root-INFO: grad norm: 11.291 11.186 1.534
2024-12-01-19:17:19-root-INFO: Loss Change: 161.520 -> 88.518
2024-12-01-19:17:19-root-INFO: Regularization Change: 0.000 -> 45.898
2024-12-01-19:17:19-root-INFO: Learning rate of xt decay: 0.34194 -> 0.34604.
2024-12-01-19:17:19-root-INFO: Coefficient of regularization decay: 0.00076 -> 0.00077.
2024-12-01-19:17:20-root-INFO: step: 44 lr_xt 0.29312635
2024-12-01-19:17:20-root-INFO: grad norm: 7.783 7.705 1.099
2024-12-01-19:17:21-root-INFO: grad norm: 7.031 6.952 1.047
2024-12-01-19:17:22-root-INFO: Loss Change: 87.924 -> 77.807
2024-12-01-19:17:22-root-INFO: Regularization Change: 0.000 -> 6.740
2024-12-01-19:17:22-root-INFO: Learning rate of xt decay: 0.34604 -> 0.35019.
2024-12-01-19:17:22-root-INFO: Coefficient of regularization decay: 0.00077 -> 0.00078.
2024-12-01-19:17:22-root-INFO: step: 43 lr_xt 0.29878886
2024-12-01-19:17:23-root-INFO: grad norm: 5.586 5.529 0.792
2024-12-01-19:17:24-root-INFO: grad norm: 5.018 4.956 0.790
2024-12-01-19:17:24-root-INFO: Loss Change: 77.010 -> 70.924
2024-12-01-19:17:24-root-INFO: Regularization Change: 0.000 -> 3.551
2024-12-01-19:17:24-root-INFO: Learning rate of xt decay: 0.35019 -> 0.35439.
2024-12-01-19:17:24-root-INFO: Coefficient of regularization decay: 0.00078 -> 0.00078.
2024-12-01-19:17:25-root-INFO: step: 42 lr_xt 0.30451205
2024-12-01-19:17:25-root-INFO: grad norm: 4.516 4.474 0.613
2024-12-01-19:17:26-root-INFO: grad norm: 4.447 4.402 0.633
2024-12-01-19:17:27-root-INFO: Loss Change: 70.500 -> 67.173
2024-12-01-19:17:27-root-INFO: Regularization Change: 0.000 -> 2.209
2024-12-01-19:17:27-root-INFO: Learning rate of xt decay: 0.35439 -> 0.35865.
2024-12-01-19:17:27-root-INFO: Coefficient of regularization decay: 0.00078 -> 0.00079.
2024-12-01-19:17:27-root-INFO: step: 41 lr_xt 0.31082203
2024-12-01-19:17:28-root-INFO: grad norm: 4.306 4.272 0.534
2024-12-01-19:17:29-root-INFO: grad norm: 4.695 4.659 0.584
2024-12-01-19:17:29-root-INFO: Loss Change: 66.642 -> 64.744
2024-12-01-19:17:29-root-INFO: Regularization Change: 0.000 -> 1.959
2024-12-01-19:17:29-root-INFO: Learning rate of xt decay: 0.35865 -> 0.36295.
2024-12-01-19:17:29-root-INFO: Coefficient of regularization decay: 0.00079 -> 0.00080.
2024-12-01-19:17:30-root-INFO: step: 40 lr_xt 0.31666177
2024-12-01-19:17:30-root-INFO: grad norm: 5.060 5.030 0.548
2024-12-01-19:17:31-root-INFO: grad norm: 5.761 5.726 0.639
2024-12-01-19:17:32-root-INFO: Loss Change: 64.219 -> 62.944
2024-12-01-19:17:32-root-INFO: Regularization Change: 0.000 -> 1.760
2024-12-01-19:17:32-root-INFO: Learning rate of xt decay: 0.36295 -> 0.36731.
2024-12-01-19:17:32-root-INFO: Coefficient of regularization decay: 0.00080 -> 0.00081.
2024-12-01-19:17:32-root-INFO: step: 39 lr_xt 0.32255964
2024-12-01-19:17:32-root-INFO: grad norm: 5.378 5.346 0.590
2024-12-01-19:17:33-root-INFO: grad norm: 5.076 5.040 0.597
2024-12-01-19:17:34-root-INFO: Loss Change: 62.535 -> 59.705
2024-12-01-19:17:34-root-INFO: Regularization Change: 0.000 -> 1.582
2024-12-01-19:17:34-root-INFO: Learning rate of xt decay: 0.36731 -> 0.37171.
2024-12-01-19:17:34-root-INFO: Coefficient of regularization decay: 0.00081 -> 0.00082.
2024-12-01-19:17:34-root-INFO: step: 38 lr_xt 0.32851483
2024-12-01-19:17:35-root-INFO: grad norm: 5.200 5.172 0.545
2024-12-01-19:17:36-root-INFO: grad norm: 5.487 5.456 0.584
2024-12-01-19:17:36-root-INFO: Loss Change: 59.332 -> 57.774
2024-12-01-19:17:37-root-INFO: Regularization Change: 0.000 -> 1.491
2024-12-01-19:17:37-root-INFO: Learning rate of xt decay: 0.37171 -> 0.37617.
2024-12-01-19:17:37-root-INFO: Coefficient of regularization decay: 0.00082 -> 0.00082.
2024-12-01-19:17:37-root-INFO: step: 37 lr_xt 0.33452649
2024-12-01-19:17:37-root-INFO: grad norm: 5.173 5.147 0.522
2024-12-01-19:17:38-root-INFO: grad norm: 4.957 4.927 0.536
2024-12-01-19:17:39-root-INFO: Loss Change: 57.292 -> 54.978
2024-12-01-19:17:39-root-INFO: Regularization Change: 0.000 -> 1.394
2024-12-01-19:17:39-root-INFO: Learning rate of xt decay: 0.37617 -> 0.38069.
2024-12-01-19:17:39-root-INFO: Coefficient of regularization decay: 0.00082 -> 0.00083.
2024-12-01-19:17:39-root-INFO: step: 36 lr_xt 0.34059371
2024-12-01-19:17:40-root-INFO: grad norm: 4.948 4.924 0.482
2024-12-01-19:17:41-root-INFO: grad norm: 5.057 5.031 0.514
2024-12-01-19:17:41-root-INFO: Loss Change: 54.678 -> 53.018
2024-12-01-19:17:41-root-INFO: Regularization Change: 0.000 -> 1.355
2024-12-01-19:17:41-root-INFO: Learning rate of xt decay: 0.38069 -> 0.38526.
2024-12-01-19:17:41-root-INFO: Coefficient of regularization decay: 0.00083 -> 0.00084.
2024-12-01-19:17:42-root-INFO: step: 35 lr_xt 0.34671555
2024-12-01-19:17:42-root-INFO: grad norm: 4.907 4.885 0.466
2024-12-01-19:17:43-root-INFO: grad norm: 4.713 4.689 0.470
2024-12-01-19:17:44-root-INFO: Loss Change: 52.697 -> 50.582
2024-12-01-19:17:44-root-INFO: Regularization Change: 0.000 -> 1.325
2024-12-01-19:17:44-root-INFO: Undo step: 35
2024-12-01-19:17:44-root-INFO: Undo step: 36
2024-12-01-19:17:44-root-INFO: Undo step: 37
2024-12-01-19:17:44-root-INFO: Undo step: 38
2024-12-01-19:17:44-root-INFO: Undo step: 39
2024-12-01-19:17:44-root-INFO: step: 40 lr_xt 0.31666177
2024-12-01-19:17:44-root-INFO: grad norm: 17.380 17.246 2.154
2024-12-01-19:17:46-root-INFO: grad norm: 9.226 9.136 1.287
2024-12-01-19:17:46-root-INFO: Loss Change: 135.023 -> 73.923
2024-12-01-19:17:46-root-INFO: Regularization Change: 0.000 -> 41.595
2024-12-01-19:17:46-root-INFO: Learning rate of xt decay: 0.36295 -> 0.36731.
2024-12-01-19:17:46-root-INFO: Coefficient of regularization decay: 0.00080 -> 0.00081.
2024-12-01-19:17:47-root-INFO: step: 39 lr_xt 0.32255964
2024-12-01-19:17:47-root-INFO: grad norm: 6.682 6.615 0.944
2024-12-01-19:17:48-root-INFO: grad norm: 5.789 5.726 0.850
2024-12-01-19:17:49-root-INFO: Loss Change: 73.138 -> 63.746
2024-12-01-19:17:49-root-INFO: Regularization Change: 0.000 -> 6.279
2024-12-01-19:17:49-root-INFO: Learning rate of xt decay: 0.36731 -> 0.37171.
2024-12-01-19:17:49-root-INFO: Coefficient of regularization decay: 0.00081 -> 0.00082.
2024-12-01-19:17:49-root-INFO: step: 38 lr_xt 0.32851483
2024-12-01-19:17:49-root-INFO: grad norm: 5.083 5.041 0.652
2024-12-01-19:17:50-root-INFO: grad norm: 4.999 4.948 0.716
2024-12-01-19:17:51-root-INFO: Loss Change: 63.089 -> 58.537
2024-12-01-19:17:51-root-INFO: Regularization Change: 0.000 -> 3.321
2024-12-01-19:17:51-root-INFO: Learning rate of xt decay: 0.37171 -> 0.37617.
2024-12-01-19:17:51-root-INFO: Coefficient of regularization decay: 0.00082 -> 0.00082.
2024-12-01-19:17:51-root-INFO: step: 37 lr_xt 0.33452649
2024-12-01-19:17:52-root-INFO: grad norm: 4.603 4.567 0.580
2024-12-01-19:17:53-root-INFO: grad norm: 4.569 4.527 0.618
2024-12-01-19:17:53-root-INFO: Loss Change: 57.870 -> 54.655
2024-12-01-19:17:53-root-INFO: Regularization Change: 0.000 -> 2.361
2024-12-01-19:17:53-root-INFO: Learning rate of xt decay: 0.37617 -> 0.38069.
2024-12-01-19:17:53-root-INFO: Coefficient of regularization decay: 0.00082 -> 0.00083.
2024-12-01-19:17:54-root-INFO: step: 36 lr_xt 0.34059371
2024-12-01-19:17:54-root-INFO: grad norm: 4.437 4.408 0.514
2024-12-01-19:17:55-root-INFO: grad norm: 4.933 4.893 0.626
2024-12-01-19:17:56-root-INFO: Loss Change: 54.150 -> 52.362
2024-12-01-19:17:56-root-INFO: Regularization Change: 0.000 -> 2.001
2024-12-01-19:17:56-root-INFO: Learning rate of xt decay: 0.38069 -> 0.38526.
2024-12-01-19:17:56-root-INFO: Coefficient of regularization decay: 0.00083 -> 0.00084.
2024-12-01-19:17:56-root-INFO: step: 35 lr_xt 0.34671555
2024-12-01-19:17:57-root-INFO: grad norm: 4.661 4.630 0.540
2024-12-01-19:17:58-root-INFO: grad norm: 4.669 4.638 0.539
2024-12-01-19:17:58-root-INFO: Loss Change: 51.818 -> 49.473
2024-12-01-19:17:58-root-INFO: Regularization Change: 0.000 -> 1.801
2024-12-01-19:17:58-root-INFO: Learning rate of xt decay: 0.38526 -> 0.38988.
2024-12-01-19:17:58-root-INFO: Coefficient of regularization decay: 0.00084 -> 0.00085.
2024-12-01-19:17:59-root-INFO: step: 34 lr_xt 0.35289102
2024-12-01-19:17:59-root-INFO: grad norm: 4.432 4.407 0.469
2024-12-01-19:18:00-root-INFO: grad norm: 4.607 4.577 0.520
2024-12-01-19:18:01-root-INFO: Loss Change: 48.958 -> 47.210
2024-12-01-19:18:01-root-INFO: Regularization Change: 0.000 -> 1.628
2024-12-01-19:18:01-root-INFO: Learning rate of xt decay: 0.38988 -> 0.39456.
2024-12-01-19:18:01-root-INFO: Coefficient of regularization decay: 0.00085 -> 0.00086.
2024-12-01-19:18:01-root-INFO: step: 33 lr_xt 0.35911909
2024-12-01-19:18:01-root-INFO: grad norm: 4.381 4.357 0.462
2024-12-01-19:18:02-root-INFO: grad norm: 4.307 4.282 0.465
2024-12-01-19:18:03-root-INFO: Loss Change: 46.574 -> 44.529
2024-12-01-19:18:03-root-INFO: Regularization Change: 0.000 -> 1.506
2024-12-01-19:18:03-root-INFO: Learning rate of xt decay: 0.39456 -> 0.39929.
2024-12-01-19:18:03-root-INFO: Coefficient of regularization decay: 0.00086 -> 0.00087.
2024-12-01-19:18:04-root-INFO: step: 32 lr_xt 0.36539868
2024-12-01-19:18:04-root-INFO: grad norm: 4.073 4.053 0.399
2024-12-01-19:18:05-root-INFO: grad norm: 4.296 4.274 0.436
2024-12-01-19:18:06-root-INFO: Loss Change: 44.017 -> 42.565
2024-12-01-19:18:06-root-INFO: Regularization Change: 0.000 -> 1.478
2024-12-01-19:18:06-root-INFO: Learning rate of xt decay: 0.39929 -> 0.40409.
2024-12-01-19:18:06-root-INFO: Coefficient of regularization decay: 0.00087 -> 0.00088.
2024-12-01-19:18:06-root-INFO: step: 31 lr_xt 0.37172867
2024-12-01-19:18:06-root-INFO: grad norm: 4.122 4.101 0.410
2024-12-01-19:18:07-root-INFO: grad norm: 4.000 3.981 0.394
2024-12-01-19:18:08-root-INFO: Loss Change: 42.186 -> 40.233
2024-12-01-19:18:08-root-INFO: Regularization Change: 0.000 -> 1.429
2024-12-01-19:18:08-root-INFO: Learning rate of xt decay: 0.40409 -> 0.40893.
2024-12-01-19:18:08-root-INFO: Coefficient of regularization decay: 0.00088 -> 0.00088.
2024-12-01-19:18:08-root-INFO: step: 30 lr_xt 0.37810791
2024-12-01-19:18:09-root-INFO: grad norm: 3.843 3.826 0.367
2024-12-01-19:18:10-root-INFO: grad norm: 3.955 3.936 0.383
2024-12-01-19:18:11-root-INFO: Loss Change: 39.769 -> 38.340
2024-12-01-19:18:11-root-INFO: Regularization Change: 0.000 -> 1.364
2024-12-01-19:18:11-root-INFO: Undo step: 30
2024-12-01-19:18:11-root-INFO: Undo step: 31
2024-12-01-19:18:11-root-INFO: Undo step: 32
2024-12-01-19:18:11-root-INFO: Undo step: 33
2024-12-01-19:18:11-root-INFO: Undo step: 34
2024-12-01-19:18:11-root-INFO: step: 35 lr_xt 0.34671555
2024-12-01-19:18:11-root-INFO: grad norm: 14.906 14.812 1.669
2024-12-01-19:18:12-root-INFO: grad norm: 7.426 7.363 0.961
2024-12-01-19:18:13-root-INFO: Loss Change: 114.875 -> 60.364
2024-12-01-19:18:13-root-INFO: Regularization Change: 0.000 -> 40.662
2024-12-01-19:18:13-root-INFO: Learning rate of xt decay: 0.38526 -> 0.38988.
2024-12-01-19:18:13-root-INFO: Coefficient of regularization decay: 0.00084 -> 0.00085.
2024-12-01-19:18:13-root-INFO: step: 34 lr_xt 0.35289102
2024-12-01-19:18:14-root-INFO: grad norm: 5.404 5.363 0.669
2024-12-01-19:18:15-root-INFO: grad norm: 4.543 4.506 0.574
2024-12-01-19:18:15-root-INFO: Loss Change: 59.770 -> 51.066
2024-12-01-19:18:15-root-INFO: Regularization Change: 0.000 -> 6.581
2024-12-01-19:18:15-root-INFO: Learning rate of xt decay: 0.38988 -> 0.39456.
2024-12-01-19:18:15-root-INFO: Coefficient of regularization decay: 0.00085 -> 0.00086.
2024-12-01-19:18:16-root-INFO: step: 33 lr_xt 0.35911909
2024-12-01-19:18:16-root-INFO: grad norm: 4.140 4.110 0.495
2024-12-01-19:18:17-root-INFO: grad norm: 4.052 4.022 0.490
2024-12-01-19:18:18-root-INFO: Loss Change: 50.549 -> 46.381
2024-12-01-19:18:18-root-INFO: Regularization Change: 0.000 -> 3.394
2024-12-01-19:18:18-root-INFO: Learning rate of xt decay: 0.39456 -> 0.39929.
2024-12-01-19:18:18-root-INFO: Coefficient of regularization decay: 0.00086 -> 0.00087.
2024-12-01-19:18:18-root-INFO: step: 32 lr_xt 0.36539868
2024-12-01-19:18:18-root-INFO: grad norm: 4.266 4.236 0.505
2024-12-01-19:18:19-root-INFO: grad norm: 4.119 4.088 0.509
2024-12-01-19:18:20-root-INFO: Loss Change: 46.147 -> 43.104
2024-12-01-19:18:20-root-INFO: Regularization Change: 0.000 -> 2.413
2024-12-01-19:18:20-root-INFO: Learning rate of xt decay: 0.39929 -> 0.40409.
2024-12-01-19:18:20-root-INFO: Coefficient of regularization decay: 0.00087 -> 0.00088.
2024-12-01-19:18:20-root-INFO: step: 31 lr_xt 0.37172867
2024-12-01-19:18:21-root-INFO: grad norm: 4.281 4.249 0.522
2024-12-01-19:18:22-root-INFO: grad norm: 4.329 4.299 0.513
2024-12-01-19:18:22-root-INFO: Loss Change: 42.974 -> 40.724
2024-12-01-19:18:22-root-INFO: Regularization Change: 0.000 -> 1.966
2024-12-01-19:18:22-root-INFO: Learning rate of xt decay: 0.40409 -> 0.40893.
2024-12-01-19:18:22-root-INFO: Coefficient of regularization decay: 0.00088 -> 0.00088.
2024-12-01-19:18:23-root-INFO: step: 30 lr_xt 0.37810791
2024-12-01-19:18:23-root-INFO: grad norm: 4.450 4.418 0.531
2024-12-01-19:18:24-root-INFO: grad norm: 4.118 4.085 0.515
2024-12-01-19:18:25-root-INFO: Loss Change: 40.570 -> 38.006
2024-12-01-19:18:25-root-INFO: Regularization Change: 0.000 -> 1.707
2024-12-01-19:18:25-root-INFO: Learning rate of xt decay: 0.40893 -> 0.41384.
2024-12-01-19:18:25-root-INFO: Coefficient of regularization decay: 0.00088 -> 0.00089.
2024-12-01-19:18:25-root-INFO: step: 29 lr_xt 0.38453518
2024-12-01-19:18:26-root-INFO: grad norm: 4.344 4.311 0.536
2024-12-01-19:18:27-root-INFO: grad norm: 4.276 4.245 0.512
2024-12-01-19:18:27-root-INFO: Loss Change: 37.999 -> 36.098
2024-12-01-19:18:27-root-INFO: Regularization Change: 0.000 -> 1.596
2024-12-01-19:18:27-root-INFO: Learning rate of xt decay: 0.41384 -> 0.41881.
2024-12-01-19:18:27-root-INFO: Coefficient of regularization decay: 0.00089 -> 0.00090.
2024-12-01-19:18:28-root-INFO: step: 28 lr_xt 0.39100924
2024-12-01-19:18:28-root-INFO: grad norm: 4.368 4.337 0.526
2024-12-01-19:18:29-root-INFO: grad norm: 3.974 3.942 0.499
2024-12-01-19:18:30-root-INFO: Loss Change: 35.932 -> 33.593
2024-12-01-19:18:30-root-INFO: Regularization Change: 0.000 -> 1.490
2024-12-01-19:18:30-root-INFO: Learning rate of xt decay: 0.41881 -> 0.42383.
2024-12-01-19:18:30-root-INFO: Coefficient of regularization decay: 0.00090 -> 0.00091.
2024-12-01-19:18:30-root-INFO: step: 27 lr_xt 0.39752879
2024-12-01-19:18:30-root-INFO: grad norm: 4.135 4.103 0.515
2024-12-01-19:18:31-root-INFO: grad norm: 3.993 3.962 0.492
2024-12-01-19:18:32-root-INFO: Loss Change: 33.633 -> 31.860
2024-12-01-19:18:32-root-INFO: Regularization Change: 0.000 -> 1.421
2024-12-01-19:18:32-root-INFO: Learning rate of xt decay: 0.42383 -> 0.42892.
2024-12-01-19:18:32-root-INFO: Coefficient of regularization decay: 0.00091 -> 0.00092.
2024-12-01-19:18:32-root-INFO: step: 26 lr_xt 0.40409250
2024-12-01-19:18:33-root-INFO: grad norm: 4.076 4.044 0.508
2024-12-01-19:18:34-root-INFO: grad norm: 3.663 3.631 0.481
2024-12-01-19:18:35-root-INFO: Loss Change: 31.857 -> 29.734
2024-12-01-19:18:35-root-INFO: Regularization Change: 0.000 -> 1.350
2024-12-01-19:18:35-root-INFO: Learning rate of xt decay: 0.42892 -> 0.43407.
2024-12-01-19:18:35-root-INFO: Coefficient of regularization decay: 0.00092 -> 0.00093.
2024-12-01-19:18:35-root-INFO: step: 25 lr_xt 0.41069899
2024-12-01-19:18:35-root-INFO: grad norm: 3.836 3.803 0.505
2024-12-01-19:18:36-root-INFO: grad norm: 3.615 3.585 0.469
2024-12-01-19:18:37-root-INFO: Loss Change: 29.616 -> 27.890
2024-12-01-19:18:37-root-INFO: Regularization Change: 0.000 -> 1.323
2024-12-01-19:18:37-root-INFO: Undo step: 25
2024-12-01-19:18:37-root-INFO: Undo step: 26
2024-12-01-19:18:37-root-INFO: Undo step: 27
2024-12-01-19:18:37-root-INFO: Undo step: 28
2024-12-01-19:18:37-root-INFO: Undo step: 29
2024-12-01-19:18:37-root-INFO: step: 30 lr_xt 0.37810791
2024-12-01-19:18:38-root-INFO: grad norm: 14.028 13.976 1.208
2024-12-01-19:18:39-root-INFO: grad norm: 6.158 6.112 0.748
2024-12-01-19:18:39-root-INFO: Loss Change: 99.357 -> 47.833
2024-12-01-19:18:39-root-INFO: Regularization Change: 0.000 -> 42.228
2024-12-01-19:18:40-root-INFO: Learning rate of xt decay: 0.40893 -> 0.41384.
2024-12-01-19:18:40-root-INFO: Coefficient of regularization decay: 0.00088 -> 0.00089.
2024-12-01-19:18:40-root-INFO: step: 29 lr_xt 0.38453518
2024-12-01-19:18:40-root-INFO: grad norm: 4.405 4.360 0.630
2024-12-01-19:18:41-root-INFO: grad norm: 3.522 3.484 0.518
2024-12-01-19:18:42-root-INFO: Loss Change: 47.523 -> 39.513
2024-12-01-19:18:42-root-INFO: Regularization Change: 0.000 -> 6.580
2024-12-01-19:18:42-root-INFO: Learning rate of xt decay: 0.41384 -> 0.41881.
2024-12-01-19:18:42-root-INFO: Coefficient of regularization decay: 0.00089 -> 0.00090.
2024-12-01-19:18:42-root-INFO: step: 28 lr_xt 0.39100924
2024-12-01-19:18:43-root-INFO: grad norm: 3.550 3.500 0.595
2024-12-01-19:18:44-root-INFO: grad norm: 3.447 3.401 0.562
2024-12-01-19:18:44-root-INFO: Loss Change: 39.133 -> 35.364
2024-12-01-19:18:44-root-INFO: Regularization Change: 0.000 -> 3.538
2024-12-01-19:18:44-root-INFO: Learning rate of xt decay: 0.41881 -> 0.42383.
2024-12-01-19:18:44-root-INFO: Coefficient of regularization decay: 0.00090 -> 0.00091.
2024-12-01-19:18:45-root-INFO: step: 27 lr_xt 0.39752879
2024-12-01-19:18:45-root-INFO: grad norm: 4.575 4.514 0.745
2024-12-01-19:18:46-root-INFO: grad norm: 5.061 5.001 0.777
2024-12-01-19:18:47-root-INFO: Loss Change: 35.476 -> 33.974
2024-12-01-19:18:47-root-INFO: Regularization Change: 0.000 -> 2.958
2024-12-01-19:18:47-root-INFO: Learning rate of xt decay: 0.42383 -> 0.42892.
2024-12-01-19:18:47-root-INFO: Coefficient of regularization decay: 0.00091 -> 0.00092.
2024-12-01-19:18:47-root-INFO: step: 26 lr_xt 0.40409250
2024-12-01-19:18:47-root-INFO: grad norm: 5.699 5.629 0.887
2024-12-01-19:18:48-root-INFO: grad norm: 5.175 5.103 0.861
2024-12-01-19:18:49-root-INFO: Loss Change: 34.217 -> 31.277
2024-12-01-19:18:49-root-INFO: Regularization Change: 0.000 -> 2.315
2024-12-01-19:18:49-root-INFO: Learning rate of xt decay: 0.42892 -> 0.43407.
2024-12-01-19:18:49-root-INFO: Coefficient of regularization decay: 0.00092 -> 0.00093.
2024-12-01-19:18:50-root-INFO: step: 25 lr_xt 0.41069899
2024-12-01-19:18:50-root-INFO: grad norm: 5.643 5.571 0.899
2024-12-01-19:18:51-root-INFO: grad norm: 4.787 4.712 0.845
2024-12-01-19:18:52-root-INFO: Loss Change: 31.465 -> 28.189
2024-12-01-19:18:52-root-INFO: Regularization Change: 0.000 -> 2.073
2024-12-01-19:18:52-root-INFO: Learning rate of xt decay: 0.43407 -> 0.43928.
2024-12-01-19:18:52-root-INFO: Coefficient of regularization decay: 0.00093 -> 0.00094.
2024-12-01-19:18:52-root-INFO: step: 24 lr_xt 0.41734684
2024-12-01-19:18:52-root-INFO: grad norm: 4.933 4.865 0.818
2024-12-01-19:18:53-root-INFO: grad norm: 4.327 4.263 0.744
2024-12-01-19:18:54-root-INFO: Loss Change: 28.596 -> 26.004
2024-12-01-19:18:54-root-INFO: Regularization Change: 0.000 -> 1.730
2024-12-01-19:18:54-root-INFO: Learning rate of xt decay: 0.43928 -> 0.44455.
2024-12-01-19:18:54-root-INFO: Coefficient of regularization decay: 0.00094 -> 0.00095.
2024-12-01-19:18:54-root-INFO: step: 23 lr_xt 0.42403458
2024-12-01-19:18:55-root-INFO: grad norm: 4.600 4.538 0.750
2024-12-01-19:18:56-root-INFO: grad norm: 4.092 4.032 0.701
2024-12-01-19:18:56-root-INFO: Loss Change: 26.129 -> 23.837
2024-12-01-19:18:56-root-INFO: Regularization Change: 0.000 -> 1.465
2024-12-01-19:18:56-root-INFO: Learning rate of xt decay: 0.44455 -> 0.44988.
2024-12-01-19:18:56-root-INFO: Coefficient of regularization decay: 0.00095 -> 0.00096.
2024-12-01-19:18:57-root-INFO: step: 22 lr_xt 0.43076069
2024-12-01-19:18:57-root-INFO: grad norm: 4.390 4.332 0.706
2024-12-01-19:18:58-root-INFO: grad norm: 3.894 3.840 0.644
2024-12-01-19:18:59-root-INFO: Loss Change: 24.119 -> 22.001
2024-12-01-19:18:59-root-INFO: Regularization Change: 0.000 -> 1.347
2024-12-01-19:18:59-root-INFO: Learning rate of xt decay: 0.44988 -> 0.45528.
2024-12-01-19:18:59-root-INFO: Coefficient of regularization decay: 0.00096 -> 0.00097.
2024-12-01-19:18:59-root-INFO: step: 21 lr_xt 0.43752364
2024-12-01-19:19:00-root-INFO: grad norm: 4.065 4.015 0.634
2024-12-01-19:19:01-root-INFO: grad norm: 3.581 3.532 0.586
2024-12-01-19:19:01-root-INFO: Loss Change: 22.164 -> 20.188
2024-12-01-19:19:01-root-INFO: Regularization Change: 0.000 -> 1.278
2024-12-01-19:19:01-root-INFO: Learning rate of xt decay: 0.45528 -> 0.46074.
2024-12-01-19:19:01-root-INFO: Coefficient of regularization decay: 0.00097 -> 0.00098.
2024-12-01-19:19:02-root-INFO: step: 20 lr_xt 0.44432183
2024-12-01-19:19:02-root-INFO: grad norm: 3.948 3.900 0.614
2024-12-01-19:19:03-root-INFO: grad norm: 3.426 3.382 0.548
2024-12-01-19:19:04-root-INFO: Loss Change: 20.425 -> 18.521
2024-12-01-19:19:04-root-INFO: Regularization Change: 0.000 -> 1.213
2024-12-01-19:19:04-root-INFO: Undo step: 20
2024-12-01-19:19:04-root-INFO: Undo step: 21
2024-12-01-19:19:04-root-INFO: Undo step: 22
2024-12-01-19:19:04-root-INFO: Undo step: 23
2024-12-01-19:19:04-root-INFO: Undo step: 24
2024-12-01-19:19:04-root-INFO: step: 25 lr_xt 0.41069899
2024-12-01-19:19:04-root-INFO: grad norm: 13.869 13.802 1.355
2024-12-01-19:19:05-root-INFO: grad norm: 6.375 6.314 0.878
2024-12-01-19:19:06-root-INFO: Loss Change: 89.881 -> 38.148
2024-12-01-19:19:06-root-INFO: Regularization Change: 0.000 -> 47.829
2024-12-01-19:19:06-root-INFO: Learning rate of xt decay: 0.43407 -> 0.43928.
2024-12-01-19:19:06-root-INFO: Coefficient of regularization decay: 0.00093 -> 0.00094.
2024-12-01-19:19:06-root-INFO: step: 24 lr_xt 0.41734684
2024-12-01-19:19:07-root-INFO: grad norm: 5.083 5.028 0.748
2024-12-01-19:19:08-root-INFO: grad norm: 4.231 4.189 0.600
2024-12-01-19:19:08-root-INFO: Loss Change: 38.033 -> 30.030
2024-12-01-19:19:08-root-INFO: Regularization Change: 0.000 -> 7.271
2024-12-01-19:19:08-root-INFO: Learning rate of xt decay: 0.43928 -> 0.44455.
2024-12-01-19:19:08-root-INFO: Coefficient of regularization decay: 0.00094 -> 0.00095.
2024-12-01-19:19:09-root-INFO: step: 23 lr_xt 0.42403458
2024-12-01-19:19:09-root-INFO: grad norm: 4.435 4.381 0.690
2024-12-01-19:19:10-root-INFO: grad norm: 3.748 3.705 0.565
2024-12-01-19:19:11-root-INFO: Loss Change: 29.844 -> 25.408
2024-12-01-19:19:11-root-INFO: Regularization Change: 0.000 -> 3.642
2024-12-01-19:19:11-root-INFO: Learning rate of xt decay: 0.44455 -> 0.44988.
2024-12-01-19:19:11-root-INFO: Coefficient of regularization decay: 0.00095 -> 0.00096.
2024-12-01-19:19:11-root-INFO: step: 22 lr_xt 0.43076069
2024-12-01-19:19:12-root-INFO: grad norm: 3.782 3.730 0.621
2024-12-01-19:19:13-root-INFO: grad norm: 3.263 3.226 0.496
2024-12-01-19:19:13-root-INFO: Loss Change: 25.389 -> 22.391
2024-12-01-19:19:13-root-INFO: Regularization Change: 0.000 -> 2.382
2024-12-01-19:19:13-root-INFO: Learning rate of xt decay: 0.44988 -> 0.45528.
2024-12-01-19:19:13-root-INFO: Coefficient of regularization decay: 0.00096 -> 0.00097.
2024-12-01-19:19:14-root-INFO: step: 21 lr_xt 0.43752364
2024-12-01-19:19:14-root-INFO: grad norm: 3.509 3.462 0.573
2024-12-01-19:19:15-root-INFO: grad norm: 3.147 3.113 0.462
2024-12-01-19:19:16-root-INFO: Loss Change: 22.339 -> 20.124
2024-12-01-19:19:16-root-INFO: Regularization Change: 0.000 -> 1.763
2024-12-01-19:19:16-root-INFO: Learning rate of xt decay: 0.45528 -> 0.46074.
2024-12-01-19:19:16-root-INFO: Coefficient of regularization decay: 0.00097 -> 0.00098.
2024-12-01-19:19:16-root-INFO: step: 20 lr_xt 0.44432183
2024-12-01-19:19:16-root-INFO: grad norm: 3.435 3.389 0.560
2024-12-01-19:19:17-root-INFO: grad norm: 3.027 2.995 0.439
2024-12-01-19:19:18-root-INFO: Loss Change: 20.142 -> 18.193
2024-12-01-19:19:18-root-INFO: Regularization Change: 0.000 -> 1.459
2024-12-01-19:19:18-root-INFO: Learning rate of xt decay: 0.46074 -> 0.46627.
2024-12-01-19:19:18-root-INFO: Coefficient of regularization decay: 0.00098 -> 0.00099.
2024-12-01-19:19:18-root-INFO: step: 19 lr_xt 0.45115363
2024-12-01-19:19:19-root-INFO: grad norm: 3.201 3.162 0.502
2024-12-01-19:19:20-root-INFO: grad norm: 2.817 2.789 0.393
2024-12-01-19:19:20-root-INFO: Loss Change: 18.139 -> 16.440
2024-12-01-19:19:20-root-INFO: Regularization Change: 0.000 -> 1.275
2024-12-01-19:19:20-root-INFO: Learning rate of xt decay: 0.46627 -> 0.47187.
2024-12-01-19:19:21-root-INFO: Coefficient of regularization decay: 0.00099 -> 0.00100.
2024-12-01-19:19:21-root-INFO: step: 18 lr_xt 0.45801735
2024-12-01-19:19:21-root-INFO: grad norm: 3.177 3.139 0.484
2024-12-01-19:19:22-root-INFO: grad norm: 2.727 2.700 0.381
2024-12-01-19:19:23-root-INFO: Loss Change: 16.480 -> 14.867
2024-12-01-19:19:23-root-INFO: Regularization Change: 0.000 -> 1.181
2024-12-01-19:19:23-root-INFO: Learning rate of xt decay: 0.47187 -> 0.47753.
2024-12-01-19:19:23-root-INFO: Coefficient of regularization decay: 0.00100 -> 0.00101.
2024-12-01-19:19:23-root-INFO: step: 17 lr_xt 0.46491129
2024-12-01-19:19:24-root-INFO: grad norm: 2.916 2.884 0.434
2024-12-01-19:19:25-root-INFO: grad norm: 2.510 2.487 0.336
2024-12-01-19:19:25-root-INFO: Loss Change: 14.911 -> 13.451
2024-12-01-19:19:25-root-INFO: Regularization Change: 0.000 -> 1.099
2024-12-01-19:19:25-root-INFO: Learning rate of xt decay: 0.47753 -> 0.48326.
2024-12-01-19:19:25-root-INFO: Coefficient of regularization decay: 0.00101 -> 0.00102.
2024-12-01-19:19:26-root-INFO: step: 16 lr_xt 0.47183369
2024-12-01-19:19:26-root-INFO: grad norm: 2.837 2.807 0.405
2024-12-01-19:19:27-root-INFO: grad norm: 2.416 2.394 0.330
2024-12-01-19:19:28-root-INFO: Loss Change: 13.526 -> 12.133
2024-12-01-19:19:28-root-INFO: Regularization Change: 0.000 -> 1.031
2024-12-01-19:19:28-root-INFO: Learning rate of xt decay: 0.48326 -> 0.48906.
2024-12-01-19:19:28-root-INFO: Coefficient of regularization decay: 0.00102 -> 0.00103.
2024-12-01-19:19:28-root-INFO: step: 15 lr_xt 0.47878275
2024-12-01-19:19:29-root-INFO: grad norm: 2.801 2.771 0.410
2024-12-01-19:19:30-root-INFO: grad norm: 2.343 2.322 0.311
2024-12-01-19:19:30-root-INFO: Loss Change: 12.238 -> 10.955
2024-12-01-19:19:30-root-INFO: Regularization Change: 0.000 -> 1.051
2024-12-01-19:19:30-root-INFO: Undo step: 15
2024-12-01-19:19:30-root-INFO: Undo step: 16
2024-12-01-19:19:30-root-INFO: Undo step: 17
2024-12-01-19:19:30-root-INFO: Undo step: 18
2024-12-01-19:19:30-root-INFO: Undo step: 19
2024-12-01-19:19:31-root-INFO: step: 20 lr_xt 0.44432183
2024-12-01-19:19:31-root-INFO: grad norm: 12.619 12.571 1.101
2024-12-01-19:19:32-root-INFO: grad norm: 5.354 5.319 0.613
2024-12-01-19:19:33-root-INFO: Loss Change: 77.612 -> 28.212
2024-12-01-19:19:33-root-INFO: Regularization Change: 0.000 -> 48.568
2024-12-01-19:19:33-root-INFO: Learning rate of xt decay: 0.46074 -> 0.46627.
2024-12-01-19:19:33-root-INFO: Coefficient of regularization decay: 0.00098 -> 0.00099.
2024-12-01-19:19:33-root-INFO: step: 19 lr_xt 0.45115363
2024-12-01-19:19:33-root-INFO: grad norm: 4.153 4.128 0.460
2024-12-01-19:19:34-root-INFO: grad norm: 3.313 3.285 0.432
2024-12-01-19:19:35-root-INFO: Loss Change: 27.685 -> 20.655
2024-12-01-19:19:35-root-INFO: Regularization Change: 0.000 -> 7.167
2024-12-01-19:19:35-root-INFO: Learning rate of xt decay: 0.46627 -> 0.47187.
2024-12-01-19:19:35-root-INFO: Coefficient of regularization decay: 0.00099 -> 0.00100.
2024-12-01-19:19:36-root-INFO: step: 18 lr_xt 0.45801735
2024-12-01-19:19:36-root-INFO: grad norm: 3.317 3.286 0.457
2024-12-01-19:19:37-root-INFO: grad norm: 2.913 2.882 0.428
2024-12-01-19:19:38-root-INFO: Loss Change: 20.363 -> 16.864
2024-12-01-19:19:38-root-INFO: Regularization Change: 0.000 -> 3.443
2024-12-01-19:19:38-root-INFO: Learning rate of xt decay: 0.47187 -> 0.47753.
2024-12-01-19:19:38-root-INFO: Coefficient of regularization decay: 0.00100 -> 0.00101.
2024-12-01-19:19:38-root-INFO: step: 17 lr_xt 0.46491129
2024-12-01-19:19:39-root-INFO: grad norm: 3.151 3.117 0.466
2024-12-01-19:19:40-root-INFO: grad norm: 2.791 2.759 0.422
2024-12-01-19:19:40-root-INFO: Loss Change: 16.743 -> 14.378
2024-12-01-19:19:40-root-INFO: Regularization Change: 0.000 -> 2.126
2024-12-01-19:19:40-root-INFO: Learning rate of xt decay: 0.47753 -> 0.48326.
2024-12-01-19:19:40-root-INFO: Coefficient of regularization decay: 0.00101 -> 0.00102.
2024-12-01-19:19:41-root-INFO: step: 16 lr_xt 0.47183369
2024-12-01-19:19:41-root-INFO: grad norm: 3.116 3.080 0.469
2024-12-01-19:19:42-root-INFO: grad norm: 2.683 2.652 0.403
2024-12-01-19:19:43-root-INFO: Loss Change: 14.355 -> 12.441
2024-12-01-19:19:43-root-INFO: Regularization Change: 0.000 -> 1.568
2024-12-01-19:19:43-root-INFO: Learning rate of xt decay: 0.48326 -> 0.48906.
2024-12-01-19:19:43-root-INFO: Coefficient of regularization decay: 0.00102 -> 0.00103.
2024-12-01-19:19:43-root-INFO: step: 15 lr_xt 0.47878275
2024-12-01-19:19:43-root-INFO: grad norm: 2.881 2.847 0.443
2024-12-01-19:19:44-root-INFO: grad norm: 2.424 2.396 0.370
2024-12-01-19:19:45-root-INFO: Loss Change: 12.455 -> 10.833
2024-12-01-19:19:45-root-INFO: Regularization Change: 0.000 -> 1.278
2024-12-01-19:19:45-root-INFO: Learning rate of xt decay: 0.48906 -> 0.49493.
2024-12-01-19:19:45-root-INFO: Coefficient of regularization decay: 0.00103 -> 0.00104.
2024-12-01-19:19:45-root-INFO: step: 14 lr_xt 0.48575663
2024-12-01-19:19:46-root-INFO: grad norm: 2.709 2.678 0.410
2024-12-01-19:19:47-root-INFO: grad norm: 2.258 2.233 0.330
2024-12-01-19:19:48-root-INFO: Loss Change: 10.881 -> 9.483
2024-12-01-19:19:48-root-INFO: Regularization Change: 0.000 -> 1.090
2024-12-01-19:19:48-root-INFO: Learning rate of xt decay: 0.49493 -> 0.50087.
2024-12-01-19:19:48-root-INFO: Coefficient of regularization decay: 0.00104 -> 0.00105.
2024-12-01-19:19:48-root-INFO: step: 13 lr_xt 0.49275347
2024-12-01-19:19:48-root-INFO: grad norm: 2.505 2.477 0.373
2024-12-01-19:19:49-root-INFO: grad norm: 2.106 2.082 0.314
2024-12-01-19:19:50-root-INFO: Loss Change: 9.579 -> 8.492
2024-12-01-19:19:50-root-INFO: Regularization Change: 0.000 -> 1.003
2024-12-01-19:19:50-root-INFO: Learning rate of xt decay: 0.50087 -> 0.50688.
2024-12-01-19:19:50-root-INFO: Coefficient of regularization decay: 0.00105 -> 0.00106.
2024-12-01-19:19:50-root-INFO: step: 12 lr_xt 0.49977135
2024-12-01-19:19:51-root-INFO: grad norm: 3.072 3.049 0.380
2024-12-01-19:19:52-root-INFO: grad norm: 2.061 2.041 0.287
2024-12-01-19:19:52-root-INFO: Loss Change: 8.659 -> 7.453
2024-12-01-19:19:52-root-INFO: Regularization Change: 0.000 -> 1.644
2024-12-01-19:19:52-root-INFO: Learning rate of xt decay: 0.50688 -> 0.51296.
2024-12-01-19:19:52-root-INFO: Coefficient of regularization decay: 0.00106 -> 0.00107.
2024-12-01-19:19:53-root-INFO: step: 11 lr_xt 0.50680833
2024-12-01-19:19:53-root-INFO: grad norm: 2.305 2.282 0.328
2024-12-01-19:19:54-root-INFO: grad norm: 1.879 1.859 0.268
2024-12-01-19:19:55-root-INFO: Loss Change: 7.622 -> 6.535
2024-12-01-19:19:55-root-INFO: Regularization Change: 0.000 -> 0.891
2024-12-01-19:19:55-root-INFO: Learning rate of xt decay: 0.51296 -> 0.51912.
2024-12-01-19:19:55-root-INFO: Coefficient of regularization decay: 0.00107 -> 0.00108.
2024-12-01-19:19:55-root-INFO: step: 10 lr_xt 0.51386241
2024-12-01-19:19:56-root-INFO: grad norm: 2.290 2.266 0.325
2024-12-01-19:19:57-root-INFO: grad norm: 1.864 1.846 0.255
2024-12-01-19:19:57-root-INFO: Loss Change: 6.752 -> 5.723
2024-12-01-19:19:57-root-INFO: Regularization Change: 0.000 -> 0.829
2024-12-01-19:19:57-root-INFO: Undo step: 10
2024-12-01-19:19:57-root-INFO: Undo step: 11
2024-12-01-19:19:57-root-INFO: Undo step: 12
2024-12-01-19:19:57-root-INFO: Undo step: 13
2024-12-01-19:19:57-root-INFO: Undo step: 14
2024-12-01-19:19:58-root-INFO: step: 15 lr_xt 0.47878275
2024-12-01-19:19:58-root-INFO: grad norm: 12.904 12.873 0.887
2024-12-01-19:19:59-root-INFO: grad norm: 5.053 5.029 0.493
2024-12-01-19:20:00-root-INFO: Loss Change: 70.380 -> 19.997
2024-12-01-19:20:00-root-INFO: Regularization Change: 0.000 -> 55.362
2024-12-01-19:20:00-root-INFO: Learning rate of xt decay: 0.48906 -> 0.49493.
2024-12-01-19:20:00-root-INFO: Coefficient of regularization decay: 0.00103 -> 0.00104.
2024-12-01-19:20:00-root-INFO: step: 14 lr_xt 0.48575663
2024-12-01-19:20:00-root-INFO: grad norm: 3.629 3.610 0.363
2024-12-01-19:20:01-root-INFO: grad norm: 2.783 2.763 0.333
2024-12-01-19:20:02-root-INFO: Loss Change: 19.491 -> 13.207
2024-12-01-19:20:02-root-INFO: Regularization Change: 0.000 -> 6.733
2024-12-01-19:20:02-root-INFO: Learning rate of xt decay: 0.49493 -> 0.50087.
2024-12-01-19:20:02-root-INFO: Coefficient of regularization decay: 0.00104 -> 0.00105.
2024-12-01-19:20:03-root-INFO: step: 13 lr_xt 0.49275347
2024-12-01-19:20:03-root-INFO: grad norm: 2.844 2.823 0.346
2024-12-01-19:20:04-root-INFO: grad norm: 2.333 2.311 0.326
2024-12-01-19:20:05-root-INFO: Loss Change: 12.997 -> 10.036
2024-12-01-19:20:05-root-INFO: Regularization Change: 0.000 -> 2.971
2024-12-01-19:20:05-root-INFO: Learning rate of xt decay: 0.50087 -> 0.50688.
2024-12-01-19:20:05-root-INFO: Coefficient of regularization decay: 0.00105 -> 0.00106.
2024-12-01-19:20:05-root-INFO: step: 12 lr_xt 0.49977135
2024-12-01-19:20:05-root-INFO: grad norm: 2.570 2.547 0.346
2024-12-01-19:20:06-root-INFO: grad norm: 2.145 2.124 0.301
2024-12-01-19:20:07-root-INFO: Loss Change: 9.963 -> 8.101
2024-12-01-19:20:07-root-INFO: Regularization Change: 0.000 -> 1.762
2024-12-01-19:20:07-root-INFO: Learning rate of xt decay: 0.50688 -> 0.51296.
2024-12-01-19:20:07-root-INFO: Coefficient of regularization decay: 0.00106 -> 0.00107.
2024-12-01-19:20:07-root-INFO: step: 11 lr_xt 0.50680833
2024-12-01-19:20:08-root-INFO: grad norm: 2.452 2.429 0.338
2024-12-01-19:20:09-root-INFO: grad norm: 1.995 1.975 0.282
2024-12-01-19:20:09-root-INFO: Loss Change: 8.154 -> 6.718
2024-12-01-19:20:09-root-INFO: Regularization Change: 0.000 -> 1.243
2024-12-01-19:20:09-root-INFO: Learning rate of xt decay: 0.51296 -> 0.51912.
2024-12-01-19:20:09-root-INFO: Coefficient of regularization decay: 0.00107 -> 0.00108.
2024-12-01-19:20:10-root-INFO: step: 10 lr_xt 0.51386241
2024-12-01-19:20:10-root-INFO: grad norm: 2.321 2.298 0.328
2024-12-01-19:20:11-root-INFO: grad norm: 1.837 1.820 0.252
2024-12-01-19:20:12-root-INFO: Loss Change: 6.840 -> 5.643
2024-12-01-19:20:12-root-INFO: Regularization Change: 0.000 -> 0.986
2024-12-01-19:20:12-root-INFO: Learning rate of xt decay: 0.51912 -> 0.52534.
2024-12-01-19:20:12-root-INFO: Coefficient of regularization decay: 0.00108 -> 0.00109.
2024-12-01-19:20:12-root-INFO: step: 9 lr_xt 0.52093157
2024-12-01-19:20:12-root-INFO: grad norm: 2.108 2.088 0.287
2024-12-01-19:20:14-root-INFO: grad norm: 1.639 1.625 0.213
2024-12-01-19:20:14-root-INFO: Loss Change: 5.790 -> 4.782
2024-12-01-19:20:14-root-INFO: Regularization Change: 0.000 -> 0.823
2024-12-01-19:20:14-root-INFO: Learning rate of xt decay: 0.52534 -> 0.53165.
2024-12-01-19:20:14-root-INFO: Coefficient of regularization decay: 0.00109 -> 0.00110.
2024-12-01-19:20:15-root-INFO: step: 8 lr_xt 0.52801377
2024-12-01-19:20:15-root-INFO: grad norm: 1.984 1.966 0.264
2024-12-01-19:20:16-root-INFO: grad norm: 1.503 1.491 0.187
2024-12-01-19:20:17-root-INFO: Loss Change: 4.969 -> 4.072
2024-12-01-19:20:17-root-INFO: Regularization Change: 0.000 -> 0.744
2024-12-01-19:20:17-root-INFO: Learning rate of xt decay: 0.53165 -> 0.53803.
2024-12-01-19:20:17-root-INFO: Coefficient of regularization decay: 0.00110 -> 0.00111.
2024-12-01-19:20:17-root-INFO: step: 7 lr_xt 0.53510690
2024-12-01-19:20:17-root-INFO: grad norm: 1.813 1.798 0.238
2024-12-01-19:20:18-root-INFO: grad norm: 1.370 1.361 0.155
2024-12-01-19:20:19-root-INFO: Loss Change: 4.268 -> 3.522
2024-12-01-19:20:19-root-INFO: Regularization Change: 0.000 -> 0.692
2024-12-01-19:20:19-root-INFO: Learning rate of xt decay: 0.53803 -> 0.54448.
2024-12-01-19:20:19-root-INFO: Coefficient of regularization decay: 0.00111 -> 0.00112.
2024-12-01-19:20:19-root-INFO: step: 6 lr_xt 0.54220886
2024-12-01-19:20:20-root-INFO: grad norm: 1.824 1.812 0.208
2024-12-01-19:20:21-root-INFO: grad norm: 1.157 1.151 0.120
2024-12-01-19:20:21-root-INFO: Loss Change: 3.729 -> 2.999
2024-12-01-19:20:21-root-INFO: Regularization Change: 0.000 -> 0.700
2024-12-01-19:20:21-root-INFO: Learning rate of xt decay: 0.54448 -> 0.55102.
2024-12-01-19:20:21-root-INFO: Coefficient of regularization decay: 0.00112 -> 0.00113.
2024-12-01-19:20:22-root-INFO: step: 5 lr_xt 0.54931747
2024-12-01-19:20:22-root-INFO: grad norm: 1.394 1.385 0.162
2024-12-01-19:20:23-root-INFO: grad norm: 0.839 0.835 0.084
2024-12-01-19:20:24-root-INFO: Loss Change: 3.178 -> 2.562
2024-12-01-19:20:24-root-INFO: Regularization Change: 0.000 -> 0.580
2024-12-01-19:20:24-root-INFO: Undo step: 5
2024-12-01-19:20:24-root-INFO: Undo step: 6
2024-12-01-19:20:24-root-INFO: Undo step: 7
2024-12-01-19:20:24-root-INFO: Undo step: 8
2024-12-01-19:20:24-root-INFO: Undo step: 9
2024-12-01-19:20:24-root-INFO: step: 10 lr_xt 0.51386241
2024-12-01-19:20:24-root-INFO: grad norm: 13.365 13.344 0.758
2024-12-01-19:20:25-root-INFO: grad norm: 5.036 5.015 0.466
2024-12-01-19:20:26-root-INFO: Loss Change: 60.146 -> 12.722
2024-12-01-19:20:26-root-INFO: Regularization Change: 0.000 -> 61.531
2024-12-01-19:20:26-root-INFO: Learning rate of xt decay: 0.51912 -> 0.52534.
2024-12-01-19:20:26-root-INFO: Coefficient of regularization decay: 0.00108 -> 0.00109.
2024-12-01-19:20:27-root-INFO: step: 9 lr_xt 0.52093157
2024-12-01-19:20:27-root-INFO: grad norm: 3.466 3.455 0.275
2024-12-01-19:20:28-root-INFO: grad norm: 2.323 2.307 0.267
2024-12-01-19:20:29-root-INFO: Loss Change: 12.354 -> 7.181
2024-12-01-19:20:29-root-INFO: Regularization Change: 0.000 -> 6.247
2024-12-01-19:20:29-root-INFO: Learning rate of xt decay: 0.52534 -> 0.53165.
2024-12-01-19:20:29-root-INFO: Coefficient of regularization decay: 0.00109 -> 0.00110.
2024-12-01-19:20:29-root-INFO: step: 8 lr_xt 0.52801377
2024-12-01-19:20:29-root-INFO: grad norm: 2.261 2.246 0.262
2024-12-01-19:20:30-root-INFO: grad norm: 1.763 1.749 0.228
2024-12-01-19:20:31-root-INFO: Loss Change: 7.032 -> 4.954
2024-12-01-19:20:31-root-INFO: Regularization Change: 0.000 -> 2.300
2024-12-01-19:20:31-root-INFO: Learning rate of xt decay: 0.53165 -> 0.53803.
2024-12-01-19:20:31-root-INFO: Coefficient of regularization decay: 0.00110 -> 0.00111.
2024-12-01-19:20:31-root-INFO: step: 7 lr_xt 0.53510690
2024-12-01-19:20:32-root-INFO: grad norm: 2.067 2.051 0.256
2024-12-01-19:20:33-root-INFO: grad norm: 1.518 1.507 0.178
2024-12-01-19:20:33-root-INFO: Loss Change: 4.963 -> 3.718
2024-12-01-19:20:33-root-INFO: Regularization Change: 0.000 -> 1.243
2024-12-01-19:20:33-root-INFO: Learning rate of xt decay: 0.53803 -> 0.54448.
2024-12-01-19:20:33-root-INFO: Coefficient of regularization decay: 0.00111 -> 0.00112.
2024-12-01-19:20:34-root-INFO: step: 6 lr_xt 0.54220886
2024-12-01-19:20:34-root-INFO: grad norm: 1.640 1.629 0.185
2024-12-01-19:20:35-root-INFO: grad norm: 1.107 1.101 0.118
2024-12-01-19:20:36-root-INFO: Loss Change: 3.784 -> 2.943
2024-12-01-19:20:36-root-INFO: Regularization Change: 0.000 -> 0.802
2024-12-01-19:20:36-root-INFO: Learning rate of xt decay: 0.54448 -> 0.55102.
2024-12-01-19:20:36-root-INFO: Coefficient of regularization decay: 0.00112 -> 0.00113.
2024-12-01-19:20:36-root-INFO: step: 5 lr_xt 0.54931747
2024-12-01-19:20:36-root-INFO: grad norm: 1.325 1.316 0.147
2024-12-01-19:20:37-root-INFO: grad norm: 0.881 0.878 0.078
2024-12-01-19:20:38-root-INFO: Loss Change: 3.040 -> 2.387
2024-12-01-19:20:38-root-INFO: Regularization Change: 0.000 -> 0.626
2024-12-01-19:20:38-root-INFO: Learning rate of xt decay: 0.55102 -> 0.55763.
2024-12-01-19:20:38-root-INFO: Coefficient of regularization decay: 0.00113 -> 0.00114.
2024-12-01-19:20:38-root-INFO: step: 4 lr_xt 0.55643055
2024-12-01-19:20:39-root-INFO: grad norm: 1.163 1.157 0.109
2024-12-01-19:20:40-root-INFO: grad norm: 0.674 0.672 0.055
2024-12-01-19:20:40-root-INFO: Loss Change: 2.498 -> 2.054
2024-12-01-19:20:40-root-INFO: Regularization Change: 0.000 -> 0.500
2024-12-01-19:20:40-root-INFO: Learning rate of xt decay: 0.55763 -> 0.56432.
2024-12-01-19:20:40-root-INFO: Coefficient of regularization decay: 0.00114 -> 0.00116.
2024-12-01-19:20:41-root-INFO: step: 3 lr_xt 0.56354589
2024-12-01-19:20:41-root-INFO: grad norm: 0.969 0.965 0.090
2024-12-01-19:20:42-root-INFO: grad norm: 0.550 0.547 0.053
2024-12-01-19:20:43-root-INFO: Loss Change: 2.176 -> 1.796
2024-12-01-19:20:43-root-INFO: Regularization Change: 0.000 -> 0.409
2024-12-01-19:20:43-root-INFO: Learning rate of xt decay: 0.56432 -> 0.57109.
2024-12-01-19:20:43-root-INFO: Coefficient of regularization decay: 0.00116 -> 0.00117.
2024-12-01-19:20:43-root-INFO: step: 2 lr_xt 0.57066124
2024-12-01-19:20:43-root-INFO: grad norm: 0.888 0.885 0.069
2024-12-01-19:20:44-root-INFO: grad norm: 0.501 0.499 0.048
2024-12-01-19:20:45-root-INFO: Loss Change: 1.918 -> 1.588
2024-12-01-19:20:45-root-INFO: Regularization Change: 0.000 -> 0.372
2024-12-01-19:20:45-root-INFO: Learning rate of xt decay: 0.57109 -> 0.57795.
2024-12-01-19:20:45-root-INFO: Coefficient of regularization decay: 0.00117 -> 0.00118.
2024-12-01-19:20:46-root-INFO: step: 1 lr_xt 0.57777431
2024-12-01-19:20:46-root-INFO: grad norm: 0.854 0.851 0.063
2024-12-01-19:20:47-root-INFO: grad norm: 0.576 0.574 0.042
2024-12-01-19:20:48-root-INFO: Loss Change: 1.694 -> 1.416
2024-12-01-19:20:48-root-INFO: Regularization Change: 0.000 -> 0.383
2024-12-01-19:20:48-root-INFO: Learning rate of xt decay: 0.57795 -> 0.58488.
2024-12-01-19:20:48-root-INFO: Coefficient of regularization decay: 0.00118 -> 0.00119.
2024-12-01-19:20:48-root-INFO: step: 0 lr_xt 0.58488282
2024-12-01-19:20:48-root-INFO: grad norm: 0.997 0.994 0.076
2024-12-01-19:20:49-root-INFO: grad norm: 0.483 0.482 0.035
2024-12-01-19:20:50-root-INFO: Loss Change: 1.566 -> 1.081
2024-12-01-19:20:50-root-INFO: Regularization Change: 0.000 -> 0.609
2024-12-01-19:20:50-root-INFO: Undo step: 0
2024-12-01-19:20:50-root-INFO: Undo step: 1
2024-12-01-19:20:50-root-INFO: Undo step: 2
2024-12-01-19:20:50-root-INFO: Undo step: 3
2024-12-01-19:20:50-root-INFO: Undo step: 4
2024-12-01-19:20:50-root-INFO: step: 5 lr_xt 0.54931747
2024-12-01-19:20:51-root-INFO: grad norm: 12.412 12.406 0.397
2024-12-01-19:20:52-root-INFO: grad norm: 6.477 6.473 0.240
2024-12-01-19:20:52-root-INFO: Loss Change: 37.722 -> 8.024
2024-12-01-19:20:52-root-INFO: Regularization Change: 0.000 -> 47.397
2024-12-01-19:20:52-root-INFO: Learning rate of xt decay: 0.55102 -> 0.55763.
2024-12-01-19:20:52-root-INFO: Coefficient of regularization decay: 0.00113 -> 0.00114.
2024-12-01-19:20:53-root-INFO: step: 4 lr_xt 0.55643055
2024-12-01-19:20:53-root-INFO: grad norm: 4.405 4.403 0.120
2024-12-01-19:20:54-root-INFO: grad norm: 2.646 2.644 0.099
2024-12-01-19:20:55-root-INFO: Loss Change: 7.875 -> 5.050
2024-12-01-19:20:55-root-INFO: Regularization Change: 0.000 -> 7.356
2024-12-01-19:20:55-root-INFO: Learning rate of xt decay: 0.55763 -> 0.56432.
2024-12-01-19:20:55-root-INFO: Coefficient of regularization decay: 0.00114 -> 0.00116.
2024-12-01-19:20:55-root-INFO: step: 3 lr_xt 0.56354589
2024-12-01-19:20:55-root-INFO: grad norm: 2.075 2.073 0.090
2024-12-01-19:20:56-root-INFO: grad norm: 1.729 1.727 0.069
2024-12-01-19:20:57-root-INFO: Loss Change: 5.071 -> 4.193
2024-12-01-19:20:57-root-INFO: Regularization Change: 0.000 -> 1.748
2024-12-01-19:20:57-root-INFO: Learning rate of xt decay: 0.56432 -> 0.57109.
2024-12-01-19:20:57-root-INFO: Coefficient of regularization decay: 0.00116 -> 0.00117.
2024-12-01-19:20:57-root-INFO: step: 2 lr_xt 0.57066124
2024-12-01-19:20:58-root-INFO: grad norm: 1.402 1.400 0.088
2024-12-01-19:20:59-root-INFO: grad norm: 1.115 1.114 0.063
2024-12-01-19:20:59-root-INFO: Loss Change: 4.316 -> 3.147
2024-12-01-19:20:59-root-INFO: Regularization Change: 0.000 -> 1.339
2024-12-01-19:20:59-root-INFO: Learning rate of xt decay: 0.57109 -> 0.57795.
2024-12-01-19:20:59-root-INFO: Coefficient of regularization decay: 0.00117 -> 0.00118.
2024-12-01-19:21:00-root-INFO: step: 1 lr_xt 0.57777431
2024-12-01-19:21:00-root-INFO: grad norm: 1.358 1.355 0.081
2024-12-01-19:21:01-root-INFO: grad norm: 1.619 1.619 0.051
2024-12-01-19:21:02-root-INFO: Loss Change: 3.282 -> 2.257
2024-12-01-19:21:02-root-INFO: Regularization Change: 0.000 -> 1.946
2024-12-01-19:21:02-root-INFO: Learning rate of xt decay: 0.57795 -> 0.58488.
2024-12-01-19:21:02-root-INFO: Coefficient of regularization decay: 0.00118 -> 0.00119.
2024-12-01-19:21:02-root-INFO: loss_sample0_0: 2.256681442260742
2024-12-01-19:21:02-root-INFO: It takes 1546.971 seconds for image sample0
2024-12-01-19:21:02-root-INFO: lpips_score_sample0: 0.140
2024-12-01-19:21:02-root-INFO: psnr_score_sample0: 17.493
2024-12-01-19:21:02-root-INFO: ssim_score_sample0: 0.712
2024-12-01-19:21:02-root-INFO: mean_lpips: 0.14017660915851593
2024-12-01-19:21:02-root-INFO: best_mean_lpips: 0.14017660915851593
2024-12-01-19:21:02-root-INFO: mean_psnr: 17.492740631103516
2024-12-01-19:21:02-root-INFO: best_mean_psnr: 17.492740631103516
2024-12-01-19:21:02-root-INFO: mean_ssim: 0.7117582559585571
2024-12-01-19:21:02-root-INFO: best_mean_ssim: 0.7117582559585571
2024-12-01-19:21:02-root-INFO: final_loss: 2.256681442260742
2024-12-01-19:21:02-root-INFO: mean time: 1546.971260547638
2024-12-01-19:21:02-root-INFO: Your samples are ready and waiting for you here: 
./hyperparam_eval/results/celebahq_o_ddim_jump5_sample2_iter2_lr0.03_10009 
 
Enjoy.
