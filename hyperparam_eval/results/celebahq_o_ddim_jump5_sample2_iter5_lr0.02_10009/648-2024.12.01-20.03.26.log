2024-12-01-20:03:29-root-INFO: Prepare model...
2024-12-01-20:03:45-root-INFO: Loading model from ./checkpoints/celeba256_250000.pt...
2024-12-01-20:04:11-root-INFO: Start sampling
2024-12-01-20:04:21-root-INFO: step: 249 lr_xt 0.00012706
2024-12-01-20:04:21-root-INFO: grad norm: 32196.164 24085.777 21365.119
2024-12-01-20:04:22-root-INFO: grad norm: 23714.289 17716.723 15763.415
2024-12-01-20:04:23-root-INFO: grad norm: 26794.332 21196.438 16390.465
2024-12-01-20:04:23-root-INFO: Loss too large (43814.371->60947.547)! Learning rate decreased to 0.00010.
2024-12-01-20:04:24-root-INFO: Loss too large (43814.371->45478.750)! Learning rate decreased to 0.00008.
2024-12-01-20:04:25-root-INFO: grad norm: 21163.650 16199.442 13619.038
2024-12-01-20:04:26-root-INFO: grad norm: 19145.469 15680.632 10984.843
2024-12-01-20:04:26-root-INFO: Loss Change: 77070.016 -> 26878.838
2024-12-01-20:04:26-root-INFO: Regularization Change: 0.000 -> 12.887
2024-12-01-20:04:26-root-INFO: Learning rate of xt decay: 0.02000 -> 0.02024.
2024-12-01-20:04:26-root-INFO: Coefficient of regularization decay: 0.00010 -> 0.00010.
2024-12-01-20:04:27-root-INFO: step: 248 lr_xt 0.00013388
2024-12-01-20:04:27-root-INFO: grad norm: 16834.871 13087.801 10588.784
2024-12-01-20:04:27-root-INFO: Loss too large (26923.914->41982.715)! Learning rate decreased to 0.00011.
2024-12-01-20:04:28-root-INFO: Loss too large (26923.914->30479.301)! Learning rate decreased to 0.00009.
2024-12-01-20:04:29-root-INFO: grad norm: 14963.449 12112.793 8785.503
2024-12-01-20:04:30-root-INFO: grad norm: 13331.716 10542.548 8160.229
2024-12-01-20:04:31-root-INFO: grad norm: 11796.768 9478.320 7023.188
2024-12-01-20:04:32-root-INFO: grad norm: 10413.921 8320.396 6262.648
2024-12-01-20:04:33-root-INFO: Loss Change: 26923.914 -> 19160.787
2024-12-01-20:04:33-root-INFO: Regularization Change: 0.000 -> 2.795
2024-12-01-20:04:33-root-INFO: Learning rate of xt decay: 0.02024 -> 0.02048.
2024-12-01-20:04:33-root-INFO: Coefficient of regularization decay: 0.00010 -> 0.00010.
2024-12-01-20:04:33-root-INFO: step: 247 lr_xt 0.00014104
2024-12-01-20:04:33-root-INFO: grad norm: 8804.280 7051.470 5271.823
2024-12-01-20:04:34-root-INFO: Loss too large (18953.590->23037.656)! Learning rate decreased to 0.00011.
2024-12-01-20:04:34-root-INFO: Loss too large (18953.590->19964.758)! Learning rate decreased to 0.00009.
2024-12-01-20:04:35-root-INFO: grad norm: 7322.825 5943.207 4278.090
2024-12-01-20:04:36-root-INFO: grad norm: 5995.929 4786.915 3610.624
2024-12-01-20:04:37-root-INFO: grad norm: 4944.256 4020.928 2877.117
2024-12-01-20:04:38-root-INFO: grad norm: 4022.918 3207.844 2427.676
2024-12-01-20:04:39-root-INFO: Loss Change: 18953.590 -> 16716.379
2024-12-01-20:04:39-root-INFO: Regularization Change: 0.000 -> 0.649
2024-12-01-20:04:39-root-INFO: Learning rate of xt decay: 0.02048 -> 0.02073.
2024-12-01-20:04:39-root-INFO: Coefficient of regularization decay: 0.00010 -> 0.00010.
2024-12-01-20:04:39-root-INFO: step: 246 lr_xt 0.00014856
2024-12-01-20:04:39-root-INFO: grad norm: 3163.320 2611.655 1784.896
2024-12-01-20:04:40-root-INFO: Loss too large (16469.229->16841.508)! Learning rate decreased to 0.00012.
2024-12-01-20:04:41-root-INFO: grad norm: 3733.771 2999.299 2223.793
2024-12-01-20:04:41-root-INFO: Loss too large (16467.037->16537.410)! Learning rate decreased to 0.00010.
2024-12-01-20:04:42-root-INFO: grad norm: 2894.191 2370.319 1660.702
2024-12-01-20:04:43-root-INFO: grad norm: 2242.474 1817.633 1313.355
2024-12-01-20:04:44-root-INFO: grad norm: 1775.927 1456.424 1016.241
2024-12-01-20:04:45-root-INFO: Loss Change: 16469.229 -> 15881.568
2024-12-01-20:04:45-root-INFO: Regularization Change: 0.000 -> 0.242
2024-12-01-20:04:45-root-INFO: Learning rate of xt decay: 0.02073 -> 0.02098.
2024-12-01-20:04:45-root-INFO: Coefficient of regularization decay: 0.00010 -> 0.00010.
2024-12-01-20:04:45-root-INFO: step: 245 lr_xt 0.00015646
2024-12-01-20:04:45-root-INFO: grad norm: 1396.643 1148.994 793.993
2024-12-01-20:04:47-root-INFO: grad norm: 2001.073 1614.603 1182.095
2024-12-01-20:04:47-root-INFO: Loss too large (15714.596->15791.698)! Learning rate decreased to 0.00013.
2024-12-01-20:04:48-root-INFO: grad norm: 2205.442 1820.398 1245.042
2024-12-01-20:04:49-root-INFO: grad norm: 2437.382 1958.367 1451.078
2024-12-01-20:04:50-root-INFO: grad norm: 2714.559 2240.424 1532.753
2024-12-01-20:04:51-root-INFO: Loss Change: 15753.126 -> 15577.911
2024-12-01-20:04:51-root-INFO: Regularization Change: 0.000 -> 0.316
2024-12-01-20:04:51-root-INFO: Learning rate of xt decay: 0.02098 -> 0.02123.
2024-12-01-20:04:51-root-INFO: Coefficient of regularization decay: 0.00010 -> 0.00011.
2024-12-01-20:04:51-root-INFO: step: 244 lr_xt 0.00016475
2024-12-01-20:04:51-root-INFO: grad norm: 3027.484 2437.467 1795.666
2024-12-01-20:04:52-root-INFO: Loss too large (15495.258->15710.771)! Learning rate decreased to 0.00013.
2024-12-01-20:04:53-root-INFO: grad norm: 3079.867 2534.367 1750.018
2024-12-01-20:04:54-root-INFO: grad norm: 3223.949 2601.101 1904.762
2024-12-01-20:04:55-root-INFO: grad norm: 3422.781 2837.761 1913.776
2024-12-01-20:04:56-root-INFO: grad norm: 3642.395 2939.370 2151.081
2024-12-01-20:04:56-root-INFO: Loss Change: 15495.258 -> 15239.013
2024-12-01-20:04:56-root-INFO: Regularization Change: 0.000 -> 0.460
2024-12-01-20:04:56-root-INFO: Learning rate of xt decay: 0.02123 -> 0.02148.
2024-12-01-20:04:56-root-INFO: Coefficient of regularization decay: 0.00011 -> 0.00011.
2024-12-01-20:04:57-root-INFO: step: 243 lr_xt 0.00017345
2024-12-01-20:04:57-root-INFO: grad norm: 3729.506 3093.444 2083.222
2024-12-01-20:04:57-root-INFO: Loss too large (15090.646->15566.859)! Learning rate decreased to 0.00014.
2024-12-01-20:04:58-root-INFO: grad norm: 3749.138 3020.912 2220.389
2024-12-01-20:04:59-root-INFO: grad norm: 3818.964 3188.540 2101.832
2024-12-01-20:05:00-root-INFO: grad norm: 3909.807 3160.745 2301.365
2024-12-01-20:05:01-root-INFO: grad norm: 4022.470 3357.718 2214.948
2024-12-01-20:05:02-root-INFO: Loss Change: 15090.646 -> 14810.211
2024-12-01-20:05:02-root-INFO: Regularization Change: 0.000 -> 0.561
2024-12-01-20:05:02-root-INFO: Learning rate of xt decay: 0.02148 -> 0.02174.
2024-12-01-20:05:02-root-INFO: Coefficient of regularization decay: 0.00011 -> 0.00011.
2024-12-01-20:05:02-root-INFO: step: 242 lr_xt 0.00018258
2024-12-01-20:05:03-root-INFO: grad norm: 3847.234 3156.738 2199.140
2024-12-01-20:05:03-root-INFO: Loss too large (14551.101->15039.625)! Learning rate decreased to 0.00015.
2024-12-01-20:05:04-root-INFO: grad norm: 3787.279 3176.532 2062.311
2024-12-01-20:05:05-root-INFO: grad norm: 3760.619 3069.745 2172.308
2024-12-01-20:05:06-root-INFO: grad norm: 3743.509 3147.055 2027.289
2024-12-01-20:05:07-root-INFO: grad norm: 3736.723 3049.090 2160.128
2024-12-01-20:05:08-root-INFO: Loss Change: 14551.101 -> 14081.684
2024-12-01-20:05:08-root-INFO: Regularization Change: 0.000 -> 0.597
2024-12-01-20:05:08-root-INFO: Learning rate of xt decay: 0.02174 -> 0.02200.
2024-12-01-20:05:08-root-INFO: Coefficient of regularization decay: 0.00011 -> 0.00011.
2024-12-01-20:05:08-root-INFO: step: 241 lr_xt 0.00019216
2024-12-01-20:05:09-root-INFO: grad norm: 3713.750 3124.962 2006.627
2024-12-01-20:05:09-root-INFO: Loss too large (14017.942->14495.167)! Learning rate decreased to 0.00015.
2024-12-01-20:05:10-root-INFO: grad norm: 3579.873 2948.195 2030.674
2024-12-01-20:05:11-root-INFO: grad norm: 3456.392 2919.434 1850.285
2024-12-01-20:05:12-root-INFO: grad norm: 3349.752 2755.369 1904.936
2024-12-01-20:05:13-root-INFO: grad norm: 3243.834 2743.839 1730.263
2024-12-01-20:05:14-root-INFO: Loss Change: 14017.942 -> 13457.917
2024-12-01-20:05:14-root-INFO: Regularization Change: 0.000 -> 0.596
2024-12-01-20:05:14-root-INFO: Learning rate of xt decay: 0.02200 -> 0.02227.
2024-12-01-20:05:14-root-INFO: Coefficient of regularization decay: 0.00011 -> 0.00011.
2024-12-01-20:05:14-root-INFO: step: 240 lr_xt 0.00020221
2024-12-01-20:05:14-root-INFO: grad norm: 2988.253 2491.478 1649.907
2024-12-01-20:05:15-root-INFO: Loss too large (13258.637->13466.534)! Learning rate decreased to 0.00016.
2024-12-01-20:05:16-root-INFO: grad norm: 2772.562 2366.816 1444.049
2024-12-01-20:05:17-root-INFO: grad norm: 2603.977 2157.317 1458.314
2024-12-01-20:05:18-root-INFO: grad norm: 2452.703 2104.493 1259.707
2024-12-01-20:05:19-root-INFO: grad norm: 2320.609 1923.386 1298.388
2024-12-01-20:05:20-root-INFO: Loss Change: 13258.637 -> 12626.677
2024-12-01-20:05:20-root-INFO: Regularization Change: 0.000 -> 0.538
2024-12-01-20:05:20-root-INFO: Undo step: 240
2024-12-01-20:05:20-root-INFO: Undo step: 241
2024-12-01-20:05:20-root-INFO: Undo step: 242
2024-12-01-20:05:20-root-INFO: Undo step: 243
2024-12-01-20:05:20-root-INFO: Undo step: 244
2024-12-01-20:05:20-root-INFO: step: 245 lr_xt 0.00015646
2024-12-01-20:05:20-root-INFO: grad norm: 12080.040 8985.854 8073.525
2024-12-01-20:05:21-root-INFO: Loss too large (20543.293->21792.020)! Learning rate decreased to 0.00013.
2024-12-01-20:05:22-root-INFO: grad norm: 8859.818 6653.514 5850.395
2024-12-01-20:05:23-root-INFO: grad norm: 7161.122 5583.259 4484.292
2024-12-01-20:05:24-root-INFO: grad norm: 6605.149 5110.435 4184.669
2024-12-01-20:05:25-root-INFO: grad norm: 6243.392 5009.179 3726.669
2024-12-01-20:05:25-root-INFO: Loss too large (15673.141->15686.631)! Learning rate decreased to 0.00010.
2024-12-01-20:05:26-root-INFO: Loss Change: 20543.293 -> 14932.214
2024-12-01-20:05:26-root-INFO: Regularization Change: 0.000 -> 1.563
2024-12-01-20:05:26-root-INFO: Learning rate of xt decay: 0.02098 -> 0.02123.
2024-12-01-20:05:26-root-INFO: Coefficient of regularization decay: 0.00010 -> 0.00011.
2024-12-01-20:05:26-root-INFO: step: 244 lr_xt 0.00016475
2024-12-01-20:05:26-root-INFO: grad norm: 3831.299 2983.716 2403.391
2024-12-01-20:05:27-root-INFO: Loss too large (14881.533->15104.500)! Learning rate decreased to 0.00013.
2024-12-01-20:05:28-root-INFO: grad norm: 3520.845 2866.447 2044.464
2024-12-01-20:05:29-root-INFO: grad norm: 3408.029 2679.835 2105.504
2024-12-01-20:05:30-root-INFO: grad norm: 3362.638 2785.856 1883.172
2024-12-01-20:05:31-root-INFO: grad norm: 3380.242 2670.674 2072.086
2024-12-01-20:05:32-root-INFO: Loss Change: 14881.533 -> 14195.961
2024-12-01-20:05:32-root-INFO: Regularization Change: 0.000 -> 0.569
2024-12-01-20:05:32-root-INFO: Learning rate of xt decay: 0.02123 -> 0.02148.
2024-12-01-20:05:32-root-INFO: Coefficient of regularization decay: 0.00011 -> 0.00011.
2024-12-01-20:05:32-root-INFO: step: 243 lr_xt 0.00017345
2024-12-01-20:05:32-root-INFO: grad norm: 3285.611 2712.243 1854.447
2024-12-01-20:05:33-root-INFO: Loss too large (13955.176->14217.403)! Learning rate decreased to 0.00014.
2024-12-01-20:05:34-root-INFO: grad norm: 3148.901 2484.740 1934.334
2024-12-01-20:05:35-root-INFO: grad norm: 3075.060 2575.043 1680.818
2024-12-01-20:05:36-root-INFO: grad norm: 3044.609 2412.090 1857.812
2024-12-01-20:05:37-root-INFO: grad norm: 3029.195 2543.222 1645.615
2024-12-01-20:05:37-root-INFO: Loss Change: 13955.176 -> 13460.555
2024-12-01-20:05:37-root-INFO: Regularization Change: 0.000 -> 0.487
2024-12-01-20:05:37-root-INFO: Learning rate of xt decay: 0.02148 -> 0.02174.
2024-12-01-20:05:37-root-INFO: Coefficient of regularization decay: 0.00011 -> 0.00011.
2024-12-01-20:05:38-root-INFO: step: 242 lr_xt 0.00018258
2024-12-01-20:05:38-root-INFO: grad norm: 2761.386 2222.353 1639.025
2024-12-01-20:05:38-root-INFO: Loss too large (13209.197->13362.792)! Learning rate decreased to 0.00015.
2024-12-01-20:05:39-root-INFO: grad norm: 2629.201 2216.537 1414.094
2024-12-01-20:05:40-root-INFO: grad norm: 2539.863 2029.734 1526.788
2024-12-01-20:05:41-root-INFO: grad norm: 2463.429 2086.614 1309.399
2024-12-01-20:05:42-root-INFO: grad norm: 2398.762 1915.401 1444.057
2024-12-01-20:05:43-root-INFO: Loss Change: 13209.197 -> 12702.123
2024-12-01-20:05:43-root-INFO: Regularization Change: 0.000 -> 0.438
2024-12-01-20:05:43-root-INFO: Learning rate of xt decay: 0.02174 -> 0.02200.
2024-12-01-20:05:43-root-INFO: Coefficient of regularization decay: 0.00011 -> 0.00011.
2024-12-01-20:05:43-root-INFO: step: 241 lr_xt 0.00019216
2024-12-01-20:05:44-root-INFO: grad norm: 2385.506 2013.248 1279.638
2024-12-01-20:05:44-root-INFO: Loss too large (12627.461->12731.473)! Learning rate decreased to 0.00015.
2024-12-01-20:05:45-root-INFO: grad norm: 2237.368 1808.725 1316.940
2024-12-01-20:05:46-root-INFO: grad norm: 2106.909 1791.460 1108.935
2024-12-01-20:05:47-root-INFO: grad norm: 1995.895 1612.493 1176.207
2024-12-01-20:05:48-root-INFO: grad norm: 1890.376 1613.021 985.741
2024-12-01-20:05:49-root-INFO: Loss Change: 12627.461 -> 12140.174
2024-12-01-20:05:49-root-INFO: Regularization Change: 0.000 -> 0.399
2024-12-01-20:05:49-root-INFO: Learning rate of xt decay: 0.02200 -> 0.02227.
2024-12-01-20:05:49-root-INFO: Coefficient of regularization decay: 0.00011 -> 0.00011.
2024-12-01-20:05:49-root-INFO: step: 240 lr_xt 0.00020221
2024-12-01-20:05:50-root-INFO: grad norm: 1727.253 1424.407 976.970
2024-12-01-20:05:51-root-INFO: grad norm: 2230.449 1892.804 1179.913
2024-12-01-20:05:51-root-INFO: Loss too large (11929.666->12001.518)! Learning rate decreased to 0.00016.
2024-12-01-20:05:52-root-INFO: grad norm: 2024.608 1651.439 1171.233
2024-12-01-20:05:53-root-INFO: grad norm: 1841.132 1576.198 951.507
2024-12-01-20:05:54-root-INFO: grad norm: 1685.781 1376.400 973.334
2024-12-01-20:05:55-root-INFO: Loss Change: 11959.135 -> 11518.334
2024-12-01-20:05:55-root-INFO: Regularization Change: 0.000 -> 0.417
2024-12-01-20:05:55-root-INFO: Learning rate of xt decay: 0.02227 -> 0.02253.
2024-12-01-20:05:55-root-INFO: Coefficient of regularization decay: 0.00011 -> 0.00011.
2024-12-01-20:05:55-root-INFO: step: 239 lr_xt 0.00021275
2024-12-01-20:05:55-root-INFO: grad norm: 1452.183 1251.651 736.346
2024-12-01-20:05:56-root-INFO: grad norm: 1830.545 1503.159 1044.705
2024-12-01-20:05:57-root-INFO: Loss too large (11389.621->11396.396)! Learning rate decreased to 0.00017.
2024-12-01-20:05:58-root-INFO: grad norm: 1616.646 1387.609 829.510
2024-12-01-20:05:59-root-INFO: grad norm: 1441.065 1189.957 812.816
2024-12-01-20:06:00-root-INFO: grad norm: 1290.115 1117.689 644.335
2024-12-01-20:06:01-root-INFO: Loss Change: 11427.755 -> 11006.363
2024-12-01-20:06:01-root-INFO: Regularization Change: 0.000 -> 0.392
2024-12-01-20:06:01-root-INFO: Learning rate of xt decay: 0.02253 -> 0.02280.
2024-12-01-20:06:01-root-INFO: Coefficient of regularization decay: 0.00011 -> 0.00011.
2024-12-01-20:06:01-root-INFO: step: 238 lr_xt 0.00022380
2024-12-01-20:06:01-root-INFO: grad norm: 1282.797 1088.981 678.002
2024-12-01-20:06:02-root-INFO: grad norm: 1423.871 1225.035 725.740
2024-12-01-20:06:03-root-INFO: grad norm: 1714.451 1426.441 951.109
2024-12-01-20:06:04-root-INFO: grad norm: 2121.990 1819.230 1092.357
2024-12-01-20:06:05-root-INFO: Loss too large (10645.200->10691.007)! Learning rate decreased to 0.00018.
2024-12-01-20:06:06-root-INFO: grad norm: 1771.556 1478.900 975.328
2024-12-01-20:06:06-root-INFO: Loss Change: 10791.797 -> 10403.829
2024-12-01-20:06:06-root-INFO: Regularization Change: 0.000 -> 0.483
2024-12-01-20:06:06-root-INFO: Learning rate of xt decay: 0.02280 -> 0.02308.
2024-12-01-20:06:06-root-INFO: Coefficient of regularization decay: 0.00011 -> 0.00011.
2024-12-01-20:06:07-root-INFO: step: 237 lr_xt 0.00023539
2024-12-01-20:06:07-root-INFO: grad norm: 1294.957 1123.240 644.397
2024-12-01-20:06:08-root-INFO: grad norm: 1493.015 1254.123 810.105
2024-12-01-20:06:09-root-INFO: grad norm: 1771.597 1536.298 882.239
2024-12-01-20:06:10-root-INFO: grad norm: 2118.217 1781.921 1145.251
2024-12-01-20:06:10-root-INFO: Loss too large (10208.398->10237.615)! Learning rate decreased to 0.00019.
2024-12-01-20:06:11-root-INFO: grad norm: 1674.753 1454.219 830.689
2024-12-01-20:06:12-root-INFO: Loss Change: 10301.802 -> 9947.139
2024-12-01-20:06:12-root-INFO: Regularization Change: 0.000 -> 0.459
2024-12-01-20:06:12-root-INFO: Learning rate of xt decay: 0.02308 -> 0.02335.
2024-12-01-20:06:12-root-INFO: Coefficient of regularization decay: 0.00011 -> 0.00011.
2024-12-01-20:06:12-root-INFO: step: 236 lr_xt 0.00024753
2024-12-01-20:06:13-root-INFO: grad norm: 1279.781 1098.370 656.828
2024-12-01-20:06:14-root-INFO: grad norm: 1462.158 1267.946 728.162
2024-12-01-20:06:15-root-INFO: grad norm: 1686.130 1431.273 891.343
2024-12-01-20:06:16-root-INFO: grad norm: 1953.491 1687.327 984.407
2024-12-01-20:06:16-root-INFO: Loss too large (9705.296->9712.354)! Learning rate decreased to 0.00020.
2024-12-01-20:06:17-root-INFO: grad norm: 1486.436 1263.284 783.331
2024-12-01-20:06:18-root-INFO: Loss Change: 9805.157 -> 9454.188
2024-12-01-20:06:18-root-INFO: Regularization Change: 0.000 -> 0.446
2024-12-01-20:06:18-root-INFO: Learning rate of xt decay: 0.02335 -> 0.02364.
2024-12-01-20:06:18-root-INFO: Coefficient of regularization decay: 0.00011 -> 0.00011.
2024-12-01-20:06:18-root-INFO: step: 235 lr_xt 0.00026027
2024-12-01-20:06:19-root-INFO: grad norm: 920.324 813.151 431.024
2024-12-01-20:06:20-root-INFO: grad norm: 974.337 838.356 496.479
2024-12-01-20:06:21-root-INFO: grad norm: 1056.542 938.969 484.374
2024-12-01-20:06:22-root-INFO: grad norm: 1150.128 985.489 592.963
2024-12-01-20:06:23-root-INFO: grad norm: 1256.229 1108.916 590.268
2024-12-01-20:06:23-root-INFO: Loss Change: 9323.922 -> 9064.269
2024-12-01-20:06:23-root-INFO: Regularization Change: 0.000 -> 0.489
2024-12-01-20:06:23-root-INFO: Undo step: 235
2024-12-01-20:06:23-root-INFO: Undo step: 236
2024-12-01-20:06:23-root-INFO: Undo step: 237
2024-12-01-20:06:23-root-INFO: Undo step: 238
2024-12-01-20:06:23-root-INFO: Undo step: 239
2024-12-01-20:06:24-root-INFO: step: 240 lr_xt 0.00020221
2024-12-01-20:06:24-root-INFO: grad norm: 7608.943 6238.630 4356.087
2024-12-01-20:06:25-root-INFO: grad norm: 7483.612 6046.503 4409.563
2024-12-01-20:06:26-root-INFO: grad norm: 8349.653 6936.061 4648.417
2024-12-01-20:06:27-root-INFO: Loss too large (13824.373->15210.766)! Learning rate decreased to 0.00016.
2024-12-01-20:06:28-root-INFO: grad norm: 6382.833 5283.695 3580.938
2024-12-01-20:06:29-root-INFO: grad norm: 4820.972 4027.218 2650.148
2024-12-01-20:06:29-root-INFO: Loss Change: 14038.941 -> 11181.525
2024-12-01-20:06:29-root-INFO: Regularization Change: 0.000 -> 1.776
2024-12-01-20:06:29-root-INFO: Learning rate of xt decay: 0.02227 -> 0.02253.
2024-12-01-20:06:29-root-INFO: Coefficient of regularization decay: 0.00011 -> 0.00011.
2024-12-01-20:06:30-root-INFO: step: 239 lr_xt 0.00021275
2024-12-01-20:06:30-root-INFO: grad norm: 3783.040 3133.416 2119.692
2024-12-01-20:06:30-root-INFO: Loss too large (11039.594->11277.514)! Learning rate decreased to 0.00017.
2024-12-01-20:06:31-root-INFO: grad norm: 2982.789 2516.980 1600.576
2024-12-01-20:06:32-root-INFO: grad norm: 2405.536 1988.256 1354.046
2024-12-01-20:06:33-root-INFO: grad norm: 1937.410 1654.133 1008.663
2024-12-01-20:06:34-root-INFO: grad norm: 1583.328 1309.569 889.919
2024-12-01-20:06:35-root-INFO: Loss Change: 11039.594 -> 10138.156
2024-12-01-20:06:35-root-INFO: Regularization Change: 0.000 -> 0.469
2024-12-01-20:06:35-root-INFO: Learning rate of xt decay: 0.02253 -> 0.02280.
2024-12-01-20:06:35-root-INFO: Coefficient of regularization decay: 0.00011 -> 0.00011.
2024-12-01-20:06:35-root-INFO: step: 238 lr_xt 0.00022380
2024-12-01-20:06:36-root-INFO: grad norm: 1252.998 1055.185 675.713
2024-12-01-20:06:36-root-INFO: grad norm: 1298.716 1078.859 722.999
2024-12-01-20:06:36-root-INFO: grad norm: 1482.130 1283.609 740.984
2024-12-01-20:06:37-root-INFO: grad norm: 1713.142 1425.057 950.825
2024-12-01-20:06:37-root-INFO: grad norm: 2004.227 1721.285 1026.695
2024-12-01-20:06:38-root-INFO: Loss too large (9790.944->9818.219)! Learning rate decreased to 0.00018.
2024-12-01-20:06:38-root-INFO: Loss Change: 9923.588 -> 9666.163
2024-12-01-20:06:38-root-INFO: Regularization Change: 0.000 -> 0.384
2024-12-01-20:06:38-root-INFO: Learning rate of xt decay: 0.02280 -> 0.02308.
2024-12-01-20:06:38-root-INFO: Coefficient of regularization decay: 0.00011 -> 0.00011.
2024-12-01-20:06:38-root-INFO: step: 237 lr_xt 0.00023539
2024-12-01-20:06:38-root-INFO: grad norm: 1666.653 1397.879 907.561
2024-12-01-20:06:39-root-INFO: grad norm: 1850.898 1599.530 931.304
2024-12-01-20:06:39-root-INFO: grad norm: 2069.898 1737.723 1124.632
2024-12-01-20:06:39-root-INFO: Loss too large (9580.200->9584.688)! Learning rate decreased to 0.00019.
2024-12-01-20:06:40-root-INFO: grad norm: 1487.713 1294.828 732.606
2024-12-01-20:06:40-root-INFO: grad norm: 1106.121 937.137 587.603
2024-12-01-20:06:41-root-INFO: Loss Change: 9607.746 -> 9257.097
2024-12-01-20:06:41-root-INFO: Regularization Change: 0.000 -> 0.310
2024-12-01-20:06:41-root-INFO: Learning rate of xt decay: 0.02308 -> 0.02335.
2024-12-01-20:06:41-root-INFO: Coefficient of regularization decay: 0.00011 -> 0.00011.
2024-12-01-20:06:41-root-INFO: step: 236 lr_xt 0.00024753
2024-12-01-20:06:41-root-INFO: grad norm: 816.121 721.219 381.965
2024-12-01-20:06:42-root-INFO: grad norm: 858.487 741.768 432.180
2024-12-01-20:06:42-root-INFO: grad norm: 917.893 812.767 426.542
2024-12-01-20:06:43-root-INFO: grad norm: 983.392 844.116 504.507
2024-12-01-20:06:43-root-INFO: grad norm: 1058.042 929.785 504.928
2024-12-01-20:06:43-root-INFO: Loss Change: 9110.057 -> 8897.829
2024-12-01-20:06:43-root-INFO: Regularization Change: 0.000 -> 0.353
2024-12-01-20:06:43-root-INFO: Learning rate of xt decay: 0.02335 -> 0.02364.
2024-12-01-20:06:43-root-INFO: Coefficient of regularization decay: 0.00011 -> 0.00011.
2024-12-01-20:06:44-root-INFO: step: 235 lr_xt 0.00026027
2024-12-01-20:06:44-root-INFO: grad norm: 1348.316 1156.848 692.574
2024-12-01-20:06:44-root-INFO: grad norm: 1388.525 1215.573 671.105
2024-12-01-20:06:45-root-INFO: grad norm: 1442.654 1232.517 749.768
2024-12-01-20:06:45-root-INFO: grad norm: 1499.510 1310.353 729.043
2024-12-01-20:06:46-root-INFO: grad norm: 1552.908 1327.591 805.621
2024-12-01-20:06:46-root-INFO: Loss Change: 8830.517 -> 8639.469
2024-12-01-20:06:46-root-INFO: Regularization Change: 0.000 -> 0.439
2024-12-01-20:06:46-root-INFO: Learning rate of xt decay: 0.02364 -> 0.02392.
2024-12-01-20:06:46-root-INFO: Coefficient of regularization decay: 0.00011 -> 0.00012.
2024-12-01-20:06:46-root-INFO: step: 234 lr_xt 0.00027361
2024-12-01-20:06:46-root-INFO: grad norm: 1466.771 1276.985 721.612
2024-12-01-20:06:47-root-INFO: grad norm: 1464.128 1256.425 751.710
2024-12-01-20:06:47-root-INFO: grad norm: 1462.316 1277.373 711.821
2024-12-01-20:06:48-root-INFO: grad norm: 1457.570 1251.668 746.886
2024-12-01-20:06:48-root-INFO: grad norm: 1451.698 1269.128 704.799
2024-12-01-20:06:49-root-INFO: Loss Change: 8556.145 -> 8323.725
2024-12-01-20:06:49-root-INFO: Regularization Change: 0.000 -> 0.464
2024-12-01-20:06:49-root-INFO: Learning rate of xt decay: 0.02392 -> 0.02421.
2024-12-01-20:06:49-root-INFO: Coefficient of regularization decay: 0.00012 -> 0.00012.
2024-12-01-20:06:49-root-INFO: step: 233 lr_xt 0.00028759
2024-12-01-20:06:49-root-INFO: grad norm: 1469.751 1273.152 734.339
2024-12-01-20:06:50-root-INFO: grad norm: 1363.943 1196.733 654.348
2024-12-01-20:06:50-root-INFO: grad norm: 1294.305 1119.472 649.621
2024-12-01-20:06:51-root-INFO: grad norm: 1229.858 1083.953 581.030
2024-12-01-20:06:51-root-INFO: grad norm: 1171.889 1015.518 584.849
2024-12-01-20:06:51-root-INFO: Loss Change: 8323.932 -> 8005.615
2024-12-01-20:06:51-root-INFO: Regularization Change: 0.000 -> 0.487
2024-12-01-20:06:51-root-INFO: Learning rate of xt decay: 0.02421 -> 0.02450.
2024-12-01-20:06:51-root-INFO: Coefficient of regularization decay: 0.00012 -> 0.00012.
2024-12-01-20:06:52-root-INFO: step: 232 lr_xt 0.00030224
2024-12-01-20:06:52-root-INFO: grad norm: 827.221 730.428 388.290
2024-12-01-20:06:52-root-INFO: grad norm: 712.502 618.715 353.343
2024-12-01-20:06:53-root-INFO: grad norm: 660.347 605.328 263.887
2024-12-01-20:06:53-root-INFO: grad norm: 619.981 547.894 290.154
2024-12-01-20:06:54-root-INFO: grad norm: 585.762 540.066 226.816
2024-12-01-20:06:54-root-INFO: Loss Change: 7799.026 -> 7535.562
2024-12-01-20:06:54-root-INFO: Regularization Change: 0.000 -> 0.385
2024-12-01-20:06:54-root-INFO: Learning rate of xt decay: 0.02450 -> 0.02479.
2024-12-01-20:06:54-root-INFO: Coefficient of regularization decay: 0.00012 -> 0.00012.
2024-12-01-20:06:54-root-INFO: step: 231 lr_xt 0.00031758
2024-12-01-20:06:54-root-INFO: grad norm: 647.096 574.114 298.541
2024-12-01-20:06:55-root-INFO: grad norm: 597.768 549.090 236.277
2024-12-01-20:06:55-root-INFO: grad norm: 558.320 499.018 250.404
2024-12-01-20:06:56-root-INFO: grad norm: 523.523 484.634 198.006
2024-12-01-20:06:56-root-INFO: grad norm: 493.346 445.084 212.816
2024-12-01-20:06:57-root-INFO: Loss Change: 7477.065 -> 7257.681
2024-12-01-20:06:57-root-INFO: Regularization Change: 0.000 -> 0.344
2024-12-01-20:06:57-root-INFO: Learning rate of xt decay: 0.02479 -> 0.02509.
2024-12-01-20:06:57-root-INFO: Coefficient of regularization decay: 0.00012 -> 0.00012.
2024-12-01-20:06:57-root-INFO: step: 230 lr_xt 0.00033364
2024-12-01-20:06:57-root-INFO: grad norm: 370.795 349.194 124.710
2024-12-01-20:06:58-root-INFO: grad norm: 348.255 327.552 118.286
2024-12-01-20:06:59-root-INFO: grad norm: 341.674 325.450 104.035
2024-12-01-20:07:00-root-INFO: grad norm: 336.237 317.752 109.950
2024-12-01-20:07:01-root-INFO: grad norm: 331.386 315.558 101.193
2024-12-01-20:07:01-root-INFO: Loss Change: 7158.310 -> 6966.551
2024-12-01-20:07:01-root-INFO: Regularization Change: 0.000 -> 0.320
2024-12-01-20:07:01-root-INFO: Undo step: 230
2024-12-01-20:07:01-root-INFO: Undo step: 231
2024-12-01-20:07:01-root-INFO: Undo step: 232
2024-12-01-20:07:01-root-INFO: Undo step: 233
2024-12-01-20:07:02-root-INFO: Undo step: 234
2024-12-01-20:07:02-root-INFO: step: 235 lr_xt 0.00026027
2024-12-01-20:07:02-root-INFO: grad norm: 9728.424 7226.562 6512.989
2024-12-01-20:07:03-root-INFO: grad norm: 4715.619 3736.263 2877.048
2024-12-01-20:07:04-root-INFO: grad norm: 3450.320 2835.963 1965.202
2024-12-01-20:07:05-root-INFO: grad norm: 3230.166 2713.051 1753.091
2024-12-01-20:07:06-root-INFO: grad norm: 3221.470 2722.268 1722.535
2024-12-01-20:07:07-root-INFO: Loss Change: 18690.621 -> 9244.005
2024-12-01-20:07:07-root-INFO: Regularization Change: 0.000 -> 5.175
2024-12-01-20:07:07-root-INFO: Learning rate of xt decay: 0.02364 -> 0.02392.
2024-12-01-20:07:07-root-INFO: Coefficient of regularization decay: 0.00011 -> 0.00012.
2024-12-01-20:07:07-root-INFO: step: 234 lr_xt 0.00027361
2024-12-01-20:07:08-root-INFO: grad norm: 3131.985 2656.236 1659.440
2024-12-01-20:07:09-root-INFO: grad norm: 3082.925 2620.210 1624.477
2024-12-01-20:07:10-root-INFO: grad norm: 3055.083 2597.426 1608.388
2024-12-01-20:07:11-root-INFO: grad norm: 3031.257 2581.646 1588.592
2024-12-01-20:07:12-root-INFO: grad norm: 3004.923 2557.419 1577.710
2024-12-01-20:07:12-root-INFO: Loss Change: 9152.029 -> 8631.427
2024-12-01-20:07:12-root-INFO: Regularization Change: 0.000 -> 1.300
2024-12-01-20:07:12-root-INFO: Learning rate of xt decay: 0.02392 -> 0.02421.
2024-12-01-20:07:12-root-INFO: Coefficient of regularization decay: 0.00012 -> 0.00012.
2024-12-01-20:07:13-root-INFO: step: 233 lr_xt 0.00028759
2024-12-01-20:07:13-root-INFO: grad norm: 2813.582 2397.187 1473.004
2024-12-01-20:07:14-root-INFO: grad norm: 2637.176 2257.732 1362.844
2024-12-01-20:07:15-root-INFO: grad norm: 2500.525 2145.392 1284.490
2024-12-01-20:07:16-root-INFO: grad norm: 2380.297 2040.003 1226.460
2024-12-01-20:07:17-root-INFO: grad norm: 2265.227 1947.474 1156.977
2024-12-01-20:07:18-root-INFO: Loss Change: 8579.250 -> 7993.781
2024-12-01-20:07:18-root-INFO: Regularization Change: 0.000 -> 1.024
2024-12-01-20:07:18-root-INFO: Learning rate of xt decay: 0.02421 -> 0.02450.
2024-12-01-20:07:18-root-INFO: Coefficient of regularization decay: 0.00012 -> 0.00012.
2024-12-01-20:07:18-root-INFO: step: 232 lr_xt 0.00030224
2024-12-01-20:07:19-root-INFO: grad norm: 2291.143 1970.183 1169.493
2024-12-01-20:07:20-root-INFO: grad norm: 2007.149 1746.853 988.510
2024-12-01-20:07:21-root-INFO: grad norm: 1817.903 1568.719 918.636
2024-12-01-20:07:22-root-INFO: grad norm: 1651.596 1440.888 807.223
2024-12-01-20:07:23-root-INFO: grad norm: 1511.854 1310.167 754.429
2024-12-01-20:07:23-root-INFO: Loss Change: 7910.449 -> 7366.594
2024-12-01-20:07:23-root-INFO: Regularization Change: 0.000 -> 0.725
2024-12-01-20:07:23-root-INFO: Learning rate of xt decay: 0.02450 -> 0.02479.
2024-12-01-20:07:23-root-INFO: Coefficient of regularization decay: 0.00012 -> 0.00012.
2024-12-01-20:07:24-root-INFO: step: 231 lr_xt 0.00031758
2024-12-01-20:07:24-root-INFO: grad norm: 1232.429 1079.968 593.761
2024-12-01-20:07:25-root-INFO: grad norm: 1101.315 960.133 539.482
2024-12-01-20:07:26-root-INFO: grad norm: 989.578 873.090 465.810
2024-12-01-20:07:27-root-INFO: grad norm: 892.606 782.278 429.869
2024-12-01-20:07:28-root-INFO: grad norm: 807.193 715.799 373.086
2024-12-01-20:07:29-root-INFO: Loss Change: 7244.032 -> 6977.513
2024-12-01-20:07:29-root-INFO: Regularization Change: 0.000 -> 0.392
2024-12-01-20:07:29-root-INFO: Learning rate of xt decay: 0.02479 -> 0.02509.
2024-12-01-20:07:29-root-INFO: Coefficient of regularization decay: 0.00012 -> 0.00012.
2024-12-01-20:07:29-root-INFO: step: 230 lr_xt 0.00033364
2024-12-01-20:07:30-root-INFO: grad norm: 879.268 770.919 422.841
2024-12-01-20:07:31-root-INFO: grad norm: 745.160 666.197 333.835
2024-12-01-20:07:32-root-INFO: grad norm: 653.340 577.112 306.260
2024-12-01-20:07:33-root-INFO: grad norm: 577.382 519.694 251.571
2024-12-01-20:07:34-root-INFO: grad norm: 515.560 461.004 230.819
2024-12-01-20:07:34-root-INFO: Loss Change: 6914.839 -> 6707.462
2024-12-01-20:07:34-root-INFO: Regularization Change: 0.000 -> 0.308
2024-12-01-20:07:34-root-INFO: Learning rate of xt decay: 0.02509 -> 0.02539.
2024-12-01-20:07:34-root-INFO: Coefficient of regularization decay: 0.00012 -> 0.00012.
2024-12-01-20:07:35-root-INFO: step: 229 lr_xt 0.00035047
2024-12-01-20:07:35-root-INFO: grad norm: 452.699 402.065 208.040
2024-12-01-20:07:36-root-INFO: grad norm: 330.526 299.719 139.342
2024-12-01-20:07:37-root-INFO: grad norm: 310.967 288.989 114.830
2024-12-01-20:07:38-root-INFO: grad norm: 298.873 277.701 110.486
2024-12-01-20:07:39-root-INFO: grad norm: 290.206 272.058 101.016
2024-12-01-20:07:40-root-INFO: Loss Change: 6650.909 -> 6481.324
2024-12-01-20:07:40-root-INFO: Regularization Change: 0.000 -> 0.282
2024-12-01-20:07:40-root-INFO: Learning rate of xt decay: 0.02539 -> 0.02569.
2024-12-01-20:07:40-root-INFO: Coefficient of regularization decay: 0.00012 -> 0.00012.
2024-12-01-20:07:40-root-INFO: step: 228 lr_xt 0.00036807
2024-12-01-20:07:41-root-INFO: grad norm: 384.923 337.905 184.352
2024-12-01-20:07:42-root-INFO: grad norm: 317.286 292.392 123.197
2024-12-01-20:07:43-root-INFO: grad norm: 293.773 273.409 107.473
2024-12-01-20:07:44-root-INFO: grad norm: 281.094 264.430 95.346
2024-12-01-20:07:45-root-INFO: grad norm: 272.716 256.713 92.046
2024-12-01-20:07:45-root-INFO: Loss Change: 6463.501 -> 6322.105
2024-12-01-20:07:45-root-INFO: Regularization Change: 0.000 -> 0.251
2024-12-01-20:07:45-root-INFO: Learning rate of xt decay: 0.02569 -> 0.02600.
2024-12-01-20:07:45-root-INFO: Coefficient of regularization decay: 0.00012 -> 0.00012.
2024-12-01-20:07:46-root-INFO: step: 227 lr_xt 0.00038651
2024-12-01-20:07:46-root-INFO: grad norm: 509.719 443.923 250.491
2024-12-01-20:07:47-root-INFO: grad norm: 367.174 335.940 148.191
2024-12-01-20:07:48-root-INFO: grad norm: 323.701 296.602 129.651
2024-12-01-20:07:49-root-INFO: grad norm: 298.129 277.854 108.067
2024-12-01-20:07:50-root-INFO: grad norm: 281.843 263.085 101.104
2024-12-01-20:07:51-root-INFO: Loss Change: 6355.677 -> 6171.717
2024-12-01-20:07:51-root-INFO: Regularization Change: 0.000 -> 0.330
2024-12-01-20:07:51-root-INFO: Learning rate of xt decay: 0.02600 -> 0.02631.
2024-12-01-20:07:51-root-INFO: Coefficient of regularization decay: 0.00012 -> 0.00013.
2024-12-01-20:07:51-root-INFO: step: 226 lr_xt 0.00040579
2024-12-01-20:07:51-root-INFO: grad norm: 329.746 289.337 158.167
2024-12-01-20:07:52-root-INFO: grad norm: 264.327 246.503 95.419
2024-12-01-20:07:53-root-INFO: grad norm: 252.383 238.334 83.032
2024-12-01-20:07:54-root-INFO: grad norm: 247.734 233.740 82.085
2024-12-01-20:07:55-root-INFO: grad norm: 244.842 231.598 79.437
2024-12-01-20:07:56-root-INFO: Loss Change: 6115.784 -> 5983.562
2024-12-01-20:07:56-root-INFO: Regularization Change: 0.000 -> 0.260
2024-12-01-20:07:56-root-INFO: Learning rate of xt decay: 0.02631 -> 0.02663.
2024-12-01-20:07:56-root-INFO: Coefficient of regularization decay: 0.00013 -> 0.00013.
2024-12-01-20:07:57-root-INFO: step: 225 lr_xt 0.00042598
2024-12-01-20:07:57-root-INFO: grad norm: 509.316 442.979 251.342
2024-12-01-20:07:58-root-INFO: grad norm: 342.147 315.210 133.068
2024-12-01-20:07:59-root-INFO: grad norm: 294.042 268.574 119.702
2024-12-01-20:08:00-root-INFO: grad norm: 267.117 249.794 94.630
2024-12-01-20:08:01-root-INFO: grad norm: 251.835 234.491 91.843
2024-12-01-20:08:02-root-INFO: Loss Change: 5969.929 -> 5798.689
2024-12-01-20:08:02-root-INFO: Regularization Change: 0.000 -> 0.326
2024-12-01-20:08:02-root-INFO: Undo step: 225
2024-12-01-20:08:02-root-INFO: Undo step: 226
2024-12-01-20:08:02-root-INFO: Undo step: 227
2024-12-01-20:08:02-root-INFO: Undo step: 228
2024-12-01-20:08:02-root-INFO: Undo step: 229
2024-12-01-20:08:02-root-INFO: step: 230 lr_xt 0.00033364
2024-12-01-20:08:02-root-INFO: grad norm: 3705.006 2822.448 2400.179
2024-12-01-20:08:03-root-INFO: grad norm: 1564.676 1250.072 941.026
2024-12-01-20:08:04-root-INFO: grad norm: 1070.541 966.382 460.612
2024-12-01-20:08:05-root-INFO: grad norm: 901.192 774.510 460.740
2024-12-01-20:08:06-root-INFO: grad norm: 799.543 732.521 320.441
2024-12-01-20:08:07-root-INFO: Loss Change: 9301.677 -> 6804.606
2024-12-01-20:08:07-root-INFO: Regularization Change: 0.000 -> 2.337
2024-12-01-20:08:07-root-INFO: Learning rate of xt decay: 0.02509 -> 0.02539.
2024-12-01-20:08:07-root-INFO: Coefficient of regularization decay: 0.00012 -> 0.00012.
2024-12-01-20:08:07-root-INFO: step: 229 lr_xt 0.00035047
2024-12-01-20:08:08-root-INFO: grad norm: 648.837 557.839 331.369
2024-12-01-20:08:09-root-INFO: grad norm: 501.189 460.893 196.896
2024-12-01-20:08:10-root-INFO: grad norm: 452.484 407.189 197.331
2024-12-01-20:08:11-root-INFO: grad norm: 416.192 386.112 155.349
2024-12-01-20:08:12-root-INFO: grad norm: 386.730 351.421 161.442
2024-12-01-20:08:12-root-INFO: Loss Change: 6643.098 -> 6362.974
2024-12-01-20:08:12-root-INFO: Regularization Change: 0.000 -> 0.468
2024-12-01-20:08:12-root-INFO: Learning rate of xt decay: 0.02539 -> 0.02569.
2024-12-01-20:08:12-root-INFO: Coefficient of regularization decay: 0.00012 -> 0.00012.
2024-12-01-20:08:13-root-INFO: step: 228 lr_xt 0.00036807
2024-12-01-20:08:13-root-INFO: grad norm: 462.051 413.431 206.314
2024-12-01-20:08:14-root-INFO: grad norm: 386.980 348.319 168.605
2024-12-01-20:08:15-root-INFO: grad norm: 353.138 327.840 131.252
2024-12-01-20:08:16-root-INFO: grad norm: 330.771 303.031 132.598
2024-12-01-20:08:17-root-INFO: grad norm: 315.136 294.908 111.086
2024-12-01-20:08:18-root-INFO: Loss Change: 6325.816 -> 6144.425
2024-12-01-20:08:18-root-INFO: Regularization Change: 0.000 -> 0.323
2024-12-01-20:08:18-root-INFO: Learning rate of xt decay: 0.02569 -> 0.02600.
2024-12-01-20:08:18-root-INFO: Coefficient of regularization decay: 0.00012 -> 0.00012.
2024-12-01-20:08:18-root-INFO: step: 227 lr_xt 0.00038651
2024-12-01-20:08:19-root-INFO: grad norm: 497.696 433.500 244.497
2024-12-01-20:08:20-root-INFO: grad norm: 370.501 338.003 151.741
2024-12-01-20:08:21-root-INFO: grad norm: 332.798 308.734 124.248
2024-12-01-20:08:22-root-INFO: grad norm: 310.635 287.796 116.909
2024-12-01-20:08:23-root-INFO: grad norm: 295.746 277.906 101.161
2024-12-01-20:08:23-root-INFO: Loss Change: 6139.360 -> 5951.184
2024-12-01-20:08:23-root-INFO: Regularization Change: 0.000 -> 0.341
2024-12-01-20:08:23-root-INFO: Learning rate of xt decay: 0.02600 -> 0.02631.
2024-12-01-20:08:23-root-INFO: Coefficient of regularization decay: 0.00012 -> 0.00013.
2024-12-01-20:08:24-root-INFO: step: 226 lr_xt 0.00040579
2024-12-01-20:08:24-root-INFO: grad norm: 346.496 305.345 163.780
2024-12-01-20:08:25-root-INFO: grad norm: 283.820 263.824 104.643
2024-12-01-20:08:26-root-INFO: grad norm: 268.976 252.067 93.862
2024-12-01-20:08:27-root-INFO: grad norm: 262.610 247.292 88.379
2024-12-01-20:08:28-root-INFO: grad norm: 258.161 242.949 87.308
2024-12-01-20:08:29-root-INFO: Loss Change: 5892.121 -> 5743.954
2024-12-01-20:08:29-root-INFO: Regularization Change: 0.000 -> 0.293
2024-12-01-20:08:29-root-INFO: Learning rate of xt decay: 0.02631 -> 0.02663.
2024-12-01-20:08:29-root-INFO: Coefficient of regularization decay: 0.00013 -> 0.00013.
2024-12-01-20:08:29-root-INFO: step: 225 lr_xt 0.00042598
2024-12-01-20:08:29-root-INFO: grad norm: 549.138 476.799 272.424
2024-12-01-20:08:30-root-INFO: grad norm: 398.163 367.263 153.791
2024-12-01-20:08:31-root-INFO: grad norm: 340.294 312.168 135.468
2024-12-01-20:08:32-root-INFO: grad norm: 302.668 282.471 108.709
2024-12-01-20:08:33-root-INFO: grad norm: 278.070 259.737 99.295
2024-12-01-20:08:34-root-INFO: Loss Change: 5719.152 -> 5539.004
2024-12-01-20:08:34-root-INFO: Regularization Change: 0.000 -> 0.344
2024-12-01-20:08:34-root-INFO: Learning rate of xt decay: 0.02663 -> 0.02695.
2024-12-01-20:08:34-root-INFO: Coefficient of regularization decay: 0.00013 -> 0.00013.
2024-12-01-20:08:35-root-INFO: step: 224 lr_xt 0.00044709
2024-12-01-20:08:35-root-INFO: grad norm: 342.909 302.512 161.471
2024-12-01-20:08:36-root-INFO: grad norm: 276.401 257.846 99.566
2024-12-01-20:08:37-root-INFO: grad norm: 256.426 239.445 91.763
2024-12-01-20:08:38-root-INFO: grad norm: 244.012 230.093 81.234
2024-12-01-20:08:39-root-INFO: grad norm: 235.595 222.180 78.365
2024-12-01-20:08:40-root-INFO: Loss Change: 5517.057 -> 5370.074
2024-12-01-20:08:40-root-INFO: Regularization Change: 0.000 -> 0.321
2024-12-01-20:08:40-root-INFO: Learning rate of xt decay: 0.02695 -> 0.02727.
2024-12-01-20:08:40-root-INFO: Coefficient of regularization decay: 0.00013 -> 0.00013.
2024-12-01-20:08:40-root-INFO: step: 223 lr_xt 0.00046917
2024-12-01-20:08:40-root-INFO: grad norm: 390.609 341.759 189.147
2024-12-01-20:08:41-root-INFO: grad norm: 305.038 284.450 110.165
2024-12-01-20:08:42-root-INFO: grad norm: 271.659 250.218 105.780
2024-12-01-20:08:43-root-INFO: grad norm: 249.807 235.166 84.266
2024-12-01-20:08:45-root-INFO: grad norm: 234.999 219.840 83.037
2024-12-01-20:08:45-root-INFO: Loss Change: 5362.136 -> 5217.808
2024-12-01-20:08:45-root-INFO: Regularization Change: 0.000 -> 0.322
2024-12-01-20:08:45-root-INFO: Learning rate of xt decay: 0.02727 -> 0.02760.
2024-12-01-20:08:45-root-INFO: Coefficient of regularization decay: 0.00013 -> 0.00013.
2024-12-01-20:08:46-root-INFO: step: 222 lr_xt 0.00049227
2024-12-01-20:08:46-root-INFO: grad norm: 224.810 211.112 77.275
2024-12-01-20:08:47-root-INFO: grad norm: 214.096 202.757 68.752
2024-12-01-20:08:48-root-INFO: grad norm: 209.679 198.902 66.357
2024-12-01-20:08:49-root-INFO: grad norm: 206.282 195.730 65.131
2024-12-01-20:08:50-root-INFO: grad norm: 203.346 193.035 63.930
2024-12-01-20:08:51-root-INFO: Loss Change: 5147.839 -> 5039.189
2024-12-01-20:08:51-root-INFO: Regularization Change: 0.000 -> 0.268
2024-12-01-20:08:51-root-INFO: Learning rate of xt decay: 0.02760 -> 0.02793.
2024-12-01-20:08:51-root-INFO: Coefficient of regularization decay: 0.00013 -> 0.00013.
2024-12-01-20:08:51-root-INFO: step: 221 lr_xt 0.00051641
2024-12-01-20:08:51-root-INFO: grad norm: 259.896 233.822 113.462
2024-12-01-20:08:53-root-INFO: grad norm: 220.766 209.099 70.819
2024-12-01-20:08:54-root-INFO: grad norm: 207.746 194.600 72.728
2024-12-01-20:08:55-root-INFO: grad norm: 199.654 189.534 62.759
2024-12-01-20:08:56-root-INFO: grad norm: 194.074 183.076 64.404
2024-12-01-20:08:56-root-INFO: Loss Change: 4998.242 -> 4893.909
2024-12-01-20:08:56-root-INFO: Regularization Change: 0.000 -> 0.264
2024-12-01-20:08:56-root-INFO: Learning rate of xt decay: 0.02793 -> 0.02827.
2024-12-01-20:08:56-root-INFO: Coefficient of regularization decay: 0.00013 -> 0.00013.
2024-12-01-20:08:57-root-INFO: step: 220 lr_xt 0.00054166
2024-12-01-20:08:57-root-INFO: grad norm: 398.928 349.935 191.544
2024-12-01-20:08:58-root-INFO: grad norm: 293.590 275.956 100.217
2024-12-01-20:08:59-root-INFO: grad norm: 249.666 229.126 99.170
2024-12-01-20:09:00-root-INFO: grad norm: 221.138 209.620 70.437
2024-12-01-20:09:01-root-INFO: grad norm: 202.931 189.520 72.548
2024-12-01-20:09:02-root-INFO: Loss Change: 4884.221 -> 4753.792
2024-12-01-20:09:02-root-INFO: Regularization Change: 0.000 -> 0.322
2024-12-01-20:09:02-root-INFO: Undo step: 220
2024-12-01-20:09:02-root-INFO: Undo step: 221
2024-12-01-20:09:02-root-INFO: Undo step: 222
2024-12-01-20:09:02-root-INFO: Undo step: 223
2024-12-01-20:09:02-root-INFO: Undo step: 224
2024-12-01-20:09:02-root-INFO: step: 225 lr_xt 0.00042598
2024-12-01-20:09:02-root-INFO: grad norm: 1865.658 1550.047 1038.285
2024-12-01-20:09:03-root-INFO: grad norm: 1460.995 1382.225 473.244
2024-12-01-20:09:04-root-INFO: grad norm: 1274.208 1126.065 596.307
2024-12-01-20:09:05-root-INFO: grad norm: 1102.042 1028.991 394.555
2024-12-01-20:09:07-root-INFO: grad norm: 951.653 846.065 435.682
2024-12-01-20:09:07-root-INFO: Loss Change: 6387.661 -> 5463.550
2024-12-01-20:09:07-root-INFO: Regularization Change: 0.000 -> 1.646
2024-12-01-20:09:07-root-INFO: Learning rate of xt decay: 0.02663 -> 0.02695.
2024-12-01-20:09:07-root-INFO: Coefficient of regularization decay: 0.00013 -> 0.00013.
2024-12-01-20:09:08-root-INFO: step: 224 lr_xt 0.00044709
2024-12-01-20:09:08-root-INFO: grad norm: 978.122 903.840 373.895
2024-12-01-20:09:09-root-INFO: grad norm: 817.249 736.008 355.229
2024-12-01-20:09:10-root-INFO: grad norm: 693.283 640.128 266.229
2024-12-01-20:09:11-root-INFO: grad norm: 588.766 530.518 255.335
2024-12-01-20:09:12-root-INFO: grad norm: 502.245 462.571 195.648
2024-12-01-20:09:13-root-INFO: Loss Change: 5438.188 -> 5185.068
2024-12-01-20:09:13-root-INFO: Regularization Change: 0.000 -> 0.471
2024-12-01-20:09:13-root-INFO: Learning rate of xt decay: 0.02695 -> 0.02727.
2024-12-01-20:09:13-root-INFO: Coefficient of regularization decay: 0.00013 -> 0.00013.
2024-12-01-20:09:13-root-INFO: step: 223 lr_xt 0.00046917
2024-12-01-20:09:13-root-INFO: grad norm: 313.666 285.661 129.553
2024-12-01-20:09:14-root-INFO: grad norm: 239.566 217.260 100.946
2024-12-01-20:09:15-root-INFO: grad norm: 223.244 204.423 89.717
2024-12-01-20:09:16-root-INFO: grad norm: 211.937 195.492 81.854
2024-12-01-20:09:17-root-INFO: grad norm: 203.636 187.921 78.442
2024-12-01-20:09:18-root-INFO: Loss Change: 5139.488 -> 5026.309
2024-12-01-20:09:18-root-INFO: Regularization Change: 0.000 -> 0.256
2024-12-01-20:09:18-root-INFO: Learning rate of xt decay: 0.02727 -> 0.02760.
2024-12-01-20:09:18-root-INFO: Coefficient of regularization decay: 0.00013 -> 0.00013.
2024-12-01-20:09:18-root-INFO: step: 222 lr_xt 0.00049227
2024-12-01-20:09:19-root-INFO: grad norm: 224.885 206.697 88.597
2024-12-01-20:09:20-root-INFO: grad norm: 205.765 190.200 78.506
2024-12-01-20:09:21-root-INFO: grad norm: 196.275 183.192 70.461
2024-12-01-20:09:22-root-INFO: grad norm: 189.819 176.984 68.614
2024-12-01-20:09:23-root-INFO: grad norm: 185.054 173.407 64.613
2024-12-01-20:09:24-root-INFO: Loss Change: 4953.939 -> 4865.829
2024-12-01-20:09:24-root-INFO: Regularization Change: 0.000 -> 0.215
2024-12-01-20:09:24-root-INFO: Learning rate of xt decay: 0.02760 -> 0.02793.
2024-12-01-20:09:24-root-INFO: Coefficient of regularization decay: 0.00013 -> 0.00013.
2024-12-01-20:09:24-root-INFO: step: 221 lr_xt 0.00051641
2024-12-01-20:09:24-root-INFO: grad norm: 213.213 195.618 84.815
2024-12-01-20:09:25-root-INFO: grad norm: 184.882 173.876 62.838
2024-12-01-20:09:26-root-INFO: grad norm: 177.793 166.899 61.277
2024-12-01-20:09:27-root-INFO: grad norm: 173.437 163.801 57.005
2024-12-01-20:09:28-root-INFO: grad norm: 170.388 160.535 57.100
2024-12-01-20:09:29-root-INFO: Loss Change: 4824.639 -> 4745.477
2024-12-01-20:09:29-root-INFO: Regularization Change: 0.000 -> 0.201
2024-12-01-20:09:29-root-INFO: Learning rate of xt decay: 0.02793 -> 0.02827.
2024-12-01-20:09:29-root-INFO: Coefficient of regularization decay: 0.00013 -> 0.00013.
2024-12-01-20:09:29-root-INFO: step: 220 lr_xt 0.00054166
2024-12-01-20:09:30-root-INFO: grad norm: 367.346 328.006 165.394
2024-12-01-20:09:31-root-INFO: grad norm: 262.300 245.022 93.625
2024-12-01-20:09:32-root-INFO: grad norm: 221.260 202.886 88.279
2024-12-01-20:09:33-root-INFO: grad norm: 196.013 184.601 65.907
2024-12-01-20:09:34-root-INFO: grad norm: 180.884 168.188 66.572
2024-12-01-20:09:34-root-INFO: Loss Change: 4736.139 -> 4631.076
2024-12-01-20:09:34-root-INFO: Regularization Change: 0.000 -> 0.255
2024-12-01-20:09:34-root-INFO: Learning rate of xt decay: 0.02827 -> 0.02861.
2024-12-01-20:09:34-root-INFO: Coefficient of regularization decay: 0.00013 -> 0.00013.
2024-12-01-20:09:35-root-INFO: step: 219 lr_xt 0.00056804
2024-12-01-20:09:35-root-INFO: grad norm: 177.270 162.305 71.285
2024-12-01-20:09:36-root-INFO: grad norm: 163.280 152.922 57.231
2024-12-01-20:09:37-root-INFO: grad norm: 160.466 151.141 53.903
2024-12-01-20:09:38-root-INFO: grad norm: 158.518 148.726 54.851
2024-12-01-20:09:39-root-INFO: grad norm: 156.984 147.712 53.152
2024-12-01-20:09:40-root-INFO: Loss Change: 4603.693 -> 4530.520
2024-12-01-20:09:40-root-INFO: Regularization Change: 0.000 -> 0.206
2024-12-01-20:09:40-root-INFO: Learning rate of xt decay: 0.02861 -> 0.02895.
2024-12-01-20:09:40-root-INFO: Coefficient of regularization decay: 0.00013 -> 0.00014.
2024-12-01-20:09:40-root-INFO: step: 218 lr_xt 0.00059561
2024-12-01-20:09:41-root-INFO: grad norm: 263.411 237.530 113.864
2024-12-01-20:09:42-root-INFO: grad norm: 206.444 194.118 70.265
2024-12-01-20:09:43-root-INFO: grad norm: 179.741 165.124 71.000
2024-12-01-20:09:44-root-INFO: grad norm: 165.571 156.011 55.447
2024-12-01-20:09:45-root-INFO: grad norm: 158.034 147.003 58.005
2024-12-01-20:09:45-root-INFO: Loss Change: 4513.959 -> 4430.330
2024-12-01-20:09:45-root-INFO: Regularization Change: 0.000 -> 0.234
2024-12-01-20:09:45-root-INFO: Learning rate of xt decay: 0.02895 -> 0.02930.
2024-12-01-20:09:45-root-INFO: Coefficient of regularization decay: 0.00014 -> 0.00014.
2024-12-01-20:09:46-root-INFO: step: 217 lr_xt 0.00062443
2024-12-01-20:09:46-root-INFO: grad norm: 250.381 216.680 125.461
2024-12-01-20:09:47-root-INFO: grad norm: 184.998 172.276 67.419
2024-12-01-20:09:48-root-INFO: grad norm: 166.906 152.177 68.554
2024-12-01-20:09:49-root-INFO: grad norm: 157.706 147.053 56.978
2024-12-01-20:09:50-root-INFO: grad norm: 152.666 140.951 58.649
2024-12-01-20:09:51-root-INFO: Loss Change: 4421.654 -> 4334.965
2024-12-01-20:09:51-root-INFO: Regularization Change: 0.000 -> 0.255
2024-12-01-20:09:51-root-INFO: Learning rate of xt decay: 0.02930 -> 0.02965.
2024-12-01-20:09:51-root-INFO: Coefficient of regularization decay: 0.00014 -> 0.00014.
2024-12-01-20:09:51-root-INFO: step: 216 lr_xt 0.00065452
2024-12-01-20:09:52-root-INFO: grad norm: 262.782 231.831 123.727
2024-12-01-20:09:53-root-INFO: grad norm: 190.818 175.185 75.640
2024-12-01-20:09:54-root-INFO: grad norm: 169.831 153.694 72.254
2024-12-01-20:09:55-root-INFO: grad norm: 158.689 146.469 61.066
2024-12-01-20:09:56-root-INFO: grad norm: 152.441 139.539 61.376
2024-12-01-20:09:56-root-INFO: Loss Change: 4336.625 -> 4242.617
2024-12-01-20:09:56-root-INFO: Regularization Change: 0.000 -> 0.289
2024-12-01-20:09:56-root-INFO: Learning rate of xt decay: 0.02965 -> 0.03000.
2024-12-01-20:09:56-root-INFO: Coefficient of regularization decay: 0.00014 -> 0.00014.
2024-12-01-20:09:57-root-INFO: step: 215 lr_xt 0.00068596
2024-12-01-20:09:57-root-INFO: grad norm: 150.265 137.362 60.922
2024-12-01-20:09:58-root-INFO: grad norm: 145.418 134.222 55.954
2024-12-01-20:09:59-root-INFO: grad norm: 143.396 132.010 55.996
2024-12-01-20:10:00-root-INFO: grad norm: 141.820 130.891 54.592
2024-12-01-20:10:01-root-INFO: grad norm: 140.504 129.587 54.302
2024-12-01-20:10:02-root-INFO: Loss Change: 4215.362 -> 4144.757
2024-12-01-20:10:02-root-INFO: Regularization Change: 0.000 -> 0.242
2024-12-01-20:10:02-root-INFO: Undo step: 215
2024-12-01-20:10:02-root-INFO: Undo step: 216
2024-12-01-20:10:02-root-INFO: Undo step: 217
2024-12-01-20:10:02-root-INFO: Undo step: 218
2024-12-01-20:10:02-root-INFO: Undo step: 219
2024-12-01-20:10:02-root-INFO: step: 220 lr_xt 0.00054166
2024-12-01-20:10:03-root-INFO: grad norm: 3460.248 2833.417 1986.219
2024-12-01-20:10:04-root-INFO: grad norm: 1851.522 1745.180 618.451
2024-12-01-20:10:05-root-INFO: grad norm: 1636.213 1517.041 613.008
2024-12-01-20:10:06-root-INFO: grad norm: 1373.986 1305.205 429.275
2024-12-01-20:10:07-root-INFO: grad norm: 1126.380 1033.747 447.325
2024-12-01-20:10:07-root-INFO: Loss Change: 8311.168 -> 5005.954
2024-12-01-20:10:07-root-INFO: Regularization Change: 0.000 -> 5.179
2024-12-01-20:10:07-root-INFO: Learning rate of xt decay: 0.02827 -> 0.02861.
2024-12-01-20:10:07-root-INFO: Coefficient of regularization decay: 0.00013 -> 0.00013.
2024-12-01-20:10:08-root-INFO: step: 219 lr_xt 0.00056804
2024-12-01-20:10:08-root-INFO: grad norm: 894.576 838.656 311.324
2024-12-01-20:10:09-root-INFO: grad norm: 679.826 622.784 272.586
2024-12-01-20:10:10-root-INFO: grad norm: 519.090 481.699 193.444
2024-12-01-20:10:11-root-INFO: grad norm: 404.707 369.809 164.405
2024-12-01-20:10:12-root-INFO: grad norm: 326.265 300.141 127.923
2024-12-01-20:10:13-root-INFO: Loss Change: 5000.795 -> 4691.219
2024-12-01-20:10:13-root-INFO: Regularization Change: 0.000 -> 0.686
2024-12-01-20:10:13-root-INFO: Learning rate of xt decay: 0.02861 -> 0.02895.
2024-12-01-20:10:13-root-INFO: Coefficient of regularization decay: 0.00013 -> 0.00014.
2024-12-01-20:10:13-root-INFO: step: 218 lr_xt 0.00059561
2024-12-01-20:10:14-root-INFO: grad norm: 239.085 222.845 86.613
2024-12-01-20:10:15-root-INFO: grad norm: 210.058 191.675 85.936
2024-12-01-20:10:16-root-INFO: grad norm: 201.636 184.724 80.833
2024-12-01-20:10:17-root-INFO: grad norm: 195.575 179.553 77.527
2024-12-01-20:10:18-root-INFO: grad norm: 190.962 175.367 75.583
2024-12-01-20:10:18-root-INFO: Loss Change: 4643.042 -> 4519.198
2024-12-01-20:10:18-root-INFO: Regularization Change: 0.000 -> 0.367
2024-12-01-20:10:18-root-INFO: Learning rate of xt decay: 0.02895 -> 0.02930.
2024-12-01-20:10:18-root-INFO: Coefficient of regularization decay: 0.00014 -> 0.00014.
2024-12-01-20:10:19-root-INFO: step: 217 lr_xt 0.00062443
2024-12-01-20:10:19-root-INFO: grad norm: 290.275 255.685 137.420
2024-12-01-20:10:20-root-INFO: grad norm: 220.072 202.843 85.359
2024-12-01-20:10:21-root-INFO: grad norm: 198.758 180.540 83.127
2024-12-01-20:10:22-root-INFO: grad norm: 186.736 172.325 71.934
2024-12-01-20:10:23-root-INFO: grad norm: 179.436 164.478 71.723
2024-12-01-20:10:24-root-INFO: Loss Change: 4505.505 -> 4384.596
2024-12-01-20:10:24-root-INFO: Regularization Change: 0.000 -> 0.360
2024-12-01-20:10:24-root-INFO: Learning rate of xt decay: 0.02930 -> 0.02965.
2024-12-01-20:10:24-root-INFO: Coefficient of regularization decay: 0.00014 -> 0.00014.
2024-12-01-20:10:24-root-INFO: step: 216 lr_xt 0.00065452
2024-12-01-20:10:25-root-INFO: grad norm: 285.165 255.907 125.819
2024-12-01-20:10:26-root-INFO: grad norm: 210.011 194.581 79.012
2024-12-01-20:10:27-root-INFO: grad norm: 187.882 171.557 76.600
2024-12-01-20:10:28-root-INFO: grad norm: 175.038 162.664 64.642
2024-12-01-20:10:29-root-INFO: grad norm: 167.147 154.119 64.696
2024-12-01-20:10:29-root-INFO: Loss Change: 4365.374 -> 4251.601
2024-12-01-20:10:29-root-INFO: Regularization Change: 0.000 -> 0.352
2024-12-01-20:10:29-root-INFO: Learning rate of xt decay: 0.02965 -> 0.03000.
2024-12-01-20:10:29-root-INFO: Coefficient of regularization decay: 0.00014 -> 0.00014.
2024-12-01-20:10:30-root-INFO: step: 215 lr_xt 0.00068596
2024-12-01-20:10:30-root-INFO: grad norm: 164.974 152.364 63.261
2024-12-01-20:10:31-root-INFO: grad norm: 159.944 147.446 61.982
2024-12-01-20:10:32-root-INFO: grad norm: 157.045 144.690 61.057
2024-12-01-20:10:33-root-INFO: grad norm: 154.629 142.640 59.699
2024-12-01-20:10:34-root-INFO: grad norm: 152.428 140.576 58.928
2024-12-01-20:10:35-root-INFO: Loss Change: 4234.758 -> 4150.260
2024-12-01-20:10:35-root-INFO: Regularization Change: 0.000 -> 0.291
2024-12-01-20:10:35-root-INFO: Learning rate of xt decay: 0.03000 -> 0.03036.
2024-12-01-20:10:35-root-INFO: Coefficient of regularization decay: 0.00014 -> 0.00014.
2024-12-01-20:10:35-root-INFO: step: 214 lr_xt 0.00071879
2024-12-01-20:10:36-root-INFO: grad norm: 215.488 193.465 94.901
2024-12-01-20:10:37-root-INFO: grad norm: 170.300 158.891 61.286
2024-12-01-20:10:38-root-INFO: grad norm: 156.950 143.563 63.427
2024-12-01-20:10:39-root-INFO: grad norm: 149.498 139.471 53.828
2024-12-01-20:10:40-root-INFO: grad norm: 144.833 133.535 56.080
2024-12-01-20:10:40-root-INFO: Loss Change: 4112.794 -> 4027.905
2024-12-01-20:10:40-root-INFO: Regularization Change: 0.000 -> 0.293
2024-12-01-20:10:40-root-INFO: Learning rate of xt decay: 0.03036 -> 0.03073.
2024-12-01-20:10:40-root-INFO: Coefficient of regularization decay: 0.00014 -> 0.00014.
2024-12-01-20:10:41-root-INFO: step: 213 lr_xt 0.00075308
2024-12-01-20:10:41-root-INFO: grad norm: 240.897 212.547 113.379
2024-12-01-20:10:42-root-INFO: grad norm: 176.656 163.633 66.571
2024-12-01-20:10:43-root-INFO: grad norm: 158.461 143.516 67.179
2024-12-01-20:10:44-root-INFO: grad norm: 149.123 138.837 54.423
2024-12-01-20:10:45-root-INFO: grad norm: 143.283 131.414 57.100
2024-12-01-20:10:46-root-INFO: Loss Change: 4027.383 -> 3935.454
2024-12-01-20:10:46-root-INFO: Regularization Change: 0.000 -> 0.327
2024-12-01-20:10:46-root-INFO: Learning rate of xt decay: 0.03073 -> 0.03110.
2024-12-01-20:10:46-root-INFO: Coefficient of regularization decay: 0.00014 -> 0.00014.
2024-12-01-20:10:46-root-INFO: step: 212 lr_xt 0.00078886
2024-12-01-20:10:47-root-INFO: grad norm: 139.781 130.778 49.354
2024-12-01-20:10:48-root-INFO: grad norm: 135.884 125.553 51.971
2024-12-01-20:10:49-root-INFO: grad norm: 133.103 124.523 47.014
2024-12-01-20:10:50-root-INFO: grad norm: 130.798 121.152 49.298
2024-12-01-20:10:51-root-INFO: grad norm: 128.891 120.571 45.559
2024-12-01-20:10:51-root-INFO: Loss Change: 3916.266 -> 3849.224
2024-12-01-20:10:51-root-INFO: Regularization Change: 0.000 -> 0.266
2024-12-01-20:10:51-root-INFO: Learning rate of xt decay: 0.03110 -> 0.03147.
2024-12-01-20:10:51-root-INFO: Coefficient of regularization decay: 0.00014 -> 0.00015.
2024-12-01-20:10:52-root-INFO: step: 211 lr_xt 0.00082622
2024-12-01-20:10:52-root-INFO: grad norm: 245.346 216.289 115.819
2024-12-01-20:10:53-root-INFO: grad norm: 159.796 149.050 57.611
2024-12-01-20:10:54-root-INFO: grad norm: 144.134 132.362 57.052
2024-12-01-20:10:55-root-INFO: grad norm: 139.550 131.444 46.871
2024-12-01-20:10:56-root-INFO: grad norm: 138.260 128.623 50.715
2024-12-01-20:10:57-root-INFO: Loss Change: 3828.039 -> 3743.001
2024-12-01-20:10:57-root-INFO: Regularization Change: 0.000 -> 0.322
2024-12-01-20:10:57-root-INFO: Learning rate of xt decay: 0.03147 -> 0.03185.
2024-12-01-20:10:57-root-INFO: Coefficient of regularization decay: 0.00015 -> 0.00015.
2024-12-01-20:10:57-root-INFO: step: 210 lr_xt 0.00086520
2024-12-01-20:10:57-root-INFO: grad norm: 135.533 123.364 56.129
2024-12-01-20:10:58-root-INFO: grad norm: 124.902 115.634 47.216
2024-12-01-20:10:59-root-INFO: grad norm: 122.832 115.188 42.656
2024-12-01-20:11:01-root-INFO: grad norm: 121.838 113.326 44.741
2024-12-01-20:11:02-root-INFO: grad norm: 121.411 114.509 40.354
2024-12-01-20:11:02-root-INFO: Loss Change: 3732.883 -> 3671.101
2024-12-01-20:11:02-root-INFO: Regularization Change: 0.000 -> 0.268
2024-12-01-20:11:02-root-INFO: Undo step: 210
2024-12-01-20:11:02-root-INFO: Undo step: 211
2024-12-01-20:11:02-root-INFO: Undo step: 212
2024-12-01-20:11:02-root-INFO: Undo step: 213
2024-12-01-20:11:02-root-INFO: Undo step: 214
2024-12-01-20:11:03-root-INFO: step: 215 lr_xt 0.00068596
2024-12-01-20:11:03-root-INFO: grad norm: 2670.125 2297.083 1361.240
2024-12-01-20:11:04-root-INFO: grad norm: 1577.450 1479.638 546.826
2024-12-01-20:11:05-root-INFO: grad norm: 879.359 816.898 325.500
2024-12-01-20:11:06-root-INFO: grad norm: 623.899 581.965 224.872
2024-12-01-20:11:07-root-INFO: grad norm: 443.053 409.200 169.857
2024-12-01-20:11:08-root-INFO: Loss Change: 6077.451 -> 4175.692
2024-12-01-20:11:08-root-INFO: Regularization Change: 0.000 -> 3.475
2024-12-01-20:11:08-root-INFO: Learning rate of xt decay: 0.03000 -> 0.03036.
2024-12-01-20:11:08-root-INFO: Coefficient of regularization decay: 0.00014 -> 0.00014.
2024-12-01-20:11:08-root-INFO: step: 214 lr_xt 0.00071879
2024-12-01-20:11:08-root-INFO: grad norm: 423.571 393.336 157.160
2024-12-01-20:11:09-root-INFO: grad norm: 297.839 275.565 113.013
2024-12-01-20:11:10-root-INFO: grad norm: 236.034 217.400 91.921
2024-12-01-20:11:12-root-INFO: grad norm: 201.235 184.152 81.138
2024-12-01-20:11:13-root-INFO: grad norm: 181.852 166.103 74.026
2024-12-01-20:11:13-root-INFO: Loss Change: 4140.907 -> 3978.910
2024-12-01-20:11:13-root-INFO: Regularization Change: 0.000 -> 0.512
2024-12-01-20:11:13-root-INFO: Learning rate of xt decay: 0.03036 -> 0.03073.
2024-12-01-20:11:13-root-INFO: Coefficient of regularization decay: 0.00014 -> 0.00014.
2024-12-01-20:11:14-root-INFO: step: 213 lr_xt 0.00075308
2024-12-01-20:11:14-root-INFO: grad norm: 230.846 206.034 104.114
2024-12-01-20:11:15-root-INFO: grad norm: 182.140 164.365 78.479
2024-12-01-20:11:16-root-INFO: grad norm: 164.628 148.016 72.066
2024-12-01-20:11:17-root-INFO: grad norm: 154.546 139.919 65.631
2024-12-01-20:11:18-root-INFO: grad norm: 148.013 134.229 62.373
2024-12-01-20:11:19-root-INFO: Loss Change: 3959.955 -> 3858.806
2024-12-01-20:11:19-root-INFO: Regularization Change: 0.000 -> 0.368
2024-12-01-20:11:19-root-INFO: Learning rate of xt decay: 0.03073 -> 0.03110.
2024-12-01-20:11:19-root-INFO: Coefficient of regularization decay: 0.00014 -> 0.00014.
2024-12-01-20:11:19-root-INFO: step: 212 lr_xt 0.00078886
2024-12-01-20:11:19-root-INFO: grad norm: 144.833 131.618 60.443
2024-12-01-20:11:21-root-INFO: grad norm: 139.656 127.667 56.612
2024-12-01-20:11:22-root-INFO: grad norm: 136.451 124.796 55.180
2024-12-01-20:11:23-root-INFO: grad norm: 133.672 122.436 53.644
2024-12-01-20:11:24-root-INFO: grad norm: 131.167 120.245 52.402
2024-12-01-20:11:24-root-INFO: Loss Change: 3838.976 -> 3765.741
2024-12-01-20:11:24-root-INFO: Regularization Change: 0.000 -> 0.290
2024-12-01-20:11:24-root-INFO: Learning rate of xt decay: 0.03110 -> 0.03147.
2024-12-01-20:11:24-root-INFO: Coefficient of regularization decay: 0.00014 -> 0.00015.
2024-12-01-20:11:25-root-INFO: step: 211 lr_xt 0.00082622
2024-12-01-20:11:25-root-INFO: grad norm: 242.707 213.307 115.787
2024-12-01-20:11:26-root-INFO: grad norm: 161.202 146.607 67.025
2024-12-01-20:11:27-root-INFO: grad norm: 139.332 125.828 59.839
2024-12-01-20:11:28-root-INFO: grad norm: 130.062 119.078 52.311
2024-12-01-20:11:29-root-INFO: grad norm: 125.471 114.925 50.349
2024-12-01-20:11:30-root-INFO: Loss Change: 3748.692 -> 3660.672
2024-12-01-20:11:30-root-INFO: Regularization Change: 0.000 -> 0.333
2024-12-01-20:11:30-root-INFO: Learning rate of xt decay: 0.03147 -> 0.03185.
2024-12-01-20:11:30-root-INFO: Coefficient of regularization decay: 0.00015 -> 0.00015.
2024-12-01-20:11:30-root-INFO: step: 210 lr_xt 0.00086520
2024-12-01-20:11:30-root-INFO: grad norm: 136.921 123.413 59.301
2024-12-01-20:11:31-root-INFO: grad norm: 123.555 114.389 46.703
2024-12-01-20:11:32-root-INFO: grad norm: 119.185 109.671 46.661
2024-12-01-20:11:33-root-INFO: grad norm: 116.745 108.013 44.302
2024-12-01-20:11:34-root-INFO: grad norm: 115.054 106.331 43.945
2024-12-01-20:11:35-root-INFO: Loss Change: 3646.937 -> 3585.535
2024-12-01-20:11:35-root-INFO: Regularization Change: 0.000 -> 0.263
2024-12-01-20:11:35-root-INFO: Learning rate of xt decay: 0.03185 -> 0.03223.
2024-12-01-20:11:35-root-INFO: Coefficient of regularization decay: 0.00015 -> 0.00015.
2024-12-01-20:11:35-root-INFO: step: 209 lr_xt 0.00090588
2024-12-01-20:11:36-root-INFO: grad norm: 157.587 140.510 71.348
2024-12-01-20:11:37-root-INFO: grad norm: 122.445 112.002 49.481
2024-12-01-20:11:38-root-INFO: grad norm: 115.485 106.037 45.749
2024-12-01-20:11:39-root-INFO: grad norm: 112.523 103.967 43.040
2024-12-01-20:11:40-root-INFO: grad norm: 110.621 102.468 41.680
2024-12-01-20:11:41-root-INFO: Loss Change: 3563.692 -> 3499.259
2024-12-01-20:11:41-root-INFO: Regularization Change: 0.000 -> 0.282
2024-12-01-20:11:41-root-INFO: Learning rate of xt decay: 0.03223 -> 0.03262.
2024-12-01-20:11:41-root-INFO: Coefficient of regularization decay: 0.00015 -> 0.00015.
2024-12-01-20:11:41-root-INFO: step: 208 lr_xt 0.00094831
2024-12-01-20:11:41-root-INFO: grad norm: 160.373 141.351 75.760
2024-12-01-20:11:42-root-INFO: grad norm: 122.620 112.521 48.729
2024-12-01-20:11:43-root-INFO: grad norm: 113.160 104.084 44.404
2024-12-01-20:11:44-root-INFO: grad norm: 109.316 101.438 40.746
2024-12-01-20:11:45-root-INFO: grad norm: 107.261 99.693 39.577
2024-12-01-20:11:46-root-INFO: Loss Change: 3491.300 -> 3425.727
2024-12-01-20:11:46-root-INFO: Regularization Change: 0.000 -> 0.299
2024-12-01-20:11:46-root-INFO: Learning rate of xt decay: 0.03262 -> 0.03301.
2024-12-01-20:11:46-root-INFO: Coefficient of regularization decay: 0.00015 -> 0.00015.
2024-12-01-20:11:46-root-INFO: step: 207 lr_xt 0.00100094
2024-12-01-20:11:47-root-INFO: grad norm: 125.385 113.951 52.312
2024-12-01-20:11:48-root-INFO: grad norm: 109.387 101.153 41.637
2024-12-01-20:11:49-root-INFO: grad norm: 106.514 99.151 38.912
2024-12-01-20:11:50-root-INFO: grad norm: 104.898 97.483 38.740
2024-12-01-20:11:51-root-INFO: grad norm: 103.637 96.815 36.980
2024-12-01-20:11:52-root-INFO: Loss Change: 3400.593 -> 3343.192
2024-12-01-20:11:52-root-INFO: Regularization Change: 0.000 -> 0.283
2024-12-01-20:11:52-root-INFO: Learning rate of xt decay: 0.03301 -> 0.03340.
2024-12-01-20:11:52-root-INFO: Coefficient of regularization decay: 0.00015 -> 0.00015.
2024-12-01-20:11:52-root-INFO: step: 206 lr_xt 0.00104745
2024-12-01-20:11:52-root-INFO: grad norm: 125.296 113.908 52.192
2024-12-01-20:11:53-root-INFO: grad norm: 106.395 98.811 39.451
2024-12-01-20:11:54-root-INFO: grad norm: 102.924 95.960 37.215
2024-12-01-20:11:55-root-INFO: grad norm: 101.365 94.595 36.422
2024-12-01-20:11:56-root-INFO: grad norm: 100.330 94.016 35.031
2024-12-01-20:11:57-root-INFO: Loss Change: 3317.417 -> 3260.262
2024-12-01-20:11:57-root-INFO: Regularization Change: 0.000 -> 0.294
2024-12-01-20:11:57-root-INFO: Learning rate of xt decay: 0.03340 -> 0.03380.
2024-12-01-20:11:57-root-INFO: Coefficient of regularization decay: 0.00015 -> 0.00015.
2024-12-01-20:11:57-root-INFO: step: 205 lr_xt 0.00109594
2024-12-01-20:11:58-root-INFO: grad norm: 128.421 115.544 56.050
2024-12-01-20:11:59-root-INFO: grad norm: 104.264 96.844 38.629
2024-12-01-20:12:00-root-INFO: grad norm: 100.650 94.068 35.800
2024-12-01-20:12:01-root-INFO: grad norm: 99.429 92.990 35.200
2024-12-01-20:12:02-root-INFO: grad norm: 99.072 93.258 33.439
2024-12-01-20:12:03-root-INFO: Loss Change: 3245.280 -> 3187.677
2024-12-01-20:12:03-root-INFO: Regularization Change: 0.000 -> 0.308
2024-12-01-20:12:03-root-INFO: Undo step: 205
2024-12-01-20:12:03-root-INFO: Undo step: 206
2024-12-01-20:12:03-root-INFO: Undo step: 207
2024-12-01-20:12:03-root-INFO: Undo step: 208
2024-12-01-20:12:03-root-INFO: Undo step: 209
2024-12-01-20:12:03-root-INFO: step: 210 lr_xt 0.00086520
2024-12-01-20:12:03-root-INFO: grad norm: 2778.842 2413.227 1377.787
2024-12-01-20:12:04-root-INFO: grad norm: 1360.303 1288.024 437.513
2024-12-01-20:12:05-root-INFO: grad norm: 1068.622 991.481 398.647
2024-12-01-20:12:06-root-INFO: grad norm: 816.202 775.227 255.361
2024-12-01-20:12:08-root-INFO: grad norm: 563.046 532.321 183.453
2024-12-01-20:12:08-root-INFO: Loss Change: 6961.013 -> 3652.612
2024-12-01-20:12:08-root-INFO: Regularization Change: 0.000 -> 7.203
2024-12-01-20:12:08-root-INFO: Learning rate of xt decay: 0.03185 -> 0.03223.
2024-12-01-20:12:08-root-INFO: Coefficient of regularization decay: 0.00015 -> 0.00015.
2024-12-01-20:12:09-root-INFO: step: 209 lr_xt 0.00090588
2024-12-01-20:12:09-root-INFO: grad norm: 453.966 422.032 167.254
2024-12-01-20:12:10-root-INFO: grad norm: 316.681 301.105 98.096
2024-12-01-20:12:11-root-INFO: grad norm: 242.301 222.909 94.979
2024-12-01-20:12:12-root-INFO: grad norm: 198.387 186.091 68.756
2024-12-01-20:12:13-root-INFO: grad norm: 172.879 157.780 70.658
2024-12-01-20:12:14-root-INFO: Loss Change: 3639.897 -> 3466.956
2024-12-01-20:12:14-root-INFO: Regularization Change: 0.000 -> 0.643
2024-12-01-20:12:14-root-INFO: Learning rate of xt decay: 0.03223 -> 0.03262.
2024-12-01-20:12:14-root-INFO: Coefficient of regularization decay: 0.00015 -> 0.00015.
2024-12-01-20:12:14-root-INFO: step: 208 lr_xt 0.00094831
2024-12-01-20:12:14-root-INFO: grad norm: 174.886 158.461 73.995
2024-12-01-20:12:15-root-INFO: grad norm: 148.640 136.087 59.784
2024-12-01-20:12:16-root-INFO: grad norm: 139.318 128.229 54.469
2024-12-01-20:12:17-root-INFO: grad norm: 133.446 122.775 52.289
2024-12-01-20:12:18-root-INFO: grad norm: 129.000 119.072 49.628
2024-12-01-20:12:19-root-INFO: Loss Change: 3457.640 -> 3361.958
2024-12-01-20:12:19-root-INFO: Regularization Change: 0.000 -> 0.450
2024-12-01-20:12:19-root-INFO: Learning rate of xt decay: 0.03262 -> 0.03301.
2024-12-01-20:12:19-root-INFO: Coefficient of regularization decay: 0.00015 -> 0.00015.
2024-12-01-20:12:20-root-INFO: step: 207 lr_xt 0.00100094
2024-12-01-20:12:20-root-INFO: grad norm: 147.073 134.080 60.439
2024-12-01-20:12:21-root-INFO: grad norm: 128.043 118.152 49.346
2024-12-01-20:12:22-root-INFO: grad norm: 122.598 113.147 47.204
2024-12-01-20:12:23-root-INFO: grad norm: 118.979 110.191 44.877
2024-12-01-20:12:24-root-INFO: grad norm: 116.054 107.471 43.801
2024-12-01-20:12:25-root-INFO: Loss Change: 3342.525 -> 3265.642
2024-12-01-20:12:25-root-INFO: Regularization Change: 0.000 -> 0.382
2024-12-01-20:12:25-root-INFO: Learning rate of xt decay: 0.03301 -> 0.03340.
2024-12-01-20:12:25-root-INFO: Coefficient of regularization decay: 0.00015 -> 0.00015.
2024-12-01-20:12:25-root-INFO: step: 206 lr_xt 0.00104745
2024-12-01-20:12:25-root-INFO: grad norm: 134.239 123.896 51.673
2024-12-01-20:12:26-root-INFO: grad norm: 115.306 107.201 42.468
2024-12-01-20:12:27-root-INFO: grad norm: 110.160 103.259 38.376
2024-12-01-20:12:29-root-INFO: grad norm: 107.474 100.395 38.361
2024-12-01-20:12:30-root-INFO: grad norm: 105.489 99.209 35.854
2024-12-01-20:12:30-root-INFO: Loss Change: 3236.584 -> 3171.799
2024-12-01-20:12:30-root-INFO: Regularization Change: 0.000 -> 0.335
2024-12-01-20:12:30-root-INFO: Learning rate of xt decay: 0.03340 -> 0.03380.
2024-12-01-20:12:30-root-INFO: Coefficient of regularization decay: 0.00015 -> 0.00015.
2024-12-01-20:12:31-root-INFO: step: 205 lr_xt 0.00109594
2024-12-01-20:12:31-root-INFO: grad norm: 133.469 121.868 54.426
2024-12-01-20:12:32-root-INFO: grad norm: 109.370 102.101 39.205
2024-12-01-20:12:33-root-INFO: grad norm: 104.675 98.957 34.125
2024-12-01-20:12:34-root-INFO: grad norm: 103.544 97.111 35.926
2024-12-01-20:12:35-root-INFO: grad norm: 103.978 98.969 31.886
2024-12-01-20:12:36-root-INFO: Loss Change: 3154.476 -> 3094.915
2024-12-01-20:12:36-root-INFO: Regularization Change: 0.000 -> 0.321
2024-12-01-20:12:36-root-INFO: Learning rate of xt decay: 0.03380 -> 0.03421.
2024-12-01-20:12:36-root-INFO: Coefficient of regularization decay: 0.00015 -> 0.00016.
2024-12-01-20:12:36-root-INFO: step: 204 lr_xt 0.00114648
2024-12-01-20:12:36-root-INFO: grad norm: 138.609 125.442 58.963
2024-12-01-20:12:37-root-INFO: grad norm: 109.007 102.922 35.911
2024-12-01-20:12:38-root-INFO: grad norm: 103.136 96.965 35.139
2024-12-01-20:12:39-root-INFO: grad norm: 103.546 98.681 31.368
2024-12-01-20:12:40-root-INFO: grad norm: 108.503 102.210 36.415
2024-12-01-20:12:41-root-INFO: Loss Change: 3081.700 -> 3021.026
2024-12-01-20:12:41-root-INFO: Regularization Change: 0.000 -> 0.344
2024-12-01-20:12:41-root-INFO: Learning rate of xt decay: 0.03421 -> 0.03462.
2024-12-01-20:12:41-root-INFO: Coefficient of regularization decay: 0.00016 -> 0.00016.
2024-12-01-20:12:41-root-INFO: step: 203 lr_xt 0.00119917
2024-12-01-20:12:42-root-INFO: grad norm: 162.334 153.910 51.614
2024-12-01-20:12:43-root-INFO: grad norm: 211.172 199.470 69.321
2024-12-01-20:12:43-root-INFO: Loss too large (3001.364->3001.470)! Learning rate decreased to 0.00096.
2024-12-01-20:12:44-root-INFO: grad norm: 210.133 201.181 60.681
2024-12-01-20:12:45-root-INFO: grad norm: 210.429 199.288 67.565
2024-12-01-20:12:46-root-INFO: grad norm: 211.942 202.878 61.321
2024-12-01-20:12:47-root-INFO: Loss Change: 3007.975 -> 2969.205
2024-12-01-20:12:47-root-INFO: Regularization Change: 0.000 -> 0.243
2024-12-01-20:12:47-root-INFO: Learning rate of xt decay: 0.03462 -> 0.03504.
2024-12-01-20:12:47-root-INFO: Coefficient of regularization decay: 0.00016 -> 0.00016.
2024-12-01-20:12:47-root-INFO: step: 202 lr_xt 0.00125407
2024-12-01-20:12:48-root-INFO: grad norm: 190.998 178.393 68.235
2024-12-01-20:12:49-root-INFO: grad norm: 200.349 190.090 63.289
2024-12-01-20:12:50-root-INFO: grad norm: 296.173 282.087 90.253
2024-12-01-20:12:50-root-INFO: Loss too large (2929.128->2950.604)! Learning rate decreased to 0.00100.
2024-12-01-20:12:51-root-INFO: grad norm: 331.620 315.786 101.247
2024-12-01-20:12:52-root-INFO: grad norm: 368.143 350.102 113.831
2024-12-01-20:12:53-root-INFO: Loss Change: 2950.339 -> 2921.948
2024-12-01-20:12:53-root-INFO: Regularization Change: 0.000 -> 0.379
2024-12-01-20:12:53-root-INFO: Learning rate of xt decay: 0.03504 -> 0.03546.
2024-12-01-20:12:53-root-INFO: Coefficient of regularization decay: 0.00016 -> 0.00016.
2024-12-01-20:12:53-root-INFO: step: 201 lr_xt 0.00131127
2024-12-01-20:12:53-root-INFO: grad norm: 386.558 367.836 118.843
2024-12-01-20:12:54-root-INFO: Loss too large (2917.006->2962.040)! Learning rate decreased to 0.00105.
2024-12-01-20:12:55-root-INFO: grad norm: 417.593 395.892 132.865
2024-12-01-20:12:56-root-INFO: grad norm: 443.600 422.309 135.779
2024-12-01-20:12:57-root-INFO: grad norm: 457.947 434.381 145.014
2024-12-01-20:12:58-root-INFO: grad norm: 460.268 437.721 142.292
2024-12-01-20:12:58-root-INFO: Loss Change: 2917.006 -> 2893.776
2024-12-01-20:12:58-root-INFO: Regularization Change: 0.000 -> 0.411
2024-12-01-20:12:58-root-INFO: Learning rate of xt decay: 0.03546 -> 0.03588.
2024-12-01-20:12:59-root-INFO: Coefficient of regularization decay: 0.00016 -> 0.00016.
2024-12-01-20:12:59-root-INFO: step: 200 lr_xt 0.00137086
2024-12-01-20:12:59-root-INFO: grad norm: 368.979 352.586 108.761
2024-12-01-20:13:00-root-INFO: Loss too large (2856.436->2883.847)! Learning rate decreased to 0.00110.
2024-12-01-20:13:01-root-INFO: grad norm: 372.477 350.545 125.925
2024-12-01-20:13:02-root-INFO: grad norm: 382.217 362.440 121.356
2024-12-01-20:13:03-root-INFO: grad norm: 394.304 373.190 127.300
2024-12-01-20:13:04-root-INFO: grad norm: 403.871 382.675 129.120
2024-12-01-20:13:04-root-INFO: Loss Change: 2856.436 -> 2816.652
2024-12-01-20:13:04-root-INFO: Regularization Change: 0.000 -> 0.436
2024-12-01-20:13:04-root-INFO: Undo step: 200
2024-12-01-20:13:04-root-INFO: Undo step: 201
2024-12-01-20:13:04-root-INFO: Undo step: 202
2024-12-01-20:13:04-root-INFO: Undo step: 203
2024-12-01-20:13:04-root-INFO: Undo step: 204
2024-12-01-20:13:05-root-INFO: step: 205 lr_xt 0.00109594
2024-12-01-20:13:05-root-INFO: grad norm: 1204.982 983.920 695.617
2024-12-01-20:13:06-root-INFO: grad norm: 461.574 397.391 234.800
2024-12-01-20:13:07-root-INFO: grad norm: 325.772 293.487 141.395
2024-12-01-20:13:08-root-INFO: grad norm: 287.124 256.833 128.361
2024-12-01-20:13:09-root-INFO: grad norm: 290.479 277.093 87.163
2024-12-01-20:13:10-root-INFO: Loss Change: 4659.047 -> 3301.932
2024-12-01-20:13:10-root-INFO: Regularization Change: 0.000 -> 5.303
2024-12-01-20:13:10-root-INFO: Learning rate of xt decay: 0.03380 -> 0.03421.
2024-12-01-20:13:10-root-INFO: Coefficient of regularization decay: 0.00015 -> 0.00016.
2024-12-01-20:13:10-root-INFO: step: 204 lr_xt 0.00114648
2024-12-01-20:13:10-root-INFO: grad norm: 282.267 267.882 88.961
2024-12-01-20:13:11-root-INFO: grad norm: 319.869 309.855 79.412
2024-12-01-20:13:12-root-INFO: grad norm: 406.904 392.445 107.506
2024-12-01-20:13:13-root-INFO: Loss too large (3207.070->3209.745)! Learning rate decreased to 0.00092.
2024-12-01-20:13:14-root-INFO: grad norm: 371.972 362.057 85.313
2024-12-01-20:13:15-root-INFO: grad norm: 339.130 327.380 88.495
2024-12-01-20:13:15-root-INFO: Loss Change: 3259.928 -> 3128.774
2024-12-01-20:13:15-root-INFO: Regularization Change: 0.000 -> 0.765
2024-12-01-20:13:15-root-INFO: Learning rate of xt decay: 0.03421 -> 0.03462.
2024-12-01-20:13:15-root-INFO: Coefficient of regularization decay: 0.00016 -> 0.00016.
2024-12-01-20:13:16-root-INFO: step: 203 lr_xt 0.00119917
2024-12-01-20:13:16-root-INFO: grad norm: 318.476 309.530 74.957
2024-12-01-20:13:17-root-INFO: grad norm: 435.846 423.463 103.155
2024-12-01-20:13:17-root-INFO: Loss too large (3104.601->3130.975)! Learning rate decreased to 0.00096.
2024-12-01-20:13:18-root-INFO: grad norm: 417.907 408.068 90.150
2024-12-01-20:13:20-root-INFO: grad norm: 400.322 388.995 94.551
2024-12-01-20:13:21-root-INFO: grad norm: 388.732 379.507 84.185
2024-12-01-20:13:21-root-INFO: Loss Change: 3108.913 -> 3030.463
2024-12-01-20:13:21-root-INFO: Regularization Change: 0.000 -> 0.542
2024-12-01-20:13:21-root-INFO: Learning rate of xt decay: 0.03462 -> 0.03504.
2024-12-01-20:13:21-root-INFO: Coefficient of regularization decay: 0.00016 -> 0.00016.
2024-12-01-20:13:22-root-INFO: step: 202 lr_xt 0.00125407
2024-12-01-20:13:22-root-INFO: grad norm: 440.899 421.512 129.305
2024-12-01-20:13:22-root-INFO: Loss too large (3017.576->3046.089)! Learning rate decreased to 0.00100.
2024-12-01-20:13:23-root-INFO: grad norm: 436.978 426.723 94.113
2024-12-01-20:13:24-root-INFO: grad norm: 455.145 442.182 107.850
2024-12-01-20:13:25-root-INFO: grad norm: 478.798 468.299 99.716
2024-12-01-20:13:26-root-INFO: grad norm: 507.242 493.908 115.540
2024-12-01-20:13:27-root-INFO: Loss Change: 3017.576 -> 2967.133
2024-12-01-20:13:27-root-INFO: Regularization Change: 0.000 -> 0.594
2024-12-01-20:13:27-root-INFO: Learning rate of xt decay: 0.03504 -> 0.03546.
2024-12-01-20:13:27-root-INFO: Coefficient of regularization decay: 0.00016 -> 0.00016.
2024-12-01-20:13:27-root-INFO: step: 201 lr_xt 0.00131127
2024-12-01-20:13:28-root-INFO: grad norm: 549.623 538.048 112.204
2024-12-01-20:13:28-root-INFO: Loss too large (2972.207->3049.559)! Learning rate decreased to 0.00105.
2024-12-01-20:13:29-root-INFO: grad norm: 561.385 547.347 124.758
2024-12-01-20:13:30-root-INFO: grad norm: 558.064 545.872 116.015
2024-12-01-20:13:31-root-INFO: grad norm: 541.165 527.409 121.242
2024-12-01-20:13:32-root-INFO: grad norm: 519.085 507.547 108.835
2024-12-01-20:13:33-root-INFO: Loss Change: 2972.207 -> 2896.662
2024-12-01-20:13:33-root-INFO: Regularization Change: 0.000 -> 0.610
2024-12-01-20:13:33-root-INFO: Learning rate of xt decay: 0.03546 -> 0.03588.
2024-12-01-20:13:33-root-INFO: Coefficient of regularization decay: 0.00016 -> 0.00016.
2024-12-01-20:13:33-root-INFO: step: 200 lr_xt 0.00137086
2024-12-01-20:13:34-root-INFO: grad norm: 579.815 559.377 152.585
2024-12-01-20:13:34-root-INFO: Loss too large (2894.620->2974.495)! Learning rate decreased to 0.00110.
2024-12-01-20:13:35-root-INFO: grad norm: 551.082 539.456 112.602
2024-12-01-20:13:36-root-INFO: grad norm: 524.227 509.831 122.011
2024-12-01-20:13:37-root-INFO: grad norm: 501.183 490.234 104.188
2024-12-01-20:13:38-root-INFO: grad norm: 479.848 467.110 109.831
2024-12-01-20:13:39-root-INFO: Loss Change: 2894.620 -> 2806.215
2024-12-01-20:13:39-root-INFO: Regularization Change: 0.000 -> 0.652
2024-12-01-20:13:39-root-INFO: Learning rate of xt decay: 0.03588 -> 0.03631.
2024-12-01-20:13:39-root-INFO: Coefficient of regularization decay: 0.00016 -> 0.00016.
2024-12-01-20:13:39-root-INFO: step: 199 lr_xt 0.00143293
2024-12-01-20:13:39-root-INFO: grad norm: 435.106 426.433 86.440
2024-12-01-20:13:40-root-INFO: Loss too large (2782.236->2824.874)! Learning rate decreased to 0.00115.
2024-12-01-20:13:41-root-INFO: grad norm: 435.950 423.605 103.010
2024-12-01-20:13:42-root-INFO: grad norm: 447.508 437.754 92.922
2024-12-01-20:13:43-root-INFO: grad norm: 467.389 455.266 105.761
2024-12-01-20:13:44-root-INFO: grad norm: 486.429 475.906 100.628
2024-12-01-20:13:44-root-INFO: Loss Change: 2782.236 -> 2740.205
2024-12-01-20:13:44-root-INFO: Regularization Change: 0.000 -> 0.583
2024-12-01-20:13:44-root-INFO: Learning rate of xt decay: 0.03631 -> 0.03675.
2024-12-01-20:13:44-root-INFO: Coefficient of regularization decay: 0.00016 -> 0.00017.
2024-12-01-20:13:45-root-INFO: step: 198 lr_xt 0.00149757
2024-12-01-20:13:45-root-INFO: grad norm: 574.559 555.008 148.608
2024-12-01-20:13:45-root-INFO: Loss too large (2749.462->2865.793)! Learning rate decreased to 0.00120.
2024-12-01-20:13:46-root-INFO: Loss too large (2749.462->2753.399)! Learning rate decreased to 0.00096.
2024-12-01-20:13:47-root-INFO: grad norm: 398.033 389.508 81.936
2024-12-01-20:13:48-root-INFO: grad norm: 288.605 279.957 70.121
2024-12-01-20:13:49-root-INFO: grad norm: 232.933 226.965 52.390
2024-12-01-20:13:50-root-INFO: grad norm: 198.602 192.635 48.318
2024-12-01-20:13:51-root-INFO: Loss Change: 2749.462 -> 2613.549
2024-12-01-20:13:51-root-INFO: Regularization Change: 0.000 -> 0.384
2024-12-01-20:13:51-root-INFO: Learning rate of xt decay: 0.03675 -> 0.03719.
2024-12-01-20:13:51-root-INFO: Coefficient of regularization decay: 0.00017 -> 0.00017.
2024-12-01-20:13:51-root-INFO: step: 197 lr_xt 0.00156486
2024-12-01-20:13:51-root-INFO: grad norm: 132.713 127.260 37.650
2024-12-01-20:13:52-root-INFO: grad norm: 184.116 178.543 44.959
2024-12-01-20:13:53-root-INFO: Loss too large (2573.861->2583.101)! Learning rate decreased to 0.00125.
2024-12-01-20:13:54-root-INFO: grad norm: 261.492 255.692 54.771
2024-12-01-20:13:54-root-INFO: Loss too large (2571.265->2583.175)! Learning rate decreased to 0.00100.
2024-12-01-20:13:55-root-INFO: grad norm: 282.891 276.032 61.917
2024-12-01-20:13:56-root-INFO: grad norm: 312.174 305.714 63.178
2024-12-01-20:13:57-root-INFO: Loss Change: 2586.557 -> 2558.576
2024-12-01-20:13:57-root-INFO: Regularization Change: 0.000 -> 0.339
2024-12-01-20:13:57-root-INFO: Learning rate of xt decay: 0.03719 -> 0.03764.
2024-12-01-20:13:57-root-INFO: Coefficient of regularization decay: 0.00017 -> 0.00017.
2024-12-01-20:13:57-root-INFO: step: 196 lr_xt 0.00163492
2024-12-01-20:13:57-root-INFO: grad norm: 436.802 422.497 110.871
2024-12-01-20:13:58-root-INFO: Loss too large (2559.340->2730.681)! Learning rate decreased to 0.00131.
2024-12-01-20:13:58-root-INFO: Loss too large (2559.340->2627.496)! Learning rate decreased to 0.00105.
2024-12-01-20:13:58-root-INFO: Loss too large (2559.340->2565.899)! Learning rate decreased to 0.00084.
2024-12-01-20:13:59-root-INFO: grad norm: 339.665 333.628 63.759
2024-12-01-20:14:00-root-INFO: grad norm: 274.034 266.423 64.135
2024-12-01-20:14:01-root-INFO: grad norm: 234.204 229.160 48.347
2024-12-01-20:14:02-root-INFO: grad norm: 206.636 201.044 47.746
2024-12-01-20:14:03-root-INFO: Loss Change: 2559.340 -> 2483.547
2024-12-01-20:14:03-root-INFO: Regularization Change: 0.000 -> 0.233
2024-12-01-20:14:03-root-INFO: Learning rate of xt decay: 0.03764 -> 0.03809.
2024-12-01-20:14:03-root-INFO: Coefficient of regularization decay: 0.00017 -> 0.00017.
2024-12-01-20:14:03-root-INFO: step: 195 lr_xt 0.00170783
2024-12-01-20:14:04-root-INFO: grad norm: 154.822 149.949 38.537
2024-12-01-20:14:04-root-INFO: Loss too large (2466.839->2475.218)! Learning rate decreased to 0.00137.
2024-12-01-20:14:05-root-INFO: grad norm: 269.005 262.939 56.805
2024-12-01-20:14:06-root-INFO: Loss too large (2465.395->2503.023)! Learning rate decreased to 0.00109.
2024-12-01-20:14:06-root-INFO: Loss too large (2465.395->2474.325)! Learning rate decreased to 0.00087.
2024-12-01-20:14:07-root-INFO: grad norm: 266.616 261.199 53.474
2024-12-01-20:14:08-root-INFO: grad norm: 269.923 264.086 55.830
2024-12-01-20:14:09-root-INFO: grad norm: 278.100 272.606 55.002
2024-12-01-20:14:10-root-INFO: Loss Change: 2466.839 -> 2440.951
2024-12-01-20:14:10-root-INFO: Regularization Change: 0.000 -> 0.214
2024-12-01-20:14:10-root-INFO: Undo step: 195
2024-12-01-20:14:10-root-INFO: Undo step: 196
2024-12-01-20:14:10-root-INFO: Undo step: 197
2024-12-01-20:14:10-root-INFO: Undo step: 198
2024-12-01-20:14:10-root-INFO: Undo step: 199
2024-12-01-20:14:10-root-INFO: step: 200 lr_xt 0.00137086
2024-12-01-20:14:10-root-INFO: grad norm: 1525.880 1447.191 483.682
2024-12-01-20:14:11-root-INFO: grad norm: 909.190 877.306 238.664
2024-12-01-20:14:13-root-INFO: grad norm: 415.834 386.165 154.255
2024-12-01-20:14:13-root-INFO: grad norm: 281.184 263.541 98.034
2024-12-01-20:14:15-root-INFO: grad norm: 213.698 200.418 74.159
2024-12-01-20:14:15-root-INFO: Loss Change: 4369.302 -> 2909.314
2024-12-01-20:14:15-root-INFO: Regularization Change: 0.000 -> 7.215
2024-12-01-20:14:15-root-INFO: Learning rate of xt decay: 0.03588 -> 0.03631.
2024-12-01-20:14:15-root-INFO: Coefficient of regularization decay: 0.00016 -> 0.00016.
2024-12-01-20:14:16-root-INFO: step: 199 lr_xt 0.00143293
2024-12-01-20:14:16-root-INFO: grad norm: 175.207 161.287 68.438
2024-12-01-20:14:17-root-INFO: grad norm: 151.540 140.232 57.441
2024-12-01-20:14:18-root-INFO: grad norm: 139.838 129.180 53.547
2024-12-01-20:14:19-root-INFO: grad norm: 132.261 121.967 51.155
2024-12-01-20:14:20-root-INFO: grad norm: 126.735 116.818 49.146
2024-12-01-20:14:21-root-INFO: Loss Change: 2883.918 -> 2738.321
2024-12-01-20:14:21-root-INFO: Regularization Change: 0.000 -> 1.038
2024-12-01-20:14:21-root-INFO: Learning rate of xt decay: 0.03631 -> 0.03675.
2024-12-01-20:14:21-root-INFO: Coefficient of regularization decay: 0.00016 -> 0.00017.
2024-12-01-20:14:21-root-INFO: step: 198 lr_xt 0.00149757
2024-12-01-20:14:21-root-INFO: grad norm: 153.490 139.172 64.733
2024-12-01-20:14:22-root-INFO: grad norm: 144.184 135.234 50.008
2024-12-01-20:14:23-root-INFO: grad norm: 152.684 143.767 51.415
2024-12-01-20:14:24-root-INFO: grad norm: 171.590 163.314 52.646
2024-12-01-20:14:25-root-INFO: grad norm: 209.036 200.170 60.233
2024-12-01-20:14:26-root-INFO: Loss Change: 2718.699 -> 2633.120
2024-12-01-20:14:26-root-INFO: Regularization Change: 0.000 -> 0.807
2024-12-01-20:14:26-root-INFO: Learning rate of xt decay: 0.03675 -> 0.03719.
2024-12-01-20:14:26-root-INFO: Coefficient of regularization decay: 0.00017 -> 0.00017.
2024-12-01-20:14:26-root-INFO: step: 197 lr_xt 0.00156486
2024-12-01-20:14:27-root-INFO: grad norm: 214.267 206.706 56.418
2024-12-01-20:14:28-root-INFO: grad norm: 297.265 286.705 78.528
2024-12-01-20:14:28-root-INFO: Loss too large (2592.642->2608.622)! Learning rate decreased to 0.00125.
2024-12-01-20:14:29-root-INFO: grad norm: 302.194 292.881 74.442
2024-12-01-20:14:30-root-INFO: grad norm: 313.129 302.744 79.975
2024-12-01-20:14:31-root-INFO: grad norm: 327.005 317.396 78.689
2024-12-01-20:14:31-root-INFO: Loss Change: 2599.632 -> 2549.626
2024-12-01-20:14:31-root-INFO: Regularization Change: 0.000 -> 0.561
2024-12-01-20:14:31-root-INFO: Learning rate of xt decay: 0.03719 -> 0.03764.
2024-12-01-20:14:31-root-INFO: Coefficient of regularization decay: 0.00017 -> 0.00017.
2024-12-01-20:14:31-root-INFO: step: 196 lr_xt 0.00163492
2024-12-01-20:14:32-root-INFO: grad norm: 432.247 414.161 123.726
2024-12-01-20:14:32-root-INFO: Loss too large (2550.370->2621.928)! Learning rate decreased to 0.00131.
2024-12-01-20:14:32-root-INFO: Loss too large (2550.370->2553.183)! Learning rate decreased to 0.00105.
2024-12-01-20:14:32-root-INFO: grad norm: 321.455 312.734 74.368
2024-12-01-20:14:33-root-INFO: grad norm: 244.138 235.081 65.881
2024-12-01-20:14:33-root-INFO: grad norm: 203.338 196.305 53.018
2024-12-01-20:14:34-root-INFO: grad norm: 175.260 168.223 49.165
2024-12-01-20:14:34-root-INFO: Loss Change: 2550.370 -> 2446.466
2024-12-01-20:14:34-root-INFO: Regularization Change: 0.000 -> 0.389
2024-12-01-20:14:34-root-INFO: Learning rate of xt decay: 0.03764 -> 0.03809.
2024-12-01-20:14:34-root-INFO: Coefficient of regularization decay: 0.00017 -> 0.00017.
2024-12-01-20:14:34-root-INFO: step: 195 lr_xt 0.00170783
2024-12-01-20:14:34-root-INFO: grad norm: 132.394 125.552 42.009
2024-12-01-20:14:35-root-INFO: grad norm: 196.936 189.922 52.092
2024-12-01-20:14:35-root-INFO: Loss too large (2415.928->2426.129)! Learning rate decreased to 0.00137.
2024-12-01-20:14:36-root-INFO: grad norm: 267.569 259.803 63.994
2024-12-01-20:14:36-root-INFO: Loss too large (2412.155->2419.663)! Learning rate decreased to 0.00109.
2024-12-01-20:14:36-root-INFO: grad norm: 271.228 262.712 67.430
2024-12-01-20:14:37-root-INFO: grad norm: 280.156 272.287 65.936
2024-12-01-20:14:37-root-INFO: Loss Change: 2428.260 -> 2382.990
2024-12-01-20:14:37-root-INFO: Regularization Change: 0.000 -> 0.432
2024-12-01-20:14:37-root-INFO: Learning rate of xt decay: 0.03809 -> 0.03854.
2024-12-01-20:14:37-root-INFO: Coefficient of regularization decay: 0.00017 -> 0.00017.
2024-12-01-20:14:37-root-INFO: step: 194 lr_xt 0.00178371
2024-12-01-20:14:37-root-INFO: grad norm: 377.588 363.118 103.527
2024-12-01-20:14:38-root-INFO: Loss too large (2380.223->2503.418)! Learning rate decreased to 0.00143.
2024-12-01-20:14:38-root-INFO: Loss too large (2380.223->2425.674)! Learning rate decreased to 0.00114.
2024-12-01-20:14:38-root-INFO: grad norm: 411.764 402.401 87.310
2024-12-01-20:14:39-root-INFO: grad norm: 462.290 448.757 111.039
2024-12-01-20:14:39-root-INFO: Loss too large (2375.544->2386.312)! Learning rate decreased to 0.00091.
2024-12-01-20:14:39-root-INFO: grad norm: 341.507 333.056 75.504
2024-12-01-20:14:40-root-INFO: grad norm: 252.868 244.813 63.315
2024-12-01-20:14:40-root-INFO: Loss Change: 2380.223 -> 2308.364
2024-12-01-20:14:40-root-INFO: Regularization Change: 0.000 -> 0.310
2024-12-01-20:14:40-root-INFO: Learning rate of xt decay: 0.03854 -> 0.03901.
2024-12-01-20:14:40-root-INFO: Coefficient of regularization decay: 0.00017 -> 0.00017.
2024-12-01-20:14:40-root-INFO: step: 193 lr_xt 0.00186266
2024-12-01-20:14:40-root-INFO: grad norm: 203.032 196.431 51.350
2024-12-01-20:14:40-root-INFO: Loss too large (2288.218->2295.293)! Learning rate decreased to 0.00149.
2024-12-01-20:14:41-root-INFO: grad norm: 263.236 256.593 58.765
2024-12-01-20:14:41-root-INFO: Loss too large (2280.751->2299.700)! Learning rate decreased to 0.00119.
2024-12-01-20:14:41-root-INFO: grad norm: 306.797 299.595 66.083
2024-12-01-20:14:42-root-INFO: Loss too large (2277.017->2283.023)! Learning rate decreased to 0.00095.
2024-12-01-20:14:42-root-INFO: grad norm: 269.886 261.901 65.164
2024-12-01-20:14:42-root-INFO: grad norm: 252.017 245.491 56.979
2024-12-01-20:14:43-root-INFO: Loss Change: 2288.218 -> 2244.002
2024-12-01-20:14:43-root-INFO: Regularization Change: 0.000 -> 0.289
2024-12-01-20:14:43-root-INFO: Learning rate of xt decay: 0.03901 -> 0.03947.
2024-12-01-20:14:43-root-INFO: Coefficient of regularization decay: 0.00017 -> 0.00018.
2024-12-01-20:14:43-root-INFO: step: 192 lr_xt 0.00194479
2024-12-01-20:14:43-root-INFO: grad norm: 357.542 346.490 88.212
2024-12-01-20:14:43-root-INFO: Loss too large (2240.200->2425.677)! Learning rate decreased to 0.00156.
2024-12-01-20:14:43-root-INFO: Loss too large (2240.200->2329.743)! Learning rate decreased to 0.00124.
2024-12-01-20:14:44-root-INFO: Loss too large (2240.200->2270.038)! Learning rate decreased to 0.00100.
2024-12-01-20:14:44-root-INFO: grad norm: 356.242 348.284 74.878
2024-12-01-20:14:45-root-INFO: grad norm: 359.682 349.718 84.074
2024-12-01-20:14:45-root-INFO: grad norm: 365.518 357.333 76.921
2024-12-01-20:14:46-root-INFO: grad norm: 375.943 365.936 86.162
2024-12-01-20:14:46-root-INFO: Loss Change: 2240.200 -> 2216.274
2024-12-01-20:14:46-root-INFO: Regularization Change: 0.000 -> 0.288
2024-12-01-20:14:46-root-INFO: Learning rate of xt decay: 0.03947 -> 0.03995.
2024-12-01-20:14:46-root-INFO: Coefficient of regularization decay: 0.00018 -> 0.00018.
2024-12-01-20:14:46-root-INFO: step: 191 lr_xt 0.00203021
2024-12-01-20:14:46-root-INFO: grad norm: 370.464 363.741 70.257
2024-12-01-20:14:46-root-INFO: Loss too large (2202.876->2420.824)! Learning rate decreased to 0.00162.
2024-12-01-20:14:46-root-INFO: Loss too large (2202.876->2301.642)! Learning rate decreased to 0.00130.
2024-12-01-20:14:47-root-INFO: Loss too large (2202.876->2230.191)! Learning rate decreased to 0.00104.
2024-12-01-20:14:47-root-INFO: grad norm: 376.827 367.026 85.382
2024-12-01-20:14:48-root-INFO: grad norm: 391.678 384.156 76.391
2024-12-01-20:14:48-root-INFO: grad norm: 422.577 412.101 93.509
2024-12-01-20:14:48-root-INFO: Loss too large (2183.984->2191.349)! Learning rate decreased to 0.00083.
2024-12-01-20:14:49-root-INFO: grad norm: 304.659 297.902 63.804
2024-12-01-20:14:49-root-INFO: Loss Change: 2202.876 -> 2143.142
2024-12-01-20:14:49-root-INFO: Regularization Change: 0.000 -> 0.242
2024-12-01-20:14:49-root-INFO: Learning rate of xt decay: 0.03995 -> 0.04043.
2024-12-01-20:14:49-root-INFO: Coefficient of regularization decay: 0.00018 -> 0.00018.
2024-12-01-20:14:49-root-INFO: step: 190 lr_xt 0.00211904
2024-12-01-20:14:49-root-INFO: grad norm: 381.628 370.205 92.673
2024-12-01-20:14:49-root-INFO: Loss too large (2147.056->2395.339)! Learning rate decreased to 0.00170.
2024-12-01-20:14:50-root-INFO: Loss too large (2147.056->2283.130)! Learning rate decreased to 0.00136.
2024-12-01-20:14:50-root-INFO: Loss too large (2147.056->2208.211)! Learning rate decreased to 0.00108.
2024-12-01-20:14:50-root-INFO: Loss too large (2147.056->2161.243)! Learning rate decreased to 0.00087.
2024-12-01-20:14:50-root-INFO: grad norm: 301.940 295.462 62.209
2024-12-01-20:14:51-root-INFO: grad norm: 228.608 221.456 56.736
2024-12-01-20:14:51-root-INFO: grad norm: 196.100 191.169 43.703
2024-12-01-20:14:52-root-INFO: grad norm: 170.324 164.691 43.443
2024-12-01-20:14:52-root-INFO: Loss Change: 2147.056 -> 2094.223
2024-12-01-20:14:52-root-INFO: Regularization Change: 0.000 -> 0.166
2024-12-01-20:14:52-root-INFO: Undo step: 190
2024-12-01-20:14:52-root-INFO: Undo step: 191
2024-12-01-20:14:52-root-INFO: Undo step: 192
2024-12-01-20:14:52-root-INFO: Undo step: 193
2024-12-01-20:14:52-root-INFO: Undo step: 194
2024-12-01-20:14:52-root-INFO: step: 195 lr_xt 0.00170783
2024-12-01-20:14:52-root-INFO: grad norm: 985.185 925.693 337.167
2024-12-01-20:14:53-root-INFO: grad norm: 869.377 846.625 197.590
2024-12-01-20:14:53-root-INFO: Loss too large (2867.553->3116.649)! Learning rate decreased to 0.00137.
2024-12-01-20:14:54-root-INFO: grad norm: 1002.237 985.839 180.552
2024-12-01-20:14:54-root-INFO: grad norm: 930.334 917.432 154.397
2024-12-01-20:14:55-root-INFO: grad norm: 693.521 680.373 134.404
2024-12-01-20:14:55-root-INFO: Loss Change: 3470.093 -> 2544.257
2024-12-01-20:14:55-root-INFO: Regularization Change: 0.000 -> 5.525
2024-12-01-20:14:55-root-INFO: Learning rate of xt decay: 0.03809 -> 0.03854.
2024-12-01-20:14:55-root-INFO: Coefficient of regularization decay: 0.00017 -> 0.00017.
2024-12-01-20:14:55-root-INFO: step: 194 lr_xt 0.00178371
2024-12-01-20:14:55-root-INFO: grad norm: 492.707 485.017 86.706
2024-12-01-20:14:55-root-INFO: Loss too large (2505.357->2530.005)! Learning rate decreased to 0.00143.
2024-12-01-20:14:56-root-INFO: grad norm: 440.611 429.563 98.048
2024-12-01-20:14:56-root-INFO: grad norm: 402.607 394.374 81.004
2024-12-01-20:14:57-root-INFO: grad norm: 392.515 383.000 85.899
2024-12-01-20:14:57-root-INFO: Loss too large (2391.571->2392.408)! Learning rate decreased to 0.00114.
2024-12-01-20:14:57-root-INFO: grad norm: 278.701 272.106 60.271
2024-12-01-20:14:58-root-INFO: Loss Change: 2505.357 -> 2328.392
2024-12-01-20:14:58-root-INFO: Regularization Change: 0.000 -> 0.804
2024-12-01-20:14:58-root-INFO: Learning rate of xt decay: 0.03854 -> 0.03901.
2024-12-01-20:14:58-root-INFO: Coefficient of regularization decay: 0.00017 -> 0.00017.
2024-12-01-20:14:58-root-INFO: step: 193 lr_xt 0.00186266
2024-12-01-20:14:58-root-INFO: grad norm: 427.297 416.612 94.960
2024-12-01-20:14:58-root-INFO: Loss too large (2334.088->2407.819)! Learning rate decreased to 0.00149.
2024-12-01-20:14:58-root-INFO: Loss too large (2334.088->2367.245)! Learning rate decreased to 0.00119.
2024-12-01-20:14:58-root-INFO: Loss too large (2334.088->2337.119)! Learning rate decreased to 0.00095.
2024-12-01-20:14:59-root-INFO: grad norm: 250.965 245.202 53.471
2024-12-01-20:14:59-root-INFO: grad norm: 107.239 99.129 40.910
2024-12-01-20:15:00-root-INFO: grad norm: 99.459 92.420 36.750
2024-12-01-20:15:00-root-INFO: grad norm: 96.100 89.091 36.026
2024-12-01-20:15:01-root-INFO: Loss Change: 2334.088 -> 2248.536
2024-12-01-20:15:01-root-INFO: Regularization Change: 0.000 -> 0.265
2024-12-01-20:15:01-root-INFO: Learning rate of xt decay: 0.03901 -> 0.03947.
2024-12-01-20:15:01-root-INFO: Coefficient of regularization decay: 0.00017 -> 0.00018.
2024-12-01-20:15:01-root-INFO: step: 192 lr_xt 0.00194479
2024-12-01-20:15:01-root-INFO: grad norm: 139.125 131.332 45.909
2024-12-01-20:15:01-root-INFO: grad norm: 247.434 242.595 48.695
2024-12-01-20:15:02-root-INFO: Loss too large (2227.862->2312.144)! Learning rate decreased to 0.00156.
2024-12-01-20:15:02-root-INFO: Loss too large (2227.862->2256.458)! Learning rate decreased to 0.00124.
2024-12-01-20:15:02-root-INFO: grad norm: 378.986 372.069 72.076
2024-12-01-20:15:02-root-INFO: Loss too large (2226.121->2255.709)! Learning rate decreased to 0.00100.
2024-12-01-20:15:02-root-INFO: Loss too large (2226.121->2232.048)! Learning rate decreased to 0.00080.
2024-12-01-20:15:03-root-INFO: grad norm: 243.366 238.629 47.783
2024-12-01-20:15:03-root-INFO: grad norm: 111.215 105.900 33.969
2024-12-01-20:15:04-root-INFO: Loss Change: 2230.306 -> 2183.795
2024-12-01-20:15:04-root-INFO: Regularization Change: 0.000 -> 0.253
2024-12-01-20:15:04-root-INFO: Learning rate of xt decay: 0.03947 -> 0.03995.
2024-12-01-20:15:04-root-INFO: Coefficient of regularization decay: 0.00018 -> 0.00018.
2024-12-01-20:15:04-root-INFO: step: 191 lr_xt 0.00203021
2024-12-01-20:15:04-root-INFO: grad norm: 260.210 250.791 69.376
2024-12-01-20:15:04-root-INFO: Loss too large (2179.427->2235.525)! Learning rate decreased to 0.00162.
2024-12-01-20:15:04-root-INFO: Loss too large (2179.427->2212.812)! Learning rate decreased to 0.00130.
2024-12-01-20:15:05-root-INFO: Loss too large (2179.427->2194.619)! Learning rate decreased to 0.00104.
2024-12-01-20:15:05-root-INFO: Loss too large (2179.427->2181.277)! Learning rate decreased to 0.00083.
2024-12-01-20:15:05-root-INFO: grad norm: 223.622 219.031 45.080
2024-12-01-20:15:06-root-INFO: grad norm: 179.795 173.574 46.885
2024-12-01-20:15:06-root-INFO: grad norm: 172.780 168.740 37.147
2024-12-01-20:15:07-root-INFO: grad norm: 166.861 161.770 40.903
2024-12-01-20:15:07-root-INFO: Loss Change: 2179.427 -> 2139.728
2024-12-01-20:15:07-root-INFO: Regularization Change: 0.000 -> 0.168
2024-12-01-20:15:07-root-INFO: Learning rate of xt decay: 0.03995 -> 0.04043.
2024-12-01-20:15:07-root-INFO: Coefficient of regularization decay: 0.00018 -> 0.00018.
2024-12-01-20:15:07-root-INFO: step: 190 lr_xt 0.00211904
2024-12-01-20:15:07-root-INFO: grad norm: 113.192 105.164 41.869
2024-12-01-20:15:08-root-INFO: grad norm: 205.826 202.305 37.910
2024-12-01-20:15:08-root-INFO: Loss too large (2111.184->2200.665)! Learning rate decreased to 0.00170.
2024-12-01-20:15:08-root-INFO: Loss too large (2111.184->2152.208)! Learning rate decreased to 0.00136.
2024-12-01-20:15:08-root-INFO: Loss too large (2111.184->2124.398)! Learning rate decreased to 0.00108.
2024-12-01-20:15:09-root-INFO: grad norm: 293.558 287.627 58.711
2024-12-01-20:15:09-root-INFO: Loss too large (2109.425->2128.266)! Learning rate decreased to 0.00087.
2024-12-01-20:15:09-root-INFO: Loss too large (2109.425->2112.021)! Learning rate decreased to 0.00069.
2024-12-01-20:15:09-root-INFO: grad norm: 217.667 214.222 38.576
2024-12-01-20:15:10-root-INFO: grad norm: 153.356 149.181 35.540
2024-12-01-20:15:10-root-INFO: Loss Change: 2118.956 -> 2086.039
2024-12-01-20:15:10-root-INFO: Regularization Change: 0.000 -> 0.187
2024-12-01-20:15:10-root-INFO: Learning rate of xt decay: 0.04043 -> 0.04091.
2024-12-01-20:15:10-root-INFO: Coefficient of regularization decay: 0.00018 -> 0.00018.
2024-12-01-20:15:10-root-INFO: step: 189 lr_xt 0.00221139
2024-12-01-20:15:10-root-INFO: grad norm: 104.678 98.062 36.623
2024-12-01-20:15:11-root-INFO: grad norm: 249.478 245.841 42.445
2024-12-01-20:15:11-root-INFO: Loss too large (2068.546->2285.698)! Learning rate decreased to 0.00177.
2024-12-01-20:15:11-root-INFO: Loss too large (2068.546->2189.772)! Learning rate decreased to 0.00142.
2024-12-01-20:15:11-root-INFO: Loss too large (2068.546->2126.596)! Learning rate decreased to 0.00113.
2024-12-01-20:15:12-root-INFO: Loss too large (2068.546->2088.351)! Learning rate decreased to 0.00091.
2024-12-01-20:15:12-root-INFO: grad norm: 350.362 344.962 61.277
2024-12-01-20:15:12-root-INFO: Loss too large (2067.255->2087.077)! Learning rate decreased to 0.00072.
2024-12-01-20:15:12-root-INFO: Loss too large (2067.255->2069.652)! Learning rate decreased to 0.00058.
2024-12-01-20:15:13-root-INFO: grad norm: 228.422 225.133 38.625
2024-12-01-20:15:13-root-INFO: grad norm: 120.385 116.624 29.856
2024-12-01-20:15:14-root-INFO: Loss Change: 2069.265 -> 2041.811
2024-12-01-20:15:14-root-INFO: Regularization Change: 0.000 -> 0.136
2024-12-01-20:15:14-root-INFO: Learning rate of xt decay: 0.04091 -> 0.04140.
2024-12-01-20:15:14-root-INFO: Coefficient of regularization decay: 0.00018 -> 0.00018.
2024-12-01-20:15:14-root-INFO: step: 188 lr_xt 0.00230740
2024-12-01-20:15:14-root-INFO: grad norm: 155.080 149.396 41.601
2024-12-01-20:15:14-root-INFO: Loss too large (2028.011->2071.054)! Learning rate decreased to 0.00185.
2024-12-01-20:15:14-root-INFO: Loss too large (2028.011->2050.737)! Learning rate decreased to 0.00148.
2024-12-01-20:15:14-root-INFO: Loss too large (2028.011->2037.549)! Learning rate decreased to 0.00118.
2024-12-01-20:15:15-root-INFO: Loss too large (2028.011->2029.483)! Learning rate decreased to 0.00095.
2024-12-01-20:15:15-root-INFO: grad norm: 192.998 189.887 34.510
2024-12-01-20:15:15-root-INFO: Loss too large (2024.922->2029.176)! Learning rate decreased to 0.00076.
2024-12-01-20:15:16-root-INFO: grad norm: 231.595 227.323 44.277
2024-12-01-20:15:16-root-INFO: Loss too large (2020.985->2023.713)! Learning rate decreased to 0.00060.
2024-12-01-20:15:16-root-INFO: grad norm: 193.323 190.300 34.056
2024-12-01-20:15:17-root-INFO: grad norm: 151.744 148.060 33.236
2024-12-01-20:15:17-root-INFO: Loss Change: 2028.011 -> 2007.329
2024-12-01-20:15:17-root-INFO: Regularization Change: 0.000 -> 0.076
2024-12-01-20:15:17-root-INFO: Learning rate of xt decay: 0.04140 -> 0.04190.
2024-12-01-20:15:17-root-INFO: Coefficient of regularization decay: 0.00018 -> 0.00019.
2024-12-01-20:15:17-root-INFO: step: 187 lr_xt 0.00240719
2024-12-01-20:15:17-root-INFO: grad norm: 139.495 132.868 42.486
2024-12-01-20:15:17-root-INFO: Loss too large (2005.596->2042.826)! Learning rate decreased to 0.00193.
2024-12-01-20:15:18-root-INFO: Loss too large (2005.596->2027.746)! Learning rate decreased to 0.00154.
2024-12-01-20:15:18-root-INFO: Loss too large (2005.596->2016.859)! Learning rate decreased to 0.00123.
2024-12-01-20:15:18-root-INFO: Loss too large (2005.596->2009.575)! Learning rate decreased to 0.00099.
2024-12-01-20:15:18-root-INFO: grad norm: 217.144 214.135 36.023
2024-12-01-20:15:19-root-INFO: Loss too large (2005.081->2019.302)! Learning rate decreased to 0.00079.
2024-12-01-20:15:19-root-INFO: Loss too large (2005.081->2005.107)! Learning rate decreased to 0.00063.
2024-12-01-20:15:19-root-INFO: grad norm: 202.624 197.922 43.398
2024-12-01-20:15:20-root-INFO: grad norm: 197.391 194.595 33.106
2024-12-01-20:15:20-root-INFO: grad norm: 191.078 186.888 39.794
2024-12-01-20:15:20-root-INFO: Loss Change: 2005.596 -> 1989.214
2024-12-01-20:15:20-root-INFO: Regularization Change: 0.000 -> 0.081
2024-12-01-20:15:20-root-INFO: Learning rate of xt decay: 0.04190 -> 0.04240.
2024-12-01-20:15:20-root-INFO: Coefficient of regularization decay: 0.00019 -> 0.00019.
2024-12-01-20:15:21-root-INFO: step: 186 lr_xt 0.00251089
2024-12-01-20:15:21-root-INFO: grad norm: 110.615 105.469 33.346
2024-12-01-20:15:21-root-INFO: Loss too large (1968.972->1975.031)! Learning rate decreased to 0.00201.
2024-12-01-20:15:21-root-INFO: grad norm: 270.250 266.916 42.319
2024-12-01-20:15:21-root-INFO: Loss too large (1967.876->2080.389)! Learning rate decreased to 0.00161.
2024-12-01-20:15:22-root-INFO: Loss too large (1967.876->2041.344)! Learning rate decreased to 0.00129.
2024-12-01-20:15:22-root-INFO: Loss too large (1967.876->2010.737)! Learning rate decreased to 0.00103.
2024-12-01-20:15:22-root-INFO: Loss too large (1967.876->1988.125)! Learning rate decreased to 0.00082.
2024-12-01-20:15:22-root-INFO: Loss too large (1967.876->1972.715)! Learning rate decreased to 0.00066.
2024-12-01-20:15:23-root-INFO: grad norm: 245.797 242.733 38.693
2024-12-01-20:15:23-root-INFO: grad norm: 270.073 266.305 44.960
2024-12-01-20:15:23-root-INFO: Loss too large (1957.920->1961.374)! Learning rate decreased to 0.00053.
2024-12-01-20:15:24-root-INFO: grad norm: 209.557 206.776 34.026
2024-12-01-20:15:24-root-INFO: Loss Change: 1968.972 -> 1946.681
2024-12-01-20:15:24-root-INFO: Regularization Change: 0.000 -> 0.106
2024-12-01-20:15:24-root-INFO: Learning rate of xt decay: 0.04240 -> 0.04291.
2024-12-01-20:15:24-root-INFO: Coefficient of regularization decay: 0.00019 -> 0.00019.
2024-12-01-20:15:24-root-INFO: step: 185 lr_xt 0.00261863
2024-12-01-20:15:24-root-INFO: grad norm: 329.798 325.327 54.123
2024-12-01-20:15:24-root-INFO: Loss too large (1945.360->2110.210)! Learning rate decreased to 0.00209.
2024-12-01-20:15:25-root-INFO: Loss too large (1945.360->2081.892)! Learning rate decreased to 0.00168.
2024-12-01-20:15:25-root-INFO: Loss too large (1945.360->2053.415)! Learning rate decreased to 0.00134.
2024-12-01-20:15:25-root-INFO: Loss too large (1945.360->2024.841)! Learning rate decreased to 0.00107.
2024-12-01-20:15:25-root-INFO: Loss too large (1945.360->1997.537)! Learning rate decreased to 0.00086.
2024-12-01-20:15:25-root-INFO: Loss too large (1945.360->1973.917)! Learning rate decreased to 0.00069.
2024-12-01-20:15:25-root-INFO: Loss too large (1945.360->1955.731)! Learning rate decreased to 0.00055.
2024-12-01-20:15:26-root-INFO: grad norm: 272.445 269.423 40.469
2024-12-01-20:15:26-root-INFO: grad norm: 205.408 202.010 37.207
2024-12-01-20:15:27-root-INFO: grad norm: 190.140 187.670 30.554
2024-12-01-20:15:27-root-INFO: grad norm: 172.949 169.830 32.698
2024-12-01-20:15:28-root-INFO: Loss Change: 1945.360 -> 1923.394
2024-12-01-20:15:28-root-INFO: Regularization Change: 0.000 -> 0.051
2024-12-01-20:15:28-root-INFO: Undo step: 185
2024-12-01-20:15:28-root-INFO: Undo step: 186
2024-12-01-20:15:28-root-INFO: Undo step: 187
2024-12-01-20:15:28-root-INFO: Undo step: 188
2024-12-01-20:15:28-root-INFO: Undo step: 189
2024-12-01-20:15:28-root-INFO: step: 190 lr_xt 0.00211904
2024-12-01-20:15:28-root-INFO: grad norm: 834.426 768.987 323.922
2024-12-01-20:15:28-root-INFO: grad norm: 1067.875 1037.937 251.088
2024-12-01-20:15:28-root-INFO: Loss too large (3065.730->3313.826)! Learning rate decreased to 0.00170.
2024-12-01-20:15:29-root-INFO: grad norm: 844.609 827.169 170.749
2024-12-01-20:15:29-root-INFO: grad norm: 391.311 380.289 92.218
2024-12-01-20:15:30-root-INFO: grad norm: 273.347 264.534 68.852
2024-12-01-20:15:30-root-INFO: Loss Change: 3367.553 -> 2377.464
2024-12-01-20:15:30-root-INFO: Regularization Change: 0.000 -> 7.212
2024-12-01-20:15:30-root-INFO: Learning rate of xt decay: 0.04043 -> 0.04091.
2024-12-01-20:15:30-root-INFO: Coefficient of regularization decay: 0.00018 -> 0.00018.
2024-12-01-20:15:30-root-INFO: step: 189 lr_xt 0.00221139
2024-12-01-20:15:31-root-INFO: grad norm: 287.547 275.586 82.070
2024-12-01-20:15:31-root-INFO: grad norm: 340.804 332.298 75.665
2024-12-01-20:15:31-root-INFO: Loss too large (2363.509->2367.966)! Learning rate decreased to 0.00177.
2024-12-01-20:15:32-root-INFO: grad norm: 352.204 340.452 90.224
2024-12-01-20:15:32-root-INFO: Loss too large (2308.307->2328.350)! Learning rate decreased to 0.00142.
2024-12-01-20:15:32-root-INFO: grad norm: 289.394 281.963 65.162
2024-12-01-20:15:33-root-INFO: grad norm: 246.877 237.907 65.942
2024-12-01-20:15:33-root-INFO: Loss too large (2250.323->2250.414)! Learning rate decreased to 0.00113.
2024-12-01-20:15:33-root-INFO: Loss Change: 2371.360 -> 2239.769
2024-12-01-20:15:33-root-INFO: Regularization Change: 0.000 -> 1.026
2024-12-01-20:15:33-root-INFO: Learning rate of xt decay: 0.04091 -> 0.04140.
2024-12-01-20:15:33-root-INFO: Coefficient of regularization decay: 0.00018 -> 0.00018.
2024-12-01-20:15:33-root-INFO: step: 188 lr_xt 0.00230740
2024-12-01-20:15:34-root-INFO: grad norm: 185.044 178.557 48.567
2024-12-01-20:15:34-root-INFO: Loss too large (2213.535->2260.155)! Learning rate decreased to 0.00185.
2024-12-01-20:15:34-root-INFO: Loss too large (2213.535->2227.083)! Learning rate decreased to 0.00148.
2024-12-01-20:15:34-root-INFO: grad norm: 340.991 333.556 70.818
2024-12-01-20:15:34-root-INFO: Loss too large (2209.232->2246.177)! Learning rate decreased to 0.00118.
2024-12-01-20:15:35-root-INFO: Loss too large (2209.232->2223.598)! Learning rate decreased to 0.00095.
2024-12-01-20:15:35-root-INFO: grad norm: 260.881 254.948 55.321
2024-12-01-20:15:36-root-INFO: grad norm: 157.040 150.685 44.222
2024-12-01-20:15:36-root-INFO: grad norm: 163.213 158.384 39.410
2024-12-01-20:15:36-root-INFO: Loss Change: 2213.535 -> 2157.929
2024-12-01-20:15:36-root-INFO: Regularization Change: 0.000 -> 0.294
2024-12-01-20:15:36-root-INFO: Learning rate of xt decay: 0.04140 -> 0.04190.
2024-12-01-20:15:36-root-INFO: Coefficient of regularization decay: 0.00018 -> 0.00019.
2024-12-01-20:15:37-root-INFO: step: 187 lr_xt 0.00240719
2024-12-01-20:15:37-root-INFO: grad norm: 437.315 427.471 92.266
2024-12-01-20:15:37-root-INFO: Loss too large (2176.975->2315.317)! Learning rate decreased to 0.00193.
2024-12-01-20:15:37-root-INFO: Loss too large (2176.975->2283.116)! Learning rate decreased to 0.00154.
2024-12-01-20:15:37-root-INFO: Loss too large (2176.975->2251.312)! Learning rate decreased to 0.00123.
2024-12-01-20:15:37-root-INFO: Loss too large (2176.975->2220.778)! Learning rate decreased to 0.00099.
2024-12-01-20:15:38-root-INFO: Loss too large (2176.975->2193.072)! Learning rate decreased to 0.00079.
2024-12-01-20:15:38-root-INFO: grad norm: 293.544 288.008 56.741
2024-12-01-20:15:39-root-INFO: grad norm: 126.462 119.819 40.449
2024-12-01-20:15:39-root-INFO: grad norm: 123.169 118.711 32.837
2024-12-01-20:15:39-root-INFO: grad norm: 122.760 116.686 38.137
2024-12-01-20:15:40-root-INFO: Loss Change: 2176.975 -> 2114.250
2024-12-01-20:15:40-root-INFO: Regularization Change: 0.000 -> 0.164
2024-12-01-20:15:40-root-INFO: Learning rate of xt decay: 0.04190 -> 0.04240.
2024-12-01-20:15:40-root-INFO: Coefficient of regularization decay: 0.00019 -> 0.00019.
2024-12-01-20:15:40-root-INFO: step: 186 lr_xt 0.00251089
2024-12-01-20:15:40-root-INFO: grad norm: 125.578 117.340 44.733
2024-12-01-20:15:41-root-INFO: grad norm: 284.698 279.191 55.724
2024-12-01-20:15:41-root-INFO: Loss too large (2093.847->2408.637)! Learning rate decreased to 0.00201.
2024-12-01-20:15:41-root-INFO: Loss too large (2093.847->2274.765)! Learning rate decreased to 0.00161.
2024-12-01-20:15:41-root-INFO: Loss too large (2093.847->2184.530)! Learning rate decreased to 0.00129.
2024-12-01-20:15:41-root-INFO: Loss too large (2093.847->2128.195)! Learning rate decreased to 0.00103.
2024-12-01-20:15:41-root-INFO: Loss too large (2093.847->2095.963)! Learning rate decreased to 0.00082.
2024-12-01-20:15:42-root-INFO: grad norm: 291.069 285.191 58.204
2024-12-01-20:15:42-root-INFO: Loss too large (2079.470->2085.868)! Learning rate decreased to 0.00066.
2024-12-01-20:15:43-root-INFO: grad norm: 239.089 234.800 45.079
2024-12-01-20:15:43-root-INFO: grad norm: 182.635 177.776 41.850
2024-12-01-20:15:43-root-INFO: Loss Change: 2095.865 -> 2059.167
2024-12-01-20:15:43-root-INFO: Regularization Change: 0.000 -> 0.215
2024-12-01-20:15:43-root-INFO: Learning rate of xt decay: 0.04240 -> 0.04291.
2024-12-01-20:15:43-root-INFO: Coefficient of regularization decay: 0.00019 -> 0.00019.
2024-12-01-20:15:44-root-INFO: step: 185 lr_xt 0.00261863
2024-12-01-20:15:44-root-INFO: grad norm: 103.161 97.815 32.779
2024-12-01-20:15:44-root-INFO: Loss too large (2043.237->2049.400)! Learning rate decreased to 0.00209.
2024-12-01-20:15:44-root-INFO: grad norm: 302.590 297.889 53.129
2024-12-01-20:15:45-root-INFO: Loss too large (2042.489->2164.500)! Learning rate decreased to 0.00168.
2024-12-01-20:15:45-root-INFO: Loss too large (2042.489->2132.382)! Learning rate decreased to 0.00134.
2024-12-01-20:15:45-root-INFO: Loss too large (2042.489->2102.241)! Learning rate decreased to 0.00107.
2024-12-01-20:15:45-root-INFO: Loss too large (2042.489->2076.039)! Learning rate decreased to 0.00086.
2024-12-01-20:15:45-root-INFO: Loss too large (2042.489->2055.714)! Learning rate decreased to 0.00069.
2024-12-01-20:15:46-root-INFO: grad norm: 284.291 279.783 50.430
2024-12-01-20:15:46-root-INFO: grad norm: 276.649 271.535 52.946
2024-12-01-20:15:46-root-INFO: Loss too large (2030.999->2032.780)! Learning rate decreased to 0.00055.
2024-12-01-20:15:47-root-INFO: grad norm: 208.582 204.929 38.863
2024-12-01-20:15:47-root-INFO: Loss Change: 2043.237 -> 2017.190
2024-12-01-20:15:47-root-INFO: Regularization Change: 0.000 -> 0.129
2024-12-01-20:15:47-root-INFO: Learning rate of xt decay: 0.04291 -> 0.04343.
2024-12-01-20:15:47-root-INFO: Coefficient of regularization decay: 0.00019 -> 0.00019.
2024-12-01-20:15:47-root-INFO: step: 184 lr_xt 0.00273055
2024-12-01-20:15:47-root-INFO: grad norm: 500.202 491.132 94.822
2024-12-01-20:15:48-root-INFO: Loss too large (2040.313->2257.282)! Learning rate decreased to 0.00218.
2024-12-01-20:15:48-root-INFO: Loss too large (2040.313->2219.803)! Learning rate decreased to 0.00175.
2024-12-01-20:15:48-root-INFO: Loss too large (2040.313->2183.742)! Learning rate decreased to 0.00140.
2024-12-01-20:15:48-root-INFO: Loss too large (2040.313->2148.356)! Learning rate decreased to 0.00112.
2024-12-01-20:15:48-root-INFO: Loss too large (2040.313->2113.343)! Learning rate decreased to 0.00089.
2024-12-01-20:15:48-root-INFO: Loss too large (2040.313->2079.470)! Learning rate decreased to 0.00072.
2024-12-01-20:15:48-root-INFO: Loss too large (2040.313->2049.563)! Learning rate decreased to 0.00057.
2024-12-01-20:15:49-root-INFO: grad norm: 335.134 330.165 57.495
2024-12-01-20:15:49-root-INFO: grad norm: 173.489 167.882 43.750
2024-12-01-20:15:50-root-INFO: grad norm: 156.169 152.715 32.666
2024-12-01-20:15:50-root-INFO: grad norm: 140.334 135.247 37.442
2024-12-01-20:15:51-root-INFO: Loss Change: 2040.313 -> 1985.698
2024-12-01-20:15:51-root-INFO: Regularization Change: 0.000 -> 0.093
2024-12-01-20:15:51-root-INFO: Learning rate of xt decay: 0.04343 -> 0.04395.
2024-12-01-20:15:51-root-INFO: Coefficient of regularization decay: 0.00019 -> 0.00019.
2024-12-01-20:15:51-root-INFO: step: 183 lr_xt 0.00284680
2024-12-01-20:15:51-root-INFO: grad norm: 117.138 110.422 39.095
2024-12-01-20:15:51-root-INFO: grad norm: 247.485 242.967 47.075
2024-12-01-20:15:52-root-INFO: Loss too large (1972.232->2225.630)! Learning rate decreased to 0.00228.
2024-12-01-20:15:52-root-INFO: Loss too large (1972.232->2112.850)! Learning rate decreased to 0.00182.
2024-12-01-20:15:52-root-INFO: Loss too large (1972.232->2041.300)! Learning rate decreased to 0.00146.
2024-12-01-20:15:52-root-INFO: Loss too large (1972.232->1998.302)! Learning rate decreased to 0.00117.
2024-12-01-20:15:52-root-INFO: Loss too large (1972.232->1974.017)! Learning rate decreased to 0.00093.
2024-12-01-20:15:53-root-INFO: grad norm: 307.729 302.474 56.626
2024-12-01-20:15:53-root-INFO: Loss too large (1961.423->1995.107)! Learning rate decreased to 0.00075.
2024-12-01-20:15:53-root-INFO: Loss too large (1961.423->1975.415)! Learning rate decreased to 0.00060.
2024-12-01-20:15:53-root-INFO: Loss too large (1961.423->1962.014)! Learning rate decreased to 0.00048.
2024-12-01-20:15:54-root-INFO: grad norm: 219.622 216.291 38.104
2024-12-01-20:15:54-root-INFO: grad norm: 148.817 144.878 34.012
2024-12-01-20:15:54-root-INFO: Loss Change: 1976.487 -> 1943.304
2024-12-01-20:15:54-root-INFO: Regularization Change: 0.000 -> 0.177
2024-12-01-20:15:54-root-INFO: Learning rate of xt decay: 0.04395 -> 0.04448.
2024-12-01-20:15:54-root-INFO: Coefficient of regularization decay: 0.00019 -> 0.00019.
2024-12-01-20:15:55-root-INFO: step: 182 lr_xt 0.00296752
2024-12-01-20:15:55-root-INFO: grad norm: 169.611 164.833 39.977
2024-12-01-20:15:55-root-INFO: Loss too large (1937.088->2051.873)! Learning rate decreased to 0.00237.
2024-12-01-20:15:55-root-INFO: Loss too large (1937.088->2021.135)! Learning rate decreased to 0.00190.
2024-12-01-20:15:55-root-INFO: Loss too large (1937.088->1994.316)! Learning rate decreased to 0.00152.
2024-12-01-20:15:55-root-INFO: Loss too large (1937.088->1972.740)! Learning rate decreased to 0.00122.
2024-12-01-20:15:55-root-INFO: Loss too large (1937.088->1956.812)! Learning rate decreased to 0.00097.
2024-12-01-20:15:56-root-INFO: Loss too large (1937.088->1945.966)! Learning rate decreased to 0.00078.
2024-12-01-20:15:56-root-INFO: Loss too large (1937.088->1939.133)! Learning rate decreased to 0.00062.
2024-12-01-20:15:56-root-INFO: grad norm: 199.292 196.218 34.866
2024-12-01-20:15:57-root-INFO: grad norm: 256.532 252.200 46.949
2024-12-01-20:15:57-root-INFO: Loss too large (1934.133->1937.546)! Learning rate decreased to 0.00050.
2024-12-01-20:15:57-root-INFO: grad norm: 220.082 216.965 36.911
2024-12-01-20:15:58-root-INFO: grad norm: 184.857 181.011 37.515
2024-12-01-20:15:58-root-INFO: Loss Change: 1937.088 -> 1922.132
2024-12-01-20:15:58-root-INFO: Regularization Change: 0.000 -> 0.048
2024-12-01-20:15:58-root-INFO: Learning rate of xt decay: 0.04448 -> 0.04501.
2024-12-01-20:15:58-root-INFO: Coefficient of regularization decay: 0.00019 -> 0.00020.
2024-12-01-20:15:58-root-INFO: step: 181 lr_xt 0.00309285
2024-12-01-20:15:58-root-INFO: grad norm: 138.884 133.945 36.706
2024-12-01-20:15:59-root-INFO: Loss too large (1914.734->2001.940)! Learning rate decreased to 0.00247.
2024-12-01-20:15:59-root-INFO: Loss too large (1914.734->1973.988)! Learning rate decreased to 0.00198.
2024-12-01-20:15:59-root-INFO: Loss too large (1914.734->1952.034)! Learning rate decreased to 0.00158.
2024-12-01-20:15:59-root-INFO: Loss too large (1914.734->1936.029)! Learning rate decreased to 0.00127.
2024-12-01-20:15:59-root-INFO: Loss too large (1914.734->1925.161)! Learning rate decreased to 0.00101.
2024-12-01-20:15:59-root-INFO: Loss too large (1914.734->1918.271)! Learning rate decreased to 0.00081.
2024-12-01-20:16:00-root-INFO: grad norm: 225.282 222.315 36.442
2024-12-01-20:16:00-root-INFO: Loss too large (1914.217->1929.382)! Learning rate decreased to 0.00065.
2024-12-01-20:16:00-root-INFO: Loss too large (1914.217->1916.837)! Learning rate decreased to 0.00052.
2024-12-01-20:16:01-root-INFO: grad norm: 223.550 219.401 42.866
2024-12-01-20:16:01-root-INFO: grad norm: 223.286 220.384 35.882
2024-12-01-20:16:02-root-INFO: grad norm: 223.930 219.944 42.063
2024-12-01-20:16:02-root-INFO: Loss Change: 1914.734 -> 1903.305
2024-12-01-20:16:02-root-INFO: Regularization Change: 0.000 -> 0.054
2024-12-01-20:16:02-root-INFO: Learning rate of xt decay: 0.04501 -> 0.04555.
2024-12-01-20:16:02-root-INFO: Coefficient of regularization decay: 0.00020 -> 0.00020.
2024-12-01-20:16:02-root-INFO: step: 180 lr_xt 0.00322295
2024-12-01-20:16:02-root-INFO: grad norm: 107.236 101.275 35.256
2024-12-01-20:16:02-root-INFO: Loss too large (1894.297->1900.531)! Learning rate decreased to 0.00258.
2024-12-01-20:16:03-root-INFO: grad norm: 321.645 317.478 51.601
2024-12-01-20:16:03-root-INFO: Loss too large (1892.907->2375.903)! Learning rate decreased to 0.00206.
2024-12-01-20:16:03-root-INFO: Loss too large (1892.907->2240.834)! Learning rate decreased to 0.00165.
2024-12-01-20:16:03-root-INFO: Loss too large (1892.907->2127.604)! Learning rate decreased to 0.00132.
2024-12-01-20:16:03-root-INFO: Loss too large (1892.907->2038.333)! Learning rate decreased to 0.00106.
2024-12-01-20:16:03-root-INFO: Loss too large (1892.907->1972.964)! Learning rate decreased to 0.00084.
2024-12-01-20:16:04-root-INFO: Loss too large (1892.907->1928.784)! Learning rate decreased to 0.00068.
2024-12-01-20:16:04-root-INFO: Loss too large (1892.907->1901.401)! Learning rate decreased to 0.00054.
2024-12-01-20:16:04-root-INFO: grad norm: 340.577 336.252 54.102
2024-12-01-20:16:04-root-INFO: Loss too large (1886.064->1889.288)! Learning rate decreased to 0.00043.
2024-12-01-20:16:05-root-INFO: grad norm: 258.445 255.331 39.999
2024-12-01-20:16:05-root-INFO: grad norm: 192.867 189.235 37.254
2024-12-01-20:16:06-root-INFO: Loss Change: 1894.297 -> 1868.925
2024-12-01-20:16:06-root-INFO: Regularization Change: 0.000 -> 0.127
2024-12-01-20:16:06-root-INFO: Undo step: 180
2024-12-01-20:16:06-root-INFO: Undo step: 181
2024-12-01-20:16:06-root-INFO: Undo step: 182
2024-12-01-20:16:06-root-INFO: Undo step: 183
2024-12-01-20:16:06-root-INFO: Undo step: 184
2024-12-01-20:16:06-root-INFO: step: 185 lr_xt 0.00261863
2024-12-01-20:16:06-root-INFO: grad norm: 656.886 628.378 191.416
2024-12-01-20:16:06-root-INFO: grad norm: 720.555 696.674 183.969
2024-12-01-20:16:07-root-INFO: grad norm: 768.705 754.534 146.920
2024-12-01-20:16:07-root-INFO: grad norm: 641.099 626.306 136.929
2024-12-01-20:16:08-root-INFO: grad norm: 448.715 438.950 93.099
2024-12-01-20:16:08-root-INFO: Loss Change: 2961.926 -> 2353.366
2024-12-01-20:16:08-root-INFO: Regularization Change: 0.000 -> 8.162
2024-12-01-20:16:08-root-INFO: Learning rate of xt decay: 0.04291 -> 0.04343.
2024-12-01-20:16:08-root-INFO: Coefficient of regularization decay: 0.00019 -> 0.00019.
2024-12-01-20:16:08-root-INFO: step: 184 lr_xt 0.00273055
2024-12-01-20:16:08-root-INFO: grad norm: 397.704 388.258 86.163
2024-12-01-20:16:09-root-INFO: grad norm: 353.594 346.991 68.018
2024-12-01-20:16:09-root-INFO: grad norm: 320.814 311.917 75.030
2024-12-01-20:16:09-root-INFO: Loss too large (2152.138->2191.804)! Learning rate decreased to 0.00218.
2024-12-01-20:16:10-root-INFO: grad norm: 302.519 297.350 55.681
2024-12-01-20:16:10-root-INFO: grad norm: 661.458 649.849 123.382
2024-12-01-20:16:11-root-INFO: Loss too large (2145.662->2250.071)! Learning rate decreased to 0.00175.
2024-12-01-20:16:11-root-INFO: Loss too large (2145.662->2217.753)! Learning rate decreased to 0.00140.
2024-12-01-20:16:11-root-INFO: Loss too large (2145.662->2184.918)! Learning rate decreased to 0.00112.
2024-12-01-20:16:11-root-INFO: Loss too large (2145.662->2151.780)! Learning rate decreased to 0.00089.
2024-12-01-20:16:11-root-INFO: Loss Change: 2352.544 -> 2119.546
2024-12-01-20:16:11-root-INFO: Regularization Change: 0.000 -> 1.356
2024-12-01-20:16:11-root-INFO: Learning rate of xt decay: 0.04343 -> 0.04395.
2024-12-01-20:16:11-root-INFO: Coefficient of regularization decay: 0.00019 -> 0.00019.
2024-12-01-20:16:11-root-INFO: step: 183 lr_xt 0.00284680
2024-12-01-20:16:12-root-INFO: grad norm: 280.784 275.222 55.608
2024-12-01-20:16:12-root-INFO: Loss too large (2108.250->2234.477)! Learning rate decreased to 0.00228.
2024-12-01-20:16:12-root-INFO: Loss too large (2108.250->2128.902)! Learning rate decreased to 0.00182.
2024-12-01-20:16:12-root-INFO: grad norm: 458.365 450.462 84.752
2024-12-01-20:16:13-root-INFO: Loss too large (2063.389->2156.080)! Learning rate decreased to 0.00146.
2024-12-01-20:16:13-root-INFO: Loss too large (2063.389->2126.128)! Learning rate decreased to 0.00117.
2024-12-01-20:16:13-root-INFO: Loss too large (2063.389->2097.075)! Learning rate decreased to 0.00093.
2024-12-01-20:16:13-root-INFO: Loss too large (2063.389->2070.883)! Learning rate decreased to 0.00075.
2024-12-01-20:16:13-root-INFO: grad norm: 274.653 269.566 52.613
2024-12-01-20:16:14-root-INFO: grad norm: 111.405 106.158 33.789
2024-12-01-20:16:14-root-INFO: grad norm: 106.907 102.465 30.495
2024-12-01-20:16:15-root-INFO: Loss Change: 2108.250 -> 1999.765
2024-12-01-20:16:15-root-INFO: Regularization Change: 0.000 -> 0.296
2024-12-01-20:16:15-root-INFO: Learning rate of xt decay: 0.04395 -> 0.04448.
2024-12-01-20:16:15-root-INFO: Coefficient of regularization decay: 0.00019 -> 0.00019.
2024-12-01-20:16:15-root-INFO: step: 182 lr_xt 0.00296752
2024-12-01-20:16:15-root-INFO: grad norm: 311.371 304.923 63.040
2024-12-01-20:16:15-root-INFO: Loss too large (1999.966->2151.919)! Learning rate decreased to 0.00237.
2024-12-01-20:16:15-root-INFO: Loss too large (1999.966->2125.842)! Learning rate decreased to 0.00190.
2024-12-01-20:16:15-root-INFO: Loss too large (1999.966->2098.709)! Learning rate decreased to 0.00152.
2024-12-01-20:16:16-root-INFO: Loss too large (1999.966->2071.547)! Learning rate decreased to 0.00122.
2024-12-01-20:16:16-root-INFO: Loss too large (1999.966->2046.111)! Learning rate decreased to 0.00097.
2024-12-01-20:16:16-root-INFO: Loss too large (1999.966->2024.380)! Learning rate decreased to 0.00078.
2024-12-01-20:16:16-root-INFO: Loss too large (1999.966->2007.680)! Learning rate decreased to 0.00062.
2024-12-01-20:16:17-root-INFO: grad norm: 262.285 258.015 47.133
2024-12-01-20:16:17-root-INFO: grad norm: 208.284 203.085 46.248
2024-12-01-20:16:17-root-INFO: grad norm: 205.363 201.746 38.374
2024-12-01-20:16:18-root-INFO: grad norm: 209.074 204.147 45.124
2024-12-01-20:16:18-root-INFO: Loss Change: 1999.966 -> 1970.333
2024-12-01-20:16:18-root-INFO: Regularization Change: 0.000 -> 0.098
2024-12-01-20:16:18-root-INFO: Learning rate of xt decay: 0.04448 -> 0.04501.
2024-12-01-20:16:18-root-INFO: Coefficient of regularization decay: 0.00019 -> 0.00020.
2024-12-01-20:16:18-root-INFO: step: 181 lr_xt 0.00309285
2024-12-01-20:16:19-root-INFO: grad norm: 102.399 97.770 30.442
2024-12-01-20:16:19-root-INFO: Loss too large (1954.556->1955.862)! Learning rate decreased to 0.00247.
2024-12-01-20:16:19-root-INFO: grad norm: 354.124 348.724 61.607
2024-12-01-20:16:19-root-INFO: Loss too large (1949.881->2114.457)! Learning rate decreased to 0.00198.
2024-12-01-20:16:20-root-INFO: Loss too large (1949.881->2089.542)! Learning rate decreased to 0.00158.
2024-12-01-20:16:20-root-INFO: Loss too large (1949.881->2062.203)! Learning rate decreased to 0.00127.
2024-12-01-20:16:20-root-INFO: Loss too large (1949.881->2033.487)! Learning rate decreased to 0.00101.
2024-12-01-20:16:20-root-INFO: Loss too large (1949.881->2005.474)! Learning rate decreased to 0.00081.
2024-12-01-20:16:20-root-INFO: Loss too large (1949.881->1980.743)! Learning rate decreased to 0.00065.
2024-12-01-20:16:20-root-INFO: Loss too large (1949.881->1961.259)! Learning rate decreased to 0.00052.
2024-12-01-20:16:21-root-INFO: grad norm: 299.900 295.664 50.232
2024-12-01-20:16:21-root-INFO: grad norm: 241.803 237.283 46.534
2024-12-01-20:16:22-root-INFO: grad norm: 235.014 231.549 40.208
2024-12-01-20:16:22-root-INFO: Loss Change: 1954.556 -> 1927.796
2024-12-01-20:16:22-root-INFO: Regularization Change: 0.000 -> 0.149
2024-12-01-20:16:22-root-INFO: Learning rate of xt decay: 0.04501 -> 0.04555.
2024-12-01-20:16:22-root-INFO: Coefficient of regularization decay: 0.00020 -> 0.00020.
2024-12-01-20:16:22-root-INFO: step: 180 lr_xt 0.00322295
2024-12-01-20:16:22-root-INFO: grad norm: 564.910 556.914 94.708
2024-12-01-20:16:22-root-INFO: Loss too large (1953.023->2162.265)! Learning rate decreased to 0.00258.
2024-12-01-20:16:23-root-INFO: Loss too large (1953.023->2145.354)! Learning rate decreased to 0.00206.
2024-12-01-20:16:23-root-INFO: Loss too large (1953.023->2126.013)! Learning rate decreased to 0.00165.
2024-12-01-20:16:23-root-INFO: Loss too large (1953.023->2103.471)! Learning rate decreased to 0.00132.
2024-12-01-20:16:23-root-INFO: Loss too large (1953.023->2077.535)! Learning rate decreased to 0.00106.
2024-12-01-20:16:23-root-INFO: Loss too large (1953.023->2048.244)! Learning rate decreased to 0.00084.
2024-12-01-20:16:23-root-INFO: Loss too large (1953.023->2016.406)! Learning rate decreased to 0.00068.
2024-12-01-20:16:23-root-INFO: Loss too large (1953.023->1984.454)! Learning rate decreased to 0.00054.
2024-12-01-20:16:24-root-INFO: Loss too large (1953.023->1956.082)! Learning rate decreased to 0.00043.
2024-12-01-20:16:24-root-INFO: grad norm: 353.041 348.305 57.637
2024-12-01-20:16:25-root-INFO: grad norm: 181.591 176.789 41.482
2024-12-01-20:16:25-root-INFO: grad norm: 161.205 158.095 31.514
2024-12-01-20:16:25-root-INFO: grad norm: 143.056 138.641 35.265
2024-12-01-20:16:26-root-INFO: Loss Change: 1953.023 -> 1901.060
2024-12-01-20:16:26-root-INFO: Regularization Change: 0.000 -> 0.058
2024-12-01-20:16:26-root-INFO: Learning rate of xt decay: 0.04555 -> 0.04610.
2024-12-01-20:16:26-root-INFO: Coefficient of regularization decay: 0.00020 -> 0.00020.
2024-12-01-20:16:26-root-INFO: step: 179 lr_xt 0.00335799
2024-12-01-20:16:26-root-INFO: grad norm: 222.660 217.757 46.467
2024-12-01-20:16:26-root-INFO: Loss too large (1899.056->2064.007)! Learning rate decreased to 0.00269.
2024-12-01-20:16:26-root-INFO: Loss too large (1899.056->2038.421)! Learning rate decreased to 0.00215.
2024-12-01-20:16:27-root-INFO: Loss too large (1899.056->2011.479)! Learning rate decreased to 0.00172.
2024-12-01-20:16:27-root-INFO: Loss too large (1899.056->1984.335)! Learning rate decreased to 0.00138.
2024-12-01-20:16:27-root-INFO: Loss too large (1899.056->1958.951)! Learning rate decreased to 0.00110.
2024-12-01-20:16:27-root-INFO: Loss too large (1899.056->1937.253)! Learning rate decreased to 0.00088.
2024-12-01-20:16:27-root-INFO: Loss too large (1899.056->1920.368)! Learning rate decreased to 0.00070.
2024-12-01-20:16:27-root-INFO: Loss too large (1899.056->1908.389)! Learning rate decreased to 0.00056.
2024-12-01-20:16:27-root-INFO: Loss too large (1899.056->1900.638)! Learning rate decreased to 0.00045.
2024-12-01-20:16:28-root-INFO: grad norm: 221.033 217.758 37.910
2024-12-01-20:16:28-root-INFO: grad norm: 222.211 217.738 44.359
2024-12-01-20:16:29-root-INFO: grad norm: 224.530 221.353 37.638
2024-12-01-20:16:29-root-INFO: grad norm: 229.313 225.042 44.049
2024-12-01-20:16:30-root-INFO: Loss Change: 1899.056 -> 1884.750
2024-12-01-20:16:30-root-INFO: Regularization Change: 0.000 -> 0.045
2024-12-01-20:16:30-root-INFO: Learning rate of xt decay: 0.04610 -> 0.04665.
2024-12-01-20:16:30-root-INFO: Coefficient of regularization decay: 0.00020 -> 0.00020.
2024-12-01-20:16:30-root-INFO: step: 178 lr_xt 0.00349812
2024-12-01-20:16:30-root-INFO: grad norm: 116.132 110.756 34.923
2024-12-01-20:16:30-root-INFO: Loss too large (1877.661->1896.310)! Learning rate decreased to 0.00280.
2024-12-01-20:16:30-root-INFO: Loss too large (1877.661->1884.492)! Learning rate decreased to 0.00224.
2024-12-01-20:16:31-root-INFO: grad norm: 371.414 366.819 58.241
2024-12-01-20:16:31-root-INFO: Loss too large (1877.185->2334.344)! Learning rate decreased to 0.00179.
2024-12-01-20:16:31-root-INFO: Loss too large (1877.185->2221.370)! Learning rate decreased to 0.00143.
2024-12-01-20:16:31-root-INFO: Loss too large (1877.185->2121.808)! Learning rate decreased to 0.00115.
2024-12-01-20:16:31-root-INFO: Loss too large (1877.185->2037.756)! Learning rate decreased to 0.00092.
2024-12-01-20:16:32-root-INFO: Loss too large (1877.185->1970.975)! Learning rate decreased to 0.00073.
2024-12-01-20:16:32-root-INFO: Loss too large (1877.185->1921.925)! Learning rate decreased to 0.00059.
2024-12-01-20:16:32-root-INFO: Loss too large (1877.185->1889.279)! Learning rate decreased to 0.00047.
2024-12-01-20:16:32-root-INFO: grad norm: 392.677 387.685 62.410
2024-12-01-20:16:33-root-INFO: Loss too large (1870.038->1874.739)! Learning rate decreased to 0.00038.
2024-12-01-20:16:33-root-INFO: grad norm: 300.038 296.315 47.120
2024-12-01-20:16:34-root-INFO: grad norm: 225.643 221.878 41.048
2024-12-01-20:16:34-root-INFO: Loss Change: 1877.661 -> 1851.538
2024-12-01-20:16:34-root-INFO: Regularization Change: 0.000 -> 0.118
2024-12-01-20:16:34-root-INFO: Learning rate of xt decay: 0.04665 -> 0.04721.
2024-12-01-20:16:34-root-INFO: Coefficient of regularization decay: 0.00020 -> 0.00020.
2024-12-01-20:16:34-root-INFO: step: 177 lr_xt 0.00364350
2024-12-01-20:16:34-root-INFO: grad norm: 88.805 84.445 27.486
2024-12-01-20:16:35-root-INFO: grad norm: 331.643 327.762 50.583
2024-12-01-20:16:35-root-INFO: Loss too large (1831.299->2523.478)! Learning rate decreased to 0.00291.
2024-12-01-20:16:35-root-INFO: Loss too large (1831.299->2388.842)! Learning rate decreased to 0.00233.
2024-12-01-20:16:35-root-INFO: Loss too large (1831.299->2271.578)! Learning rate decreased to 0.00187.
2024-12-01-20:16:35-root-INFO: Loss too large (1831.299->2166.779)! Learning rate decreased to 0.00149.
2024-12-01-20:16:35-root-INFO: Loss too large (1831.299->2074.558)! Learning rate decreased to 0.00119.
2024-12-01-20:16:36-root-INFO: Loss too large (1831.299->1996.764)! Learning rate decreased to 0.00096.
2024-12-01-20:16:36-root-INFO: Loss too large (1831.299->1934.695)! Learning rate decreased to 0.00076.
2024-12-01-20:16:36-root-INFO: Loss too large (1831.299->1888.393)! Learning rate decreased to 0.00061.
2024-12-01-20:16:36-root-INFO: Loss too large (1831.299->1856.499)! Learning rate decreased to 0.00049.
2024-12-01-20:16:36-root-INFO: Loss too large (1831.299->1836.464)! Learning rate decreased to 0.00039.
2024-12-01-20:16:37-root-INFO: grad norm: 310.738 306.883 48.796
2024-12-01-20:16:37-root-INFO: grad norm: 302.773 299.260 45.994
2024-12-01-20:16:38-root-INFO: grad norm: 296.109 292.304 47.316
2024-12-01-20:16:38-root-INFO: Loss Change: 1841.875 -> 1819.272
2024-12-01-20:16:38-root-INFO: Regularization Change: 0.000 -> 0.175
2024-12-01-20:16:38-root-INFO: Learning rate of xt decay: 0.04721 -> 0.04778.
2024-12-01-20:16:38-root-INFO: Coefficient of regularization decay: 0.00020 -> 0.00021.
2024-12-01-20:16:38-root-INFO: step: 176 lr_xt 0.00379432
2024-12-01-20:16:38-root-INFO: grad norm: 110.108 106.385 28.389
2024-12-01-20:16:39-root-INFO: Loss too large (1807.134->1885.241)! Learning rate decreased to 0.00304.
2024-12-01-20:16:39-root-INFO: Loss too large (1807.134->1861.848)! Learning rate decreased to 0.00243.
2024-12-01-20:16:39-root-INFO: Loss too large (1807.134->1842.856)! Learning rate decreased to 0.00194.
2024-12-01-20:16:39-root-INFO: Loss too large (1807.134->1828.612)! Learning rate decreased to 0.00155.
2024-12-01-20:16:39-root-INFO: Loss too large (1807.134->1818.686)! Learning rate decreased to 0.00124.
2024-12-01-20:16:39-root-INFO: Loss too large (1807.134->1812.222)! Learning rate decreased to 0.00099.
2024-12-01-20:16:39-root-INFO: Loss too large (1807.134->1808.289)! Learning rate decreased to 0.00080.
2024-12-01-20:16:40-root-INFO: grad norm: 234.577 231.822 35.843
2024-12-01-20:16:40-root-INFO: Loss too large (1806.076->1842.484)! Learning rate decreased to 0.00064.
2024-12-01-20:16:40-root-INFO: Loss too large (1806.076->1823.512)! Learning rate decreased to 0.00051.
2024-12-01-20:16:40-root-INFO: Loss too large (1806.076->1811.810)! Learning rate decreased to 0.00041.
2024-12-01-20:16:41-root-INFO: grad norm: 274.427 270.534 46.061
2024-12-01-20:16:41-root-INFO: Loss too large (1805.145->1805.853)! Learning rate decreased to 0.00033.
2024-12-01-20:16:41-root-INFO: grad norm: 215.166 212.578 33.277
2024-12-01-20:16:42-root-INFO: grad norm: 170.831 167.570 33.217
2024-12-01-20:16:42-root-INFO: Loss Change: 1807.134 -> 1794.796
2024-12-01-20:16:42-root-INFO: Regularization Change: 0.000 -> 0.030
2024-12-01-20:16:42-root-INFO: Learning rate of xt decay: 0.04778 -> 0.04835.
2024-12-01-20:16:42-root-INFO: Coefficient of regularization decay: 0.00021 -> 0.00021.
2024-12-01-20:16:42-root-INFO: step: 175 lr_xt 0.00395074
2024-12-01-20:16:43-root-INFO: grad norm: 261.239 257.307 45.150
2024-12-01-20:16:43-root-INFO: Loss too large (1795.172->2014.241)! Learning rate decreased to 0.00316.
2024-12-01-20:16:43-root-INFO: Loss too large (1795.172->1995.032)! Learning rate decreased to 0.00253.
2024-12-01-20:16:43-root-INFO: Loss too large (1795.172->1973.173)! Learning rate decreased to 0.00202.
2024-12-01-20:16:43-root-INFO: Loss too large (1795.172->1948.174)! Learning rate decreased to 0.00162.
2024-12-01-20:16:43-root-INFO: Loss too large (1795.172->1920.181)! Learning rate decreased to 0.00129.
2024-12-01-20:16:44-root-INFO: Loss too large (1795.172->1890.568)! Learning rate decreased to 0.00104.
2024-12-01-20:16:44-root-INFO: Loss too large (1795.172->1861.947)! Learning rate decreased to 0.00083.
2024-12-01-20:16:44-root-INFO: Loss too large (1795.172->1837.118)! Learning rate decreased to 0.00066.
2024-12-01-20:16:44-root-INFO: Loss too large (1795.172->1817.848)! Learning rate decreased to 0.00053.
2024-12-01-20:16:44-root-INFO: Loss too large (1795.172->1804.421)! Learning rate decreased to 0.00042.
2024-12-01-20:16:44-root-INFO: Loss too large (1795.172->1795.984)! Learning rate decreased to 0.00034.
2024-12-01-20:16:45-root-INFO: grad norm: 229.718 226.977 35.378
2024-12-01-20:16:45-root-INFO: grad norm: 203.392 199.909 37.484
2024-12-01-20:16:46-root-INFO: grad norm: 184.530 182.041 30.203
2024-12-01-20:16:46-root-INFO: grad norm: 168.266 165.036 32.809
2024-12-01-20:16:46-root-INFO: Loss Change: 1795.172 -> 1779.682
2024-12-01-20:16:46-root-INFO: Regularization Change: 0.000 -> 0.025
2024-12-01-20:16:46-root-INFO: Undo step: 175
2024-12-01-20:16:47-root-INFO: Undo step: 176
2024-12-01-20:16:47-root-INFO: Undo step: 177
2024-12-01-20:16:47-root-INFO: Undo step: 178
2024-12-01-20:16:47-root-INFO: Undo step: 179
2024-12-01-20:16:47-root-INFO: step: 180 lr_xt 0.00322295
2024-12-01-20:16:47-root-INFO: grad norm: 1010.699 993.455 185.903
2024-12-01-20:16:47-root-INFO: grad norm: 621.001 609.489 119.016
2024-12-01-20:16:48-root-INFO: grad norm: 462.524 454.065 88.049
2024-12-01-20:16:48-root-INFO: grad norm: 362.291 357.359 59.577
2024-12-01-20:16:49-root-INFO: grad norm: 298.283 292.851 56.664
2024-12-01-20:16:49-root-INFO: Loss Change: 3075.427 -> 2019.434
2024-12-01-20:16:49-root-INFO: Regularization Change: 0.000 -> 10.358
2024-12-01-20:16:49-root-INFO: Learning rate of xt decay: 0.04555 -> 0.04610.
2024-12-01-20:16:49-root-INFO: Coefficient of regularization decay: 0.00020 -> 0.00020.
2024-12-01-20:16:49-root-INFO: step: 179 lr_xt 0.00335799
2024-12-01-20:16:49-root-INFO: grad norm: 266.034 261.434 49.259
2024-12-01-20:16:50-root-INFO: grad norm: 255.744 251.906 44.140
2024-12-01-20:16:50-root-INFO: Loss too large (1964.950->2039.292)! Learning rate decreased to 0.00269.
2024-12-01-20:16:50-root-INFO: Loss too large (1964.950->1965.886)! Learning rate decreased to 0.00215.
2024-12-01-20:16:51-root-INFO: grad norm: 339.476 335.435 52.222
2024-12-01-20:16:51-root-INFO: Loss too large (1929.285->1980.964)! Learning rate decreased to 0.00172.
2024-12-01-20:16:51-root-INFO: Loss too large (1929.285->1952.071)! Learning rate decreased to 0.00138.
2024-12-01-20:16:51-root-INFO: grad norm: 236.965 233.494 40.411
2024-12-01-20:16:52-root-INFO: grad norm: 113.622 109.530 30.218
2024-12-01-20:16:52-root-INFO: Loss Change: 2019.695 -> 1866.574
2024-12-01-20:16:52-root-INFO: Regularization Change: 0.000 -> 1.087
2024-12-01-20:16:52-root-INFO: Learning rate of xt decay: 0.04610 -> 0.04665.
2024-12-01-20:16:52-root-INFO: Coefficient of regularization decay: 0.00020 -> 0.00020.
2024-12-01-20:16:52-root-INFO: step: 178 lr_xt 0.00349812
2024-12-01-20:16:52-root-INFO: grad norm: 115.446 110.686 32.807
2024-12-01-20:16:53-root-INFO: grad norm: 210.848 207.696 36.322
2024-12-01-20:16:53-root-INFO: Loss too large (1831.543->2183.463)! Learning rate decreased to 0.00280.
2024-12-01-20:16:53-root-INFO: Loss too large (1831.543->2068.373)! Learning rate decreased to 0.00224.
2024-12-01-20:16:53-root-INFO: Loss too large (1831.543->1977.664)! Learning rate decreased to 0.00179.
2024-12-01-20:16:54-root-INFO: Loss too large (1831.543->1911.839)! Learning rate decreased to 0.00143.
2024-12-01-20:16:54-root-INFO: Loss too large (1831.543->1868.265)! Learning rate decreased to 0.00115.
2024-12-01-20:16:54-root-INFO: Loss too large (1831.543->1842.082)! Learning rate decreased to 0.00092.
2024-12-01-20:16:54-root-INFO: grad norm: 296.939 294.373 38.947
2024-12-01-20:16:55-root-INFO: Loss too large (1827.932->1840.466)! Learning rate decreased to 0.00073.
2024-12-01-20:16:55-root-INFO: grad norm: 257.984 254.706 40.990
2024-12-01-20:16:55-root-INFO: grad norm: 210.444 208.054 31.626
2024-12-01-20:16:56-root-INFO: Loss Change: 1856.828 -> 1810.219
2024-12-01-20:16:56-root-INFO: Regularization Change: 0.000 -> 0.366
2024-12-01-20:16:56-root-INFO: Learning rate of xt decay: 0.04665 -> 0.04721.
2024-12-01-20:16:56-root-INFO: Coefficient of regularization decay: 0.00020 -> 0.00020.
2024-12-01-20:16:56-root-INFO: step: 177 lr_xt 0.00364350
2024-12-01-20:16:56-root-INFO: grad norm: 149.543 146.208 31.407
2024-12-01-20:16:56-root-INFO: Loss too large (1794.194->2009.668)! Learning rate decreased to 0.00291.
2024-12-01-20:16:56-root-INFO: Loss too large (1794.194->1934.541)! Learning rate decreased to 0.00233.
2024-12-01-20:16:57-root-INFO: Loss too large (1794.194->1879.011)! Learning rate decreased to 0.00187.
2024-12-01-20:16:57-root-INFO: Loss too large (1794.194->1840.973)! Learning rate decreased to 0.00149.
2024-12-01-20:16:57-root-INFO: Loss too large (1794.194->1816.754)! Learning rate decreased to 0.00119.
2024-12-01-20:16:57-root-INFO: Loss too large (1794.194->1802.376)! Learning rate decreased to 0.00096.
2024-12-01-20:16:57-root-INFO: Loss too large (1794.194->1794.451)! Learning rate decreased to 0.00076.
2024-12-01-20:16:58-root-INFO: grad norm: 195.439 192.865 31.613
2024-12-01-20:16:58-root-INFO: Loss too large (1790.484->1791.464)! Learning rate decreased to 0.00061.
2024-12-01-20:16:58-root-INFO: grad norm: 183.394 180.359 33.223
2024-12-01-20:16:59-root-INFO: grad norm: 174.295 171.886 28.874
2024-12-01-20:16:59-root-INFO: grad norm: 174.332 171.410 31.782
2024-12-01-20:16:59-root-INFO: Loss Change: 1794.194 -> 1774.558
2024-12-01-20:16:59-root-INFO: Regularization Change: 0.000 -> 0.072
2024-12-01-20:16:59-root-INFO: Learning rate of xt decay: 0.04721 -> 0.04778.
2024-12-01-20:16:59-root-INFO: Coefficient of regularization decay: 0.00020 -> 0.00021.
2024-12-01-20:17:00-root-INFO: step: 176 lr_xt 0.00379432
2024-12-01-20:17:00-root-INFO: grad norm: 454.768 451.025 58.222
2024-12-01-20:17:00-root-INFO: Loss too large (1793.685->2001.961)! Learning rate decreased to 0.00304.
2024-12-01-20:17:00-root-INFO: Loss too large (1793.685->1983.204)! Learning rate decreased to 0.00243.
2024-12-01-20:17:00-root-INFO: Loss too large (1793.685->1961.203)! Learning rate decreased to 0.00194.
2024-12-01-20:17:00-root-INFO: Loss too large (1793.685->1936.014)! Learning rate decreased to 0.00155.
2024-12-01-20:17:01-root-INFO: Loss too large (1793.685->1908.176)! Learning rate decreased to 0.00124.
2024-12-01-20:17:01-root-INFO: Loss too large (1793.685->1878.551)! Learning rate decreased to 0.00099.
2024-12-01-20:17:01-root-INFO: Loss too large (1793.685->1848.561)! Learning rate decreased to 0.00080.
2024-12-01-20:17:01-root-INFO: Loss too large (1793.685->1820.445)! Learning rate decreased to 0.00064.
2024-12-01-20:17:01-root-INFO: Loss too large (1793.685->1796.936)! Learning rate decreased to 0.00051.
2024-12-01-20:17:02-root-INFO: grad norm: 293.087 289.877 43.261
2024-12-01-20:17:02-root-INFO: grad norm: 156.752 154.041 29.026
2024-12-01-20:17:03-root-INFO: grad norm: 134.974 132.075 27.826
2024-12-01-20:17:03-root-INFO: grad norm: 117.517 114.822 25.020
2024-12-01-20:17:03-root-INFO: Loss Change: 1793.685 -> 1750.580
2024-12-01-20:17:03-root-INFO: Regularization Change: 0.000 -> 0.063
2024-12-01-20:17:03-root-INFO: Learning rate of xt decay: 0.04778 -> 0.04835.
2024-12-01-20:17:03-root-INFO: Coefficient of regularization decay: 0.00021 -> 0.00021.
2024-12-01-20:17:04-root-INFO: step: 175 lr_xt 0.00395074
2024-12-01-20:17:04-root-INFO: grad norm: 179.389 176.447 32.358
2024-12-01-20:17:04-root-INFO: Loss too large (1748.431->1885.716)! Learning rate decreased to 0.00316.
2024-12-01-20:17:04-root-INFO: Loss too large (1748.431->1859.798)! Learning rate decreased to 0.00253.
2024-12-01-20:17:04-root-INFO: Loss too large (1748.431->1833.985)! Learning rate decreased to 0.00202.
2024-12-01-20:17:04-root-INFO: Loss too large (1748.431->1809.675)! Learning rate decreased to 0.00162.
2024-12-01-20:17:05-root-INFO: Loss too large (1748.431->1788.509)! Learning rate decreased to 0.00129.
2024-12-01-20:17:05-root-INFO: Loss too large (1748.431->1771.699)! Learning rate decreased to 0.00104.
2024-12-01-20:17:05-root-INFO: Loss too large (1748.431->1759.544)! Learning rate decreased to 0.00083.
2024-12-01-20:17:05-root-INFO: Loss too large (1748.431->1751.526)! Learning rate decreased to 0.00066.
2024-12-01-20:17:06-root-INFO: grad norm: 222.831 219.936 35.799
2024-12-01-20:17:06-root-INFO: grad norm: 304.960 302.273 40.390
2024-12-01-20:17:06-root-INFO: Loss too large (1746.297->1754.271)! Learning rate decreased to 0.00053.
2024-12-01-20:17:07-root-INFO: grad norm: 269.326 266.404 39.565
2024-12-01-20:17:07-root-INFO: grad norm: 232.996 230.693 32.678
2024-12-01-20:17:07-root-INFO: Loss Change: 1748.431 -> 1732.789
2024-12-01-20:17:07-root-INFO: Regularization Change: 0.000 -> 0.067
2024-12-01-20:17:07-root-INFO: Learning rate of xt decay: 0.04835 -> 0.04893.
2024-12-01-20:17:07-root-INFO: Coefficient of regularization decay: 0.00021 -> 0.00021.
2024-12-01-20:17:08-root-INFO: step: 174 lr_xt 0.00411294
2024-12-01-20:17:08-root-INFO: grad norm: 156.851 154.083 29.333
2024-12-01-20:17:08-root-INFO: Loss too large (1727.723->2026.391)! Learning rate decreased to 0.00329.
2024-12-01-20:17:08-root-INFO: Loss too large (1727.723->1943.496)! Learning rate decreased to 0.00263.
2024-12-01-20:17:08-root-INFO: Loss too large (1727.723->1875.602)! Learning rate decreased to 0.00211.
2024-12-01-20:17:08-root-INFO: Loss too large (1727.723->1823.240)! Learning rate decreased to 0.00168.
2024-12-01-20:17:09-root-INFO: Loss too large (1727.723->1785.361)! Learning rate decreased to 0.00135.
2024-12-01-20:17:09-root-INFO: Loss too large (1727.723->1759.632)! Learning rate decreased to 0.00108.
2024-12-01-20:17:09-root-INFO: Loss too large (1727.723->1743.185)! Learning rate decreased to 0.00086.
2024-12-01-20:17:09-root-INFO: Loss too large (1727.723->1733.286)! Learning rate decreased to 0.00069.
2024-12-01-20:17:10-root-INFO: grad norm: 248.945 246.628 33.882
2024-12-01-20:17:10-root-INFO: Loss too large (1727.719->1736.571)! Learning rate decreased to 0.00055.
2024-12-01-20:17:10-root-INFO: grad norm: 265.176 262.325 38.785
2024-12-01-20:17:11-root-INFO: grad norm: 286.513 284.177 36.507
2024-12-01-20:17:11-root-INFO: Loss too large (1724.094->1725.275)! Learning rate decreased to 0.00044.
2024-12-01-20:17:11-root-INFO: grad norm: 214.919 212.328 33.268
2024-12-01-20:17:12-root-INFO: Loss Change: 1727.723 -> 1712.622
2024-12-01-20:17:12-root-INFO: Regularization Change: 0.000 -> 0.045
2024-12-01-20:17:12-root-INFO: Learning rate of xt decay: 0.04893 -> 0.04952.
2024-12-01-20:17:12-root-INFO: Coefficient of regularization decay: 0.00021 -> 0.00021.
2024-12-01-20:17:12-root-INFO: step: 173 lr_xt 0.00428111
2024-12-01-20:17:12-root-INFO: grad norm: 423.957 420.460 54.334
2024-12-01-20:17:12-root-INFO: Loss too large (1734.172->1948.968)! Learning rate decreased to 0.00342.
2024-12-01-20:17:12-root-INFO: Loss too large (1734.172->1934.751)! Learning rate decreased to 0.00274.
2024-12-01-20:17:12-root-INFO: Loss too large (1734.172->1917.622)! Learning rate decreased to 0.00219.
2024-12-01-20:17:13-root-INFO: Loss too large (1734.172->1896.884)! Learning rate decreased to 0.00175.
2024-12-01-20:17:13-root-INFO: Loss too large (1734.172->1872.538)! Learning rate decreased to 0.00140.
2024-12-01-20:17:13-root-INFO: Loss too large (1734.172->1844.903)! Learning rate decreased to 0.00112.
2024-12-01-20:17:13-root-INFO: Loss too large (1734.172->1814.832)! Learning rate decreased to 0.00090.
2024-12-01-20:17:13-root-INFO: Loss too large (1734.172->1784.233)! Learning rate decreased to 0.00072.
2024-12-01-20:17:13-root-INFO: Loss too large (1734.172->1756.338)! Learning rate decreased to 0.00057.
2024-12-01-20:17:13-root-INFO: Loss too large (1734.172->1734.413)! Learning rate decreased to 0.00046.
2024-12-01-20:17:14-root-INFO: grad norm: 291.365 288.295 42.186
2024-12-01-20:17:14-root-INFO: grad norm: 198.220 195.601 32.115
2024-12-01-20:17:15-root-INFO: grad norm: 164.789 162.116 29.558
2024-12-01-20:17:15-root-INFO: grad norm: 137.916 135.408 26.182
2024-12-01-20:17:16-root-INFO: Loss Change: 1734.172 -> 1695.922
2024-12-01-20:17:16-root-INFO: Regularization Change: 0.000 -> 0.056
2024-12-01-20:17:16-root-INFO: Learning rate of xt decay: 0.04952 -> 0.05011.
2024-12-01-20:17:16-root-INFO: Coefficient of regularization decay: 0.00021 -> 0.00022.
2024-12-01-20:17:16-root-INFO: step: 172 lr_xt 0.00445543
2024-12-01-20:17:16-root-INFO: grad norm: 104.690 101.552 25.442
2024-12-01-20:17:16-root-INFO: Loss too large (1693.882->1750.090)! Learning rate decreased to 0.00356.
2024-12-01-20:17:16-root-INFO: Loss too large (1693.882->1730.694)! Learning rate decreased to 0.00285.
2024-12-01-20:17:16-root-INFO: Loss too large (1693.882->1715.607)! Learning rate decreased to 0.00228.
2024-12-01-20:17:17-root-INFO: Loss too large (1693.882->1704.878)! Learning rate decreased to 0.00182.
2024-12-01-20:17:17-root-INFO: Loss too large (1693.882->1697.859)! Learning rate decreased to 0.00146.
2024-12-01-20:17:17-root-INFO: grad norm: 275.838 273.174 38.243
2024-12-01-20:17:17-root-INFO: Loss too large (1693.634->1827.083)! Learning rate decreased to 0.00117.
2024-12-01-20:17:18-root-INFO: Loss too large (1693.634->1773.666)! Learning rate decreased to 0.00093.
2024-12-01-20:17:18-root-INFO: Loss too large (1693.634->1735.469)! Learning rate decreased to 0.00075.
2024-12-01-20:17:18-root-INFO: Loss too large (1693.634->1710.255)! Learning rate decreased to 0.00060.
2024-12-01-20:17:18-root-INFO: Loss too large (1693.634->1695.017)! Learning rate decreased to 0.00048.
2024-12-01-20:17:18-root-INFO: grad norm: 232.967 230.748 32.081
2024-12-01-20:17:19-root-INFO: grad norm: 210.736 208.400 31.293
2024-12-01-20:17:19-root-INFO: grad norm: 190.890 188.855 27.802
2024-12-01-20:17:20-root-INFO: Loss Change: 1693.882 -> 1676.747
2024-12-01-20:17:20-root-INFO: Regularization Change: 0.000 -> 0.072
2024-12-01-20:17:20-root-INFO: Learning rate of xt decay: 0.05011 -> 0.05071.
2024-12-01-20:17:20-root-INFO: Coefficient of regularization decay: 0.00022 -> 0.00022.
2024-12-01-20:17:20-root-INFO: step: 171 lr_xt 0.00463611
2024-12-01-20:17:20-root-INFO: grad norm: 91.102 88.131 23.074
2024-12-01-20:17:20-root-INFO: Loss too large (1671.188->1693.402)! Learning rate decreased to 0.00371.
2024-12-01-20:17:20-root-INFO: Loss too large (1671.188->1681.693)! Learning rate decreased to 0.00297.
2024-12-01-20:17:20-root-INFO: Loss too large (1671.188->1674.080)! Learning rate decreased to 0.00237.
2024-12-01-20:17:21-root-INFO: grad norm: 309.892 307.052 41.859
2024-12-01-20:17:21-root-INFO: Loss too large (1669.569->2009.648)! Learning rate decreased to 0.00190.
2024-12-01-20:17:21-root-INFO: Loss too large (1669.569->1917.425)! Learning rate decreased to 0.00152.
2024-12-01-20:17:21-root-INFO: Loss too large (1669.569->1839.714)! Learning rate decreased to 0.00122.
2024-12-01-20:17:22-root-INFO: Loss too large (1669.569->1777.203)! Learning rate decreased to 0.00097.
2024-12-01-20:17:22-root-INFO: Loss too large (1669.569->1730.057)! Learning rate decreased to 0.00078.
2024-12-01-20:17:22-root-INFO: Loss too large (1669.569->1697.121)! Learning rate decreased to 0.00062.
2024-12-01-20:17:22-root-INFO: Loss too large (1669.569->1676.027)! Learning rate decreased to 0.00050.
2024-12-01-20:17:22-root-INFO: grad norm: 284.193 282.126 34.215
2024-12-01-20:17:23-root-INFO: grad norm: 269.755 267.185 37.153
2024-12-01-20:17:23-root-INFO: grad norm: 256.852 254.902 31.592
2024-12-01-20:17:24-root-INFO: Loss Change: 1671.188 -> 1655.034
2024-12-01-20:17:24-root-INFO: Regularization Change: 0.000 -> 0.111
2024-12-01-20:17:24-root-INFO: Learning rate of xt decay: 0.05071 -> 0.05132.
2024-12-01-20:17:24-root-INFO: Coefficient of regularization decay: 0.00022 -> 0.00022.
2024-12-01-20:17:24-root-INFO: step: 170 lr_xt 0.00482333
2024-12-01-20:17:24-root-INFO: grad norm: 112.745 110.038 24.562
2024-12-01-20:17:24-root-INFO: Loss too large (1648.991->1794.656)! Learning rate decreased to 0.00386.
2024-12-01-20:17:24-root-INFO: Loss too large (1648.991->1748.450)! Learning rate decreased to 0.00309.
2024-12-01-20:17:25-root-INFO: Loss too large (1648.991->1713.473)! Learning rate decreased to 0.00247.
2024-12-01-20:17:25-root-INFO: Loss too large (1648.991->1688.336)! Learning rate decreased to 0.00198.
2024-12-01-20:17:25-root-INFO: Loss too large (1648.991->1671.182)! Learning rate decreased to 0.00158.
2024-12-01-20:17:25-root-INFO: Loss too large (1648.991->1660.057)! Learning rate decreased to 0.00126.
2024-12-01-20:17:25-root-INFO: Loss too large (1648.991->1653.213)! Learning rate decreased to 0.00101.
2024-12-01-20:17:25-root-INFO: Loss too large (1648.991->1649.251)! Learning rate decreased to 0.00081.
2024-12-01-20:17:26-root-INFO: grad norm: 195.645 193.522 28.741
2024-12-01-20:17:26-root-INFO: Loss too large (1647.142->1658.212)! Learning rate decreased to 0.00065.
2024-12-01-20:17:26-root-INFO: Loss too large (1647.142->1649.820)! Learning rate decreased to 0.00052.
2024-12-01-20:17:27-root-INFO: grad norm: 208.731 206.436 30.864
2024-12-01-20:17:27-root-INFO: grad norm: 221.666 219.625 30.007
2024-12-01-20:17:28-root-INFO: grad norm: 232.909 230.614 32.621
2024-12-01-20:17:28-root-INFO: Loss Change: 1648.991 -> 1639.137
2024-12-01-20:17:28-root-INFO: Regularization Change: 0.000 -> 0.053
2024-12-01-20:17:28-root-INFO: Undo step: 170
2024-12-01-20:17:28-root-INFO: Undo step: 171
2024-12-01-20:17:28-root-INFO: Undo step: 172
2024-12-01-20:17:28-root-INFO: Undo step: 173
2024-12-01-20:17:28-root-INFO: Undo step: 174
2024-12-01-20:17:28-root-INFO: step: 175 lr_xt 0.00395074
2024-12-01-20:17:28-root-INFO: grad norm: 644.094 619.916 174.817
2024-12-01-20:17:29-root-INFO: grad norm: 653.240 639.908 131.303
2024-12-01-20:17:29-root-INFO: Loss too large (2260.108->2394.476)! Learning rate decreased to 0.00316.
2024-12-01-20:17:29-root-INFO: grad norm: 431.884 423.283 85.761
2024-12-01-20:17:30-root-INFO: grad norm: 454.719 448.024 77.743
2024-12-01-20:17:30-root-INFO: grad norm: 563.176 558.002 76.167
2024-12-01-20:17:30-root-INFO: Loss too large (2051.805->2115.295)! Learning rate decreased to 0.00253.
2024-12-01-20:17:31-root-INFO: Loss Change: 2761.241 -> 1959.308
2024-12-01-20:17:31-root-INFO: Regularization Change: 0.000 -> 10.322
2024-12-01-20:17:31-root-INFO: Learning rate of xt decay: 0.04835 -> 0.04893.
2024-12-01-20:17:31-root-INFO: Coefficient of regularization decay: 0.00021 -> 0.00021.
2024-12-01-20:17:31-root-INFO: step: 174 lr_xt 0.00411294
2024-12-01-20:17:31-root-INFO: grad norm: 522.687 518.788 63.721
2024-12-01-20:17:31-root-INFO: Loss too large (1964.493->2090.150)! Learning rate decreased to 0.00329.
2024-12-01-20:17:31-root-INFO: Loss too large (1964.493->2007.591)! Learning rate decreased to 0.00263.
2024-12-01-20:17:32-root-INFO: grad norm: 229.365 224.793 45.565
2024-12-01-20:17:32-root-INFO: grad norm: 212.155 208.802 37.574
2024-12-01-20:17:33-root-INFO: grad norm: 182.452 179.293 33.803
2024-12-01-20:17:33-root-INFO: Loss too large (1766.546->1770.445)! Learning rate decreased to 0.00211.
2024-12-01-20:17:33-root-INFO: grad norm: 229.687 225.703 42.593
2024-12-01-20:17:33-root-INFO: Loss too large (1757.228->1781.430)! Learning rate decreased to 0.00168.
2024-12-01-20:17:34-root-INFO: Loss Change: 1964.493 -> 1749.799
2024-12-01-20:17:34-root-INFO: Regularization Change: 0.000 -> 1.226
2024-12-01-20:17:34-root-INFO: Learning rate of xt decay: 0.04893 -> 0.04952.
2024-12-01-20:17:34-root-INFO: Coefficient of regularization decay: 0.00021 -> 0.00021.
2024-12-01-20:17:34-root-INFO: step: 173 lr_xt 0.00428111
2024-12-01-20:17:34-root-INFO: grad norm: 420.561 416.708 56.795
2024-12-01-20:17:34-root-INFO: Loss too large (1772.412->1940.742)! Learning rate decreased to 0.00342.
2024-12-01-20:17:34-root-INFO: Loss too large (1772.412->1906.089)! Learning rate decreased to 0.00274.
2024-12-01-20:17:35-root-INFO: Loss too large (1772.412->1869.162)! Learning rate decreased to 0.00219.
2024-12-01-20:17:35-root-INFO: Loss too large (1772.412->1830.607)! Learning rate decreased to 0.00175.
2024-12-01-20:17:35-root-INFO: Loss too large (1772.412->1792.742)! Learning rate decreased to 0.00140.
2024-12-01-20:17:35-root-INFO: grad norm: 262.562 258.370 46.734
2024-12-01-20:17:36-root-INFO: grad norm: 110.977 108.080 25.192
2024-12-01-20:17:36-root-INFO: grad norm: 115.035 111.995 26.272
2024-12-01-20:17:37-root-INFO: grad norm: 151.722 149.429 26.275
2024-12-01-20:17:37-root-INFO: Loss too large (1683.360->1683.432)! Learning rate decreased to 0.00112.
2024-12-01-20:17:37-root-INFO: Loss Change: 1772.412 -> 1678.646
2024-12-01-20:17:37-root-INFO: Regularization Change: 0.000 -> 0.384
2024-12-01-20:17:37-root-INFO: Learning rate of xt decay: 0.04952 -> 0.05011.
2024-12-01-20:17:37-root-INFO: Coefficient of regularization decay: 0.00021 -> 0.00022.
2024-12-01-20:17:37-root-INFO: step: 172 lr_xt 0.00445543
2024-12-01-20:17:38-root-INFO: grad norm: 127.423 124.463 27.306
2024-12-01-20:17:38-root-INFO: Loss too large (1667.871->1782.520)! Learning rate decreased to 0.00356.
2024-12-01-20:17:38-root-INFO: Loss too large (1667.871->1737.644)! Learning rate decreased to 0.00285.
2024-12-01-20:17:38-root-INFO: Loss too large (1667.871->1706.283)! Learning rate decreased to 0.00228.
2024-12-01-20:17:38-root-INFO: Loss too large (1667.871->1685.784)! Learning rate decreased to 0.00182.
2024-12-01-20:17:38-root-INFO: Loss too large (1667.871->1673.312)! Learning rate decreased to 0.00146.
2024-12-01-20:17:39-root-INFO: grad norm: 213.644 211.353 31.201
2024-12-01-20:17:39-root-INFO: Loss too large (1666.325->1683.495)! Learning rate decreased to 0.00117.
2024-12-01-20:17:39-root-INFO: Loss too large (1666.325->1669.291)! Learning rate decreased to 0.00093.
2024-12-01-20:17:40-root-INFO: grad norm: 189.405 186.360 33.825
2024-12-01-20:17:40-root-INFO: grad norm: 171.993 169.909 26.694
2024-12-01-20:17:41-root-INFO: grad norm: 167.934 165.093 30.759
2024-12-01-20:17:41-root-INFO: Loss Change: 1667.871 -> 1643.825
2024-12-01-20:17:41-root-INFO: Regularization Change: 0.000 -> 0.150
2024-12-01-20:17:41-root-INFO: Learning rate of xt decay: 0.05011 -> 0.05071.
2024-12-01-20:17:41-root-INFO: Coefficient of regularization decay: 0.00022 -> 0.00022.
2024-12-01-20:17:41-root-INFO: step: 171 lr_xt 0.00463611
2024-12-01-20:17:41-root-INFO: grad norm: 285.941 283.536 37.006
2024-12-01-20:17:41-root-INFO: Loss too large (1651.248->1838.666)! Learning rate decreased to 0.00371.
2024-12-01-20:17:42-root-INFO: Loss too large (1651.248->1813.057)! Learning rate decreased to 0.00297.
2024-12-01-20:17:42-root-INFO: Loss too large (1651.248->1784.012)! Learning rate decreased to 0.00237.
2024-12-01-20:17:42-root-INFO: Loss too large (1651.248->1752.573)! Learning rate decreased to 0.00190.
2024-12-01-20:17:42-root-INFO: Loss too large (1651.248->1720.520)! Learning rate decreased to 0.00152.
2024-12-01-20:17:42-root-INFO: Loss too large (1651.248->1690.473)! Learning rate decreased to 0.00122.
2024-12-01-20:17:42-root-INFO: Loss too large (1651.248->1665.479)! Learning rate decreased to 0.00097.
2024-12-01-20:17:43-root-INFO: grad norm: 264.787 260.945 44.945
2024-12-01-20:17:43-root-INFO: grad norm: 247.586 245.407 32.776
2024-12-01-20:17:44-root-INFO: grad norm: 246.392 242.885 41.422
2024-12-01-20:17:44-root-INFO: grad norm: 248.021 245.845 32.782
2024-12-01-20:17:45-root-INFO: Loss Change: 1651.248 -> 1627.145
2024-12-01-20:17:45-root-INFO: Regularization Change: 0.000 -> 0.171
2024-12-01-20:17:45-root-INFO: Learning rate of xt decay: 0.05071 -> 0.05132.
2024-12-01-20:17:45-root-INFO: Coefficient of regularization decay: 0.00022 -> 0.00022.
2024-12-01-20:17:45-root-INFO: step: 170 lr_xt 0.00482333
2024-12-01-20:17:45-root-INFO: grad norm: 206.395 203.245 35.927
2024-12-01-20:17:45-root-INFO: Loss too large (1615.746->1944.245)! Learning rate decreased to 0.00386.
2024-12-01-20:17:45-root-INFO: Loss too large (1615.746->1852.813)! Learning rate decreased to 0.00309.
2024-12-01-20:17:45-root-INFO: Loss too large (1615.746->1778.356)! Learning rate decreased to 0.00247.
2024-12-01-20:17:46-root-INFO: Loss too large (1615.746->1719.595)! Learning rate decreased to 0.00198.
2024-12-01-20:17:46-root-INFO: Loss too large (1615.746->1675.524)! Learning rate decreased to 0.00158.
2024-12-01-20:17:46-root-INFO: Loss too large (1615.746->1644.589)! Learning rate decreased to 0.00126.
2024-12-01-20:17:46-root-INFO: Loss too large (1615.746->1624.520)! Learning rate decreased to 0.00101.
2024-12-01-20:17:47-root-INFO: grad norm: 238.054 235.815 32.569
2024-12-01-20:17:47-root-INFO: Loss too large (1612.676->1613.232)! Learning rate decreased to 0.00081.
2024-12-01-20:17:47-root-INFO: grad norm: 190.022 187.109 33.144
2024-12-01-20:17:48-root-INFO: grad norm: 158.698 156.824 24.314
2024-12-01-20:17:48-root-INFO: grad norm: 141.958 139.371 26.976
2024-12-01-20:17:48-root-INFO: Loss Change: 1615.746 -> 1588.489
2024-12-01-20:17:48-root-INFO: Regularization Change: 0.000 -> 0.106
2024-12-01-20:17:48-root-INFO: Learning rate of xt decay: 0.05132 -> 0.05194.
2024-12-01-20:17:48-root-INFO: Coefficient of regularization decay: 0.00022 -> 0.00022.
2024-12-01-20:17:49-root-INFO: step: 169 lr_xt 0.00501730
2024-12-01-20:17:49-root-INFO: grad norm: 241.426 239.166 32.962
2024-12-01-20:17:49-root-INFO: Loss too large (1594.243->1783.955)! Learning rate decreased to 0.00401.
2024-12-01-20:17:49-root-INFO: Loss too large (1594.243->1759.459)! Learning rate decreased to 0.00321.
2024-12-01-20:17:49-root-INFO: Loss too large (1594.243->1731.159)! Learning rate decreased to 0.00257.
2024-12-01-20:17:49-root-INFO: Loss too large (1594.243->1700.175)! Learning rate decreased to 0.00206.
2024-12-01-20:17:50-root-INFO: Loss too large (1594.243->1668.398)! Learning rate decreased to 0.00164.
2024-12-01-20:17:50-root-INFO: Loss too large (1594.243->1638.729)! Learning rate decreased to 0.00132.
2024-12-01-20:17:50-root-INFO: Loss too large (1594.243->1614.343)! Learning rate decreased to 0.00105.
2024-12-01-20:17:50-root-INFO: Loss too large (1594.243->1597.040)! Learning rate decreased to 0.00084.
2024-12-01-20:17:50-root-INFO: grad norm: 208.701 205.803 34.659
2024-12-01-20:17:51-root-INFO: grad norm: 187.119 185.155 27.045
2024-12-01-20:17:51-root-INFO: grad norm: 174.326 171.744 29.894
2024-12-01-20:17:52-root-INFO: grad norm: 165.495 163.663 24.558
2024-12-01-20:17:52-root-INFO: Loss Change: 1594.243 -> 1567.434
2024-12-01-20:17:52-root-INFO: Regularization Change: 0.000 -> 0.108
2024-12-01-20:17:52-root-INFO: Learning rate of xt decay: 0.05194 -> 0.05256.
2024-12-01-20:17:52-root-INFO: Coefficient of regularization decay: 0.00022 -> 0.00022.
2024-12-01-20:17:52-root-INFO: step: 168 lr_xt 0.00521823
2024-12-01-20:17:52-root-INFO: grad norm: 70.846 68.286 18.874
2024-12-01-20:17:53-root-INFO: grad norm: 231.802 229.912 29.541
2024-12-01-20:17:53-root-INFO: Loss too large (1551.031->1750.434)! Learning rate decreased to 0.00417.
2024-12-01-20:17:53-root-INFO: Loss too large (1551.031->1728.845)! Learning rate decreased to 0.00334.
2024-12-01-20:17:53-root-INFO: Loss too large (1551.031->1702.634)! Learning rate decreased to 0.00267.
2024-12-01-20:17:54-root-INFO: Loss too large (1551.031->1672.587)! Learning rate decreased to 0.00214.
2024-12-01-20:17:54-root-INFO: Loss too large (1551.031->1640.212)! Learning rate decreased to 0.00171.
2024-12-01-20:17:54-root-INFO: Loss too large (1551.031->1608.386)! Learning rate decreased to 0.00137.
2024-12-01-20:17:54-root-INFO: Loss too large (1551.031->1580.966)! Learning rate decreased to 0.00109.
2024-12-01-20:17:54-root-INFO: Loss too large (1551.031->1560.727)! Learning rate decreased to 0.00088.
2024-12-01-20:17:55-root-INFO: grad norm: 240.587 237.854 36.161
2024-12-01-20:17:55-root-INFO: grad norm: 245.365 243.378 31.166
2024-12-01-20:17:56-root-INFO: grad norm: 247.671 244.927 36.762
2024-12-01-20:17:56-root-INFO: Loss Change: 1560.844 -> 1541.358
2024-12-01-20:17:56-root-INFO: Regularization Change: 0.000 -> 0.311
2024-12-01-20:17:56-root-INFO: Learning rate of xt decay: 0.05256 -> 0.05319.
2024-12-01-20:17:56-root-INFO: Coefficient of regularization decay: 0.00022 -> 0.00023.
2024-12-01-20:17:56-root-INFO: step: 167 lr_xt 0.00542633
2024-12-01-20:17:56-root-INFO: grad norm: 328.819 326.258 40.964
2024-12-01-20:17:56-root-INFO: Loss too large (1554.436->1766.616)! Learning rate decreased to 0.00434.
2024-12-01-20:17:57-root-INFO: Loss too large (1554.436->1749.137)! Learning rate decreased to 0.00347.
2024-12-01-20:17:57-root-INFO: Loss too large (1554.436->1727.110)! Learning rate decreased to 0.00278.
2024-12-01-20:17:57-root-INFO: Loss too large (1554.436->1699.774)! Learning rate decreased to 0.00222.
2024-12-01-20:17:57-root-INFO: Loss too large (1554.436->1667.321)! Learning rate decreased to 0.00178.
2024-12-01-20:17:57-root-INFO: Loss too large (1554.436->1630.883)! Learning rate decreased to 0.00142.
2024-12-01-20:17:57-root-INFO: Loss too large (1554.436->1593.647)! Learning rate decreased to 0.00114.
2024-12-01-20:17:58-root-INFO: Loss too large (1554.436->1561.286)! Learning rate decreased to 0.00091.
2024-12-01-20:17:58-root-INFO: grad norm: 282.047 279.056 40.961
2024-12-01-20:17:59-root-INFO: grad norm: 264.007 261.786 34.173
2024-12-01-20:17:59-root-INFO: grad norm: 250.857 248.169 36.625
2024-12-01-20:17:59-root-INFO: grad norm: 242.807 240.721 31.764
2024-12-01-20:18:00-root-INFO: Loss Change: 1554.436 -> 1519.257
2024-12-01-20:18:00-root-INFO: Regularization Change: 0.000 -> 0.153
2024-12-01-20:18:00-root-INFO: Learning rate of xt decay: 0.05319 -> 0.05383.
2024-12-01-20:18:00-root-INFO: Coefficient of regularization decay: 0.00023 -> 0.00023.
2024-12-01-20:18:00-root-INFO: step: 166 lr_xt 0.00564182
2024-12-01-20:18:00-root-INFO: grad norm: 142.897 140.768 24.576
2024-12-01-20:18:00-root-INFO: Loss too large (1507.954->1708.371)! Learning rate decreased to 0.00451.
2024-12-01-20:18:00-root-INFO: Loss too large (1507.954->1650.507)! Learning rate decreased to 0.00361.
2024-12-01-20:18:01-root-INFO: Loss too large (1507.954->1604.750)! Learning rate decreased to 0.00289.
2024-12-01-20:18:01-root-INFO: Loss too large (1507.954->1569.799)! Learning rate decreased to 0.00231.
2024-12-01-20:18:01-root-INFO: Loss too large (1507.954->1544.320)! Learning rate decreased to 0.00185.
2024-12-01-20:18:01-root-INFO: Loss too large (1507.954->1526.735)! Learning rate decreased to 0.00148.
2024-12-01-20:18:01-root-INFO: Loss too large (1507.954->1515.317)! Learning rate decreased to 0.00118.
2024-12-01-20:18:01-root-INFO: Loss too large (1507.954->1508.407)! Learning rate decreased to 0.00095.
2024-12-01-20:18:02-root-INFO: grad norm: 149.422 147.571 23.441
2024-12-01-20:18:02-root-INFO: grad norm: 159.122 157.053 25.581
2024-12-01-20:18:03-root-INFO: grad norm: 167.597 165.815 24.379
2024-12-01-20:18:03-root-INFO: grad norm: 177.606 175.524 27.116
2024-12-01-20:18:03-root-INFO: Loss Change: 1507.954 -> 1494.072
2024-12-01-20:18:03-root-INFO: Regularization Change: 0.000 -> 0.106
2024-12-01-20:18:03-root-INFO: Learning rate of xt decay: 0.05383 -> 0.05447.
2024-12-01-20:18:03-root-INFO: Coefficient of regularization decay: 0.00023 -> 0.00023.
2024-12-01-20:18:04-root-INFO: step: 165 lr_xt 0.00586491
2024-12-01-20:18:04-root-INFO: grad norm: 259.671 257.593 32.785
2024-12-01-20:18:04-root-INFO: Loss too large (1503.414->1714.696)! Learning rate decreased to 0.00469.
2024-12-01-20:18:04-root-INFO: Loss too large (1503.414->1695.742)! Learning rate decreased to 0.00375.
2024-12-01-20:18:04-root-INFO: Loss too large (1503.414->1671.614)! Learning rate decreased to 0.00300.
2024-12-01-20:18:04-root-INFO: Loss too large (1503.414->1642.315)! Learning rate decreased to 0.00240.
2024-12-01-20:18:05-root-INFO: Loss too large (1503.414->1608.614)! Learning rate decreased to 0.00192.
2024-12-01-20:18:05-root-INFO: Loss too large (1503.414->1572.568)! Learning rate decreased to 0.00154.
2024-12-01-20:18:05-root-INFO: Loss too large (1503.414->1538.537)! Learning rate decreased to 0.00123.
2024-12-01-20:18:05-root-INFO: Loss too large (1503.414->1511.729)! Learning rate decreased to 0.00098.
2024-12-01-20:18:05-root-INFO: grad norm: 251.697 249.063 36.320
2024-12-01-20:18:06-root-INFO: grad norm: 244.962 242.984 31.065
2024-12-01-20:18:06-root-INFO: grad norm: 235.245 232.811 33.748
2024-12-01-20:18:07-root-INFO: grad norm: 229.023 227.133 29.358
2024-12-01-20:18:07-root-INFO: Loss Change: 1503.414 -> 1477.865
2024-12-01-20:18:07-root-INFO: Regularization Change: 0.000 -> 0.144
2024-12-01-20:18:07-root-INFO: Undo step: 165
2024-12-01-20:18:07-root-INFO: Undo step: 166
2024-12-01-20:18:07-root-INFO: Undo step: 167
2024-12-01-20:18:07-root-INFO: Undo step: 168
2024-12-01-20:18:07-root-INFO: Undo step: 169
2024-12-01-20:18:07-root-INFO: step: 170 lr_xt 0.00482333
2024-12-01-20:18:07-root-INFO: grad norm: 448.757 440.099 87.722
2024-12-01-20:18:08-root-INFO: grad norm: 404.020 399.840 57.968
2024-12-01-20:18:08-root-INFO: grad norm: 447.998 444.118 58.835
2024-12-01-20:18:09-root-INFO: grad norm: 361.621 356.844 58.584
2024-12-01-20:18:09-root-INFO: grad norm: 470.248 467.247 53.041
2024-12-01-20:18:09-root-INFO: Loss too large (1845.579->1879.082)! Learning rate decreased to 0.00386.
2024-12-01-20:18:10-root-INFO: Loss Change: 2393.328 -> 1805.804
2024-12-01-20:18:10-root-INFO: Regularization Change: 0.000 -> 11.244
2024-12-01-20:18:10-root-INFO: Learning rate of xt decay: 0.05132 -> 0.05194.
2024-12-01-20:18:10-root-INFO: Coefficient of regularization decay: 0.00022 -> 0.00022.
2024-12-01-20:18:10-root-INFO: step: 169 lr_xt 0.00501730
2024-12-01-20:18:10-root-INFO: grad norm: 225.191 221.357 41.378
2024-12-01-20:18:11-root-INFO: grad norm: 232.645 229.849 35.959
2024-12-01-20:18:11-root-INFO: grad norm: 229.604 227.563 30.551
2024-12-01-20:18:11-root-INFO: Loss too large (1617.561->1648.266)! Learning rate decreased to 0.00401.
2024-12-01-20:18:12-root-INFO: grad norm: 229.657 226.729 36.553
2024-12-01-20:18:12-root-INFO: Loss too large (1611.722->1627.833)! Learning rate decreased to 0.00321.
2024-12-01-20:18:12-root-INFO: grad norm: 276.810 274.118 38.512
2024-12-01-20:18:12-root-INFO: Loss too large (1576.092->1628.448)! Learning rate decreased to 0.00257.
2024-12-01-20:18:13-root-INFO: Loss too large (1576.092->1588.531)! Learning rate decreased to 0.00206.
2024-12-01-20:18:13-root-INFO: Loss Change: 1798.713 -> 1558.315
2024-12-01-20:18:13-root-INFO: Regularization Change: 0.000 -> 2.056
2024-12-01-20:18:13-root-INFO: Learning rate of xt decay: 0.05194 -> 0.05256.
2024-12-01-20:18:13-root-INFO: Coefficient of regularization decay: 0.00022 -> 0.00022.
2024-12-01-20:18:13-root-INFO: step: 168 lr_xt 0.00521823
2024-12-01-20:18:13-root-INFO: grad norm: 215.392 212.450 35.481
2024-12-01-20:18:13-root-INFO: Loss too large (1544.718->1755.787)! Learning rate decreased to 0.00417.
2024-12-01-20:18:14-root-INFO: Loss too large (1544.718->1668.703)! Learning rate decreased to 0.00334.
2024-12-01-20:18:14-root-INFO: Loss too large (1544.718->1605.360)! Learning rate decreased to 0.00267.
2024-12-01-20:18:14-root-INFO: Loss too large (1544.718->1561.798)! Learning rate decreased to 0.00214.
2024-12-01-20:18:14-root-INFO: grad norm: 231.705 229.567 31.404
2024-12-01-20:18:14-root-INFO: Loss too large (1534.591->1537.387)! Learning rate decreased to 0.00171.
2024-12-01-20:18:15-root-INFO: grad norm: 188.518 186.066 30.312
2024-12-01-20:18:15-root-INFO: grad norm: 171.175 169.118 26.456
2024-12-01-20:18:16-root-INFO: grad norm: 173.853 171.611 27.832
2024-12-01-20:18:16-root-INFO: Loss Change: 1544.718 -> 1496.034
2024-12-01-20:18:16-root-INFO: Regularization Change: 0.000 -> 0.430
2024-12-01-20:18:16-root-INFO: Learning rate of xt decay: 0.05256 -> 0.05319.
2024-12-01-20:18:16-root-INFO: Coefficient of regularization decay: 0.00022 -> 0.00023.
2024-12-01-20:18:16-root-INFO: step: 167 lr_xt 0.00542633
2024-12-01-20:18:17-root-INFO: grad norm: 233.213 230.962 32.327
2024-12-01-20:18:17-root-INFO: Loss too large (1501.863->1665.013)! Learning rate decreased to 0.00434.
2024-12-01-20:18:17-root-INFO: Loss too large (1501.863->1629.112)! Learning rate decreased to 0.00347.
2024-12-01-20:18:17-root-INFO: Loss too large (1501.863->1590.505)! Learning rate decreased to 0.00278.
2024-12-01-20:18:17-root-INFO: Loss too large (1501.863->1552.698)! Learning rate decreased to 0.00222.
2024-12-01-20:18:17-root-INFO: Loss too large (1501.863->1520.201)! Learning rate decreased to 0.00178.
2024-12-01-20:18:18-root-INFO: grad norm: 233.180 230.541 34.979
2024-12-01-20:18:18-root-INFO: grad norm: 233.896 231.790 31.316
2024-12-01-20:18:19-root-INFO: grad norm: 235.456 232.885 34.695
2024-12-01-20:18:19-root-INFO: grad norm: 235.955 233.872 31.281
2024-12-01-20:18:19-root-INFO: Loss Change: 1501.863 -> 1475.724
2024-12-01-20:18:19-root-INFO: Regularization Change: 0.000 -> 0.417
2024-12-01-20:18:19-root-INFO: Learning rate of xt decay: 0.05319 -> 0.05383.
2024-12-01-20:18:19-root-INFO: Coefficient of regularization decay: 0.00023 -> 0.00023.
2024-12-01-20:18:20-root-INFO: step: 166 lr_xt 0.00564182
2024-12-01-20:18:20-root-INFO: grad norm: 208.064 205.824 30.448
2024-12-01-20:18:20-root-INFO: Loss too large (1462.724->1716.213)! Learning rate decreased to 0.00451.
2024-12-01-20:18:20-root-INFO: Loss too large (1462.724->1629.313)! Learning rate decreased to 0.00361.
2024-12-01-20:18:20-root-INFO: Loss too large (1462.724->1563.768)! Learning rate decreased to 0.00289.
2024-12-01-20:18:20-root-INFO: Loss too large (1462.724->1515.655)! Learning rate decreased to 0.00231.
2024-12-01-20:18:21-root-INFO: Loss too large (1462.724->1482.154)! Learning rate decreased to 0.00185.
2024-12-01-20:18:21-root-INFO: grad norm: 222.655 220.687 29.535
2024-12-01-20:18:22-root-INFO: grad norm: 234.402 231.984 33.585
2024-12-01-20:18:22-root-INFO: grad norm: 238.033 236.095 30.314
2024-12-01-20:18:23-root-INFO: grad norm: 237.883 235.452 33.924
2024-12-01-20:18:23-root-INFO: Loss Change: 1462.724 -> 1445.479
2024-12-01-20:18:23-root-INFO: Regularization Change: 0.000 -> 0.400
2024-12-01-20:18:23-root-INFO: Learning rate of xt decay: 0.05383 -> 0.05447.
2024-12-01-20:18:23-root-INFO: Coefficient of regularization decay: 0.00023 -> 0.00023.
2024-12-01-20:18:23-root-INFO: step: 165 lr_xt 0.00586491
2024-12-01-20:18:23-root-INFO: grad norm: 267.933 266.038 31.813
2024-12-01-20:18:23-root-INFO: Loss too large (1456.094->1631.102)! Learning rate decreased to 0.00469.
2024-12-01-20:18:23-root-INFO: Loss too large (1456.094->1597.479)! Learning rate decreased to 0.00375.
2024-12-01-20:18:24-root-INFO: Loss too large (1456.094->1557.611)! Learning rate decreased to 0.00300.
2024-12-01-20:18:24-root-INFO: Loss too large (1456.094->1514.410)! Learning rate decreased to 0.00240.
2024-12-01-20:18:24-root-INFO: Loss too large (1456.094->1473.117)! Learning rate decreased to 0.00192.
2024-12-01-20:18:24-root-INFO: grad norm: 249.612 247.055 35.640
2024-12-01-20:18:25-root-INFO: grad norm: 239.418 237.569 29.694
2024-12-01-20:18:25-root-INFO: grad norm: 232.058 229.721 32.855
2024-12-01-20:18:26-root-INFO: grad norm: 227.495 225.674 28.724
2024-12-01-20:18:26-root-INFO: Loss Change: 1456.094 -> 1414.957
2024-12-01-20:18:26-root-INFO: Regularization Change: 0.000 -> 0.469
2024-12-01-20:18:26-root-INFO: Learning rate of xt decay: 0.05447 -> 0.05513.
2024-12-01-20:18:26-root-INFO: Coefficient of regularization decay: 0.00023 -> 0.00023.
2024-12-01-20:18:26-root-INFO: step: 164 lr_xt 0.00609585
2024-12-01-20:18:27-root-INFO: grad norm: 195.080 192.982 28.536
2024-12-01-20:18:27-root-INFO: Loss too large (1404.857->1644.557)! Learning rate decreased to 0.00488.
2024-12-01-20:18:27-root-INFO: Loss too large (1404.857->1561.950)! Learning rate decreased to 0.00390.
2024-12-01-20:18:27-root-INFO: Loss too large (1404.857->1500.532)! Learning rate decreased to 0.00312.
2024-12-01-20:18:27-root-INFO: Loss too large (1404.857->1455.882)! Learning rate decreased to 0.00250.
2024-12-01-20:18:27-root-INFO: Loss too large (1404.857->1424.877)! Learning rate decreased to 0.00200.
2024-12-01-20:18:28-root-INFO: grad norm: 206.514 204.701 27.304
2024-12-01-20:18:28-root-INFO: grad norm: 217.851 215.688 30.619
2024-12-01-20:18:28-root-INFO: Loss too large (1399.004->1399.812)! Learning rate decreased to 0.00160.
2024-12-01-20:18:29-root-INFO: grad norm: 159.155 157.365 23.807
2024-12-01-20:18:29-root-INFO: grad norm: 125.654 124.118 19.584
2024-12-01-20:18:30-root-INFO: Loss Change: 1404.857 -> 1370.272
2024-12-01-20:18:30-root-INFO: Regularization Change: 0.000 -> 0.262
2024-12-01-20:18:30-root-INFO: Learning rate of xt decay: 0.05513 -> 0.05579.
2024-12-01-20:18:30-root-INFO: Coefficient of regularization decay: 0.00023 -> 0.00024.
2024-12-01-20:18:30-root-INFO: step: 163 lr_xt 0.00633485
2024-12-01-20:18:30-root-INFO: grad norm: 148.377 146.603 22.877
2024-12-01-20:18:30-root-INFO: Loss too large (1371.564->1513.318)! Learning rate decreased to 0.00507.
2024-12-01-20:18:30-root-INFO: Loss too large (1371.564->1475.170)! Learning rate decreased to 0.00405.
2024-12-01-20:18:31-root-INFO: Loss too large (1371.564->1438.190)! Learning rate decreased to 0.00324.
2024-12-01-20:18:31-root-INFO: Loss too large (1371.564->1406.850)! Learning rate decreased to 0.00259.
2024-12-01-20:18:31-root-INFO: Loss too large (1371.564->1384.135)! Learning rate decreased to 0.00208.
2024-12-01-20:18:31-root-INFO: grad norm: 185.391 183.571 25.913
2024-12-01-20:18:32-root-INFO: Loss too large (1370.054->1375.579)! Learning rate decreased to 0.00166.
2024-12-01-20:18:32-root-INFO: grad norm: 154.919 153.272 22.527
2024-12-01-20:18:33-root-INFO: grad norm: 130.379 128.896 19.609
2024-12-01-20:18:33-root-INFO: grad norm: 119.945 118.297 19.817
2024-12-01-20:18:34-root-INFO: Loss Change: 1371.564 -> 1345.082
2024-12-01-20:18:34-root-INFO: Regularization Change: 0.000 -> 0.225
2024-12-01-20:18:34-root-INFO: Learning rate of xt decay: 0.05579 -> 0.05646.
2024-12-01-20:18:34-root-INFO: Coefficient of regularization decay: 0.00024 -> 0.00024.
2024-12-01-20:18:34-root-INFO: step: 162 lr_xt 0.00658217
2024-12-01-20:18:34-root-INFO: grad norm: 70.018 67.597 18.255
2024-12-01-20:18:34-root-INFO: Loss too large (1342.632->1348.653)! Learning rate decreased to 0.00527.
2024-12-01-20:18:35-root-INFO: grad norm: 173.151 171.601 23.114
2024-12-01-20:18:35-root-INFO: Loss too large (1342.075->1473.137)! Learning rate decreased to 0.00421.
2024-12-01-20:18:35-root-INFO: Loss too large (1342.075->1434.212)! Learning rate decreased to 0.00337.
2024-12-01-20:18:35-root-INFO: Loss too large (1342.075->1396.448)! Learning rate decreased to 0.00270.
2024-12-01-20:18:35-root-INFO: Loss too large (1342.075->1365.102)! Learning rate decreased to 0.00216.
2024-12-01-20:18:35-root-INFO: Loss too large (1342.075->1343.565)! Learning rate decreased to 0.00173.
2024-12-01-20:18:36-root-INFO: grad norm: 153.903 152.435 21.207
2024-12-01-20:18:36-root-INFO: grad norm: 145.198 143.560 21.744
2024-12-01-20:18:37-root-INFO: grad norm: 135.042 133.684 19.106
2024-12-01-20:18:37-root-INFO: Loss Change: 1342.632 -> 1319.304
2024-12-01-20:18:37-root-INFO: Regularization Change: 0.000 -> 0.390
2024-12-01-20:18:37-root-INFO: Learning rate of xt decay: 0.05646 -> 0.05714.
2024-12-01-20:18:37-root-INFO: Coefficient of regularization decay: 0.00024 -> 0.00024.
2024-12-01-20:18:37-root-INFO: step: 161 lr_xt 0.00683803
2024-12-01-20:18:37-root-INFO: grad norm: 163.045 161.517 22.267
2024-12-01-20:18:38-root-INFO: Loss too large (1323.141->1488.982)! Learning rate decreased to 0.00547.
2024-12-01-20:18:38-root-INFO: Loss too large (1323.141->1451.196)! Learning rate decreased to 0.00438.
2024-12-01-20:18:38-root-INFO: Loss too large (1323.141->1410.661)! Learning rate decreased to 0.00350.
2024-12-01-20:18:38-root-INFO: Loss too large (1323.141->1372.245)! Learning rate decreased to 0.00280.
2024-12-01-20:18:38-root-INFO: Loss too large (1323.141->1341.725)! Learning rate decreased to 0.00224.
2024-12-01-20:18:39-root-INFO: grad norm: 210.995 209.086 28.315
2024-12-01-20:18:39-root-INFO: Loss too large (1321.849->1333.718)! Learning rate decreased to 0.00179.
2024-12-01-20:18:39-root-INFO: grad norm: 172.279 170.824 22.344
2024-12-01-20:18:40-root-INFO: grad norm: 131.668 130.281 19.057
2024-12-01-20:18:40-root-INFO: grad norm: 120.386 118.946 18.570
2024-12-01-20:18:41-root-INFO: Loss Change: 1323.141 -> 1292.886
2024-12-01-20:18:41-root-INFO: Regularization Change: 0.000 -> 0.256
2024-12-01-20:18:41-root-INFO: Learning rate of xt decay: 0.05714 -> 0.05782.
2024-12-01-20:18:41-root-INFO: Coefficient of regularization decay: 0.00024 -> 0.00024.
2024-12-01-20:18:41-root-INFO: step: 160 lr_xt 0.00710269
2024-12-01-20:18:41-root-INFO: grad norm: 61.800 59.944 15.032
2024-12-01-20:18:41-root-INFO: Loss too large (1289.483->1293.012)! Learning rate decreased to 0.00568.
2024-12-01-20:18:42-root-INFO: grad norm: 147.772 146.453 19.698
2024-12-01-20:18:42-root-INFO: Loss too large (1288.074->1408.255)! Learning rate decreased to 0.00455.
2024-12-01-20:18:42-root-INFO: Loss too large (1288.074->1368.936)! Learning rate decreased to 0.00364.
2024-12-01-20:18:42-root-INFO: Loss too large (1288.074->1332.636)! Learning rate decreased to 0.00291.
2024-12-01-20:18:42-root-INFO: Loss too large (1288.074->1304.731)! Learning rate decreased to 0.00233.
2024-12-01-20:18:43-root-INFO: grad norm: 198.798 197.129 25.702
2024-12-01-20:18:43-root-INFO: Loss too large (1287.113->1299.939)! Learning rate decreased to 0.00186.
2024-12-01-20:18:44-root-INFO: grad norm: 163.963 162.557 21.426
2024-12-01-20:18:44-root-INFO: grad norm: 121.903 120.662 17.350
2024-12-01-20:18:45-root-INFO: Loss Change: 1289.483 -> 1266.839
2024-12-01-20:18:45-root-INFO: Regularization Change: 0.000 -> 0.405
2024-12-01-20:18:45-root-INFO: Undo step: 160
2024-12-01-20:18:45-root-INFO: Undo step: 161
2024-12-01-20:18:45-root-INFO: Undo step: 162
2024-12-01-20:18:45-root-INFO: Undo step: 163
2024-12-01-20:18:45-root-INFO: Undo step: 164
2024-12-01-20:18:45-root-INFO: step: 165 lr_xt 0.00586491
2024-12-01-20:18:45-root-INFO: grad norm: 423.889 417.187 75.078
2024-12-01-20:18:46-root-INFO: grad norm: 460.391 450.029 97.129
2024-12-01-20:18:46-root-INFO: Loss too large (1794.497->2386.437)! Learning rate decreased to 0.00469.
2024-12-01-20:18:46-root-INFO: Loss too large (1794.497->2113.237)! Learning rate decreased to 0.00375.
2024-12-01-20:18:46-root-INFO: Loss too large (1794.497->1921.620)! Learning rate decreased to 0.00300.
2024-12-01-20:18:47-root-INFO: grad norm: 501.585 497.225 65.997
2024-12-01-20:18:47-root-INFO: grad norm: 278.268 272.878 54.503
2024-12-01-20:18:48-root-INFO: grad norm: 174.179 169.993 37.957
2024-12-01-20:18:48-root-INFO: Loss Change: 2146.676 -> 1449.322
2024-12-01-20:18:48-root-INFO: Regularization Change: 0.000 -> 10.331
2024-12-01-20:18:48-root-INFO: Learning rate of xt decay: 0.05447 -> 0.05513.
2024-12-01-20:18:48-root-INFO: Coefficient of regularization decay: 0.00023 -> 0.00023.
2024-12-01-20:18:48-root-INFO: step: 164 lr_xt 0.00609585
2024-12-01-20:18:48-root-INFO: grad norm: 246.040 243.083 38.029
2024-12-01-20:18:49-root-INFO: Loss too large (1452.482->1636.902)! Learning rate decreased to 0.00488.
2024-12-01-20:18:49-root-INFO: Loss too large (1452.482->1612.302)! Learning rate decreased to 0.00390.
2024-12-01-20:18:49-root-INFO: Loss too large (1452.482->1580.445)! Learning rate decreased to 0.00312.
2024-12-01-20:18:49-root-INFO: Loss too large (1452.482->1541.773)! Learning rate decreased to 0.00250.
2024-12-01-20:18:49-root-INFO: Loss too large (1452.482->1500.552)! Learning rate decreased to 0.00200.
2024-12-01-20:18:49-root-INFO: Loss too large (1452.482->1464.472)! Learning rate decreased to 0.00160.
2024-12-01-20:18:50-root-INFO: grad norm: 293.579 289.331 49.762
2024-12-01-20:18:50-root-INFO: Loss too large (1439.704->1446.471)! Learning rate decreased to 0.00128.
2024-12-01-20:18:51-root-INFO: grad norm: 238.043 234.914 38.470
2024-12-01-20:18:51-root-INFO: grad norm: 190.435 187.207 34.912
2024-12-01-20:18:52-root-INFO: grad norm: 178.538 175.496 32.815
2024-12-01-20:18:52-root-INFO: Loss Change: 1452.482 -> 1383.136
2024-12-01-20:18:52-root-INFO: Regularization Change: 0.000 -> 0.429
2024-12-01-20:18:52-root-INFO: Learning rate of xt decay: 0.05513 -> 0.05579.
2024-12-01-20:18:52-root-INFO: Coefficient of regularization decay: 0.00023 -> 0.00024.
2024-12-01-20:18:52-root-INFO: step: 163 lr_xt 0.00633485
2024-12-01-20:18:52-root-INFO: grad norm: 117.278 113.971 27.653
2024-12-01-20:18:52-root-INFO: Loss too large (1372.246->1442.845)! Learning rate decreased to 0.00507.
2024-12-01-20:18:53-root-INFO: Loss too large (1372.246->1414.151)! Learning rate decreased to 0.00405.
2024-12-01-20:18:53-root-INFO: Loss too large (1372.246->1393.988)! Learning rate decreased to 0.00324.
2024-12-01-20:18:53-root-INFO: Loss too large (1372.246->1380.520)! Learning rate decreased to 0.00259.
2024-12-01-20:18:54-root-INFO: grad norm: 215.915 213.187 34.211
2024-12-01-20:18:54-root-INFO: Loss too large (1372.092->1436.668)! Learning rate decreased to 0.00208.
2024-12-01-20:18:54-root-INFO: Loss too large (1372.092->1396.557)! Learning rate decreased to 0.00166.
2024-12-01-20:18:55-root-INFO: grad norm: 302.348 298.762 46.426
2024-12-01-20:18:55-root-INFO: Loss too large (1369.577->1392.630)! Learning rate decreased to 0.00133.
2024-12-01-20:18:55-root-INFO: grad norm: 249.984 247.300 36.533
2024-12-01-20:18:56-root-INFO: grad norm: 183.238 180.647 30.711
2024-12-01-20:18:56-root-INFO: Loss Change: 1372.246 -> 1336.980
2024-12-01-20:18:56-root-INFO: Regularization Change: 0.000 -> 0.401
2024-12-01-20:18:56-root-INFO: Learning rate of xt decay: 0.05579 -> 0.05646.
2024-12-01-20:18:56-root-INFO: Coefficient of regularization decay: 0.00024 -> 0.00024.
2024-12-01-20:18:56-root-INFO: step: 162 lr_xt 0.00658217
2024-12-01-20:18:56-root-INFO: grad norm: 225.328 222.474 35.751
2024-12-01-20:18:56-root-INFO: Loss too large (1347.128->1569.499)! Learning rate decreased to 0.00527.
2024-12-01-20:18:57-root-INFO: Loss too large (1347.128->1546.021)! Learning rate decreased to 0.00421.
2024-12-01-20:18:57-root-INFO: Loss too large (1347.128->1512.499)! Learning rate decreased to 0.00337.
2024-12-01-20:18:57-root-INFO: Loss too large (1347.128->1468.292)! Learning rate decreased to 0.00270.
2024-12-01-20:18:57-root-INFO: Loss too large (1347.128->1417.591)! Learning rate decreased to 0.00216.
2024-12-01-20:18:57-root-INFO: Loss too large (1347.128->1371.724)! Learning rate decreased to 0.00173.
2024-12-01-20:18:58-root-INFO: grad norm: 307.869 304.530 45.221
2024-12-01-20:18:58-root-INFO: Loss too large (1340.747->1367.860)! Learning rate decreased to 0.00138.
2024-12-01-20:18:58-root-INFO: Loss too large (1340.747->1342.414)! Learning rate decreased to 0.00110.
2024-12-01-20:18:58-root-INFO: grad norm: 194.129 191.535 31.629
2024-12-01-20:18:59-root-INFO: grad norm: 95.380 92.863 21.766
2024-12-01-20:18:59-root-INFO: grad norm: 80.001 77.005 21.687
2024-12-01-20:19:00-root-INFO: Loss Change: 1347.128 -> 1297.123
2024-12-01-20:19:00-root-INFO: Regularization Change: 0.000 -> 0.214
2024-12-01-20:19:00-root-INFO: Learning rate of xt decay: 0.05646 -> 0.05714.
2024-12-01-20:19:00-root-INFO: Coefficient of regularization decay: 0.00024 -> 0.00024.
2024-12-01-20:19:00-root-INFO: step: 161 lr_xt 0.00683803
2024-12-01-20:19:00-root-INFO: grad norm: 72.202 69.049 21.103
2024-12-01-20:19:00-root-INFO: Loss too large (1293.605->1299.342)! Learning rate decreased to 0.00547.
2024-12-01-20:19:00-root-INFO: grad norm: 266.623 263.930 37.798
2024-12-01-20:19:01-root-INFO: Loss too large (1290.989->1613.273)! Learning rate decreased to 0.00438.
2024-12-01-20:19:01-root-INFO: Loss too large (1290.989->1514.190)! Learning rate decreased to 0.00350.
2024-12-01-20:19:01-root-INFO: Loss too large (1290.989->1441.295)! Learning rate decreased to 0.00280.
2024-12-01-20:19:01-root-INFO: Loss too large (1290.989->1386.914)! Learning rate decreased to 0.00224.
2024-12-01-20:19:01-root-INFO: Loss too large (1290.989->1346.376)! Learning rate decreased to 0.00179.
2024-12-01-20:19:01-root-INFO: Loss too large (1290.989->1316.837)! Learning rate decreased to 0.00143.
2024-12-01-20:19:01-root-INFO: Loss too large (1290.989->1296.285)! Learning rate decreased to 0.00115.
2024-12-01-20:19:02-root-INFO: grad norm: 174.726 172.718 26.415
2024-12-01-20:19:02-root-INFO: grad norm: 81.183 79.123 18.169
2024-12-01-20:19:03-root-INFO: grad norm: 68.634 66.172 18.221
2024-12-01-20:19:03-root-INFO: Loss Change: 1293.605 -> 1259.266
2024-12-01-20:19:03-root-INFO: Regularization Change: 0.000 -> 0.355
2024-12-01-20:19:03-root-INFO: Learning rate of xt decay: 0.05714 -> 0.05782.
2024-12-01-20:19:03-root-INFO: Coefficient of regularization decay: 0.00024 -> 0.00024.
2024-12-01-20:19:03-root-INFO: step: 160 lr_xt 0.00710269
2024-12-01-20:19:04-root-INFO: grad norm: 78.114 75.567 19.785
2024-12-01-20:19:04-root-INFO: Loss too large (1259.236->1329.271)! Learning rate decreased to 0.00568.
2024-12-01-20:19:04-root-INFO: Loss too large (1259.236->1298.792)! Learning rate decreased to 0.00455.
2024-12-01-20:19:04-root-INFO: Loss too large (1259.236->1278.240)! Learning rate decreased to 0.00364.
2024-12-01-20:19:04-root-INFO: Loss too large (1259.236->1265.984)! Learning rate decreased to 0.00291.
2024-12-01-20:19:04-root-INFO: Loss too large (1259.236->1259.330)! Learning rate decreased to 0.00233.
2024-12-01-20:19:05-root-INFO: grad norm: 145.493 143.713 22.688
2024-12-01-20:19:05-root-INFO: Loss too large (1256.064->1271.938)! Learning rate decreased to 0.00186.
2024-12-01-20:19:05-root-INFO: Loss too large (1256.064->1261.565)! Learning rate decreased to 0.00149.
2024-12-01-20:19:06-root-INFO: grad norm: 141.750 139.812 23.359
2024-12-01-20:19:06-root-INFO: grad norm: 135.158 133.489 21.170
2024-12-01-20:19:07-root-INFO: grad norm: 132.770 130.885 22.297
2024-12-01-20:19:07-root-INFO: Loss Change: 1259.236 -> 1239.045
2024-12-01-20:19:07-root-INFO: Regularization Change: 0.000 -> 0.207
2024-12-01-20:19:07-root-INFO: Learning rate of xt decay: 0.05782 -> 0.05852.
2024-12-01-20:19:07-root-INFO: Coefficient of regularization decay: 0.00024 -> 0.00024.
2024-12-01-20:19:07-root-INFO: step: 159 lr_xt 0.00737641
2024-12-01-20:19:08-root-INFO: grad norm: 87.649 85.805 17.881
2024-12-01-20:19:08-root-INFO: Loss too large (1232.861->1289.494)! Learning rate decreased to 0.00590.
2024-12-01-20:19:08-root-INFO: Loss too large (1232.861->1268.862)! Learning rate decreased to 0.00472.
2024-12-01-20:19:08-root-INFO: Loss too large (1232.861->1254.049)! Learning rate decreased to 0.00378.
2024-12-01-20:19:08-root-INFO: Loss too large (1232.861->1243.790)! Learning rate decreased to 0.00302.
2024-12-01-20:19:08-root-INFO: Loss too large (1232.861->1237.009)! Learning rate decreased to 0.00242.
2024-12-01-20:19:09-root-INFO: grad norm: 134.350 132.648 21.320
2024-12-01-20:19:09-root-INFO: Loss too large (1232.787->1245.058)! Learning rate decreased to 0.00193.
2024-12-01-20:19:10-root-INFO: grad norm: 204.060 202.121 28.063
2024-12-01-20:19:10-root-INFO: Loss too large (1231.009->1246.773)! Learning rate decreased to 0.00155.
2024-12-01-20:19:10-root-INFO: Loss too large (1231.009->1233.744)! Learning rate decreased to 0.00124.
2024-12-01-20:19:10-root-INFO: grad norm: 135.446 133.780 21.183
2024-12-01-20:19:11-root-INFO: grad norm: 65.777 63.943 15.425
2024-12-01-20:19:11-root-INFO: Loss Change: 1232.861 -> 1211.548
2024-12-01-20:19:11-root-INFO: Regularization Change: 0.000 -> 0.169
2024-12-01-20:19:11-root-INFO: Learning rate of xt decay: 0.05852 -> 0.05922.
2024-12-01-20:19:11-root-INFO: Coefficient of regularization decay: 0.00024 -> 0.00025.
2024-12-01-20:19:11-root-INFO: step: 158 lr_xt 0.00765943
2024-12-01-20:19:12-root-INFO: grad norm: 95.000 92.954 19.611
2024-12-01-20:19:12-root-INFO: Loss too large (1213.000->1354.320)! Learning rate decreased to 0.00613.
2024-12-01-20:19:12-root-INFO: Loss too large (1213.000->1309.407)! Learning rate decreased to 0.00490.
2024-12-01-20:19:12-root-INFO: Loss too large (1213.000->1269.260)! Learning rate decreased to 0.00392.
2024-12-01-20:19:12-root-INFO: Loss too large (1213.000->1240.316)! Learning rate decreased to 0.00314.
2024-12-01-20:19:12-root-INFO: Loss too large (1213.000->1222.756)! Learning rate decreased to 0.00251.
2024-12-01-20:19:13-root-INFO: Loss too large (1213.000->1213.333)! Learning rate decreased to 0.00201.
2024-12-01-20:19:13-root-INFO: grad norm: 131.449 129.837 20.526
2024-12-01-20:19:13-root-INFO: Loss too large (1208.818->1211.788)! Learning rate decreased to 0.00161.
2024-12-01-20:19:14-root-INFO: grad norm: 119.823 118.147 19.971
2024-12-01-20:19:14-root-INFO: grad norm: 101.338 99.838 17.372
2024-12-01-20:19:15-root-INFO: grad norm: 95.997 94.332 17.804
2024-12-01-20:19:15-root-INFO: Loss Change: 1213.000 -> 1191.033
2024-12-01-20:19:15-root-INFO: Regularization Change: 0.000 -> 0.194
2024-12-01-20:19:15-root-INFO: Learning rate of xt decay: 0.05922 -> 0.05993.
2024-12-01-20:19:15-root-INFO: Coefficient of regularization decay: 0.00025 -> 0.00025.
2024-12-01-20:19:15-root-INFO: step: 157 lr_xt 0.00795203
2024-12-01-20:19:15-root-INFO: grad norm: 56.336 53.692 17.058
2024-12-01-20:19:16-root-INFO: grad norm: 184.763 183.174 24.173
2024-12-01-20:19:16-root-INFO: Loss too large (1179.135->1435.743)! Learning rate decreased to 0.00636.
2024-12-01-20:19:16-root-INFO: Loss too large (1179.135->1356.563)! Learning rate decreased to 0.00509.
2024-12-01-20:19:16-root-INFO: Loss too large (1179.135->1300.089)! Learning rate decreased to 0.00407.
2024-12-01-20:19:17-root-INFO: Loss too large (1179.135->1258.979)! Learning rate decreased to 0.00326.
2024-12-01-20:19:17-root-INFO: Loss too large (1179.135->1228.721)! Learning rate decreased to 0.00261.
2024-12-01-20:19:17-root-INFO: Loss too large (1179.135->1206.600)! Learning rate decreased to 0.00208.
2024-12-01-20:19:17-root-INFO: Loss too large (1179.135->1190.873)! Learning rate decreased to 0.00167.
2024-12-01-20:19:17-root-INFO: Loss too large (1179.135->1180.228)! Learning rate decreased to 0.00133.
2024-12-01-20:19:18-root-INFO: grad norm: 115.881 114.382 18.582
2024-12-01-20:19:18-root-INFO: grad norm: 51.751 49.985 13.403
2024-12-01-20:19:19-root-INFO: grad norm: 46.106 44.025 13.694
2024-12-01-20:19:19-root-INFO: Loss Change: 1188.630 -> 1158.937
2024-12-01-20:19:19-root-INFO: Regularization Change: 0.000 -> 0.407
2024-12-01-20:19:19-root-INFO: Learning rate of xt decay: 0.05993 -> 0.06065.
2024-12-01-20:19:19-root-INFO: Coefficient of regularization decay: 0.00025 -> 0.00025.
2024-12-01-20:19:19-root-INFO: step: 156 lr_xt 0.00825448
2024-12-01-20:19:19-root-INFO: grad norm: 62.022 60.207 14.895
2024-12-01-20:19:19-root-INFO: Loss too large (1157.417->1213.568)! Learning rate decreased to 0.00660.
2024-12-01-20:19:20-root-INFO: Loss too large (1157.417->1186.428)! Learning rate decreased to 0.00528.
2024-12-01-20:19:20-root-INFO: Loss too large (1157.417->1170.005)! Learning rate decreased to 0.00423.
2024-12-01-20:19:20-root-INFO: Loss too large (1157.417->1161.004)! Learning rate decreased to 0.00338.
2024-12-01-20:19:20-root-INFO: grad norm: 145.111 143.749 19.839
2024-12-01-20:19:20-root-INFO: Loss too large (1156.444->1186.345)! Learning rate decreased to 0.00270.
2024-12-01-20:19:21-root-INFO: Loss too large (1156.444->1171.773)! Learning rate decreased to 0.00216.
2024-12-01-20:19:21-root-INFO: Loss too large (1156.444->1161.715)! Learning rate decreased to 0.00173.
2024-12-01-20:19:21-root-INFO: grad norm: 115.785 114.429 17.670
2024-12-01-20:19:22-root-INFO: grad norm: 71.337 69.994 13.780
2024-12-01-20:19:22-root-INFO: grad norm: 64.719 63.161 14.115
2024-12-01-20:19:23-root-INFO: Loss Change: 1157.417 -> 1138.585
2024-12-01-20:19:23-root-INFO: Regularization Change: 0.000 -> 0.198
2024-12-01-20:19:23-root-INFO: Learning rate of xt decay: 0.06065 -> 0.06138.
2024-12-01-20:19:23-root-INFO: Coefficient of regularization decay: 0.00025 -> 0.00025.
2024-12-01-20:19:23-root-INFO: step: 155 lr_xt 0.00856705
2024-12-01-20:19:23-root-INFO: grad norm: 50.176 48.107 14.263
2024-12-01-20:19:23-root-INFO: grad norm: 215.274 213.592 26.856
2024-12-01-20:19:24-root-INFO: Loss too large (1134.789->1454.679)! Learning rate decreased to 0.00685.
2024-12-01-20:19:24-root-INFO: Loss too large (1134.789->1351.655)! Learning rate decreased to 0.00548.
2024-12-01-20:19:24-root-INFO: Loss too large (1134.789->1280.587)! Learning rate decreased to 0.00439.
2024-12-01-20:19:24-root-INFO: Loss too large (1134.789->1230.586)! Learning rate decreased to 0.00351.
2024-12-01-20:19:24-root-INFO: Loss too large (1134.789->1194.646)! Learning rate decreased to 0.00281.
2024-12-01-20:19:24-root-INFO: Loss too large (1134.789->1168.499)! Learning rate decreased to 0.00225.
2024-12-01-20:19:24-root-INFO: Loss too large (1134.789->1149.610)! Learning rate decreased to 0.00180.
2024-12-01-20:19:25-root-INFO: Loss too large (1134.789->1136.403)! Learning rate decreased to 0.00144.
2024-12-01-20:19:25-root-INFO: grad norm: 115.812 114.585 16.811
2024-12-01-20:19:26-root-INFO: grad norm: 39.607 37.782 11.885
2024-12-01-20:19:26-root-INFO: grad norm: 39.104 37.266 11.845
2024-12-01-20:19:26-root-INFO: Loss Change: 1136.338 -> 1111.390
2024-12-01-20:19:26-root-INFO: Regularization Change: 0.000 -> 0.363
2024-12-01-20:19:26-root-INFO: Undo step: 155
2024-12-01-20:19:26-root-INFO: Undo step: 156
2024-12-01-20:19:26-root-INFO: Undo step: 157
2024-12-01-20:19:26-root-INFO: Undo step: 158
2024-12-01-20:19:26-root-INFO: Undo step: 159
2024-12-01-20:19:27-root-INFO: step: 160 lr_xt 0.00710269
2024-12-01-20:19:27-root-INFO: grad norm: 259.317 252.386 59.555
2024-12-01-20:19:27-root-INFO: grad norm: 228.153 223.751 44.600
2024-12-01-20:19:27-root-INFO: Loss too large (1408.798->1619.860)! Learning rate decreased to 0.00568.
2024-12-01-20:19:28-root-INFO: Loss too large (1408.798->1583.946)! Learning rate decreased to 0.00455.
2024-12-01-20:19:28-root-INFO: Loss too large (1408.798->1543.463)! Learning rate decreased to 0.00364.
2024-12-01-20:19:28-root-INFO: Loss too large (1408.798->1494.351)! Learning rate decreased to 0.00291.
2024-12-01-20:19:28-root-INFO: Loss too large (1408.798->1441.647)! Learning rate decreased to 0.00233.
2024-12-01-20:19:29-root-INFO: grad norm: 524.264 518.161 79.763
2024-12-01-20:19:29-root-INFO: Loss too large (1400.663->1543.708)! Learning rate decreased to 0.00186.
2024-12-01-20:19:29-root-INFO: Loss too large (1400.663->1479.464)! Learning rate decreased to 0.00149.
2024-12-01-20:19:29-root-INFO: Loss too large (1400.663->1432.195)! Learning rate decreased to 0.00119.
2024-12-01-20:19:30-root-INFO: grad norm: 261.634 258.168 42.451
2024-12-01-20:19:30-root-INFO: grad norm: 153.375 149.338 34.958
2024-12-01-20:19:30-root-INFO: Loss Change: 1615.634 -> 1313.470
2024-12-01-20:19:30-root-INFO: Regularization Change: 0.000 -> 4.337
2024-12-01-20:19:30-root-INFO: Learning rate of xt decay: 0.05782 -> 0.05852.
2024-12-01-20:19:30-root-INFO: Coefficient of regularization decay: 0.00024 -> 0.00024.
2024-12-01-20:19:30-root-INFO: step: 159 lr_xt 0.00737641
2024-12-01-20:19:31-root-INFO: grad norm: 91.761 87.426 27.870
2024-12-01-20:19:31-root-INFO: grad norm: 132.099 129.400 26.566
2024-12-01-20:19:31-root-INFO: Loss too large (1264.192->1451.074)! Learning rate decreased to 0.00590.
2024-12-01-20:19:31-root-INFO: Loss too large (1264.192->1418.038)! Learning rate decreased to 0.00472.
2024-12-01-20:19:31-root-INFO: Loss too large (1264.192->1376.660)! Learning rate decreased to 0.00378.
2024-12-01-20:19:32-root-INFO: Loss too large (1264.192->1331.676)! Learning rate decreased to 0.00302.
2024-12-01-20:19:32-root-INFO: Loss too large (1264.192->1294.507)! Learning rate decreased to 0.00242.
2024-12-01-20:19:32-root-INFO: Loss too large (1264.192->1271.164)! Learning rate decreased to 0.00193.
2024-12-01-20:19:32-root-INFO: grad norm: 220.271 217.966 31.787
2024-12-01-20:19:33-root-INFO: Loss too large (1259.232->1278.832)! Learning rate decreased to 0.00155.
2024-12-01-20:19:33-root-INFO: Loss too large (1259.232->1264.709)! Learning rate decreased to 0.00124.
2024-12-01-20:19:33-root-INFO: grad norm: 158.064 155.726 27.082
2024-12-01-20:19:34-root-INFO: grad norm: 78.049 75.497 19.795
2024-12-01-20:19:34-root-INFO: Loss Change: 1307.077 -> 1234.154
2024-12-01-20:19:34-root-INFO: Regularization Change: 0.000 -> 1.008
2024-12-01-20:19:34-root-INFO: Learning rate of xt decay: 0.05852 -> 0.05922.
2024-12-01-20:19:34-root-INFO: Coefficient of regularization decay: 0.00024 -> 0.00025.
2024-12-01-20:19:34-root-INFO: step: 158 lr_xt 0.00765943
2024-12-01-20:19:34-root-INFO: grad norm: 111.115 108.802 22.554
2024-12-01-20:19:34-root-INFO: Loss too large (1232.449->1410.036)! Learning rate decreased to 0.00613.
2024-12-01-20:19:35-root-INFO: Loss too large (1232.449->1366.869)! Learning rate decreased to 0.00490.
2024-12-01-20:19:35-root-INFO: Loss too large (1232.449->1318.858)! Learning rate decreased to 0.00392.
2024-12-01-20:19:35-root-INFO: Loss too large (1232.449->1277.179)! Learning rate decreased to 0.00314.
2024-12-01-20:19:35-root-INFO: Loss too large (1232.449->1249.478)! Learning rate decreased to 0.00251.
2024-12-01-20:19:35-root-INFO: Loss too large (1232.449->1234.323)! Learning rate decreased to 0.00201.
2024-12-01-20:19:36-root-INFO: grad norm: 167.839 166.108 24.045
2024-12-01-20:19:36-root-INFO: Loss too large (1227.132->1235.298)! Learning rate decreased to 0.00161.
2024-12-01-20:19:36-root-INFO: grad norm: 149.522 147.505 24.477
2024-12-01-20:19:37-root-INFO: grad norm: 112.779 111.147 19.113
2024-12-01-20:19:37-root-INFO: grad norm: 109.689 107.719 20.697
2024-12-01-20:19:38-root-INFO: Loss Change: 1232.449 -> 1202.028
2024-12-01-20:19:38-root-INFO: Regularization Change: 0.000 -> 0.265
2024-12-01-20:19:38-root-INFO: Learning rate of xt decay: 0.05922 -> 0.05993.
2024-12-01-20:19:38-root-INFO: Coefficient of regularization decay: 0.00025 -> 0.00025.
2024-12-01-20:19:38-root-INFO: step: 157 lr_xt 0.00795203
2024-12-01-20:19:38-root-INFO: grad norm: 64.351 61.677 18.359
2024-12-01-20:19:38-root-INFO: grad norm: 302.285 299.791 38.748
2024-12-01-20:19:38-root-INFO: Loss too large (1195.880->1719.080)! Learning rate decreased to 0.00636.
2024-12-01-20:19:39-root-INFO: Loss too large (1195.880->1557.175)! Learning rate decreased to 0.00509.
2024-12-01-20:19:39-root-INFO: Loss too large (1195.880->1441.304)! Learning rate decreased to 0.00407.
2024-12-01-20:19:39-root-INFO: Loss too large (1195.880->1359.394)! Learning rate decreased to 0.00326.
2024-12-01-20:19:39-root-INFO: Loss too large (1195.880->1301.086)! Learning rate decreased to 0.00261.
2024-12-01-20:19:39-root-INFO: Loss too large (1195.880->1258.849)! Learning rate decreased to 0.00208.
2024-12-01-20:19:39-root-INFO: Loss too large (1195.880->1227.916)! Learning rate decreased to 0.00167.
2024-12-01-20:19:40-root-INFO: Loss too large (1195.880->1205.493)! Learning rate decreased to 0.00133.
2024-12-01-20:19:40-root-INFO: grad norm: 162.625 160.889 23.696
2024-12-01-20:19:40-root-INFO: grad norm: 54.699 52.539 15.221
2024-12-01-20:19:41-root-INFO: grad norm: 50.232 48.148 14.319
2024-12-01-20:19:41-root-INFO: Loss Change: 1196.599 -> 1159.132
2024-12-01-20:19:41-root-INFO: Regularization Change: 0.000 -> 0.510
2024-12-01-20:19:41-root-INFO: Learning rate of xt decay: 0.05993 -> 0.06065.
2024-12-01-20:19:41-root-INFO: Coefficient of regularization decay: 0.00025 -> 0.00025.
2024-12-01-20:19:41-root-INFO: step: 156 lr_xt 0.00825448
2024-12-01-20:19:42-root-INFO: grad norm: 74.808 72.855 16.981
2024-12-01-20:19:42-root-INFO: Loss too large (1157.421->1259.337)! Learning rate decreased to 0.00660.
2024-12-01-20:19:42-root-INFO: Loss too large (1157.421->1215.643)! Learning rate decreased to 0.00528.
2024-12-01-20:19:42-root-INFO: Loss too large (1157.421->1185.137)! Learning rate decreased to 0.00423.
2024-12-01-20:19:42-root-INFO: Loss too large (1157.421->1167.533)! Learning rate decreased to 0.00338.
2024-12-01-20:19:42-root-INFO: Loss too large (1157.421->1158.469)! Learning rate decreased to 0.00270.
2024-12-01-20:19:43-root-INFO: grad norm: 132.328 130.971 18.901
2024-12-01-20:19:43-root-INFO: Loss too large (1154.231->1164.508)! Learning rate decreased to 0.00216.
2024-12-01-20:19:43-root-INFO: Loss too large (1154.231->1156.748)! Learning rate decreased to 0.00173.
2024-12-01-20:19:44-root-INFO: grad norm: 108.105 106.497 18.582
2024-12-01-20:19:44-root-INFO: grad norm: 71.661 70.207 14.362
2024-12-01-20:19:45-root-INFO: grad norm: 65.659 63.915 15.031
2024-12-01-20:19:45-root-INFO: Loss Change: 1157.421 -> 1134.555
2024-12-01-20:19:45-root-INFO: Regularization Change: 0.000 -> 0.218
2024-12-01-20:19:45-root-INFO: Learning rate of xt decay: 0.06065 -> 0.06138.
2024-12-01-20:19:45-root-INFO: Coefficient of regularization decay: 0.00025 -> 0.00025.
2024-12-01-20:19:45-root-INFO: step: 155 lr_xt 0.00856705
2024-12-01-20:19:45-root-INFO: grad norm: 58.318 56.196 15.587
2024-12-01-20:19:45-root-INFO: Loss too large (1131.520->1145.989)! Learning rate decreased to 0.00685.
2024-12-01-20:19:46-root-INFO: Loss too large (1131.520->1134.372)! Learning rate decreased to 0.00548.
2024-12-01-20:19:46-root-INFO: grad norm: 181.720 180.174 23.659
2024-12-01-20:19:46-root-INFO: Loss too large (1128.686->1234.416)! Learning rate decreased to 0.00439.
2024-12-01-20:19:46-root-INFO: Loss too large (1128.686->1197.649)! Learning rate decreased to 0.00351.
2024-12-01-20:19:47-root-INFO: Loss too large (1128.686->1170.971)! Learning rate decreased to 0.00281.
2024-12-01-20:19:47-root-INFO: Loss too large (1128.686->1151.584)! Learning rate decreased to 0.00225.
2024-12-01-20:19:47-root-INFO: Loss too large (1128.686->1137.768)! Learning rate decreased to 0.00180.
2024-12-01-20:19:47-root-INFO: grad norm: 127.051 125.586 19.239
2024-12-01-20:19:48-root-INFO: grad norm: 49.928 48.251 12.832
2024-12-01-20:19:48-root-INFO: grad norm: 47.244 45.384 13.124
2024-12-01-20:19:49-root-INFO: Loss Change: 1131.520 -> 1105.092
2024-12-01-20:19:49-root-INFO: Regularization Change: 0.000 -> 0.335
2024-12-01-20:19:49-root-INFO: Learning rate of xt decay: 0.06138 -> 0.06211.
2024-12-01-20:19:49-root-INFO: Coefficient of regularization decay: 0.00025 -> 0.00026.
2024-12-01-20:19:49-root-INFO: step: 154 lr_xt 0.00889002
2024-12-01-20:19:49-root-INFO: grad norm: 60.382 58.438 15.197
2024-12-01-20:19:49-root-INFO: Loss too large (1103.515->1145.943)! Learning rate decreased to 0.00711.
2024-12-01-20:19:49-root-INFO: Loss too large (1103.515->1121.767)! Learning rate decreased to 0.00569.
2024-12-01-20:19:49-root-INFO: Loss too large (1103.515->1108.782)! Learning rate decreased to 0.00455.
2024-12-01-20:19:50-root-INFO: grad norm: 164.070 162.713 21.058
2024-12-01-20:19:50-root-INFO: Loss too large (1102.396->1156.524)! Learning rate decreased to 0.00364.
2024-12-01-20:19:50-root-INFO: Loss too large (1102.396->1134.409)! Learning rate decreased to 0.00291.
2024-12-01-20:19:50-root-INFO: Loss too large (1102.396->1118.512)! Learning rate decreased to 0.00233.
2024-12-01-20:19:50-root-INFO: Loss too large (1102.396->1107.370)! Learning rate decreased to 0.00186.
2024-12-01-20:19:51-root-INFO: grad norm: 108.685 107.298 17.308
2024-12-01-20:19:51-root-INFO: grad norm: 44.055 42.334 12.194
2024-12-01-20:19:52-root-INFO: grad norm: 42.003 40.162 12.302
2024-12-01-20:19:52-root-INFO: Loss Change: 1103.515 -> 1080.800
2024-12-01-20:19:52-root-INFO: Regularization Change: 0.000 -> 0.266
2024-12-01-20:19:52-root-INFO: Learning rate of xt decay: 0.06211 -> 0.06286.
2024-12-01-20:19:52-root-INFO: Coefficient of regularization decay: 0.00026 -> 0.00026.
2024-12-01-20:19:52-root-INFO: step: 153 lr_xt 0.00922367
2024-12-01-20:19:52-root-INFO: grad norm: 61.314 59.384 15.262
2024-12-01-20:19:53-root-INFO: Loss too large (1080.179->1124.516)! Learning rate decreased to 0.00738.
2024-12-01-20:19:53-root-INFO: Loss too large (1080.179->1098.588)! Learning rate decreased to 0.00590.
2024-12-01-20:19:53-root-INFO: Loss too large (1080.179->1084.948)! Learning rate decreased to 0.00472.
2024-12-01-20:19:53-root-INFO: grad norm: 152.372 151.043 20.075
2024-12-01-20:19:53-root-INFO: Loss too large (1078.390->1121.833)! Learning rate decreased to 0.00378.
2024-12-01-20:19:54-root-INFO: Loss too large (1078.390->1102.768)! Learning rate decreased to 0.00302.
2024-12-01-20:19:54-root-INFO: Loss too large (1078.390->1089.285)! Learning rate decreased to 0.00242.
2024-12-01-20:19:54-root-INFO: Loss too large (1078.390->1080.036)! Learning rate decreased to 0.00193.
2024-12-01-20:19:54-root-INFO: grad norm: 93.495 92.133 15.901
2024-12-01-20:19:55-root-INFO: grad norm: 40.059 38.224 11.985
2024-12-01-20:19:55-root-INFO: grad norm: 39.013 37.157 11.890
2024-12-01-20:19:56-root-INFO: Loss Change: 1080.179 -> 1057.761
2024-12-01-20:19:56-root-INFO: Regularization Change: 0.000 -> 0.269
2024-12-01-20:19:56-root-INFO: Learning rate of xt decay: 0.06286 -> 0.06361.
2024-12-01-20:19:56-root-INFO: Coefficient of regularization decay: 0.00026 -> 0.00026.
2024-12-01-20:19:56-root-INFO: step: 152 lr_xt 0.00956831
2024-12-01-20:19:56-root-INFO: grad norm: 50.872 49.104 13.293
2024-12-01-20:19:56-root-INFO: Loss too large (1056.783->1072.767)! Learning rate decreased to 0.00765.
2024-12-01-20:19:56-root-INFO: Loss too large (1056.783->1060.769)! Learning rate decreased to 0.00612.
2024-12-01-20:19:57-root-INFO: grad norm: 146.223 144.996 18.905
2024-12-01-20:19:57-root-INFO: Loss too large (1055.021->1117.890)! Learning rate decreased to 0.00490.
2024-12-01-20:19:57-root-INFO: Loss too large (1055.021->1093.071)! Learning rate decreased to 0.00392.
2024-12-01-20:19:57-root-INFO: Loss too large (1055.021->1075.524)! Learning rate decreased to 0.00314.
2024-12-01-20:19:57-root-INFO: Loss too large (1055.021->1063.242)! Learning rate decreased to 0.00251.
2024-12-01-20:19:58-root-INFO: grad norm: 101.919 100.745 15.428
2024-12-01-20:19:58-root-INFO: grad norm: 39.894 38.335 11.041
2024-12-01-20:19:59-root-INFO: grad norm: 38.377 36.738 11.097
2024-12-01-20:19:59-root-INFO: Loss Change: 1056.783 -> 1032.755
2024-12-01-20:19:59-root-INFO: Regularization Change: 0.000 -> 0.384
2024-12-01-20:19:59-root-INFO: Learning rate of xt decay: 0.06361 -> 0.06438.
2024-12-01-20:19:59-root-INFO: Coefficient of regularization decay: 0.00026 -> 0.00027.
2024-12-01-20:19:59-root-INFO: step: 151 lr_xt 0.00992422
2024-12-01-20:20:00-root-INFO: grad norm: 52.024 50.280 13.358
2024-12-01-20:20:00-root-INFO: Loss too large (1033.104->1048.014)! Learning rate decreased to 0.00794.
2024-12-01-20:20:00-root-INFO: Loss too large (1033.104->1035.918)! Learning rate decreased to 0.00635.
2024-12-01-20:20:00-root-INFO: grad norm: 131.649 130.528 17.145
2024-12-01-20:20:00-root-INFO: Loss too large (1030.295->1077.077)! Learning rate decreased to 0.00508.
2024-12-01-20:20:01-root-INFO: Loss too large (1030.295->1057.049)! Learning rate decreased to 0.00406.
2024-12-01-20:20:01-root-INFO: Loss too large (1030.295->1043.097)! Learning rate decreased to 0.00325.
2024-12-01-20:20:01-root-INFO: Loss too large (1030.295->1033.554)! Learning rate decreased to 0.00260.
2024-12-01-20:20:01-root-INFO: grad norm: 85.561 84.392 14.095
2024-12-01-20:20:02-root-INFO: grad norm: 36.626 35.033 10.682
2024-12-01-20:20:03-root-INFO: grad norm: 35.596 33.967 10.646
2024-12-01-20:20:03-root-INFO: Loss Change: 1033.104 -> 1009.091
2024-12-01-20:20:03-root-INFO: Regularization Change: 0.000 -> 0.391
2024-12-01-20:20:03-root-INFO: Learning rate of xt decay: 0.06438 -> 0.06515.
2024-12-01-20:20:03-root-INFO: Coefficient of regularization decay: 0.00027 -> 0.00027.
2024-12-01-20:20:03-root-INFO: step: 150 lr_xt 0.01029171
2024-12-01-20:20:03-root-INFO: grad norm: 41.380 39.729 11.573
2024-12-01-20:20:04-root-INFO: grad norm: 129.217 128.183 16.318
2024-12-01-20:20:04-root-INFO: Loss too large (1003.097->1117.132)! Learning rate decreased to 0.00823.
2024-12-01-20:20:04-root-INFO: Loss too large (1003.097->1075.570)! Learning rate decreased to 0.00659.
2024-12-01-20:20:04-root-INFO: Loss too large (1003.097->1047.276)! Learning rate decreased to 0.00527.
2024-12-01-20:20:04-root-INFO: Loss too large (1003.097->1027.770)! Learning rate decreased to 0.00422.
2024-12-01-20:20:04-root-INFO: Loss too large (1003.097->1014.304)! Learning rate decreased to 0.00337.
2024-12-01-20:20:05-root-INFO: Loss too large (1003.097->1005.178)! Learning rate decreased to 0.00270.
2024-12-01-20:20:05-root-INFO: grad norm: 78.856 77.819 12.751
2024-12-01-20:20:06-root-INFO: grad norm: 33.661 32.205 9.794
2024-12-01-20:20:06-root-INFO: grad norm: 33.187 31.726 9.738
2024-12-01-20:20:06-root-INFO: Loss Change: 1008.237 -> 982.656
2024-12-01-20:20:06-root-INFO: Regularization Change: 0.000 -> 0.539
2024-12-01-20:20:06-root-INFO: Undo step: 150
2024-12-01-20:20:06-root-INFO: Undo step: 151
2024-12-01-20:20:06-root-INFO: Undo step: 152
2024-12-01-20:20:06-root-INFO: Undo step: 153
2024-12-01-20:20:06-root-INFO: Undo step: 154
2024-12-01-20:20:07-root-INFO: step: 155 lr_xt 0.00856705
2024-12-01-20:20:07-root-INFO: grad norm: 275.434 267.905 63.961
2024-12-01-20:20:07-root-INFO: grad norm: 361.471 359.015 42.065
2024-12-01-20:20:08-root-INFO: grad norm: 229.624 227.871 28.320
2024-12-01-20:20:08-root-INFO: Loss too large (1362.628->1385.997)! Learning rate decreased to 0.00685.
2024-12-01-20:20:08-root-INFO: grad norm: 548.986 544.912 66.761
2024-12-01-20:20:08-root-INFO: Loss too large (1266.605->1986.686)! Learning rate decreased to 0.00548.
2024-12-01-20:20:09-root-INFO: Loss too large (1266.605->1714.461)! Learning rate decreased to 0.00439.
2024-12-01-20:20:09-root-INFO: Loss too large (1266.605->1524.047)! Learning rate decreased to 0.00351.
2024-12-01-20:20:09-root-INFO: Loss too large (1266.605->1397.615)! Learning rate decreased to 0.00281.
2024-12-01-20:20:09-root-INFO: Loss too large (1266.605->1314.231)! Learning rate decreased to 0.00225.
2024-12-01-20:20:10-root-INFO: grad norm: 187.873 186.645 21.444
2024-12-01-20:20:10-root-INFO: Loss Change: 1729.092 -> 1188.791
2024-12-01-20:20:10-root-INFO: Regularization Change: 0.000 -> 14.802
2024-12-01-20:20:10-root-INFO: Learning rate of xt decay: 0.06138 -> 0.06211.
2024-12-01-20:20:10-root-INFO: Coefficient of regularization decay: 0.00025 -> 0.00026.
2024-12-01-20:20:10-root-INFO: step: 154 lr_xt 0.00889002
2024-12-01-20:20:10-root-INFO: grad norm: 144.569 143.321 18.957
2024-12-01-20:20:10-root-INFO: Loss too large (1189.145->1289.795)! Learning rate decreased to 0.00711.
2024-12-01-20:20:11-root-INFO: Loss too large (1189.145->1193.382)! Learning rate decreased to 0.00569.
2024-12-01-20:20:11-root-INFO: grad norm: 210.517 208.662 27.887
2024-12-01-20:20:11-root-INFO: Loss too large (1134.716->1213.827)! Learning rate decreased to 0.00455.
2024-12-01-20:20:11-root-INFO: Loss too large (1134.716->1178.096)! Learning rate decreased to 0.00364.
2024-12-01-20:20:12-root-INFO: Loss too large (1134.716->1154.149)! Learning rate decreased to 0.00291.
2024-12-01-20:20:12-root-INFO: Loss too large (1134.716->1138.177)! Learning rate decreased to 0.00233.
2024-12-01-20:20:12-root-INFO: grad norm: 112.307 110.990 17.150
2024-12-01-20:20:13-root-INFO: grad norm: 65.854 63.973 15.625
2024-12-01-20:20:13-root-INFO: grad norm: 56.163 54.012 15.396
2024-12-01-20:20:13-root-INFO: Loss Change: 1189.145 -> 1088.871
2024-12-01-20:20:13-root-INFO: Regularization Change: 0.000 -> 1.110
2024-12-01-20:20:13-root-INFO: Learning rate of xt decay: 0.06211 -> 0.06286.
2024-12-01-20:20:13-root-INFO: Coefficient of regularization decay: 0.00026 -> 0.00026.
2024-12-01-20:20:13-root-INFO: step: 153 lr_xt 0.00922367
2024-12-01-20:20:14-root-INFO: grad norm: 63.721 61.736 15.779
2024-12-01-20:20:14-root-INFO: grad norm: 216.022 214.040 29.196
2024-12-01-20:20:14-root-INFO: Loss too large (1078.451->1338.770)! Learning rate decreased to 0.00738.
2024-12-01-20:20:14-root-INFO: Loss too large (1078.451->1244.593)! Learning rate decreased to 0.00590.
2024-12-01-20:20:15-root-INFO: Loss too large (1078.451->1180.841)! Learning rate decreased to 0.00472.
2024-12-01-20:20:15-root-INFO: Loss too large (1078.451->1137.330)! Learning rate decreased to 0.00378.
2024-12-01-20:20:15-root-INFO: Loss too large (1078.451->1107.292)! Learning rate decreased to 0.00302.
2024-12-01-20:20:15-root-INFO: Loss too large (1078.451->1086.600)! Learning rate decreased to 0.00242.
2024-12-01-20:20:15-root-INFO: grad norm: 116.926 115.777 16.349
2024-12-01-20:20:16-root-INFO: grad norm: 49.542 47.587 13.781
2024-12-01-20:20:16-root-INFO: grad norm: 44.860 42.743 13.619
2024-12-01-20:20:17-root-INFO: Loss Change: 1086.024 -> 1039.742
2024-12-01-20:20:17-root-INFO: Regularization Change: 0.000 -> 0.872
2024-12-01-20:20:17-root-INFO: Learning rate of xt decay: 0.06286 -> 0.06361.
2024-12-01-20:20:17-root-INFO: Coefficient of regularization decay: 0.00026 -> 0.00026.
2024-12-01-20:20:17-root-INFO: step: 152 lr_xt 0.00956831
2024-12-01-20:20:17-root-INFO: grad norm: 51.088 49.291 13.432
2024-12-01-20:20:17-root-INFO: grad norm: 175.952 174.252 24.399
2024-12-01-20:20:18-root-INFO: Loss too large (1033.367->1225.234)! Learning rate decreased to 0.00765.
2024-12-01-20:20:18-root-INFO: Loss too large (1033.367->1156.068)! Learning rate decreased to 0.00612.
2024-12-01-20:20:18-root-INFO: Loss too large (1033.367->1108.738)! Learning rate decreased to 0.00490.
2024-12-01-20:20:18-root-INFO: Loss too large (1033.367->1075.989)! Learning rate decreased to 0.00392.
2024-12-01-20:20:18-root-INFO: Loss too large (1033.367->1053.235)! Learning rate decreased to 0.00314.
2024-12-01-20:20:18-root-INFO: Loss too large (1033.367->1037.663)! Learning rate decreased to 0.00251.
2024-12-01-20:20:19-root-INFO: grad norm: 101.085 100.049 14.431
2024-12-01-20:20:19-root-INFO: grad norm: 39.032 37.112 12.090
2024-12-01-20:20:20-root-INFO: grad norm: 38.263 36.363 11.907
2024-12-01-20:20:20-root-INFO: Loss Change: 1036.892 -> 1003.856
2024-12-01-20:20:20-root-INFO: Regularization Change: 0.000 -> 0.645
2024-12-01-20:20:20-root-INFO: Learning rate of xt decay: 0.06361 -> 0.06438.
2024-12-01-20:20:20-root-INFO: Coefficient of regularization decay: 0.00026 -> 0.00027.
2024-12-01-20:20:20-root-INFO: step: 151 lr_xt 0.00992422
2024-12-01-20:20:20-root-INFO: grad norm: 51.489 49.794 13.101
2024-12-01-20:20:21-root-INFO: Loss too large (1003.968->1009.350)! Learning rate decreased to 0.00794.
2024-12-01-20:20:21-root-INFO: grad norm: 141.708 140.245 20.309
2024-12-01-20:20:21-root-INFO: Loss too large (1001.630->1082.282)! Learning rate decreased to 0.00635.
2024-12-01-20:20:21-root-INFO: Loss too large (1001.630->1049.178)! Learning rate decreased to 0.00508.
2024-12-01-20:20:22-root-INFO: Loss too large (1001.630->1026.349)! Learning rate decreased to 0.00406.
2024-12-01-20:20:22-root-INFO: Loss too large (1001.630->1010.763)! Learning rate decreased to 0.00325.
2024-12-01-20:20:22-root-INFO: grad norm: 99.291 98.340 13.704
2024-12-01-20:20:23-root-INFO: grad norm: 40.579 38.995 11.226
2024-12-01-20:20:23-root-INFO: grad norm: 37.515 35.947 10.734
2024-12-01-20:20:24-root-INFO: Loss Change: 1003.968 -> 974.461
2024-12-01-20:20:24-root-INFO: Regularization Change: 0.000 -> 0.607
2024-12-01-20:20:24-root-INFO: Learning rate of xt decay: 0.06438 -> 0.06515.
2024-12-01-20:20:24-root-INFO: Coefficient of regularization decay: 0.00027 -> 0.00027.
2024-12-01-20:20:24-root-INFO: step: 150 lr_xt 0.01029171
2024-12-01-20:20:24-root-INFO: grad norm: 36.841 35.288 10.583
2024-12-01-20:20:24-root-INFO: grad norm: 46.976 45.750 10.664
2024-12-01-20:20:24-root-INFO: Loss too large (960.922->965.028)! Learning rate decreased to 0.00823.
2024-12-01-20:20:25-root-INFO: Loss too large (960.922->961.008)! Learning rate decreased to 0.00659.
2024-12-01-20:20:25-root-INFO: grad norm: 72.918 72.042 11.265
2024-12-01-20:20:25-root-INFO: Loss too large (958.685->972.119)! Learning rate decreased to 0.00527.
2024-12-01-20:20:26-root-INFO: grad norm: 135.138 133.877 18.417
2024-12-01-20:20:26-root-INFO: Loss too large (958.456->982.069)! Learning rate decreased to 0.00422.
2024-12-01-20:20:26-root-INFO: Loss too large (958.456->967.113)! Learning rate decreased to 0.00337.
2024-12-01-20:20:27-root-INFO: grad norm: 91.631 90.843 11.995
2024-12-01-20:20:27-root-INFO: Loss Change: 972.475 -> 941.828
2024-12-01-20:20:27-root-INFO: Regularization Change: 0.000 -> 0.906
2024-12-01-20:20:27-root-INFO: Learning rate of xt decay: 0.06515 -> 0.06593.
2024-12-01-20:20:27-root-INFO: Coefficient of regularization decay: 0.00027 -> 0.00027.
2024-12-01-20:20:27-root-INFO: step: 149 lr_xt 0.01067108
2024-12-01-20:20:27-root-INFO: grad norm: 36.968 35.562 10.098
2024-12-01-20:20:28-root-INFO: grad norm: 68.561 67.595 11.471
2024-12-01-20:20:28-root-INFO: Loss too large (932.352->962.491)! Learning rate decreased to 0.00854.
2024-12-01-20:20:28-root-INFO: Loss too large (932.352->948.856)! Learning rate decreased to 0.00683.
2024-12-01-20:20:28-root-INFO: Loss too large (932.352->939.757)! Learning rate decreased to 0.00546.
2024-12-01-20:20:28-root-INFO: Loss too large (932.352->933.907)! Learning rate decreased to 0.00437.
2024-12-01-20:20:29-root-INFO: grad norm: 66.312 65.509 10.292
2024-12-01-20:20:29-root-INFO: grad norm: 61.158 60.251 10.490
2024-12-01-20:20:30-root-INFO: grad norm: 58.971 58.168 9.697
2024-12-01-20:20:30-root-INFO: Loss Change: 940.605 -> 916.116
2024-12-01-20:20:30-root-INFO: Regularization Change: 0.000 -> 0.749
2024-12-01-20:20:30-root-INFO: Learning rate of xt decay: 0.06593 -> 0.06672.
2024-12-01-20:20:30-root-INFO: Coefficient of regularization decay: 0.00027 -> 0.00027.
2024-12-01-20:20:30-root-INFO: step: 148 lr_xt 0.01106266
2024-12-01-20:20:30-root-INFO: grad norm: 37.189 36.015 9.271
2024-12-01-20:20:31-root-INFO: grad norm: 62.269 61.512 9.679
2024-12-01-20:20:31-root-INFO: Loss too large (907.666->959.561)! Learning rate decreased to 0.00885.
2024-12-01-20:20:31-root-INFO: Loss too large (907.666->926.479)! Learning rate decreased to 0.00708.
2024-12-01-20:20:31-root-INFO: Loss too large (907.666->910.745)! Learning rate decreased to 0.00566.
2024-12-01-20:20:32-root-INFO: grad norm: 83.974 83.095 12.121
2024-12-01-20:20:32-root-INFO: Loss too large (903.681->907.931)! Learning rate decreased to 0.00453.
2024-12-01-20:20:32-root-INFO: grad norm: 69.838 69.111 10.050
2024-12-01-20:20:33-root-INFO: grad norm: 45.920 45.115 8.562
2024-12-01-20:20:33-root-INFO: Loss Change: 913.245 -> 889.476
2024-12-01-20:20:33-root-INFO: Regularization Change: 0.000 -> 0.766
2024-12-01-20:20:33-root-INFO: Learning rate of xt decay: 0.06672 -> 0.06752.
2024-12-01-20:20:33-root-INFO: Coefficient of regularization decay: 0.00027 -> 0.00028.
2024-12-01-20:20:33-root-INFO: step: 147 lr_xt 0.01146675
2024-12-01-20:20:33-root-INFO: grad norm: 50.216 49.394 9.054
2024-12-01-20:20:34-root-INFO: Loss too large (888.557->906.575)! Learning rate decreased to 0.00917.
2024-12-01-20:20:34-root-INFO: Loss too large (888.557->892.492)! Learning rate decreased to 0.00734.
2024-12-01-20:20:34-root-INFO: grad norm: 85.139 84.279 12.073
2024-12-01-20:20:34-root-INFO: Loss too large (886.059->897.600)! Learning rate decreased to 0.00587.
2024-12-01-20:20:34-root-INFO: Loss too large (886.059->888.651)! Learning rate decreased to 0.00470.
2024-12-01-20:20:35-root-INFO: grad norm: 64.244 63.545 9.455
2024-12-01-20:20:35-root-INFO: grad norm: 37.077 36.288 7.608
2024-12-01-20:20:36-root-INFO: grad norm: 32.434 31.576 7.409
2024-12-01-20:20:36-root-INFO: Loss Change: 888.557 -> 866.763
2024-12-01-20:20:36-root-INFO: Regularization Change: 0.000 -> 0.528
2024-12-01-20:20:36-root-INFO: Learning rate of xt decay: 0.06752 -> 0.06833.
2024-12-01-20:20:36-root-INFO: Coefficient of regularization decay: 0.00028 -> 0.00028.
2024-12-01-20:20:36-root-INFO: step: 146 lr_xt 0.01188369
2024-12-01-20:20:37-root-INFO: grad norm: 29.193 28.245 7.381
2024-12-01-20:20:37-root-INFO: grad norm: 34.027 33.238 7.288
2024-12-01-20:20:37-root-INFO: grad norm: 60.616 59.976 8.791
2024-12-01-20:20:38-root-INFO: Loss too large (854.535->891.467)! Learning rate decreased to 0.00951.
2024-12-01-20:20:38-root-INFO: Loss too large (854.535->865.637)! Learning rate decreased to 0.00761.
2024-12-01-20:20:38-root-INFO: grad norm: 101.372 100.436 13.739
2024-12-01-20:20:39-root-INFO: Loss too large (853.619->869.980)! Learning rate decreased to 0.00608.
2024-12-01-20:20:39-root-INFO: Loss too large (853.619->857.695)! Learning rate decreased to 0.00487.
2024-12-01-20:20:39-root-INFO: grad norm: 66.170 65.571 8.887
2024-12-01-20:20:39-root-INFO: Loss Change: 865.020 -> 838.641
2024-12-01-20:20:39-root-INFO: Regularization Change: 0.000 -> 1.112
2024-12-01-20:20:39-root-INFO: Learning rate of xt decay: 0.06833 -> 0.06915.
2024-12-01-20:20:39-root-INFO: Coefficient of regularization decay: 0.00028 -> 0.00028.
2024-12-01-20:20:40-root-INFO: step: 145 lr_xt 0.01231381
2024-12-01-20:20:40-root-INFO: grad norm: 29.895 28.949 7.463
2024-12-01-20:20:40-root-INFO: grad norm: 30.105 29.334 6.768
2024-12-01-20:20:41-root-INFO: grad norm: 45.267 44.583 7.842
2024-12-01-20:20:41-root-INFO: Loss too large (824.454->835.067)! Learning rate decreased to 0.00985.
2024-12-01-20:20:41-root-INFO: Loss too large (824.454->825.738)! Learning rate decreased to 0.00788.
2024-12-01-20:20:42-root-INFO: grad norm: 63.443 62.756 9.314
2024-12-01-20:20:42-root-INFO: Loss too large (821.353->824.053)! Learning rate decreased to 0.00630.
2024-12-01-20:20:42-root-INFO: grad norm: 56.414 55.810 8.235
2024-12-01-20:20:42-root-INFO: Loss Change: 837.822 -> 811.999
2024-12-01-20:20:42-root-INFO: Regularization Change: 0.000 -> 1.246
2024-12-01-20:20:42-root-INFO: Undo step: 145
2024-12-01-20:20:42-root-INFO: Undo step: 146
2024-12-01-20:20:42-root-INFO: Undo step: 147
2024-12-01-20:20:42-root-INFO: Undo step: 148
2024-12-01-20:20:42-root-INFO: Undo step: 149
2024-12-01-20:20:43-root-INFO: step: 150 lr_xt 0.01029171
2024-12-01-20:20:43-root-INFO: grad norm: 245.551 242.172 40.597
2024-12-01-20:20:43-root-INFO: grad norm: 186.853 185.251 24.414
2024-12-01-20:20:43-root-INFO: Loss too large (1159.045->1170.517)! Learning rate decreased to 0.00823.
2024-12-01-20:20:44-root-INFO: grad norm: 334.166 331.775 39.902
2024-12-01-20:20:44-root-INFO: Loss too large (1079.964->1324.016)! Learning rate decreased to 0.00659.
2024-12-01-20:20:44-root-INFO: Loss too large (1079.964->1202.422)! Learning rate decreased to 0.00527.
2024-12-01-20:20:44-root-INFO: Loss too large (1079.964->1123.537)! Learning rate decreased to 0.00422.
2024-12-01-20:20:45-root-INFO: grad norm: 164.990 164.004 18.014
2024-12-01-20:20:45-root-INFO: grad norm: 91.529 90.296 14.973
2024-12-01-20:20:46-root-INFO: Loss Change: 1329.287 -> 957.501
2024-12-01-20:20:46-root-INFO: Regularization Change: 0.000 -> 9.305
2024-12-01-20:20:46-root-INFO: Learning rate of xt decay: 0.06515 -> 0.06593.
2024-12-01-20:20:46-root-INFO: Coefficient of regularization decay: 0.00027 -> 0.00027.
2024-12-01-20:20:46-root-INFO: step: 149 lr_xt 0.01067108
2024-12-01-20:20:46-root-INFO: grad norm: 63.810 62.244 14.053
2024-12-01-20:20:46-root-INFO: grad norm: 71.011 69.763 13.256
2024-12-01-20:20:47-root-INFO: Loss too large (923.571->924.777)! Learning rate decreased to 0.00854.
2024-12-01-20:20:47-root-INFO: grad norm: 90.880 90.028 12.418
2024-12-01-20:20:47-root-INFO: Loss too large (918.496->922.824)! Learning rate decreased to 0.00683.
2024-12-01-20:20:48-root-INFO: grad norm: 118.163 117.155 15.400
2024-12-01-20:20:48-root-INFO: Loss too large (902.783->916.694)! Learning rate decreased to 0.00546.
2024-12-01-20:20:48-root-INFO: Loss too large (902.783->903.959)! Learning rate decreased to 0.00437.
2024-12-01-20:20:48-root-INFO: grad norm: 76.880 76.075 11.100
2024-12-01-20:20:49-root-INFO: Loss Change: 954.729 -> 880.148
2024-12-01-20:20:49-root-INFO: Regularization Change: 0.000 -> 2.534
2024-12-01-20:20:49-root-INFO: Learning rate of xt decay: 0.06593 -> 0.06672.
2024-12-01-20:20:49-root-INFO: Coefficient of regularization decay: 0.00027 -> 0.00027.
2024-12-01-20:20:49-root-INFO: step: 148 lr_xt 0.01106266
2024-12-01-20:20:49-root-INFO: grad norm: 39.345 38.024 10.111
2024-12-01-20:20:50-root-INFO: grad norm: 39.666 38.574 9.243
2024-12-01-20:20:50-root-INFO: grad norm: 55.188 54.352 9.570
2024-12-01-20:20:50-root-INFO: Loss too large (855.179->866.777)! Learning rate decreased to 0.00885.
2024-12-01-20:20:51-root-INFO: grad norm: 116.754 115.893 14.153
2024-12-01-20:20:51-root-INFO: Loss too large (854.136->890.694)! Learning rate decreased to 0.00708.
2024-12-01-20:20:51-root-INFO: Loss too large (854.136->870.165)! Learning rate decreased to 0.00566.
2024-12-01-20:20:51-root-INFO: Loss too large (854.136->856.955)! Learning rate decreased to 0.00453.
2024-12-01-20:20:52-root-INFO: grad norm: 69.925 69.247 9.713
2024-12-01-20:20:52-root-INFO: Loss Change: 877.354 -> 835.056
2024-12-01-20:20:52-root-INFO: Regularization Change: 0.000 -> 1.698
2024-12-01-20:20:52-root-INFO: Learning rate of xt decay: 0.06672 -> 0.06752.
2024-12-01-20:20:52-root-INFO: Coefficient of regularization decay: 0.00027 -> 0.00028.
2024-12-01-20:20:52-root-INFO: step: 147 lr_xt 0.01146675
2024-12-01-20:20:53-root-INFO: grad norm: 32.696 31.568 8.516
2024-12-01-20:20:53-root-INFO: grad norm: 34.625 33.734 7.803
2024-12-01-20:20:54-root-INFO: grad norm: 48.765 48.007 8.564
2024-12-01-20:20:54-root-INFO: Loss too large (816.779->822.583)! Learning rate decreased to 0.00917.
2024-12-01-20:20:54-root-INFO: grad norm: 84.907 84.224 10.752
2024-12-01-20:20:55-root-INFO: Loss too large (814.583->829.693)! Learning rate decreased to 0.00734.
2024-12-01-20:20:55-root-INFO: Loss too large (814.583->818.499)! Learning rate decreased to 0.00587.
2024-12-01-20:20:55-root-INFO: grad norm: 62.907 62.295 8.756
2024-12-01-20:20:56-root-INFO: Loss Change: 832.235 -> 800.171
2024-12-01-20:20:56-root-INFO: Regularization Change: 0.000 -> 1.443
2024-12-01-20:20:56-root-INFO: Learning rate of xt decay: 0.06752 -> 0.06833.
2024-12-01-20:20:56-root-INFO: Coefficient of regularization decay: 0.00028 -> 0.00028.
2024-12-01-20:20:56-root-INFO: step: 146 lr_xt 0.01188369
2024-12-01-20:20:56-root-INFO: grad norm: 28.009 27.064 7.218
2024-12-01-20:20:56-root-INFO: grad norm: 27.625 26.766 6.834
2024-12-01-20:20:57-root-INFO: grad norm: 35.938 35.231 7.094
2024-12-01-20:20:57-root-INFO: grad norm: 53.427 52.824 8.003
2024-12-01-20:20:57-root-INFO: Loss too large (781.944->789.851)! Learning rate decreased to 0.00951.
2024-12-01-20:20:58-root-INFO: grad norm: 80.840 80.200 10.152
2024-12-01-20:20:58-root-INFO: Loss too large (779.384->790.807)! Learning rate decreased to 0.00761.
2024-12-01-20:20:58-root-INFO: Loss too large (779.384->780.665)! Learning rate decreased to 0.00608.
2024-12-01-20:20:59-root-INFO: Loss Change: 797.479 -> 774.656
2024-12-01-20:20:59-root-INFO: Regularization Change: 0.000 -> 1.566
2024-12-01-20:20:59-root-INFO: Learning rate of xt decay: 0.06833 -> 0.06915.
2024-12-01-20:20:59-root-INFO: Coefficient of regularization decay: 0.00028 -> 0.00028.
2024-12-01-20:20:59-root-INFO: step: 145 lr_xt 0.01231381
2024-12-01-20:20:59-root-INFO: grad norm: 61.339 60.675 9.001
2024-12-01-20:20:59-root-INFO: Loss too large (776.481->780.910)! Learning rate decreased to 0.00985.
2024-12-01-20:21:00-root-INFO: grad norm: 72.615 72.034 9.173
2024-12-01-20:21:00-root-INFO: Loss too large (768.869->773.948)! Learning rate decreased to 0.00788.
2024-12-01-20:21:00-root-INFO: grad norm: 57.543 56.986 7.985
2024-12-01-20:21:01-root-INFO: grad norm: 35.389 34.804 6.405
2024-12-01-20:21:01-root-INFO: grad norm: 30.793 30.126 6.374
2024-12-01-20:21:01-root-INFO: Loss Change: 776.481 -> 747.165
2024-12-01-20:21:01-root-INFO: Regularization Change: 0.000 -> 0.987
2024-12-01-20:21:01-root-INFO: Learning rate of xt decay: 0.06915 -> 0.06998.
2024-12-01-20:21:01-root-INFO: Coefficient of regularization decay: 0.00028 -> 0.00028.
2024-12-01-20:21:02-root-INFO: step: 144 lr_xt 0.01275743
2024-12-01-20:21:02-root-INFO: grad norm: 24.971 24.076 6.624
2024-12-01-20:21:02-root-INFO: grad norm: 25.275 24.506 6.188
2024-12-01-20:21:03-root-INFO: grad norm: 32.503 31.892 6.269
2024-12-01-20:21:03-root-INFO: grad norm: 45.342 44.711 7.538
2024-12-01-20:21:04-root-INFO: Loss too large (732.867->734.903)! Learning rate decreased to 0.01021.
2024-12-01-20:21:04-root-INFO: grad norm: 54.064 53.475 7.961
2024-12-01-20:21:04-root-INFO: Loss too large (729.152->729.665)! Learning rate decreased to 0.00816.
2024-12-01-20:21:05-root-INFO: Loss Change: 745.362 -> 725.610
2024-12-01-20:21:05-root-INFO: Regularization Change: 0.000 -> 1.411
2024-12-01-20:21:05-root-INFO: Learning rate of xt decay: 0.06998 -> 0.07082.
2024-12-01-20:21:05-root-INFO: Coefficient of regularization decay: 0.00028 -> 0.00029.
2024-12-01-20:21:05-root-INFO: step: 143 lr_xt 0.01321490
2024-12-01-20:21:05-root-INFO: grad norm: 47.158 46.492 7.900
2024-12-01-20:21:05-root-INFO: Loss too large (724.568->725.506)! Learning rate decreased to 0.01057.
2024-12-01-20:21:06-root-INFO: grad norm: 52.023 51.445 7.736
2024-12-01-20:21:06-root-INFO: grad norm: 53.819 53.147 8.475
2024-12-01-20:21:07-root-INFO: grad norm: 56.635 56.052 8.100
2024-12-01-20:21:07-root-INFO: Loss too large (712.892->713.299)! Learning rate decreased to 0.00846.
2024-12-01-20:21:07-root-INFO: grad norm: 43.275 42.635 7.411
2024-12-01-20:21:08-root-INFO: Loss Change: 724.568 -> 702.374
2024-12-01-20:21:08-root-INFO: Regularization Change: 0.000 -> 0.997
2024-12-01-20:21:08-root-INFO: Learning rate of xt decay: 0.07082 -> 0.07167.
2024-12-01-20:21:08-root-INFO: Coefficient of regularization decay: 0.00029 -> 0.00029.
2024-12-01-20:21:08-root-INFO: step: 142 lr_xt 0.01368658
2024-12-01-20:21:08-root-INFO: grad norm: 36.077 35.341 7.248
2024-12-01-20:21:08-root-INFO: grad norm: 44.403 43.661 8.085
2024-12-01-20:21:09-root-INFO: grad norm: 73.650 72.934 10.251
2024-12-01-20:21:09-root-INFO: Loss too large (699.099->710.765)! Learning rate decreased to 0.01095.
2024-12-01-20:21:09-root-INFO: Loss too large (699.099->701.637)! Learning rate decreased to 0.00876.
2024-12-01-20:21:10-root-INFO: grad norm: 47.040 46.279 8.428
2024-12-01-20:21:10-root-INFO: grad norm: 21.186 20.577 5.046
2024-12-01-20:21:11-root-INFO: Loss Change: 701.599 -> 680.925
2024-12-01-20:21:11-root-INFO: Regularization Change: 0.000 -> 1.042
2024-12-01-20:21:11-root-INFO: Learning rate of xt decay: 0.07167 -> 0.07253.
2024-12-01-20:21:11-root-INFO: Coefficient of regularization decay: 0.00029 -> 0.00029.
2024-12-01-20:21:11-root-INFO: step: 141 lr_xt 0.01417280
2024-12-01-20:21:11-root-INFO: grad norm: 21.742 21.024 5.543
2024-12-01-20:21:11-root-INFO: grad norm: 22.310 21.745 4.989
2024-12-01-20:21:12-root-INFO: grad norm: 25.119 24.558 5.280
2024-12-01-20:21:12-root-INFO: grad norm: 31.447 31.016 5.188
2024-12-01-20:21:13-root-INFO: grad norm: 38.901 38.431 6.030
2024-12-01-20:21:13-root-INFO: Loss Change: 679.836 -> 664.543
2024-12-01-20:21:13-root-INFO: Regularization Change: 0.000 -> 1.637
2024-12-01-20:21:13-root-INFO: Learning rate of xt decay: 0.07253 -> 0.07340.
2024-12-01-20:21:13-root-INFO: Coefficient of regularization decay: 0.00029 -> 0.00030.
2024-12-01-20:21:13-root-INFO: step: 140 lr_xt 0.01467393
2024-12-01-20:21:13-root-INFO: grad norm: 48.087 47.575 6.996
2024-12-01-20:21:14-root-INFO: Loss too large (661.502->664.753)! Learning rate decreased to 0.01174.
2024-12-01-20:21:14-root-INFO: grad norm: 45.830 45.203 7.557
2024-12-01-20:21:15-root-INFO: grad norm: 47.873 47.344 7.099
2024-12-01-20:21:15-root-INFO: Loss too large (653.945->653.945)! Learning rate decreased to 0.00939.
2024-12-01-20:21:15-root-INFO: grad norm: 36.588 35.942 6.847
2024-12-01-20:21:16-root-INFO: grad norm: 25.614 25.086 5.172
2024-12-01-20:21:16-root-INFO: Loss Change: 661.502 -> 642.569
2024-12-01-20:21:16-root-INFO: Regularization Change: 0.000 -> 0.850
2024-12-01-20:21:16-root-INFO: Undo step: 140
2024-12-01-20:21:16-root-INFO: Undo step: 141
2024-12-01-20:21:16-root-INFO: Undo step: 142
2024-12-01-20:21:16-root-INFO: Undo step: 143
2024-12-01-20:21:16-root-INFO: Undo step: 144
2024-12-01-20:21:16-root-INFO: step: 145 lr_xt 0.01231381
2024-12-01-20:21:16-root-INFO: grad norm: 227.282 222.998 43.917
2024-12-01-20:21:17-root-INFO: grad norm: 203.052 200.812 30.079
2024-12-01-20:21:17-root-INFO: grad norm: 340.586 337.878 42.860
2024-12-01-20:21:17-root-INFO: Loss too large (899.576->1328.647)! Learning rate decreased to 0.00985.
2024-12-01-20:21:18-root-INFO: Loss too large (899.576->1114.969)! Learning rate decreased to 0.00788.
2024-12-01-20:21:18-root-INFO: Loss too large (899.576->982.660)! Learning rate decreased to 0.00630.
2024-12-01-20:21:18-root-INFO: Loss too large (899.576->902.591)! Learning rate decreased to 0.00504.
2024-12-01-20:21:18-root-INFO: grad norm: 120.940 119.966 15.313
2024-12-01-20:21:19-root-INFO: grad norm: 75.923 74.774 13.156
2024-12-01-20:21:19-root-INFO: Loss Change: 1091.271 -> 771.780
2024-12-01-20:21:19-root-INFO: Regularization Change: 0.000 -> 11.173
2024-12-01-20:21:19-root-INFO: Learning rate of xt decay: 0.06915 -> 0.06998.
2024-12-01-20:21:19-root-INFO: Coefficient of regularization decay: 0.00028 -> 0.00028.
2024-12-01-20:21:19-root-INFO: step: 144 lr_xt 0.01275743
2024-12-01-20:21:20-root-INFO: grad norm: 55.666 54.383 11.884
2024-12-01-20:21:20-root-INFO: grad norm: 46.063 45.017 9.764
2024-12-01-20:21:20-root-INFO: grad norm: 42.628 41.573 9.429
2024-12-01-20:21:21-root-INFO: grad norm: 42.783 41.978 8.259
2024-12-01-20:21:21-root-INFO: grad norm: 43.848 43.003 8.567
2024-12-01-20:21:22-root-INFO: Loss Change: 767.366 -> 691.287
2024-12-01-20:21:22-root-INFO: Regularization Change: 0.000 -> 4.977
2024-12-01-20:21:22-root-INFO: Learning rate of xt decay: 0.06998 -> 0.07082.
2024-12-01-20:21:22-root-INFO: Coefficient of regularization decay: 0.00028 -> 0.00029.
2024-12-01-20:21:22-root-INFO: step: 143 lr_xt 0.01321490
2024-12-01-20:21:22-root-INFO: grad norm: 40.425 39.767 7.260
2024-12-01-20:21:22-root-INFO: grad norm: 41.061 40.365 7.528
2024-12-01-20:21:23-root-INFO: grad norm: 45.663 45.128 6.963
2024-12-01-20:21:23-root-INFO: grad norm: 48.183 47.577 7.622
2024-12-01-20:21:24-root-INFO: grad norm: 55.458 54.951 7.481
2024-12-01-20:21:24-root-INFO: Loss too large (662.113->664.131)! Learning rate decreased to 0.01057.
2024-12-01-20:21:24-root-INFO: Loss Change: 686.425 -> 658.636
2024-12-01-20:21:24-root-INFO: Regularization Change: 0.000 -> 2.255
2024-12-01-20:21:24-root-INFO: Learning rate of xt decay: 0.07082 -> 0.07167.
2024-12-01-20:21:24-root-INFO: Coefficient of regularization decay: 0.00029 -> 0.00029.
2024-12-01-20:21:25-root-INFO: step: 142 lr_xt 0.01368658
2024-12-01-20:21:25-root-INFO: grad norm: 51.610 50.829 8.944
2024-12-01-20:21:25-root-INFO: grad norm: 53.076 52.539 7.537
2024-12-01-20:21:25-root-INFO: Loss too large (650.254->650.508)! Learning rate decreased to 0.01095.
2024-12-01-20:21:26-root-INFO: grad norm: 42.612 41.990 7.256
2024-12-01-20:21:26-root-INFO: grad norm: 33.955 33.434 5.925
2024-12-01-20:21:27-root-INFO: grad norm: 31.734 31.117 6.229
2024-12-01-20:21:27-root-INFO: Loss Change: 659.278 -> 630.074
2024-12-01-20:21:27-root-INFO: Regularization Change: 0.000 -> 1.434
2024-12-01-20:21:27-root-INFO: Learning rate of xt decay: 0.07167 -> 0.07253.
2024-12-01-20:21:27-root-INFO: Coefficient of regularization decay: 0.00029 -> 0.00029.
2024-12-01-20:21:27-root-INFO: step: 141 lr_xt 0.01417280
2024-12-01-20:21:27-root-INFO: grad norm: 35.714 35.130 6.433
2024-12-01-20:21:28-root-INFO: grad norm: 39.291 38.602 7.327
2024-12-01-20:21:28-root-INFO: grad norm: 48.192 47.598 7.542
2024-12-01-20:21:28-root-INFO: Loss too large (622.638->624.693)! Learning rate decreased to 0.01134.
2024-12-01-20:21:29-root-INFO: grad norm: 39.015 38.332 7.267
2024-12-01-20:21:29-root-INFO: grad norm: 26.300 25.777 5.221
2024-12-01-20:21:30-root-INFO: Loss Change: 629.197 -> 609.500
2024-12-01-20:21:30-root-INFO: Regularization Change: 0.000 -> 1.244
2024-12-01-20:21:30-root-INFO: Learning rate of xt decay: 0.07253 -> 0.07340.
2024-12-01-20:21:30-root-INFO: Coefficient of regularization decay: 0.00029 -> 0.00030.
2024-12-01-20:21:30-root-INFO: step: 140 lr_xt 0.01467393
2024-12-01-20:21:30-root-INFO: grad norm: 26.693 26.019 5.961
2024-12-01-20:21:31-root-INFO: grad norm: 32.815 32.278 5.912
2024-12-01-20:21:31-root-INFO: grad norm: 37.534 36.894 6.904
2024-12-01-20:21:31-root-INFO: grad norm: 48.545 47.983 7.366
2024-12-01-20:21:32-root-INFO: Loss too large (599.860->602.878)! Learning rate decreased to 0.01174.
2024-12-01-20:21:32-root-INFO: grad norm: 38.466 37.814 7.050
2024-12-01-20:21:32-root-INFO: Loss Change: 608.280 -> 590.219
2024-12-01-20:21:32-root-INFO: Regularization Change: 0.000 -> 1.247
2024-12-01-20:21:32-root-INFO: Learning rate of xt decay: 0.07340 -> 0.07428.
2024-12-01-20:21:32-root-INFO: Coefficient of regularization decay: 0.00030 -> 0.00030.
2024-12-01-20:21:33-root-INFO: step: 139 lr_xt 0.01519033
2024-12-01-20:21:33-root-INFO: grad norm: 29.766 29.188 5.834
2024-12-01-20:21:33-root-INFO: grad norm: 34.222 33.554 6.726
2024-12-01-20:21:34-root-INFO: grad norm: 48.700 48.124 7.470
2024-12-01-20:21:34-root-INFO: Loss too large (586.285->590.251)! Learning rate decreased to 0.01215.
2024-12-01-20:21:34-root-INFO: grad norm: 40.528 39.824 7.520
2024-12-01-20:21:35-root-INFO: grad norm: 28.814 28.340 5.203
2024-12-01-20:21:35-root-INFO: Loss Change: 590.401 -> 574.794
2024-12-01-20:21:35-root-INFO: Regularization Change: 0.000 -> 1.127
2024-12-01-20:21:35-root-INFO: Learning rate of xt decay: 0.07428 -> 0.07517.
2024-12-01-20:21:35-root-INFO: Coefficient of regularization decay: 0.00030 -> 0.00030.
2024-12-01-20:21:35-root-INFO: step: 138 lr_xt 0.01572237
2024-12-01-20:21:35-root-INFO: grad norm: 25.483 24.897 5.436
2024-12-01-20:21:36-root-INFO: grad norm: 35.670 35.155 6.041
2024-12-01-20:21:36-root-INFO: Loss too large (570.868->572.338)! Learning rate decreased to 0.01258.
2024-12-01-20:21:36-root-INFO: grad norm: 33.542 32.912 6.473
2024-12-01-20:21:37-root-INFO: grad norm: 30.381 29.893 5.424
2024-12-01-20:21:37-root-INFO: grad norm: 29.911 29.317 5.932
2024-12-01-20:21:38-root-INFO: Loss Change: 573.233 -> 559.895
2024-12-01-20:21:38-root-INFO: Regularization Change: 0.000 -> 0.974
2024-12-01-20:21:38-root-INFO: Learning rate of xt decay: 0.07517 -> 0.07608.
2024-12-01-20:21:38-root-INFO: Coefficient of regularization decay: 0.00030 -> 0.00030.
2024-12-01-20:21:38-root-INFO: step: 137 lr_xt 0.01627042
2024-12-01-20:21:38-root-INFO: grad norm: 42.310 41.554 7.963
2024-12-01-20:21:38-root-INFO: Loss too large (562.114->563.212)! Learning rate decreased to 0.01302.
2024-12-01-20:21:39-root-INFO: grad norm: 36.737 35.997 7.338
2024-12-01-20:21:39-root-INFO: grad norm: 31.905 31.392 5.698
2024-12-01-20:21:40-root-INFO: grad norm: 30.858 30.223 6.228
2024-12-01-20:21:40-root-INFO: grad norm: 30.118 29.641 5.337
2024-12-01-20:21:41-root-INFO: Loss Change: 562.114 -> 546.984
2024-12-01-20:21:41-root-INFO: Regularization Change: 0.000 -> 1.038
2024-12-01-20:21:41-root-INFO: Learning rate of xt decay: 0.07608 -> 0.07699.
2024-12-01-20:21:41-root-INFO: Coefficient of regularization decay: 0.00030 -> 0.00031.
2024-12-01-20:21:41-root-INFO: step: 136 lr_xt 0.01683487
2024-12-01-20:21:41-root-INFO: grad norm: 27.560 26.978 5.630
2024-12-01-20:21:42-root-INFO: grad norm: 40.316 39.819 6.310
2024-12-01-20:21:42-root-INFO: Loss too large (544.386->547.579)! Learning rate decreased to 0.01347.
2024-12-01-20:21:42-root-INFO: grad norm: 35.156 34.487 6.823
2024-12-01-20:21:43-root-INFO: grad norm: 27.060 26.606 4.934
2024-12-01-20:21:43-root-INFO: grad norm: 26.550 25.982 5.461
2024-12-01-20:21:43-root-INFO: Loss Change: 545.956 -> 532.950
2024-12-01-20:21:43-root-INFO: Regularization Change: 0.000 -> 0.969
2024-12-01-20:21:43-root-INFO: Learning rate of xt decay: 0.07699 -> 0.07791.
2024-12-01-20:21:43-root-INFO: Coefficient of regularization decay: 0.00031 -> 0.00031.
2024-12-01-20:21:44-root-INFO: step: 135 lr_xt 0.01741608
2024-12-01-20:21:44-root-INFO: grad norm: 32.237 31.665 6.045
2024-12-01-20:21:44-root-INFO: Loss too large (533.134->533.449)! Learning rate decreased to 0.01393.
2024-12-01-20:21:44-root-INFO: grad norm: 30.254 29.631 6.110
2024-12-01-20:21:45-root-INFO: grad norm: 29.448 28.994 5.149
2024-12-01-20:21:45-root-INFO: grad norm: 28.990 28.404 5.799
2024-12-01-20:21:46-root-INFO: grad norm: 28.576 28.138 4.981
2024-12-01-20:21:46-root-INFO: Loss Change: 533.134 -> 521.768
2024-12-01-20:21:46-root-INFO: Regularization Change: 0.000 -> 0.936
2024-12-01-20:21:46-root-INFO: Undo step: 135
2024-12-01-20:21:46-root-INFO: Undo step: 136
2024-12-01-20:21:46-root-INFO: Undo step: 137
2024-12-01-20:21:46-root-INFO: Undo step: 138
2024-12-01-20:21:46-root-INFO: Undo step: 139
2024-12-01-20:21:46-root-INFO: step: 140 lr_xt 0.01467393
2024-12-01-20:21:47-root-INFO: grad norm: 160.921 156.761 36.353
2024-12-01-20:21:47-root-INFO: grad norm: 100.328 96.345 27.989
2024-12-01-20:21:48-root-INFO: grad norm: 76.102 73.286 20.511
2024-12-01-20:21:48-root-INFO: grad norm: 66.066 63.640 17.739
2024-12-01-20:21:48-root-INFO: grad norm: 126.394 124.895 19.412
2024-12-01-20:21:49-root-INFO: Loss too large (637.288->712.222)! Learning rate decreased to 0.01174.
2024-12-01-20:21:49-root-INFO: Loss too large (637.288->669.603)! Learning rate decreased to 0.00939.
2024-12-01-20:21:49-root-INFO: Loss too large (637.288->643.510)! Learning rate decreased to 0.00751.
2024-12-01-20:21:49-root-INFO: Loss Change: 926.716 -> 628.082
2024-12-01-20:21:49-root-INFO: Regularization Change: 0.000 -> 16.111
2024-12-01-20:21:49-root-INFO: Learning rate of xt decay: 0.07340 -> 0.07428.
2024-12-01-20:21:49-root-INFO: Coefficient of regularization decay: 0.00030 -> 0.00030.
2024-12-01-20:21:49-root-INFO: step: 139 lr_xt 0.01519033
2024-12-01-20:21:49-root-INFO: grad norm: 75.000 73.889 12.859
2024-12-01-20:21:50-root-INFO: grad norm: 117.326 116.190 16.283
2024-12-01-20:21:50-root-INFO: Loss too large (618.925->671.811)! Learning rate decreased to 0.01215.
2024-12-01-20:21:50-root-INFO: Loss too large (618.925->636.199)! Learning rate decreased to 0.00972.
2024-12-01-20:21:51-root-INFO: grad norm: 75.759 74.912 11.299
2024-12-01-20:21:51-root-INFO: grad norm: 32.233 31.302 7.688
2024-12-01-20:21:52-root-INFO: grad norm: 26.817 25.835 7.191
2024-12-01-20:21:52-root-INFO: Loss Change: 629.406 -> 574.531
2024-12-01-20:21:52-root-INFO: Regularization Change: 0.000 -> 2.275
2024-12-01-20:21:52-root-INFO: Learning rate of xt decay: 0.07428 -> 0.07517.
2024-12-01-20:21:52-root-INFO: Coefficient of regularization decay: 0.00030 -> 0.00030.
2024-12-01-20:21:52-root-INFO: step: 138 lr_xt 0.01572237
2024-12-01-20:21:52-root-INFO: grad norm: 28.712 27.785 7.236
2024-12-01-20:21:53-root-INFO: grad norm: 35.203 34.399 7.480
2024-12-01-20:21:53-root-INFO: grad norm: 57.186 56.436 9.234
2024-12-01-20:21:54-root-INFO: Loss too large (567.452->573.010)! Learning rate decreased to 0.01258.
2024-12-01-20:21:54-root-INFO: grad norm: 45.228 44.431 8.451
2024-12-01-20:21:54-root-INFO: grad norm: 30.199 29.598 5.996
2024-12-01-20:21:55-root-INFO: Loss Change: 573.711 -> 550.901
2024-12-01-20:21:55-root-INFO: Regularization Change: 0.000 -> 1.722
2024-12-01-20:21:55-root-INFO: Learning rate of xt decay: 0.07517 -> 0.07608.
2024-12-01-20:21:55-root-INFO: Coefficient of regularization decay: 0.00030 -> 0.00030.
2024-12-01-20:21:55-root-INFO: step: 137 lr_xt 0.01627042
2024-12-01-20:21:55-root-INFO: grad norm: 26.668 25.810 6.711
2024-12-01-20:21:56-root-INFO: grad norm: 30.936 30.403 5.722
2024-12-01-20:21:56-root-INFO: grad norm: 42.438 41.815 7.242
2024-12-01-20:21:56-root-INFO: Loss too large (544.344->546.861)! Learning rate decreased to 0.01302.
2024-12-01-20:21:57-root-INFO: grad norm: 45.687 45.189 6.727
2024-12-01-20:21:57-root-INFO: grad norm: 44.274 43.625 7.555
2024-12-01-20:21:58-root-INFO: Loss Change: 549.337 -> 534.320
2024-12-01-20:21:58-root-INFO: Regularization Change: 0.000 -> 1.393
2024-12-01-20:21:58-root-INFO: Learning rate of xt decay: 0.07608 -> 0.07699.
2024-12-01-20:21:58-root-INFO: Coefficient of regularization decay: 0.00030 -> 0.00031.
2024-12-01-20:21:58-root-INFO: step: 136 lr_xt 0.01683487
2024-12-01-20:21:58-root-INFO: grad norm: 46.624 46.048 7.305
2024-12-01-20:21:58-root-INFO: Loss too large (535.622->540.462)! Learning rate decreased to 0.01347.
2024-12-01-20:21:59-root-INFO: grad norm: 44.431 43.790 7.518
2024-12-01-20:21:59-root-INFO: grad norm: 41.571 41.081 6.366
2024-12-01-20:22:00-root-INFO: grad norm: 40.586 39.984 6.960
2024-12-01-20:22:00-root-INFO: grad norm: 39.577 39.100 6.123
2024-12-01-20:22:00-root-INFO: Loss Change: 535.622 -> 521.961
2024-12-01-20:22:00-root-INFO: Regularization Change: 0.000 -> 1.167
2024-12-01-20:22:00-root-INFO: Learning rate of xt decay: 0.07699 -> 0.07791.
2024-12-01-20:22:00-root-INFO: Coefficient of regularization decay: 0.00031 -> 0.00031.
2024-12-01-20:22:01-root-INFO: step: 135 lr_xt 0.01741608
2024-12-01-20:22:01-root-INFO: grad norm: 35.890 35.282 6.578
2024-12-01-20:22:01-root-INFO: grad norm: 51.036 50.535 7.132
2024-12-01-20:22:01-root-INFO: Loss too large (520.049->526.411)! Learning rate decreased to 0.01393.
2024-12-01-20:22:02-root-INFO: grad norm: 44.399 43.762 7.494
2024-12-01-20:22:03-root-INFO: grad norm: 35.874 35.455 5.470
2024-12-01-20:22:03-root-INFO: grad norm: 34.833 34.324 5.934
2024-12-01-20:22:03-root-INFO: Loss Change: 520.368 -> 507.122
2024-12-01-20:22:03-root-INFO: Regularization Change: 0.000 -> 1.114
2024-12-01-20:22:03-root-INFO: Learning rate of xt decay: 0.07791 -> 0.07885.
2024-12-01-20:22:03-root-INFO: Coefficient of regularization decay: 0.00031 -> 0.00031.
2024-12-01-20:22:04-root-INFO: step: 134 lr_xt 0.01801447
2024-12-01-20:22:04-root-INFO: grad norm: 44.407 43.857 6.963
2024-12-01-20:22:04-root-INFO: Loss too large (509.150->513.064)! Learning rate decreased to 0.01441.
2024-12-01-20:22:04-root-INFO: grad norm: 41.689 41.115 6.895
2024-12-01-20:22:05-root-INFO: grad norm: 39.675 39.229 5.929
2024-12-01-20:22:05-root-INFO: grad norm: 37.816 37.259 6.470
2024-12-01-20:22:06-root-INFO: grad norm: 36.218 35.792 5.541
2024-12-01-20:22:06-root-INFO: Loss Change: 509.150 -> 496.387
2024-12-01-20:22:06-root-INFO: Regularization Change: 0.000 -> 1.079
2024-12-01-20:22:06-root-INFO: Learning rate of xt decay: 0.07885 -> 0.07979.
2024-12-01-20:22:06-root-INFO: Coefficient of regularization decay: 0.00031 -> 0.00032.
2024-12-01-20:22:06-root-INFO: step: 133 lr_xt 0.01863041
2024-12-01-20:22:06-root-INFO: grad norm: 31.421 30.829 6.073
2024-12-01-20:22:07-root-INFO: grad norm: 43.958 43.509 6.267
2024-12-01-20:22:07-root-INFO: Loss too large (494.723->499.672)! Learning rate decreased to 0.01490.
2024-12-01-20:22:07-root-INFO: grad norm: 39.360 38.766 6.813
2024-12-01-20:22:08-root-INFO: grad norm: 33.349 32.955 5.112
2024-12-01-20:22:08-root-INFO: grad norm: 32.109 31.614 5.616
2024-12-01-20:22:09-root-INFO: Loss Change: 495.131 -> 484.035
2024-12-01-20:22:09-root-INFO: Regularization Change: 0.000 -> 1.024
2024-12-01-20:22:09-root-INFO: Learning rate of xt decay: 0.07979 -> 0.08075.
2024-12-01-20:22:09-root-INFO: Coefficient of regularization decay: 0.00032 -> 0.00032.
2024-12-01-20:22:09-root-INFO: step: 132 lr_xt 0.01926430
2024-12-01-20:22:09-root-INFO: grad norm: 37.902 37.405 6.115
2024-12-01-20:22:09-root-INFO: Loss too large (485.493->488.428)! Learning rate decreased to 0.01541.
2024-12-01-20:22:10-root-INFO: grad norm: 36.037 35.501 6.194
2024-12-01-20:22:10-root-INFO: grad norm: 34.602 34.201 5.254
2024-12-01-20:22:11-root-INFO: grad norm: 33.370 32.855 5.842
2024-12-01-20:22:11-root-INFO: grad norm: 32.279 31.898 4.942
2024-12-01-20:22:11-root-INFO: Loss Change: 485.493 -> 474.716
2024-12-01-20:22:11-root-INFO: Regularization Change: 0.000 -> 0.997
2024-12-01-20:22:11-root-INFO: Learning rate of xt decay: 0.08075 -> 0.08172.
2024-12-01-20:22:11-root-INFO: Coefficient of regularization decay: 0.00032 -> 0.00032.
2024-12-01-20:22:12-root-INFO: step: 131 lr_xt 0.01991656
2024-12-01-20:22:12-root-INFO: grad norm: 27.865 27.304 5.561
2024-12-01-20:22:12-root-INFO: grad norm: 38.215 37.820 5.479
2024-12-01-20:22:12-root-INFO: Loss too large (473.243->476.872)! Learning rate decreased to 0.01593.
2024-12-01-20:22:13-root-INFO: grad norm: 34.817 34.256 6.221
2024-12-01-20:22:13-root-INFO: grad norm: 30.458 30.098 4.665
2024-12-01-20:22:14-root-INFO: grad norm: 29.142 28.663 5.262
2024-12-01-20:22:14-root-INFO: Loss Change: 473.943 -> 463.788
2024-12-01-20:22:14-root-INFO: Regularization Change: 0.000 -> 1.001
2024-12-01-20:22:14-root-INFO: Learning rate of xt decay: 0.08172 -> 0.08270.
2024-12-01-20:22:14-root-INFO: Coefficient of regularization decay: 0.00032 -> 0.00033.
2024-12-01-20:22:14-root-INFO: step: 130 lr_xt 0.02058758
2024-12-01-20:22:14-root-INFO: grad norm: 35.060 34.610 5.604
2024-12-01-20:22:15-root-INFO: Loss too large (465.238->467.848)! Learning rate decreased to 0.01647.
2024-12-01-20:22:15-root-INFO: grad norm: 33.306 32.800 5.783
2024-12-01-20:22:15-root-INFO: grad norm: 31.888 31.534 4.736
2024-12-01-20:22:16-root-INFO: grad norm: 30.803 30.328 5.387
2024-12-01-20:22:16-root-INFO: grad norm: 29.788 29.452 4.460
2024-12-01-20:22:17-root-INFO: Loss Change: 465.238 -> 455.202
2024-12-01-20:22:17-root-INFO: Regularization Change: 0.000 -> 0.980
2024-12-01-20:22:17-root-INFO: Undo step: 130
2024-12-01-20:22:17-root-INFO: Undo step: 131
2024-12-01-20:22:17-root-INFO: Undo step: 132
2024-12-01-20:22:17-root-INFO: Undo step: 133
2024-12-01-20:22:17-root-INFO: Undo step: 134
2024-12-01-20:22:17-root-INFO: step: 135 lr_xt 0.01741608
2024-12-01-20:22:17-root-INFO: grad norm: 174.401 170.625 36.093
2024-12-01-20:22:18-root-INFO: grad norm: 77.733 75.044 20.270
2024-12-01-20:22:18-root-INFO: grad norm: 55.157 53.273 14.292
2024-12-01-20:22:18-root-INFO: grad norm: 44.847 43.459 11.069
2024-12-01-20:22:19-root-INFO: grad norm: 39.504 38.427 9.161
2024-12-01-20:22:19-root-INFO: Loss Change: 868.390 -> 525.064
2024-12-01-20:22:19-root-INFO: Regularization Change: 0.000 -> 22.226
2024-12-01-20:22:19-root-INFO: Learning rate of xt decay: 0.07791 -> 0.07885.
2024-12-01-20:22:19-root-INFO: Coefficient of regularization decay: 0.00031 -> 0.00031.
2024-12-01-20:22:19-root-INFO: step: 134 lr_xt 0.01801447
2024-12-01-20:22:20-root-INFO: grad norm: 43.273 42.405 8.623
2024-12-01-20:22:20-root-INFO: grad norm: 40.647 39.995 7.249
2024-12-01-20:22:21-root-INFO: grad norm: 38.830 38.224 6.838
2024-12-01-20:22:21-root-INFO: grad norm: 37.442 36.932 6.161
2024-12-01-20:22:22-root-INFO: grad norm: 36.590 36.090 6.028
2024-12-01-20:22:22-root-INFO: Loss Change: 525.979 -> 489.679
2024-12-01-20:22:22-root-INFO: Regularization Change: 0.000 -> 3.506
2024-12-01-20:22:22-root-INFO: Learning rate of xt decay: 0.07885 -> 0.07979.
2024-12-01-20:22:22-root-INFO: Coefficient of regularization decay: 0.00031 -> 0.00032.
2024-12-01-20:22:22-root-INFO: step: 133 lr_xt 0.01863041
2024-12-01-20:22:22-root-INFO: grad norm: 31.121 30.633 5.488
2024-12-01-20:22:23-root-INFO: grad norm: 30.681 30.191 5.459
2024-12-01-20:22:23-root-INFO: grad norm: 32.018 31.645 4.870
2024-12-01-20:22:23-root-INFO: grad norm: 33.385 32.990 5.122
2024-12-01-20:22:24-root-INFO: grad norm: 35.205 34.885 4.737
2024-12-01-20:22:24-root-INFO: Loss Change: 487.233 -> 470.355
2024-12-01-20:22:24-root-INFO: Regularization Change: 0.000 -> 2.141
2024-12-01-20:22:24-root-INFO: Learning rate of xt decay: 0.07979 -> 0.08075.
2024-12-01-20:22:24-root-INFO: Coefficient of regularization decay: 0.00032 -> 0.00032.
2024-12-01-20:22:24-root-INFO: step: 132 lr_xt 0.01926430
2024-12-01-20:22:25-root-INFO: grad norm: 42.262 41.841 5.948
2024-12-01-20:22:25-root-INFO: grad norm: 41.826 41.534 4.939
2024-12-01-20:22:26-root-INFO: grad norm: 40.973 40.651 5.127
2024-12-01-20:22:26-root-INFO: grad norm: 39.483 39.205 4.676
2024-12-01-20:22:26-root-INFO: grad norm: 38.325 38.032 4.724
2024-12-01-20:22:27-root-INFO: Loss Change: 472.163 -> 455.018
2024-12-01-20:22:27-root-INFO: Regularization Change: 0.000 -> 1.954
2024-12-01-20:22:27-root-INFO: Learning rate of xt decay: 0.08075 -> 0.08172.
2024-12-01-20:22:27-root-INFO: Coefficient of regularization decay: 0.00032 -> 0.00032.
2024-12-01-20:22:27-root-INFO: step: 131 lr_xt 0.01991656
2024-12-01-20:22:27-root-INFO: grad norm: 32.394 32.089 4.436
2024-12-01-20:22:28-root-INFO: grad norm: 31.770 31.452 4.483
2024-12-01-20:22:28-root-INFO: grad norm: 32.639 32.388 4.046
2024-12-01-20:22:29-root-INFO: grad norm: 33.370 33.097 4.258
2024-12-01-20:22:29-root-INFO: grad norm: 34.033 33.787 4.088
2024-12-01-20:22:29-root-INFO: Loss Change: 453.128 -> 441.842
2024-12-01-20:22:29-root-INFO: Regularization Change: 0.000 -> 1.644
2024-12-01-20:22:29-root-INFO: Learning rate of xt decay: 0.08172 -> 0.08270.
2024-12-01-20:22:29-root-INFO: Coefficient of regularization decay: 0.00032 -> 0.00033.
2024-12-01-20:22:29-root-INFO: step: 130 lr_xt 0.02058758
2024-12-01-20:22:30-root-INFO: grad norm: 39.950 39.596 5.307
2024-12-01-20:22:30-root-INFO: grad norm: 38.801 38.545 4.450
2024-12-01-20:22:31-root-INFO: grad norm: 37.330 37.075 4.358
2024-12-01-20:22:31-root-INFO: grad norm: 35.408 35.156 4.217
2024-12-01-20:22:32-root-INFO: grad norm: 34.049 33.814 4.001
2024-12-01-20:22:32-root-INFO: Loss Change: 443.846 -> 429.677
2024-12-01-20:22:32-root-INFO: Regularization Change: 0.000 -> 1.661
2024-12-01-20:22:32-root-INFO: Learning rate of xt decay: 0.08270 -> 0.08369.
2024-12-01-20:22:32-root-INFO: Coefficient of regularization decay: 0.00033 -> 0.00033.
2024-12-01-20:22:32-root-INFO: step: 129 lr_xt 0.02127779
2024-12-01-20:22:32-root-INFO: grad norm: 27.876 27.616 3.795
2024-12-01-20:22:33-root-INFO: grad norm: 27.564 27.319 3.670
2024-12-01-20:22:33-root-INFO: grad norm: 28.736 28.502 3.660
2024-12-01-20:22:34-root-INFO: grad norm: 29.727 29.500 3.666
2024-12-01-20:22:34-root-INFO: grad norm: 30.669 30.428 3.834
2024-12-01-20:22:34-root-INFO: Loss Change: 427.556 -> 418.917
2024-12-01-20:22:34-root-INFO: Regularization Change: 0.000 -> 1.424
2024-12-01-20:22:34-root-INFO: Learning rate of xt decay: 0.08369 -> 0.08470.
2024-12-01-20:22:34-root-INFO: Coefficient of regularization decay: 0.00033 -> 0.00033.
2024-12-01-20:22:35-root-INFO: step: 128 lr_xt 0.02198759
2024-12-01-20:22:35-root-INFO: grad norm: 38.601 38.196 5.575
2024-12-01-20:22:35-root-INFO: grad norm: 37.404 37.144 4.405
2024-12-01-20:22:36-root-INFO: grad norm: 35.583 35.333 4.210
2024-12-01-20:22:36-root-INFO: grad norm: 33.261 33.002 4.140
2024-12-01-20:22:37-root-INFO: grad norm: 31.689 31.463 3.783
2024-12-01-20:22:37-root-INFO: Loss Change: 421.334 -> 408.205
2024-12-01-20:22:37-root-INFO: Regularization Change: 0.000 -> 1.599
2024-12-01-20:22:37-root-INFO: Learning rate of xt decay: 0.08470 -> 0.08571.
2024-12-01-20:22:37-root-INFO: Coefficient of regularization decay: 0.00033 -> 0.00034.
2024-12-01-20:22:37-root-INFO: step: 127 lr_xt 0.02271741
2024-12-01-20:22:37-root-INFO: grad norm: 27.578 27.366 3.408
2024-12-01-20:22:38-root-INFO: grad norm: 27.520 27.303 3.447
2024-12-01-20:22:38-root-INFO: grad norm: 28.238 28.013 3.554
2024-12-01-20:22:39-root-INFO: grad norm: 28.793 28.587 3.439
2024-12-01-20:22:39-root-INFO: grad norm: 29.291 29.061 3.661
2024-12-01-20:22:40-root-INFO: Loss Change: 407.020 -> 399.266
2024-12-01-20:22:40-root-INFO: Regularization Change: 0.000 -> 1.387
2024-12-01-20:22:40-root-INFO: Learning rate of xt decay: 0.08571 -> 0.08674.
2024-12-01-20:22:40-root-INFO: Coefficient of regularization decay: 0.00034 -> 0.00034.
2024-12-01-20:22:40-root-INFO: step: 126 lr_xt 0.02346768
2024-12-01-20:22:40-root-INFO: grad norm: 33.878 33.570 4.553
2024-12-01-20:22:40-root-INFO: grad norm: 33.620 33.391 3.921
2024-12-01-20:22:41-root-INFO: grad norm: 32.867 32.655 3.730
2024-12-01-20:22:41-root-INFO: grad norm: 31.711 31.483 3.800
2024-12-01-20:22:42-root-INFO: grad norm: 30.819 30.621 3.491
2024-12-01-20:22:42-root-INFO: Loss Change: 400.712 -> 390.464
2024-12-01-20:22:42-root-INFO: Regularization Change: 0.000 -> 1.515
2024-12-01-20:22:42-root-INFO: Learning rate of xt decay: 0.08674 -> 0.08778.
2024-12-01-20:22:42-root-INFO: Coefficient of regularization decay: 0.00034 -> 0.00034.
2024-12-01-20:22:42-root-INFO: step: 125 lr_xt 0.02423882
2024-12-01-20:22:42-root-INFO: grad norm: 26.629 26.394 3.529
2024-12-01-20:22:43-root-INFO: grad norm: 26.286 26.087 3.225
2024-12-01-20:22:43-root-INFO: grad norm: 26.805 26.596 3.343
2024-12-01-20:22:44-root-INFO: grad norm: 27.209 27.023 3.176
2024-12-01-20:22:44-root-INFO: grad norm: 27.557 27.346 3.409
2024-12-01-20:22:44-root-INFO: Loss Change: 388.678 -> 381.289
2024-12-01-20:22:44-root-INFO: Regularization Change: 0.000 -> 1.380
2024-12-01-20:22:44-root-INFO: Undo step: 125
2024-12-01-20:22:44-root-INFO: Undo step: 126
2024-12-01-20:22:45-root-INFO: Undo step: 127
2024-12-01-20:22:45-root-INFO: Undo step: 128
2024-12-01-20:22:45-root-INFO: Undo step: 129
2024-12-01-20:22:45-root-INFO: step: 130 lr_xt 0.02058758
2024-12-01-20:22:45-root-INFO: grad norm: 122.051 119.798 23.342
2024-12-01-20:22:45-root-INFO: grad norm: 61.839 60.435 13.106
2024-12-01-20:22:46-root-INFO: grad norm: 42.551 41.273 10.350
2024-12-01-20:22:46-root-INFO: grad norm: 34.193 33.136 8.434
2024-12-01-20:22:47-root-INFO: grad norm: 29.738 28.804 7.394
2024-12-01-20:22:47-root-INFO: Loss Change: 763.349 -> 453.362
2024-12-01-20:22:47-root-INFO: Regularization Change: 0.000 -> 24.773
2024-12-01-20:22:47-root-INFO: Learning rate of xt decay: 0.08270 -> 0.08369.
2024-12-01-20:22:47-root-INFO: Coefficient of regularization decay: 0.00033 -> 0.00033.
2024-12-01-20:22:47-root-INFO: step: 129 lr_xt 0.02127779
2024-12-01-20:22:47-root-INFO: grad norm: 31.803 31.014 7.041
2024-12-01-20:22:48-root-INFO: grad norm: 29.302 28.489 6.856
2024-12-01-20:22:48-root-INFO: grad norm: 27.923 27.278 5.968
2024-12-01-20:22:49-root-INFO: grad norm: 27.172 26.469 6.142
2024-12-01-20:22:49-root-INFO: grad norm: 26.632 26.072 5.433
2024-12-01-20:22:49-root-INFO: Loss Change: 452.640 -> 420.347
2024-12-01-20:22:50-root-INFO: Regularization Change: 0.000 -> 3.683
2024-12-01-20:22:50-root-INFO: Learning rate of xt decay: 0.08369 -> 0.08470.
2024-12-01-20:22:50-root-INFO: Coefficient of regularization decay: 0.00033 -> 0.00033.
2024-12-01-20:22:50-root-INFO: step: 128 lr_xt 0.02198759
2024-12-01-20:22:50-root-INFO: grad norm: 23.463 22.892 5.143
2024-12-01-20:22:50-root-INFO: grad norm: 22.086 21.571 4.741
2024-12-01-20:22:51-root-INFO: grad norm: 22.479 21.954 4.831
2024-12-01-20:22:51-root-INFO: grad norm: 23.242 22.790 4.561
2024-12-01-20:22:52-root-INFO: grad norm: 24.704 24.229 4.821
2024-12-01-20:22:52-root-INFO: Loss Change: 418.420 -> 402.174
2024-12-01-20:22:52-root-INFO: Regularization Change: 0.000 -> 2.101
2024-12-01-20:22:52-root-INFO: Learning rate of xt decay: 0.08470 -> 0.08571.
2024-12-01-20:22:52-root-INFO: Coefficient of regularization decay: 0.00033 -> 0.00034.
2024-12-01-20:22:52-root-INFO: step: 127 lr_xt 0.02271741
2024-12-01-20:22:52-root-INFO: grad norm: 32.980 32.459 5.840
2024-12-01-20:22:53-root-INFO: grad norm: 35.197 34.741 5.644
2024-12-01-20:22:53-root-INFO: grad norm: 35.846 35.437 5.402
2024-12-01-20:22:54-root-INFO: grad norm: 35.636 35.210 5.493
2024-12-01-20:22:54-root-INFO: grad norm: 34.781 34.412 5.053
2024-12-01-20:22:54-root-INFO: Loss Change: 403.783 -> 391.826
2024-12-01-20:22:54-root-INFO: Regularization Change: 0.000 -> 1.942
2024-12-01-20:22:54-root-INFO: Learning rate of xt decay: 0.08571 -> 0.08674.
2024-12-01-20:22:54-root-INFO: Coefficient of regularization decay: 0.00034 -> 0.00034.
2024-12-01-20:22:55-root-INFO: step: 126 lr_xt 0.02346768
2024-12-01-20:22:55-root-INFO: grad norm: 30.196 29.881 4.346
2024-12-01-20:22:55-root-INFO: grad norm: 29.912 29.592 4.363
2024-12-01-20:22:56-root-INFO: grad norm: 30.131 29.806 4.415
2024-12-01-20:22:56-root-INFO: grad norm: 30.163 29.868 4.205
2024-12-01-20:22:57-root-INFO: grad norm: 30.104 29.785 4.367
2024-12-01-20:22:57-root-INFO: Loss Change: 390.041 -> 380.131
2024-12-01-20:22:57-root-INFO: Regularization Change: 0.000 -> 1.678
2024-12-01-20:22:57-root-INFO: Learning rate of xt decay: 0.08674 -> 0.08778.
2024-12-01-20:22:57-root-INFO: Coefficient of regularization decay: 0.00034 -> 0.00034.
2024-12-01-20:22:57-root-INFO: step: 125 lr_xt 0.02423882
2024-12-01-20:22:57-root-INFO: grad norm: 36.776 36.361 5.511
2024-12-01-20:22:58-root-INFO: grad norm: 34.656 34.321 4.809
2024-12-01-20:22:58-root-INFO: grad norm: 32.535 32.237 4.390
2024-12-01-20:22:59-root-INFO: grad norm: 30.237 29.919 4.375
2024-12-01-20:22:59-root-INFO: grad norm: 28.769 28.499 3.930
2024-12-01-20:23:00-root-INFO: Loss Change: 382.633 -> 369.075
2024-12-01-20:23:00-root-INFO: Regularization Change: 0.000 -> 1.726
2024-12-01-20:23:00-root-INFO: Learning rate of xt decay: 0.08778 -> 0.08884.
2024-12-01-20:23:00-root-INFO: Coefficient of regularization decay: 0.00034 -> 0.00035.
2024-12-01-20:23:00-root-INFO: step: 124 lr_xt 0.02515763
2024-12-01-20:23:00-root-INFO: grad norm: 21.737 21.456 3.485
2024-12-01-20:23:00-root-INFO: grad norm: 20.665 20.428 3.117
2024-12-01-20:23:01-root-INFO: grad norm: 21.498 21.268 3.133
2024-12-01-20:23:01-root-INFO: grad norm: 22.432 22.220 3.083
2024-12-01-20:23:02-root-INFO: grad norm: 23.561 23.328 3.300
2024-12-01-20:23:02-root-INFO: Loss Change: 366.876 -> 358.915
2024-12-01-20:23:02-root-INFO: Regularization Change: 0.000 -> 1.400
2024-12-01-20:23:02-root-INFO: Learning rate of xt decay: 0.08884 -> 0.08990.
2024-12-01-20:23:02-root-INFO: Coefficient of regularization decay: 0.00035 -> 0.00035.
2024-12-01-20:23:02-root-INFO: step: 123 lr_xt 0.02597490
2024-12-01-20:23:02-root-INFO: grad norm: 29.814 29.512 4.237
2024-12-01-20:23:03-root-INFO: grad norm: 30.232 29.987 3.842
2024-12-01-20:23:03-root-INFO: grad norm: 29.856 29.625 3.705
2024-12-01-20:23:04-root-INFO: grad norm: 28.978 28.731 3.775
2024-12-01-20:23:04-root-INFO: grad norm: 28.249 28.033 3.485
2024-12-01-20:23:05-root-INFO: Loss Change: 360.686 -> 351.555
2024-12-01-20:23:05-root-INFO: Regularization Change: 0.000 -> 1.554
2024-12-01-20:23:05-root-INFO: Learning rate of xt decay: 0.08990 -> 0.09098.
2024-12-01-20:23:05-root-INFO: Coefficient of regularization decay: 0.00035 -> 0.00035.
2024-12-01-20:23:05-root-INFO: step: 122 lr_xt 0.02681440
2024-12-01-20:23:05-root-INFO: grad norm: 23.463 23.278 2.940
2024-12-01-20:23:06-root-INFO: grad norm: 23.115 22.929 2.929
2024-12-01-20:23:06-root-INFO: grad norm: 23.257 23.064 2.987
2024-12-01-20:23:06-root-INFO: grad norm: 23.416 23.243 2.846
2024-12-01-20:23:07-root-INFO: grad norm: 23.591 23.396 3.031
2024-12-01-20:23:07-root-INFO: Loss Change: 349.935 -> 342.837
2024-12-01-20:23:07-root-INFO: Regularization Change: 0.000 -> 1.372
2024-12-01-20:23:07-root-INFO: Learning rate of xt decay: 0.09098 -> 0.09207.
2024-12-01-20:23:07-root-INFO: Coefficient of regularization decay: 0.00035 -> 0.00036.
2024-12-01-20:23:07-root-INFO: step: 121 lr_xt 0.02767658
2024-12-01-20:23:08-root-INFO: grad norm: 29.048 28.784 3.904
2024-12-01-20:23:08-root-INFO: grad norm: 28.237 28.021 3.488
2024-12-01-20:23:09-root-INFO: grad norm: 27.282 27.091 3.219
2024-12-01-20:23:09-root-INFO: grad norm: 26.103 25.892 3.312
2024-12-01-20:23:10-root-INFO: grad norm: 25.300 25.123 2.993
2024-12-01-20:23:10-root-INFO: Loss Change: 344.488 -> 335.159
2024-12-01-20:23:10-root-INFO: Regularization Change: 0.000 -> 1.521
2024-12-01-20:23:10-root-INFO: Learning rate of xt decay: 0.09207 -> 0.09318.
2024-12-01-20:23:10-root-INFO: Coefficient of regularization decay: 0.00036 -> 0.00036.
2024-12-01-20:23:10-root-INFO: step: 120 lr_xt 0.02856188
2024-12-01-20:23:10-root-INFO: grad norm: 20.648 20.481 2.622
2024-12-01-20:23:11-root-INFO: grad norm: 20.401 20.236 2.587
2024-12-01-20:23:11-root-INFO: grad norm: 20.810 20.642 2.641
2024-12-01-20:23:12-root-INFO: grad norm: 21.184 21.032 2.540
2024-12-01-20:23:12-root-INFO: grad norm: 21.607 21.438 2.700
2024-12-01-20:23:12-root-INFO: Loss Change: 333.848 -> 327.587
2024-12-01-20:23:12-root-INFO: Regularization Change: 0.000 -> 1.318
2024-12-01-20:23:12-root-INFO: Undo step: 120
2024-12-01-20:23:12-root-INFO: Undo step: 121
2024-12-01-20:23:12-root-INFO: Undo step: 122
2024-12-01-20:23:12-root-INFO: Undo step: 123
2024-12-01-20:23:12-root-INFO: Undo step: 124
2024-12-01-20:23:12-root-INFO: step: 125 lr_xt 0.02423882
2024-12-01-20:23:13-root-INFO: grad norm: 114.203 112.368 20.386
2024-12-01-20:23:13-root-INFO: grad norm: 56.934 55.476 12.802
2024-12-01-20:23:14-root-INFO: grad norm: 40.923 39.301 11.408
2024-12-01-20:23:14-root-INFO: grad norm: 34.474 33.323 8.833
2024-12-01-20:23:15-root-INFO: grad norm: 31.046 29.838 8.578
2024-12-01-20:23:15-root-INFO: Loss Change: 664.554 -> 392.353
2024-12-01-20:23:15-root-INFO: Regularization Change: 0.000 -> 23.665
2024-12-01-20:23:15-root-INFO: Learning rate of xt decay: 0.08778 -> 0.08884.
2024-12-01-20:23:15-root-INFO: Coefficient of regularization decay: 0.00034 -> 0.00035.
2024-12-01-20:23:15-root-INFO: step: 124 lr_xt 0.02515763
2024-12-01-20:23:15-root-INFO: grad norm: 36.875 35.874 8.531
2024-12-01-20:23:16-root-INFO: grad norm: 33.790 32.831 7.995
2024-12-01-20:23:16-root-INFO: grad norm: 31.615 30.872 6.812
2024-12-01-20:23:17-root-INFO: grad norm: 30.169 29.378 6.863
2024-12-01-20:23:17-root-INFO: grad norm: 28.747 28.117 5.984
2024-12-01-20:23:17-root-INFO: Loss Change: 393.667 -> 363.095
2024-12-01-20:23:17-root-INFO: Regularization Change: 0.000 -> 4.165
2024-12-01-20:23:17-root-INFO: Learning rate of xt decay: 0.08884 -> 0.08990.
2024-12-01-20:23:17-root-INFO: Coefficient of regularization decay: 0.00035 -> 0.00035.
2024-12-01-20:23:18-root-INFO: step: 123 lr_xt 0.02597490
2024-12-01-20:23:18-root-INFO: grad norm: 25.526 24.895 5.643
2024-12-01-20:23:18-root-INFO: grad norm: 24.554 24.002 5.178
2024-12-01-20:23:19-root-INFO: grad norm: 24.401 23.830 5.246
2024-12-01-20:23:19-root-INFO: grad norm: 24.242 23.756 4.831
2024-12-01-20:23:20-root-INFO: grad norm: 24.432 23.912 5.010
2024-12-01-20:23:20-root-INFO: Loss Change: 361.554 -> 346.541
2024-12-01-20:23:20-root-INFO: Regularization Change: 0.000 -> 2.271
2024-12-01-20:23:20-root-INFO: Learning rate of xt decay: 0.08990 -> 0.09098.
2024-12-01-20:23:20-root-INFO: Coefficient of regularization decay: 0.00035 -> 0.00035.
2024-12-01-20:23:20-root-INFO: step: 122 lr_xt 0.02681440
2024-12-01-20:23:20-root-INFO: grad norm: 29.655 29.102 5.701
2024-12-01-20:23:21-root-INFO: grad norm: 28.911 28.427 5.272
2024-12-01-20:23:21-root-INFO: grad norm: 27.986 27.565 4.839
2024-12-01-20:23:22-root-INFO: grad norm: 27.240 26.799 4.884
2024-12-01-20:23:22-root-INFO: grad norm: 26.495 26.121 4.441
2024-12-01-20:23:22-root-INFO: Loss Change: 347.956 -> 336.253
2024-12-01-20:23:22-root-INFO: Regularization Change: 0.000 -> 1.913
2024-12-01-20:23:22-root-INFO: Learning rate of xt decay: 0.09098 -> 0.09207.
2024-12-01-20:23:22-root-INFO: Coefficient of regularization decay: 0.00035 -> 0.00036.
2024-12-01-20:23:23-root-INFO: step: 121 lr_xt 0.02767658
2024-12-01-20:23:23-root-INFO: grad norm: 22.274 21.901 4.060
2024-12-01-20:23:23-root-INFO: grad norm: 21.992 21.655 3.838
2024-12-01-20:23:24-root-INFO: grad norm: 22.327 21.979 3.930
2024-12-01-20:23:24-root-INFO: grad norm: 22.609 22.302 3.711
2024-12-01-20:23:25-root-INFO: grad norm: 23.031 22.697 3.912
2024-12-01-20:23:25-root-INFO: Loss Change: 334.532 -> 326.311
2024-12-01-20:23:25-root-INFO: Regularization Change: 0.000 -> 1.560
2024-12-01-20:23:25-root-INFO: Learning rate of xt decay: 0.09207 -> 0.09318.
2024-12-01-20:23:25-root-INFO: Coefficient of regularization decay: 0.00036 -> 0.00036.
2024-12-01-20:23:25-root-INFO: step: 120 lr_xt 0.02856188
2024-12-01-20:23:25-root-INFO: grad norm: 28.956 28.558 4.786
2024-12-01-20:23:26-root-INFO: grad norm: 28.564 28.230 4.358
2024-12-01-20:23:26-root-INFO: grad norm: 27.985 27.677 4.136
2024-12-01-20:23:27-root-INFO: grad norm: 27.242 26.914 4.212
2024-12-01-20:23:27-root-INFO: grad norm: 26.667 26.379 3.903
2024-12-01-20:23:27-root-INFO: Loss Change: 328.455 -> 319.369
2024-12-01-20:23:27-root-INFO: Regularization Change: 0.000 -> 1.691
2024-12-01-20:23:27-root-INFO: Learning rate of xt decay: 0.09318 -> 0.09430.
2024-12-01-20:23:27-root-INFO: Coefficient of regularization decay: 0.00036 -> 0.00036.
2024-12-01-20:23:28-root-INFO: step: 119 lr_xt 0.02947075
2024-12-01-20:23:28-root-INFO: grad norm: 21.839 21.536 3.623
2024-12-01-20:23:28-root-INFO: grad norm: 21.336 21.058 3.432
2024-12-01-20:23:29-root-INFO: grad norm: 21.533 21.264 3.390
2024-12-01-20:23:29-root-INFO: grad norm: 21.797 21.549 3.278
2024-12-01-20:23:30-root-INFO: grad norm: 22.153 21.888 3.415
2024-12-01-20:23:30-root-INFO: Loss Change: 317.409 -> 310.540
2024-12-01-20:23:30-root-INFO: Regularization Change: 0.000 -> 1.450
2024-12-01-20:23:30-root-INFO: Learning rate of xt decay: 0.09430 -> 0.09543.
2024-12-01-20:23:30-root-INFO: Coefficient of regularization decay: 0.00036 -> 0.00037.
2024-12-01-20:23:30-root-INFO: step: 118 lr_xt 0.03040366
2024-12-01-20:23:30-root-INFO: grad norm: 26.118 25.808 4.011
2024-12-01-20:23:31-root-INFO: grad norm: 26.220 25.960 3.686
2024-12-01-20:23:31-root-INFO: grad norm: 26.144 25.897 3.584
2024-12-01-20:23:32-root-INFO: grad norm: 25.935 25.679 3.635
2024-12-01-20:23:32-root-INFO: grad norm: 25.781 25.548 3.458
2024-12-01-20:23:33-root-INFO: Loss Change: 312.247 -> 305.305
2024-12-01-20:23:33-root-INFO: Regularization Change: 0.000 -> 1.571
2024-12-01-20:23:33-root-INFO: Learning rate of xt decay: 0.09543 -> 0.09657.
2024-12-01-20:23:33-root-INFO: Coefficient of regularization decay: 0.00037 -> 0.00037.
2024-12-01-20:23:33-root-INFO: step: 117 lr_xt 0.03136105
2024-12-01-20:23:33-root-INFO: grad norm: 20.824 20.598 3.060
2024-12-01-20:23:33-root-INFO: grad norm: 20.998 20.770 3.081
2024-12-01-20:23:34-root-INFO: grad norm: 21.905 21.700 2.988
2024-12-01-20:23:34-root-INFO: grad norm: 22.709 22.506 3.029
2024-12-01-20:23:35-root-INFO: grad norm: 23.539 23.332 3.108
2024-12-01-20:23:35-root-INFO: Loss Change: 303.447 -> 298.546
2024-12-01-20:23:35-root-INFO: Regularization Change: 0.000 -> 1.440
2024-12-01-20:23:35-root-INFO: Learning rate of xt decay: 0.09657 -> 0.09773.
2024-12-01-20:23:35-root-INFO: Coefficient of regularization decay: 0.00037 -> 0.00038.
2024-12-01-20:23:35-root-INFO: step: 116 lr_xt 0.03234339
2024-12-01-20:23:35-root-INFO: grad norm: 28.782 28.490 4.095
2024-12-01-20:23:36-root-INFO: grad norm: 28.564 28.349 3.498
2024-12-01-20:23:36-root-INFO: grad norm: 27.965 27.748 3.478
2024-12-01-20:23:37-root-INFO: grad norm: 27.223 27.008 3.411
2024-12-01-20:23:37-root-INFO: grad norm: 26.597 26.393 3.286
2024-12-01-20:23:38-root-INFO: Loss Change: 300.508 -> 293.178
2024-12-01-20:23:38-root-INFO: Regularization Change: 0.000 -> 1.714
2024-12-01-20:23:38-root-INFO: Learning rate of xt decay: 0.09773 -> 0.09891.
2024-12-01-20:23:38-root-INFO: Coefficient of regularization decay: 0.00038 -> 0.00038.
2024-12-01-20:23:38-root-INFO: step: 115 lr_xt 0.03335113
2024-12-01-20:23:38-root-INFO: grad norm: 21.746 21.582 2.667
2024-12-01-20:23:38-root-INFO: grad norm: 21.744 21.553 2.874
2024-12-01-20:23:39-root-INFO: grad norm: 22.076 21.903 2.761
2024-12-01-20:23:39-root-INFO: grad norm: 22.390 22.215 2.798
2024-12-01-20:23:40-root-INFO: grad norm: 22.747 22.572 2.816
2024-12-01-20:23:40-root-INFO: Loss Change: 291.556 -> 286.610
2024-12-01-20:23:40-root-INFO: Regularization Change: 0.000 -> 1.461
2024-12-01-20:23:40-root-INFO: Undo step: 115
2024-12-01-20:23:40-root-INFO: Undo step: 116
2024-12-01-20:23:40-root-INFO: Undo step: 117
2024-12-01-20:23:40-root-INFO: Undo step: 118
2024-12-01-20:23:40-root-INFO: Undo step: 119
2024-12-01-20:23:40-root-INFO: step: 120 lr_xt 0.02856188
2024-12-01-20:23:40-root-INFO: grad norm: 101.684 99.736 19.809
2024-12-01-20:23:41-root-INFO: grad norm: 48.481 47.338 10.464
2024-12-01-20:23:41-root-INFO: grad norm: 33.458 32.685 7.152
2024-12-01-20:23:42-root-INFO: grad norm: 24.846 24.195 5.649
2024-12-01-20:23:42-root-INFO: grad norm: 20.472 19.961 4.545
2024-12-01-20:23:43-root-INFO: Loss Change: 581.120 -> 337.779
2024-12-01-20:23:43-root-INFO: Regularization Change: 0.000 -> 26.790
2024-12-01-20:23:43-root-INFO: Learning rate of xt decay: 0.09318 -> 0.09430.
2024-12-01-20:23:43-root-INFO: Coefficient of regularization decay: 0.00036 -> 0.00036.
2024-12-01-20:23:43-root-INFO: step: 119 lr_xt 0.02947075
2024-12-01-20:23:43-root-INFO: grad norm: 17.700 17.230 4.051
2024-12-01-20:23:43-root-INFO: grad norm: 14.855 14.415 3.587
2024-12-01-20:23:44-root-INFO: grad norm: 13.417 13.031 3.194
2024-12-01-20:23:44-root-INFO: grad norm: 12.420 12.045 3.031
2024-12-01-20:23:45-root-INFO: grad norm: 11.775 11.439 2.793
2024-12-01-20:23:45-root-INFO: Loss Change: 336.579 -> 311.738
2024-12-01-20:23:45-root-INFO: Regularization Change: 0.000 -> 3.684
2024-12-01-20:23:45-root-INFO: Learning rate of xt decay: 0.09430 -> 0.09543.
2024-12-01-20:23:45-root-INFO: Coefficient of regularization decay: 0.00036 -> 0.00037.
2024-12-01-20:23:45-root-INFO: step: 118 lr_xt 0.03040366
2024-12-01-20:23:45-root-INFO: grad norm: 12.106 11.763 2.859
2024-12-01-20:23:46-root-INFO: grad norm: 11.635 11.348 2.569
2024-12-01-20:23:46-root-INFO: grad norm: 12.225 11.963 2.517
2024-12-01-20:23:47-root-INFO: grad norm: 14.113 13.898 2.456
2024-12-01-20:23:47-root-INFO: grad norm: 16.496 16.291 2.588
2024-12-01-20:23:48-root-INFO: Loss Change: 312.003 -> 301.526
2024-12-01-20:23:48-root-INFO: Regularization Change: 0.000 -> 1.989
2024-12-01-20:23:48-root-INFO: Learning rate of xt decay: 0.09543 -> 0.09657.
2024-12-01-20:23:48-root-INFO: Coefficient of regularization decay: 0.00037 -> 0.00037.
2024-12-01-20:23:48-root-INFO: step: 117 lr_xt 0.03136105
2024-12-01-20:23:48-root-INFO: grad norm: 25.674 25.353 4.051
2024-12-01-20:23:48-root-INFO: Loss too large (302.883->302.938)! Learning rate decreased to 0.02509.
2024-12-01-20:23:49-root-INFO: grad norm: 20.027 19.825 2.837
2024-12-01-20:23:49-root-INFO: grad norm: 14.783 14.570 2.496
2024-12-01-20:23:50-root-INFO: grad norm: 13.187 12.981 2.321
2024-12-01-20:23:50-root-INFO: grad norm: 11.719 11.515 2.177
2024-12-01-20:23:50-root-INFO: Loss Change: 302.883 -> 292.079
2024-12-01-20:23:50-root-INFO: Regularization Change: 0.000 -> 1.130
2024-12-01-20:23:50-root-INFO: Learning rate of xt decay: 0.09657 -> 0.09773.
2024-12-01-20:23:50-root-INFO: Coefficient of regularization decay: 0.00037 -> 0.00038.
2024-12-01-20:23:51-root-INFO: step: 116 lr_xt 0.03234339
2024-12-01-20:23:51-root-INFO: grad norm: 10.812 10.500 2.579
2024-12-01-20:23:51-root-INFO: grad norm: 11.252 11.045 2.152
2024-12-01-20:23:52-root-INFO: grad norm: 13.042 12.864 2.145
2024-12-01-20:23:52-root-INFO: grad norm: 16.114 15.963 2.206
2024-12-01-20:23:53-root-INFO: grad norm: 17.855 17.703 2.324
2024-12-01-20:23:53-root-INFO: Loss Change: 291.900 -> 286.156
2024-12-01-20:23:53-root-INFO: Regularization Change: 0.000 -> 1.370
2024-12-01-20:23:53-root-INFO: Learning rate of xt decay: 0.09773 -> 0.09891.
2024-12-01-20:23:53-root-INFO: Coefficient of regularization decay: 0.00038 -> 0.00038.
2024-12-01-20:23:53-root-INFO: step: 115 lr_xt 0.03335113
2024-12-01-20:23:53-root-INFO: grad norm: 23.518 23.276 3.363
2024-12-01-20:23:54-root-INFO: grad norm: 21.810 21.630 2.797
2024-12-01-20:23:54-root-INFO: grad norm: 19.268 19.080 2.686
2024-12-01-20:23:55-root-INFO: grad norm: 19.319 19.108 2.851
2024-12-01-20:23:55-root-INFO: grad norm: 19.459 19.247 2.869
2024-12-01-20:23:56-root-INFO: Loss Change: 287.480 -> 280.693
2024-12-01-20:23:56-root-INFO: Regularization Change: 0.000 -> 1.541
2024-12-01-20:23:56-root-INFO: Learning rate of xt decay: 0.09891 -> 0.10009.
2024-12-01-20:23:56-root-INFO: Coefficient of regularization decay: 0.00038 -> 0.00038.
2024-12-01-20:23:56-root-INFO: step: 114 lr_xt 0.03438473
2024-12-01-20:23:56-root-INFO: grad norm: 18.509 18.268 2.978
2024-12-01-20:23:56-root-INFO: grad norm: 19.239 19.010 2.959
2024-12-01-20:23:57-root-INFO: grad norm: 19.950 19.698 3.165
2024-12-01-20:23:57-root-INFO: grad norm: 20.683 20.451 3.094
2024-12-01-20:23:58-root-INFO: grad norm: 21.105 20.838 3.344
2024-12-01-20:23:58-root-INFO: Loss Change: 280.061 -> 274.676
2024-12-01-20:23:58-root-INFO: Regularization Change: 0.000 -> 1.438
2024-12-01-20:23:58-root-INFO: Learning rate of xt decay: 0.10009 -> 0.10129.
2024-12-01-20:23:58-root-INFO: Coefficient of regularization decay: 0.00038 -> 0.00039.
2024-12-01-20:23:58-root-INFO: step: 113 lr_xt 0.03544467
2024-12-01-20:23:59-root-INFO: grad norm: 25.750 25.420 4.108
2024-12-01-20:23:59-root-INFO: grad norm: 25.212 24.929 3.763
2024-12-01-20:24:00-root-INFO: grad norm: 24.534 24.270 3.591
2024-12-01-20:24:00-root-INFO: grad norm: 24.576 24.298 3.682
2024-12-01-20:24:00-root-INFO: grad norm: 24.454 24.204 3.489
2024-12-01-20:24:01-root-INFO: Loss Change: 276.106 -> 270.959
2024-12-01-20:24:01-root-INFO: Regularization Change: 0.000 -> 1.696
2024-12-01-20:24:01-root-INFO: Learning rate of xt decay: 0.10129 -> 0.10251.
2024-12-01-20:24:01-root-INFO: Coefficient of regularization decay: 0.00039 -> 0.00039.
2024-12-01-20:24:01-root-INFO: step: 112 lr_xt 0.03653141
2024-12-01-20:24:01-root-INFO: grad norm: 21.086 20.843 3.195
2024-12-01-20:24:02-root-INFO: grad norm: 21.042 20.812 3.104
2024-12-01-20:24:02-root-INFO: grad norm: 21.744 21.515 3.150
2024-12-01-20:24:03-root-INFO: grad norm: 22.446 22.232 3.097
2024-12-01-20:24:03-root-INFO: grad norm: 23.323 23.103 3.197
2024-12-01-20:24:03-root-INFO: Loss Change: 269.237 -> 265.030
2024-12-01-20:24:03-root-INFO: Regularization Change: 0.000 -> 1.577
2024-12-01-20:24:03-root-INFO: Learning rate of xt decay: 0.10251 -> 0.10374.
2024-12-01-20:24:03-root-INFO: Coefficient of regularization decay: 0.00039 -> 0.00039.
2024-12-01-20:24:03-root-INFO: step: 111 lr_xt 0.03764541
2024-12-01-20:24:04-root-INFO: grad norm: 27.955 27.679 3.919
2024-12-01-20:24:04-root-INFO: grad norm: 27.775 27.557 3.473
2024-12-01-20:24:05-root-INFO: grad norm: 27.123 26.916 3.343
2024-12-01-20:24:05-root-INFO: grad norm: 26.560 26.363 3.234
2024-12-01-20:24:06-root-INFO: grad norm: 25.959 25.776 3.074
2024-12-01-20:24:06-root-INFO: Loss Change: 267.137 -> 261.041
2024-12-01-20:24:06-root-INFO: Regularization Change: 0.000 -> 1.889
2024-12-01-20:24:06-root-INFO: Learning rate of xt decay: 0.10374 -> 0.10498.
2024-12-01-20:24:06-root-INFO: Coefficient of regularization decay: 0.00039 -> 0.00040.
2024-12-01-20:24:06-root-INFO: step: 110 lr_xt 0.03878715
2024-12-01-20:24:06-root-INFO: grad norm: 22.309 22.173 2.461
2024-12-01-20:24:07-root-INFO: grad norm: 22.557 22.390 2.737
2024-12-01-20:24:07-root-INFO: grad norm: 22.975 22.831 2.565
2024-12-01-20:24:08-root-INFO: grad norm: 23.339 23.187 2.656
2024-12-01-20:24:08-root-INFO: grad norm: 23.680 23.542 2.559
2024-12-01-20:24:08-root-INFO: Loss Change: 259.631 -> 255.994
2024-12-01-20:24:08-root-INFO: Regularization Change: 0.000 -> 1.666
2024-12-01-20:24:08-root-INFO: Undo step: 110
2024-12-01-20:24:08-root-INFO: Undo step: 111
2024-12-01-20:24:08-root-INFO: Undo step: 112
2024-12-01-20:24:08-root-INFO: Undo step: 113
2024-12-01-20:24:08-root-INFO: Undo step: 114
2024-12-01-20:24:09-root-INFO: step: 115 lr_xt 0.03335113
2024-12-01-20:24:09-root-INFO: grad norm: 83.922 82.610 14.781
2024-12-01-20:24:09-root-INFO: grad norm: 45.219 44.451 8.299
2024-12-01-20:24:10-root-INFO: grad norm: 34.894 34.225 6.802
2024-12-01-20:24:10-root-INFO: grad norm: 30.596 30.179 5.035
2024-12-01-20:24:11-root-INFO: grad norm: 28.469 28.038 4.934
2024-12-01-20:24:11-root-INFO: Loss Change: 524.649 -> 300.993
2024-12-01-20:24:11-root-INFO: Regularization Change: 0.000 -> 28.939
2024-12-01-20:24:11-root-INFO: Learning rate of xt decay: 0.09891 -> 0.10009.
2024-12-01-20:24:11-root-INFO: Coefficient of regularization decay: 0.00038 -> 0.00038.
2024-12-01-20:24:11-root-INFO: step: 114 lr_xt 0.03438473
2024-12-01-20:24:11-root-INFO: grad norm: 32.407 32.105 4.417
2024-12-01-20:24:12-root-INFO: grad norm: 31.270 30.962 4.384
2024-12-01-20:24:12-root-INFO: grad norm: 29.715 29.499 3.578
2024-12-01-20:24:13-root-INFO: grad norm: 29.017 28.754 3.901
2024-12-01-20:24:13-root-INFO: grad norm: 28.471 28.285 3.245
2024-12-01-20:24:13-root-INFO: Loss Change: 302.960 -> 281.194
2024-12-01-20:24:13-root-INFO: Regularization Change: 0.000 -> 4.494
2024-12-01-20:24:13-root-INFO: Learning rate of xt decay: 0.10009 -> 0.10129.
2024-12-01-20:24:13-root-INFO: Coefficient of regularization decay: 0.00038 -> 0.00039.
2024-12-01-20:24:14-root-INFO: step: 113 lr_xt 0.03544467
2024-12-01-20:24:14-root-INFO: grad norm: 24.691 24.528 2.831
2024-12-01-20:24:14-root-INFO: grad norm: 24.817 24.650 2.872
2024-12-01-20:24:15-root-INFO: grad norm: 25.230 25.042 3.075
2024-12-01-20:24:15-root-INFO: grad norm: 25.676 25.519 2.835
2024-12-01-20:24:16-root-INFO: grad norm: 26.078 25.893 3.103
2024-12-01-20:24:16-root-INFO: Loss Change: 278.824 -> 269.710
2024-12-01-20:24:16-root-INFO: Regularization Change: 0.000 -> 2.578
2024-12-01-20:24:16-root-INFO: Learning rate of xt decay: 0.10129 -> 0.10251.
2024-12-01-20:24:16-root-INFO: Coefficient of regularization decay: 0.00039 -> 0.00039.
2024-12-01-20:24:16-root-INFO: step: 112 lr_xt 0.03653141
2024-12-01-20:24:16-root-INFO: grad norm: 32.344 32.080 4.126
2024-12-01-20:24:17-root-INFO: grad norm: 31.315 31.116 3.526
2024-12-01-20:24:17-root-INFO: grad norm: 29.871 29.698 3.210
2024-12-01-20:24:18-root-INFO: grad norm: 28.636 28.451 3.252
2024-12-01-20:24:18-root-INFO: grad norm: 27.567 27.410 2.935
2024-12-01-20:24:18-root-INFO: Loss Change: 272.510 -> 262.097
2024-12-01-20:24:18-root-INFO: Regularization Change: 0.000 -> 2.501
2024-12-01-20:24:18-root-INFO: Learning rate of xt decay: 0.10251 -> 0.10374.
2024-12-01-20:24:18-root-INFO: Coefficient of regularization decay: 0.00039 -> 0.00039.
2024-12-01-20:24:19-root-INFO: step: 111 lr_xt 0.03764541
2024-12-01-20:24:19-root-INFO: grad norm: 23.414 23.289 2.408
2024-12-01-20:24:19-root-INFO: grad norm: 23.147 23.002 2.589
2024-12-01-20:24:20-root-INFO: grad norm: 23.159 23.012 2.602
2024-12-01-20:24:20-root-INFO: grad norm: 23.272 23.132 2.547
2024-12-01-20:24:21-root-INFO: grad norm: 23.461 23.313 2.629
2024-12-01-20:24:21-root-INFO: Loss Change: 260.332 -> 254.433
2024-12-01-20:24:21-root-INFO: Regularization Change: 0.000 -> 1.891
2024-12-01-20:24:21-root-INFO: Learning rate of xt decay: 0.10374 -> 0.10498.
2024-12-01-20:24:21-root-INFO: Coefficient of regularization decay: 0.00039 -> 0.00040.
2024-12-01-20:24:21-root-INFO: step: 110 lr_xt 0.03878715
2024-12-01-20:24:21-root-INFO: grad norm: 27.888 27.673 3.450
2024-12-01-20:24:22-root-INFO: grad norm: 27.673 27.520 2.906
2024-12-01-20:24:22-root-INFO: grad norm: 27.208 27.052 2.906
2024-12-01-20:24:23-root-INFO: grad norm: 26.691 26.541 2.834
2024-12-01-20:24:23-root-INFO: grad norm: 26.163 26.017 2.759
2024-12-01-20:24:23-root-INFO: Loss Change: 256.574 -> 250.175
2024-12-01-20:24:23-root-INFO: Regularization Change: 0.000 -> 2.087
2024-12-01-20:24:23-root-INFO: Learning rate of xt decay: 0.10498 -> 0.10624.
2024-12-01-20:24:23-root-INFO: Coefficient of regularization decay: 0.00040 -> 0.00040.
2024-12-01-20:24:24-root-INFO: step: 109 lr_xt 0.03995709
2024-12-01-20:24:24-root-INFO: grad norm: 22.287 22.183 2.152
2024-12-01-20:24:24-root-INFO: grad norm: 22.069 21.927 2.503
2024-12-01-20:24:25-root-INFO: grad norm: 22.152 22.023 2.387
2024-12-01-20:24:25-root-INFO: grad norm: 22.288 22.150 2.478
2024-12-01-20:24:26-root-INFO: grad norm: 22.440 22.307 2.436
2024-12-01-20:24:26-root-INFO: Loss Change: 248.726 -> 243.978
2024-12-01-20:24:26-root-INFO: Regularization Change: 0.000 -> 1.748
2024-12-01-20:24:26-root-INFO: Learning rate of xt decay: 0.10624 -> 0.10752.
2024-12-01-20:24:26-root-INFO: Coefficient of regularization decay: 0.00040 -> 0.00041.
2024-12-01-20:24:26-root-INFO: step: 108 lr_xt 0.04115569
2024-12-01-20:24:26-root-INFO: grad norm: 26.104 25.900 3.253
2024-12-01-20:24:27-root-INFO: grad norm: 25.494 25.355 2.661
2024-12-01-20:24:27-root-INFO: grad norm: 24.762 24.614 2.703
2024-12-01-20:24:28-root-INFO: grad norm: 24.057 23.923 2.540
2024-12-01-20:24:28-root-INFO: grad norm: 23.409 23.272 2.528
2024-12-01-20:24:28-root-INFO: Loss Change: 245.556 -> 239.479
2024-12-01-20:24:28-root-INFO: Regularization Change: 0.000 -> 1.919
2024-12-01-20:24:28-root-INFO: Learning rate of xt decay: 0.10752 -> 0.10881.
2024-12-01-20:24:28-root-INFO: Coefficient of regularization decay: 0.00041 -> 0.00041.
2024-12-01-20:24:29-root-INFO: step: 107 lr_xt 0.04238344
2024-12-01-20:24:29-root-INFO: grad norm: 19.188 19.096 1.879
2024-12-01-20:24:29-root-INFO: grad norm: 18.923 18.800 2.158
2024-12-01-20:24:30-root-INFO: grad norm: 19.102 18.991 2.054
2024-12-01-20:24:30-root-INFO: grad norm: 19.373 19.251 2.178
2024-12-01-20:24:31-root-INFO: grad norm: 19.691 19.576 2.131
2024-12-01-20:24:31-root-INFO: Loss Change: 238.023 -> 234.012
2024-12-01-20:24:31-root-INFO: Regularization Change: 0.000 -> 1.562
2024-12-01-20:24:31-root-INFO: Learning rate of xt decay: 0.10881 -> 0.11011.
2024-12-01-20:24:31-root-INFO: Coefficient of regularization decay: 0.00041 -> 0.00041.
2024-12-01-20:24:31-root-INFO: step: 106 lr_xt 0.04364080
2024-12-01-20:24:31-root-INFO: grad norm: 24.652 24.434 3.273
2024-12-01-20:24:32-root-INFO: grad norm: 24.541 24.407 2.553
2024-12-01-20:24:32-root-INFO: grad norm: 24.244 24.094 2.695
2024-12-01-20:24:33-root-INFO: grad norm: 23.837 23.707 2.486
2024-12-01-20:24:33-root-INFO: grad norm: 23.359 23.221 2.537
2024-12-01-20:24:33-root-INFO: Loss Change: 236.063 -> 231.239
2024-12-01-20:24:33-root-INFO: Regularization Change: 0.000 -> 1.945
2024-12-01-20:24:33-root-INFO: Learning rate of xt decay: 0.11011 -> 0.11144.
2024-12-01-20:24:33-root-INFO: Coefficient of regularization decay: 0.00041 -> 0.00042.
2024-12-01-20:24:34-root-INFO: step: 105 lr_xt 0.04492824
2024-12-01-20:24:34-root-INFO: grad norm: 20.174 20.089 1.850
2024-12-01-20:24:34-root-INFO: grad norm: 20.063 19.938 2.238
2024-12-01-20:24:35-root-INFO: grad norm: 20.140 20.035 2.055
2024-12-01-20:24:35-root-INFO: grad norm: 20.240 20.118 2.216
2024-12-01-20:24:36-root-INFO: grad norm: 20.336 20.226 2.110
2024-12-01-20:24:36-root-INFO: Loss Change: 230.207 -> 226.436
2024-12-01-20:24:36-root-INFO: Regularization Change: 0.000 -> 1.668
2024-12-01-20:24:36-root-INFO: Undo step: 105
2024-12-01-20:24:36-root-INFO: Undo step: 106
2024-12-01-20:24:36-root-INFO: Undo step: 107
2024-12-01-20:24:36-root-INFO: Undo step: 108
2024-12-01-20:24:36-root-INFO: Undo step: 109
2024-12-01-20:24:36-root-INFO: step: 110 lr_xt 0.03878715
2024-12-01-20:24:36-root-INFO: grad norm: 63.874 62.790 11.720
2024-12-01-20:24:37-root-INFO: grad norm: 34.120 33.372 7.105
2024-12-01-20:24:37-root-INFO: grad norm: 23.769 23.044 5.823
2024-12-01-20:24:38-root-INFO: grad norm: 18.562 18.007 4.507
2024-12-01-20:24:38-root-INFO: grad norm: 15.737 15.241 3.918
2024-12-01-20:24:39-root-INFO: Loss Change: 423.880 -> 264.842
2024-12-01-20:24:39-root-INFO: Regularization Change: 0.000 -> 23.883
2024-12-01-20:24:39-root-INFO: Learning rate of xt decay: 0.10498 -> 0.10624.
2024-12-01-20:24:39-root-INFO: Coefficient of regularization decay: 0.00040 -> 0.00040.
2024-12-01-20:24:39-root-INFO: step: 109 lr_xt 0.03995709
2024-12-01-20:24:39-root-INFO: grad norm: 16.790 16.411 3.545
2024-12-01-20:24:39-root-INFO: grad norm: 15.238 14.926 3.065
2024-12-01-20:24:40-root-INFO: grad norm: 14.447 14.189 2.722
2024-12-01-20:24:40-root-INFO: grad norm: 13.980 13.739 2.588
2024-12-01-20:24:41-root-INFO: grad norm: 13.779 13.572 2.375
2024-12-01-20:24:41-root-INFO: Loss Change: 265.504 -> 247.257
2024-12-01-20:24:41-root-INFO: Regularization Change: 0.000 -> 3.845
2024-12-01-20:24:41-root-INFO: Learning rate of xt decay: 0.10624 -> 0.10752.
2024-12-01-20:24:41-root-INFO: Coefficient of regularization decay: 0.00040 -> 0.00041.
2024-12-01-20:24:41-root-INFO: step: 108 lr_xt 0.04115569
2024-12-01-20:24:41-root-INFO: grad norm: 11.486 11.305 2.030
2024-12-01-20:24:42-root-INFO: grad norm: 11.051 10.869 1.996
2024-12-01-20:24:42-root-INFO: grad norm: 11.081 10.912 1.928
2024-12-01-20:24:43-root-INFO: grad norm: 11.272 11.113 1.891
2024-12-01-20:24:43-root-INFO: grad norm: 11.601 11.448 1.879
2024-12-01-20:24:43-root-INFO: Loss Change: 246.059 -> 236.930
2024-12-01-20:24:43-root-INFO: Regularization Change: 0.000 -> 2.109
2024-12-01-20:24:43-root-INFO: Learning rate of xt decay: 0.10752 -> 0.10881.
2024-12-01-20:24:44-root-INFO: Coefficient of regularization decay: 0.00041 -> 0.00041.
2024-12-01-20:24:44-root-INFO: step: 107 lr_xt 0.04238344
2024-12-01-20:24:44-root-INFO: grad norm: 17.868 17.629 2.912
2024-12-01-20:24:44-root-INFO: grad norm: 18.242 18.094 2.318
2024-12-01-20:24:45-root-INFO: grad norm: 19.012 18.859 2.409
2024-12-01-20:24:45-root-INFO: grad norm: 19.690 19.547 2.370
2024-12-01-20:24:46-root-INFO: grad norm: 20.368 20.222 2.440
2024-12-01-20:24:46-root-INFO: Loss Change: 238.837 -> 233.396
2024-12-01-20:24:46-root-INFO: Regularization Change: 0.000 -> 2.050
2024-12-01-20:24:46-root-INFO: Learning rate of xt decay: 0.10881 -> 0.11011.
2024-12-01-20:24:46-root-INFO: Coefficient of regularization decay: 0.00041 -> 0.00041.
2024-12-01-20:24:46-root-INFO: step: 106 lr_xt 0.04364080
2024-12-01-20:24:46-root-INFO: grad norm: 17.417 17.325 1.795
2024-12-01-20:24:47-root-INFO: grad norm: 17.899 17.765 2.183
2024-12-01-20:24:47-root-INFO: grad norm: 18.698 18.577 2.120
2024-12-01-20:24:48-root-INFO: grad norm: 19.549 19.409 2.336
2024-12-01-20:24:48-root-INFO: grad norm: 20.343 20.209 2.331
2024-12-01-20:24:49-root-INFO: Loss Change: 231.579 -> 227.594
2024-12-01-20:24:49-root-INFO: Regularization Change: 0.000 -> 1.834
2024-12-01-20:24:49-root-INFO: Learning rate of xt decay: 0.11011 -> 0.11144.
2024-12-01-20:24:49-root-INFO: Coefficient of regularization decay: 0.00041 -> 0.00042.
2024-12-01-20:24:49-root-INFO: step: 105 lr_xt 0.04492824
2024-12-01-20:24:49-root-INFO: grad norm: 25.127 24.896 3.395
2024-12-01-20:24:49-root-INFO: grad norm: 25.131 24.978 2.773
2024-12-01-20:24:50-root-INFO: grad norm: 24.794 24.624 2.903
2024-12-01-20:24:50-root-INFO: grad norm: 24.388 24.239 2.696
2024-12-01-20:24:51-root-INFO: grad norm: 23.891 23.734 2.741
2024-12-01-20:24:51-root-INFO: Loss Change: 230.042 -> 224.743
2024-12-01-20:24:51-root-INFO: Regularization Change: 0.000 -> 2.215
2024-12-01-20:24:51-root-INFO: Learning rate of xt decay: 0.11144 -> 0.11277.
2024-12-01-20:24:51-root-INFO: Coefficient of regularization decay: 0.00042 -> 0.00042.
2024-12-01-20:24:51-root-INFO: step: 104 lr_xt 0.04624623
2024-12-01-20:24:51-root-INFO: grad norm: 20.059 19.972 1.863
2024-12-01-20:24:52-root-INFO: grad norm: 19.618 19.492 2.224
2024-12-01-20:24:52-root-INFO: grad norm: 19.519 19.410 2.066
2024-12-01-20:24:53-root-INFO: grad norm: 19.477 19.349 2.234
2024-12-01-20:24:53-root-INFO: grad norm: 19.475 19.359 2.120
2024-12-01-20:24:54-root-INFO: Loss Change: 222.918 -> 218.361
2024-12-01-20:24:54-root-INFO: Regularization Change: 0.000 -> 1.793
2024-12-01-20:24:54-root-INFO: Learning rate of xt decay: 0.11277 -> 0.11413.
2024-12-01-20:24:54-root-INFO: Coefficient of regularization decay: 0.00042 -> 0.00043.
2024-12-01-20:24:54-root-INFO: step: 103 lr_xt 0.04759523
2024-12-01-20:24:54-root-INFO: grad norm: 23.215 23.011 3.072
2024-12-01-20:24:54-root-INFO: grad norm: 22.352 22.213 2.487
2024-12-01-20:24:55-root-INFO: grad norm: 21.488 21.338 2.538
2024-12-01-20:24:55-root-INFO: grad norm: 20.699 20.570 2.308
2024-12-01-20:24:56-root-INFO: grad norm: 20.029 19.892 2.335
2024-12-01-20:24:56-root-INFO: Loss Change: 220.535 -> 214.669
2024-12-01-20:24:56-root-INFO: Regularization Change: 0.000 -> 1.953
2024-12-01-20:24:56-root-INFO: Learning rate of xt decay: 0.11413 -> 0.11550.
2024-12-01-20:24:56-root-INFO: Coefficient of regularization decay: 0.00043 -> 0.00043.
2024-12-01-20:24:56-root-INFO: step: 102 lr_xt 0.04897571
2024-12-01-20:24:56-root-INFO: grad norm: 17.340 17.258 1.684
2024-12-01-20:24:57-root-INFO: grad norm: 17.068 16.952 1.986
2024-12-01-20:24:57-root-INFO: grad norm: 17.052 16.954 1.829
2024-12-01-20:24:58-root-INFO: grad norm: 17.084 16.968 1.990
2024-12-01-20:24:58-root-INFO: grad norm: 17.159 17.055 1.883
2024-12-01-20:24:59-root-INFO: Loss Change: 213.452 -> 209.667
2024-12-01-20:24:59-root-INFO: Regularization Change: 0.000 -> 1.600
2024-12-01-20:24:59-root-INFO: Learning rate of xt decay: 0.11550 -> 0.11688.
2024-12-01-20:24:59-root-INFO: Coefficient of regularization decay: 0.00043 -> 0.00044.
2024-12-01-20:24:59-root-INFO: step: 101 lr_xt 0.05038813
2024-12-01-20:24:59-root-INFO: grad norm: 20.926 20.732 2.839
2024-12-01-20:24:59-root-INFO: grad norm: 20.252 20.129 2.225
2024-12-01-20:25:00-root-INFO: grad norm: 19.561 19.419 2.350
2024-12-01-20:25:00-root-INFO: grad norm: 18.913 18.798 2.082
2024-12-01-20:25:01-root-INFO: grad norm: 18.344 18.216 2.169
2024-12-01-20:25:01-root-INFO: Loss Change: 211.663 -> 206.573
2024-12-01-20:25:01-root-INFO: Regularization Change: 0.000 -> 1.832
2024-12-01-20:25:01-root-INFO: Learning rate of xt decay: 0.11688 -> 0.11828.
2024-12-01-20:25:01-root-INFO: Coefficient of regularization decay: 0.00044 -> 0.00044.
2024-12-01-20:25:01-root-INFO: step: 100 lr_xt 0.05183295
2024-12-01-20:25:01-root-INFO: grad norm: 14.833 14.765 1.412
2024-12-01-20:25:02-root-INFO: grad norm: 14.456 14.350 1.744
2024-12-01-20:25:02-root-INFO: grad norm: 14.295 14.211 1.544
2024-12-01-20:25:03-root-INFO: grad norm: 14.207 14.102 1.725
2024-12-01-20:25:03-root-INFO: grad norm: 14.171 14.083 1.577
2024-12-01-20:25:04-root-INFO: Loss Change: 205.366 -> 201.737
2024-12-01-20:25:04-root-INFO: Regularization Change: 0.000 -> 1.411
2024-12-01-20:25:04-root-INFO: Undo step: 100
2024-12-01-20:25:04-root-INFO: Undo step: 101
2024-12-01-20:25:04-root-INFO: Undo step: 102
2024-12-01-20:25:04-root-INFO: Undo step: 103
2024-12-01-20:25:04-root-INFO: Undo step: 104
2024-12-01-20:25:04-root-INFO: step: 105 lr_xt 0.04492824
2024-12-01-20:25:04-root-INFO: grad norm: 70.844 69.920 11.408
2024-12-01-20:25:04-root-INFO: grad norm: 35.278 34.558 7.093
2024-12-01-20:25:05-root-INFO: grad norm: 25.344 24.841 5.024
2024-12-01-20:25:05-root-INFO: grad norm: 20.997 20.455 4.741
2024-12-01-20:25:06-root-INFO: grad norm: 18.945 18.578 3.711
2024-12-01-20:25:06-root-INFO: Loss Change: 453.232 -> 249.442
2024-12-01-20:25:06-root-INFO: Regularization Change: 0.000 -> 34.087
2024-12-01-20:25:06-root-INFO: Learning rate of xt decay: 0.11144 -> 0.11277.
2024-12-01-20:25:06-root-INFO: Coefficient of regularization decay: 0.00042 -> 0.00042.
2024-12-01-20:25:06-root-INFO: step: 104 lr_xt 0.04624623
2024-12-01-20:25:06-root-INFO: grad norm: 15.002 14.652 3.222
2024-12-01-20:25:07-root-INFO: grad norm: 13.773 13.472 2.866
2024-12-01-20:25:07-root-INFO: grad norm: 13.183 12.876 2.828
2024-12-01-20:25:08-root-INFO: grad norm: 12.928 12.678 2.527
2024-12-01-20:25:08-root-INFO: grad norm: 12.922 12.664 2.571
2024-12-01-20:25:09-root-INFO: Loss Change: 247.807 -> 226.887
2024-12-01-20:25:09-root-INFO: Regularization Change: 0.000 -> 5.192
2024-12-01-20:25:09-root-INFO: Learning rate of xt decay: 0.11277 -> 0.11413.
2024-12-01-20:25:09-root-INFO: Coefficient of regularization decay: 0.00042 -> 0.00043.
2024-12-01-20:25:09-root-INFO: step: 103 lr_xt 0.04759523
2024-12-01-20:25:09-root-INFO: grad norm: 16.978 16.734 2.866
2024-12-01-20:25:09-root-INFO: grad norm: 17.202 16.981 2.744
2024-12-01-20:25:10-root-INFO: grad norm: 17.535 17.343 2.587
2024-12-01-20:25:10-root-INFO: grad norm: 17.926 17.724 2.683
2024-12-01-20:25:11-root-INFO: grad norm: 18.360 18.182 2.545
2024-12-01-20:25:11-root-INFO: Loss Change: 228.185 -> 218.861
2024-12-01-20:25:11-root-INFO: Regularization Change: 0.000 -> 3.081
2024-12-01-20:25:11-root-INFO: Learning rate of xt decay: 0.11413 -> 0.11550.
2024-12-01-20:25:11-root-INFO: Coefficient of regularization decay: 0.00043 -> 0.00043.
2024-12-01-20:25:11-root-INFO: step: 102 lr_xt 0.04897571
2024-12-01-20:25:11-root-INFO: grad norm: 16.201 16.059 2.142
2024-12-01-20:25:12-root-INFO: grad norm: 16.696 16.538 2.294
2024-12-01-20:25:12-root-INFO: grad norm: 17.391 17.233 2.340
2024-12-01-20:25:13-root-INFO: grad norm: 18.096 17.940 2.373
2024-12-01-20:25:13-root-INFO: grad norm: 18.767 18.605 2.461
2024-12-01-20:25:14-root-INFO: Loss Change: 217.330 -> 212.038
2024-12-01-20:25:14-root-INFO: Regularization Change: 0.000 -> 2.371
2024-12-01-20:25:14-root-INFO: Learning rate of xt decay: 0.11550 -> 0.11688.
2024-12-01-20:25:14-root-INFO: Coefficient of regularization decay: 0.00043 -> 0.00044.
2024-12-01-20:25:14-root-INFO: step: 101 lr_xt 0.05038813
2024-12-01-20:25:14-root-INFO: grad norm: 23.254 23.022 3.275
2024-12-01-20:25:15-root-INFO: grad norm: 23.009 22.825 2.906
2024-12-01-20:25:15-root-INFO: grad norm: 22.591 22.401 2.927
2024-12-01-20:25:16-root-INFO: grad norm: 22.091 21.909 2.829
2024-12-01-20:25:16-root-INFO: grad norm: 21.614 21.432 2.800
2024-12-01-20:25:16-root-INFO: Loss Change: 214.296 -> 207.905
2024-12-01-20:25:16-root-INFO: Regularization Change: 0.000 -> 2.558
2024-12-01-20:25:16-root-INFO: Learning rate of xt decay: 0.11688 -> 0.11828.
2024-12-01-20:25:16-root-INFO: Coefficient of regularization decay: 0.00044 -> 0.00044.
2024-12-01-20:25:16-root-INFO: step: 100 lr_xt 0.05183295
2024-12-01-20:25:17-root-INFO: grad norm: 17.966 17.842 2.107
2024-12-01-20:25:17-root-INFO: grad norm: 17.767 17.601 2.425
2024-12-01-20:25:18-root-INFO: grad norm: 17.682 17.532 2.301
2024-12-01-20:25:18-root-INFO: grad norm: 17.654 17.489 2.407
2024-12-01-20:25:18-root-INFO: grad norm: 17.640 17.483 2.344
2024-12-01-20:25:19-root-INFO: Loss Change: 206.280 -> 201.797
2024-12-01-20:25:19-root-INFO: Regularization Change: 0.000 -> 1.961
2024-12-01-20:25:19-root-INFO: Learning rate of xt decay: 0.11828 -> 0.11970.
2024-12-01-20:25:19-root-INFO: Coefficient of regularization decay: 0.00044 -> 0.00044.
2024-12-01-20:25:19-root-INFO: step: 99 lr_xt 0.05331064
2024-12-01-20:25:19-root-INFO: grad norm: 20.971 20.735 3.138
2024-12-01-20:25:20-root-INFO: grad norm: 20.198 20.014 2.716
2024-12-01-20:25:20-root-INFO: grad norm: 19.457 19.264 2.735
2024-12-01-20:25:20-root-INFO: grad norm: 18.768 18.589 2.584
2024-12-01-20:25:21-root-INFO: grad norm: 18.181 17.998 2.575
2024-12-01-20:25:21-root-INFO: Loss Change: 203.550 -> 197.797
2024-12-01-20:25:21-root-INFO: Regularization Change: 0.000 -> 2.104
2024-12-01-20:25:21-root-INFO: Learning rate of xt decay: 0.11970 -> 0.12114.
2024-12-01-20:25:21-root-INFO: Coefficient of regularization decay: 0.00044 -> 0.00045.
2024-12-01-20:25:21-root-INFO: step: 98 lr_xt 0.05482165
2024-12-01-20:25:22-root-INFO: grad norm: 14.645 14.529 1.838
2024-12-01-20:25:22-root-INFO: grad norm: 14.445 14.288 2.126
2024-12-01-20:25:22-root-INFO: grad norm: 14.418 14.277 2.008
2024-12-01-20:25:23-root-INFO: grad norm: 14.462 14.305 2.127
2024-12-01-20:25:23-root-INFO: grad norm: 14.548 14.402 2.060
2024-12-01-20:25:24-root-INFO: Loss Change: 196.471 -> 192.915
2024-12-01-20:25:24-root-INFO: Regularization Change: 0.000 -> 1.599
2024-12-01-20:25:24-root-INFO: Learning rate of xt decay: 0.12114 -> 0.12259.
2024-12-01-20:25:24-root-INFO: Coefficient of regularization decay: 0.00045 -> 0.00045.
2024-12-01-20:25:24-root-INFO: step: 97 lr_xt 0.05636643
2024-12-01-20:25:24-root-INFO: grad norm: 18.435 18.197 2.954
2024-12-01-20:25:25-root-INFO: grad norm: 17.978 17.805 2.491
2024-12-01-20:25:25-root-INFO: grad norm: 17.525 17.340 2.544
2024-12-01-20:25:25-root-INFO: grad norm: 17.068 16.898 2.403
2024-12-01-20:25:26-root-INFO: grad norm: 16.660 16.484 2.415
2024-12-01-20:25:26-root-INFO: Loss Change: 194.715 -> 190.162
2024-12-01-20:25:26-root-INFO: Regularization Change: 0.000 -> 1.892
2024-12-01-20:25:26-root-INFO: Learning rate of xt decay: 0.12259 -> 0.12406.
2024-12-01-20:25:26-root-INFO: Coefficient of regularization decay: 0.00045 -> 0.00046.
2024-12-01-20:25:26-root-INFO: step: 96 lr_xt 0.05794543
2024-12-01-20:25:26-root-INFO: grad norm: 13.642 13.527 1.771
2024-12-01-20:25:27-root-INFO: grad norm: 13.314 13.159 2.030
2024-12-01-20:25:27-root-INFO: grad norm: 13.110 12.976 1.870
2024-12-01-20:25:28-root-INFO: grad norm: 12.991 12.840 1.975
2024-12-01-20:25:28-root-INFO: grad norm: 12.910 12.775 1.861
2024-12-01-20:25:29-root-INFO: Loss Change: 189.062 -> 185.646
2024-12-01-20:25:29-root-INFO: Regularization Change: 0.000 -> 1.482
2024-12-01-20:25:29-root-INFO: Learning rate of xt decay: 0.12406 -> 0.12555.
2024-12-01-20:25:29-root-INFO: Coefficient of regularization decay: 0.00046 -> 0.00046.
2024-12-01-20:25:29-root-INFO: step: 95 lr_xt 0.05955910
2024-12-01-20:25:29-root-INFO: grad norm: 16.446 16.223 2.698
2024-12-01-20:25:29-root-INFO: grad norm: 15.960 15.809 2.196
2024-12-01-20:25:30-root-INFO: grad norm: 15.512 15.343 2.285
2024-12-01-20:25:30-root-INFO: grad norm: 15.071 14.925 2.092
2024-12-01-20:25:31-root-INFO: grad norm: 14.688 14.531 2.140
2024-12-01-20:25:31-root-INFO: Loss Change: 187.464 -> 183.283
2024-12-01-20:25:31-root-INFO: Regularization Change: 0.000 -> 1.736
2024-12-01-20:25:31-root-INFO: Undo step: 95
2024-12-01-20:25:31-root-INFO: Undo step: 96
2024-12-01-20:25:31-root-INFO: Undo step: 97
2024-12-01-20:25:31-root-INFO: Undo step: 98
2024-12-01-20:25:31-root-INFO: Undo step: 99
2024-12-01-20:25:31-root-INFO: step: 100 lr_xt 0.05183295
2024-12-01-20:25:31-root-INFO: grad norm: 64.289 63.428 10.488
2024-12-01-20:25:32-root-INFO: grad norm: 33.477 33.030 5.453
2024-12-01-20:25:32-root-INFO: grad norm: 23.583 23.233 4.047
2024-12-01-20:25:33-root-INFO: grad norm: 18.998 18.688 3.420
2024-12-01-20:25:33-root-INFO: grad norm: 16.039 15.780 2.868
2024-12-01-20:25:34-root-INFO: Loss Change: 404.075 -> 221.998
2024-12-01-20:25:34-root-INFO: Regularization Change: 0.000 -> 34.076
2024-12-01-20:25:34-root-INFO: Learning rate of xt decay: 0.11828 -> 0.11970.
2024-12-01-20:25:34-root-INFO: Coefficient of regularization decay: 0.00044 -> 0.00044.
2024-12-01-20:25:34-root-INFO: step: 99 lr_xt 0.05331064
2024-12-01-20:25:34-root-INFO: grad norm: 15.064 14.810 2.751
2024-12-01-20:25:34-root-INFO: grad norm: 13.124 12.911 2.353
2024-12-01-20:25:35-root-INFO: grad norm: 11.756 11.549 2.198
2024-12-01-20:25:35-root-INFO: grad norm: 10.652 10.463 1.999
2024-12-01-20:25:36-root-INFO: grad norm: 9.826 9.646 1.873
2024-12-01-20:25:36-root-INFO: Loss Change: 222.132 -> 204.132
2024-12-01-20:25:36-root-INFO: Regularization Change: 0.000 -> 4.756
2024-12-01-20:25:36-root-INFO: Learning rate of xt decay: 0.11970 -> 0.12114.
2024-12-01-20:25:36-root-INFO: Coefficient of regularization decay: 0.00044 -> 0.00045.
2024-12-01-20:25:36-root-INFO: step: 98 lr_xt 0.05482165
2024-12-01-20:25:36-root-INFO: grad norm: 8.256 8.081 1.693
2024-12-01-20:25:37-root-INFO: grad norm: 7.343 7.167 1.597
2024-12-01-20:25:37-root-INFO: grad norm: 6.804 6.645 1.463
2024-12-01-20:25:38-root-INFO: grad norm: 6.393 6.231 1.429
2024-12-01-20:25:38-root-INFO: grad norm: 6.068 5.919 1.337
2024-12-01-20:25:39-root-INFO: Loss Change: 203.807 -> 194.921
2024-12-01-20:25:39-root-INFO: Regularization Change: 0.000 -> 2.441
2024-12-01-20:25:39-root-INFO: Learning rate of xt decay: 0.12114 -> 0.12259.
2024-12-01-20:25:39-root-INFO: Coefficient of regularization decay: 0.00045 -> 0.00045.
2024-12-01-20:25:39-root-INFO: step: 97 lr_xt 0.05636643
2024-12-01-20:25:39-root-INFO: grad norm: 8.499 8.333 1.674
2024-12-01-20:25:39-root-INFO: grad norm: 8.198 8.076 1.408
2024-12-01-20:25:40-root-INFO: grad norm: 8.266 8.150 1.380
2024-12-01-20:25:40-root-INFO: grad norm: 8.489 8.377 1.374
2024-12-01-20:25:41-root-INFO: grad norm: 8.836 8.735 1.336
2024-12-01-20:25:41-root-INFO: Loss Change: 195.201 -> 189.488
2024-12-01-20:25:41-root-INFO: Regularization Change: 0.000 -> 1.857
2024-12-01-20:25:41-root-INFO: Learning rate of xt decay: 0.12259 -> 0.12406.
2024-12-01-20:25:41-root-INFO: Coefficient of regularization decay: 0.00045 -> 0.00046.
2024-12-01-20:25:41-root-INFO: step: 96 lr_xt 0.05794543
2024-12-01-20:25:42-root-INFO: grad norm: 7.280 7.186 1.165
2024-12-01-20:25:42-root-INFO: grad norm: 7.364 7.271 1.171
2024-12-01-20:25:42-root-INFO: grad norm: 7.752 7.665 1.161
2024-12-01-20:25:43-root-INFO: grad norm: 8.246 8.161 1.181
2024-12-01-20:25:43-root-INFO: grad norm: 8.827 8.741 1.223
2024-12-01-20:25:44-root-INFO: Loss Change: 188.987 -> 184.817
2024-12-01-20:25:44-root-INFO: Regularization Change: 0.000 -> 1.539
2024-12-01-20:25:44-root-INFO: Learning rate of xt decay: 0.12406 -> 0.12555.
2024-12-01-20:25:44-root-INFO: Coefficient of regularization decay: 0.00046 -> 0.00046.
2024-12-01-20:25:44-root-INFO: step: 95 lr_xt 0.05955910
2024-12-01-20:25:44-root-INFO: grad norm: 13.030 12.884 1.944
2024-12-01-20:25:44-root-INFO: grad norm: 13.708 13.604 1.681
2024-12-01-20:25:45-root-INFO: grad norm: 14.377 14.265 1.791
2024-12-01-20:25:45-root-INFO: grad norm: 14.892 14.781 1.819
2024-12-01-20:25:46-root-INFO: grad norm: 15.288 15.174 1.866
2024-12-01-20:25:46-root-INFO: Loss Change: 186.112 -> 183.258
2024-12-01-20:25:46-root-INFO: Regularization Change: 0.000 -> 1.868
2024-12-01-20:25:46-root-INFO: Learning rate of xt decay: 0.12555 -> 0.12706.
2024-12-01-20:25:46-root-INFO: Coefficient of regularization decay: 0.00046 -> 0.00047.
2024-12-01-20:25:46-root-INFO: step: 94 lr_xt 0.06120788
2024-12-01-20:25:46-root-INFO: grad norm: 13.083 12.995 1.512
2024-12-01-20:25:47-root-INFO: grad norm: 13.436 13.336 1.635
2024-12-01-20:25:47-root-INFO: grad norm: 13.752 13.649 1.679
2024-12-01-20:25:48-root-INFO: grad norm: 14.049 13.944 1.711
2024-12-01-20:25:48-root-INFO: grad norm: 14.286 14.176 1.774
2024-12-01-20:25:49-root-INFO: Loss Change: 181.899 -> 178.967
2024-12-01-20:25:49-root-INFO: Regularization Change: 0.000 -> 1.765
2024-12-01-20:25:49-root-INFO: Learning rate of xt decay: 0.12706 -> 0.12858.
2024-12-01-20:25:49-root-INFO: Coefficient of regularization decay: 0.00047 -> 0.00047.
2024-12-01-20:25:49-root-INFO: step: 93 lr_xt 0.06289219
2024-12-01-20:25:49-root-INFO: grad norm: 18.136 17.954 2.565
2024-12-01-20:25:49-root-INFO: grad norm: 17.811 17.672 2.216
2024-12-01-20:25:50-root-INFO: grad norm: 17.371 17.231 2.199
2024-12-01-20:25:50-root-INFO: grad norm: 16.879 16.742 2.146
2024-12-01-20:25:51-root-INFO: grad norm: 16.389 16.257 2.070
2024-12-01-20:25:51-root-INFO: Loss Change: 180.769 -> 176.244
2024-12-01-20:25:51-root-INFO: Regularization Change: 0.000 -> 2.204
2024-12-01-20:25:51-root-INFO: Learning rate of xt decay: 0.12858 -> 0.13013.
2024-12-01-20:25:51-root-INFO: Coefficient of regularization decay: 0.00047 -> 0.00048.
2024-12-01-20:25:51-root-INFO: step: 92 lr_xt 0.06461248
2024-12-01-20:25:51-root-INFO: grad norm: 13.732 13.629 1.685
2024-12-01-20:25:52-root-INFO: grad norm: 13.502 13.390 1.737
2024-12-01-20:25:52-root-INFO: grad norm: 13.367 13.255 1.725
2024-12-01-20:25:53-root-INFO: grad norm: 13.283 13.175 1.693
2024-12-01-20:25:53-root-INFO: grad norm: 13.233 13.123 1.704
2024-12-01-20:25:54-root-INFO: Loss Change: 175.216 -> 171.823
2024-12-01-20:25:54-root-INFO: Regularization Change: 0.000 -> 1.753
2024-12-01-20:25:54-root-INFO: Learning rate of xt decay: 0.13013 -> 0.13169.
2024-12-01-20:25:54-root-INFO: Coefficient of regularization decay: 0.00048 -> 0.00048.
2024-12-01-20:25:54-root-INFO: step: 91 lr_xt 0.06636917
2024-12-01-20:25:54-root-INFO: grad norm: 16.230 16.069 2.280
2024-12-01-20:25:54-root-INFO: grad norm: 15.822 15.695 2.005
2024-12-01-20:25:55-root-INFO: grad norm: 15.360 15.233 1.973
2024-12-01-20:25:55-root-INFO: grad norm: 14.893 14.772 1.895
2024-12-01-20:25:56-root-INFO: grad norm: 14.457 14.339 1.846
2024-12-01-20:25:56-root-INFO: Loss Change: 173.332 -> 169.199
2024-12-01-20:25:56-root-INFO: Regularization Change: 0.000 -> 1.992
2024-12-01-20:25:56-root-INFO: Learning rate of xt decay: 0.13169 -> 0.13327.
2024-12-01-20:25:56-root-INFO: Coefficient of regularization decay: 0.00048 -> 0.00049.
2024-12-01-20:25:56-root-INFO: step: 90 lr_xt 0.06816268
2024-12-01-20:25:57-root-INFO: grad norm: 11.665 11.590 1.315
2024-12-01-20:25:57-root-INFO: grad norm: 11.369 11.274 1.464
2024-12-01-20:25:58-root-INFO: grad norm: 11.174 11.091 1.365
2024-12-01-20:25:58-root-INFO: grad norm: 11.045 10.954 1.421
2024-12-01-20:25:59-root-INFO: grad norm: 10.949 10.865 1.355
2024-12-01-20:25:59-root-INFO: Loss Change: 168.161 -> 164.998
2024-12-01-20:25:59-root-INFO: Regularization Change: 0.000 -> 1.549
2024-12-01-20:25:59-root-INFO: Undo step: 90
2024-12-01-20:25:59-root-INFO: Undo step: 91
2024-12-01-20:25:59-root-INFO: Undo step: 92
2024-12-01-20:25:59-root-INFO: Undo step: 93
2024-12-01-20:25:59-root-INFO: Undo step: 94
2024-12-01-20:25:59-root-INFO: step: 95 lr_xt 0.05955910
2024-12-01-20:25:59-root-INFO: grad norm: 49.366 48.438 9.527
2024-12-01-20:26:00-root-INFO: grad norm: 28.225 27.533 6.209
2024-12-01-20:26:00-root-INFO: grad norm: 20.966 20.449 4.625
2024-12-01-20:26:01-root-INFO: grad norm: 16.623 16.180 3.813
2024-12-01-20:26:01-root-INFO: grad norm: 13.943 13.611 3.020
2024-12-01-20:26:02-root-INFO: Loss Change: 356.142 -> 201.972
2024-12-01-20:26:02-root-INFO: Regularization Change: 0.000 -> 36.815
2024-12-01-20:26:02-root-INFO: Learning rate of xt decay: 0.12555 -> 0.12706.
2024-12-01-20:26:02-root-INFO: Coefficient of regularization decay: 0.00046 -> 0.00047.
2024-12-01-20:26:02-root-INFO: step: 94 lr_xt 0.06120788
2024-12-01-20:26:02-root-INFO: grad norm: 11.407 11.099 2.631
2024-12-01-20:26:03-root-INFO: grad norm: 9.793 9.531 2.249
2024-12-01-20:26:03-root-INFO: grad norm: 8.631 8.375 2.088
2024-12-01-20:26:04-root-INFO: grad norm: 7.800 7.576 1.855
2024-12-01-20:26:04-root-INFO: grad norm: 7.178 6.956 1.774
2024-12-01-20:26:05-root-INFO: Loss Change: 201.317 -> 183.884
2024-12-01-20:26:05-root-INFO: Regularization Change: 0.000 -> 5.342
2024-12-01-20:26:05-root-INFO: Learning rate of xt decay: 0.12706 -> 0.12858.
2024-12-01-20:26:05-root-INFO: Coefficient of regularization decay: 0.00047 -> 0.00047.
2024-12-01-20:26:05-root-INFO: step: 93 lr_xt 0.06289219
2024-12-01-20:26:05-root-INFO: grad norm: 7.415 7.244 1.583
2024-12-01-20:26:05-root-INFO: grad norm: 6.575 6.407 1.478
2024-12-01-20:26:06-root-INFO: grad norm: 6.083 5.938 1.320
2024-12-01-20:26:06-root-INFO: grad norm: 5.707 5.555 1.307
2024-12-01-20:26:07-root-INFO: grad norm: 5.420 5.288 1.190
2024-12-01-20:26:07-root-INFO: Loss Change: 183.636 -> 175.339
2024-12-01-20:26:07-root-INFO: Regularization Change: 0.000 -> 2.619
2024-12-01-20:26:07-root-INFO: Learning rate of xt decay: 0.12858 -> 0.13013.
2024-12-01-20:26:07-root-INFO: Coefficient of regularization decay: 0.00047 -> 0.00048.
2024-12-01-20:26:07-root-INFO: step: 92 lr_xt 0.06461248
2024-12-01-20:26:08-root-INFO: grad norm: 4.804 4.652 1.201
2024-12-01-20:26:08-root-INFO: grad norm: 4.352 4.207 1.114
2024-12-01-20:26:08-root-INFO: grad norm: 4.171 4.034 1.060
2024-12-01-20:26:09-root-INFO: grad norm: 4.049 3.913 1.038
2024-12-01-20:26:09-root-INFO: grad norm: 3.962 3.834 0.997
2024-12-01-20:26:10-root-INFO: Loss Change: 175.228 -> 169.780
2024-12-01-20:26:10-root-INFO: Regularization Change: 0.000 -> 1.770
2024-12-01-20:26:10-root-INFO: Learning rate of xt decay: 0.13013 -> 0.13169.
2024-12-01-20:26:10-root-INFO: Coefficient of regularization decay: 0.00048 -> 0.00048.
2024-12-01-20:26:10-root-INFO: step: 91 lr_xt 0.06636917
2024-12-01-20:26:10-root-INFO: grad norm: 4.807 4.678 1.105
2024-12-01-20:26:11-root-INFO: grad norm: 4.541 4.427 1.008
2024-12-01-20:26:11-root-INFO: grad norm: 4.525 4.418 0.981
2024-12-01-20:26:11-root-INFO: grad norm: 4.614 4.506 0.995
2024-12-01-20:26:12-root-INFO: grad norm: 4.803 4.701 0.983
2024-12-01-20:26:12-root-INFO: Loss Change: 169.768 -> 165.651
2024-12-01-20:26:12-root-INFO: Regularization Change: 0.000 -> 1.443
2024-12-01-20:26:12-root-INFO: Learning rate of xt decay: 0.13169 -> 0.13327.
2024-12-01-20:26:12-root-INFO: Coefficient of regularization decay: 0.00048 -> 0.00049.
2024-12-01-20:26:12-root-INFO: step: 90 lr_xt 0.06816268
2024-12-01-20:26:13-root-INFO: grad norm: 3.995 3.883 0.939
2024-12-01-20:26:13-root-INFO: grad norm: 3.645 3.546 0.843
2024-12-01-20:26:14-root-INFO: grad norm: 3.647 3.549 0.839
2024-12-01-20:26:14-root-INFO: grad norm: 3.729 3.635 0.830
2024-12-01-20:26:15-root-INFO: grad norm: 3.889 3.797 0.843
2024-12-01-20:26:15-root-INFO: Loss Change: 165.439 -> 161.880
2024-12-01-20:26:15-root-INFO: Regularization Change: 0.000 -> 1.250
2024-12-01-20:26:15-root-INFO: Learning rate of xt decay: 0.13327 -> 0.13487.
2024-12-01-20:26:15-root-INFO: Coefficient of regularization decay: 0.00049 -> 0.00049.
2024-12-01-20:26:15-root-INFO: step: 89 lr_xt 0.06999342
2024-12-01-20:26:15-root-INFO: grad norm: 7.324 7.190 1.394
2024-12-01-20:26:16-root-INFO: grad norm: 7.928 7.821 1.294
2024-12-01-20:26:16-root-INFO: grad norm: 8.835 8.728 1.373
2024-12-01-20:26:17-root-INFO: grad norm: 9.993 9.873 1.546
2024-12-01-20:26:17-root-INFO: grad norm: 11.078 10.954 1.652
2024-12-01-20:26:17-root-INFO: Loss Change: 162.263 -> 160.578
2024-12-01-20:26:17-root-INFO: Regularization Change: 0.000 -> 1.497
2024-12-01-20:26:17-root-INFO: Learning rate of xt decay: 0.13487 -> 0.13649.
2024-12-01-20:26:17-root-INFO: Coefficient of regularization decay: 0.00049 -> 0.00050.
2024-12-01-20:26:18-root-INFO: step: 88 lr_xt 0.07186179
2024-12-01-20:26:18-root-INFO: grad norm: 10.162 10.067 1.387
2024-12-01-20:26:18-root-INFO: grad norm: 10.833 10.712 1.613
2024-12-01-20:26:19-root-INFO: grad norm: 11.511 11.376 1.761
2024-12-01-20:26:19-root-INFO: grad norm: 12.066 11.922 1.859
2024-12-01-20:26:20-root-INFO: grad norm: 12.519 12.360 1.991
2024-12-01-20:26:20-root-INFO: Loss Change: 159.990 -> 158.481
2024-12-01-20:26:20-root-INFO: Regularization Change: 0.000 -> 1.676
2024-12-01-20:26:20-root-INFO: Learning rate of xt decay: 0.13649 -> 0.13813.
2024-12-01-20:26:20-root-INFO: Coefficient of regularization decay: 0.00050 -> 0.00050.
2024-12-01-20:26:20-root-INFO: step: 87 lr_xt 0.07376819
2024-12-01-20:26:20-root-INFO: grad norm: 15.925 15.725 2.513
2024-12-01-20:26:21-root-INFO: grad norm: 15.852 15.658 2.469
2024-12-01-20:26:21-root-INFO: grad norm: 15.658 15.477 2.377
2024-12-01-20:26:22-root-INFO: grad norm: 15.303 15.107 2.446
2024-12-01-20:26:22-root-INFO: grad norm: 14.953 14.774 2.308
2024-12-01-20:26:23-root-INFO: Loss Change: 159.928 -> 156.260
2024-12-01-20:26:23-root-INFO: Regularization Change: 0.000 -> 2.291
2024-12-01-20:26:23-root-INFO: Learning rate of xt decay: 0.13813 -> 0.13978.
2024-12-01-20:26:23-root-INFO: Coefficient of regularization decay: 0.00050 -> 0.00051.
2024-12-01-20:26:23-root-INFO: step: 86 lr_xt 0.07571301
2024-12-01-20:26:23-root-INFO: grad norm: 12.055 11.913 1.843
2024-12-01-20:26:23-root-INFO: grad norm: 11.724 11.576 1.857
2024-12-01-20:26:24-root-INFO: grad norm: 11.419 11.269 1.847
2024-12-01-20:26:24-root-INFO: grad norm: 11.202 11.060 1.780
2024-12-01-20:26:25-root-INFO: grad norm: 10.987 10.842 1.777
2024-12-01-20:26:25-root-INFO: Loss Change: 155.044 -> 151.979
2024-12-01-20:26:25-root-INFO: Regularization Change: 0.000 -> 1.718
2024-12-01-20:26:25-root-INFO: Learning rate of xt decay: 0.13978 -> 0.14146.
2024-12-01-20:26:25-root-INFO: Coefficient of regularization decay: 0.00051 -> 0.00051.
2024-12-01-20:26:25-root-INFO: step: 85 lr_xt 0.07769664
2024-12-01-20:26:25-root-INFO: grad norm: 13.309 13.131 2.170
2024-12-01-20:26:26-root-INFO: grad norm: 12.811 12.656 1.988
2024-12-01-20:26:26-root-INFO: grad norm: 12.356 12.209 1.901
2024-12-01-20:26:27-root-INFO: grad norm: 11.901 11.752 1.872
2024-12-01-20:26:27-root-INFO: grad norm: 11.503 11.364 1.781
2024-12-01-20:26:28-root-INFO: Loss Change: 153.130 -> 149.438
2024-12-01-20:26:28-root-INFO: Regularization Change: 0.000 -> 1.884
2024-12-01-20:26:28-root-INFO: Undo step: 85
2024-12-01-20:26:28-root-INFO: Undo step: 86
2024-12-01-20:26:28-root-INFO: Undo step: 87
2024-12-01-20:26:28-root-INFO: Undo step: 88
2024-12-01-20:26:28-root-INFO: Undo step: 89
2024-12-01-20:26:28-root-INFO: step: 90 lr_xt 0.06816268
2024-12-01-20:26:28-root-INFO: grad norm: 48.543 47.962 7.490
2024-12-01-20:26:28-root-INFO: grad norm: 26.547 26.123 4.727
2024-12-01-20:26:29-root-INFO: grad norm: 18.402 18.033 3.666
2024-12-01-20:26:29-root-INFO: grad norm: 15.453 15.136 3.113
2024-12-01-20:26:30-root-INFO: grad norm: 13.822 13.554 2.711
2024-12-01-20:26:30-root-INFO: Loss Change: 331.577 -> 181.832
2024-12-01-20:26:30-root-INFO: Regularization Change: 0.000 -> 39.027
2024-12-01-20:26:30-root-INFO: Learning rate of xt decay: 0.13327 -> 0.13487.
2024-12-01-20:26:30-root-INFO: Coefficient of regularization decay: 0.00049 -> 0.00049.
2024-12-01-20:26:30-root-INFO: step: 89 lr_xt 0.06999342
2024-12-01-20:26:30-root-INFO: grad norm: 16.262 15.986 2.984
2024-12-01-20:26:31-root-INFO: grad norm: 15.528 15.309 2.598
2024-12-01-20:26:31-root-INFO: grad norm: 14.993 14.781 2.515
2024-12-01-20:26:32-root-INFO: grad norm: 14.575 14.377 2.396
2024-12-01-20:26:32-root-INFO: grad norm: 14.251 14.059 2.332
2024-12-01-20:26:33-root-INFO: Loss Change: 182.996 -> 168.019
2024-12-01-20:26:33-root-INFO: Regularization Change: 0.000 -> 6.060
2024-12-01-20:26:33-root-INFO: Learning rate of xt decay: 0.13487 -> 0.13649.
2024-12-01-20:26:33-root-INFO: Coefficient of regularization decay: 0.00049 -> 0.00050.
2024-12-01-20:26:33-root-INFO: step: 88 lr_xt 0.07186179
2024-12-01-20:26:33-root-INFO: grad norm: 12.008 11.872 1.801
2024-12-01-20:26:33-root-INFO: grad norm: 11.690 11.529 1.931
2024-12-01-20:26:34-root-INFO: grad norm: 11.532 11.385 1.833
2024-12-01-20:26:34-root-INFO: grad norm: 11.437 11.283 1.870
2024-12-01-20:26:35-root-INFO: grad norm: 11.419 11.274 1.814
2024-12-01-20:26:35-root-INFO: Loss Change: 167.205 -> 160.101
2024-12-01-20:26:35-root-INFO: Regularization Change: 0.000 -> 3.148
2024-12-01-20:26:35-root-INFO: Learning rate of xt decay: 0.13649 -> 0.13813.
2024-12-01-20:26:35-root-INFO: Coefficient of regularization decay: 0.00050 -> 0.00050.
2024-12-01-20:26:35-root-INFO: step: 87 lr_xt 0.07376819
2024-12-01-20:26:35-root-INFO: grad norm: 14.893 14.681 2.507
2024-12-01-20:26:36-root-INFO: grad norm: 14.439 14.278 2.151
2024-12-01-20:26:36-root-INFO: grad norm: 13.987 13.824 2.129
2024-12-01-20:26:37-root-INFO: grad norm: 13.616 13.461 2.046
2024-12-01-20:26:37-root-INFO: grad norm: 13.248 13.096 2.003
2024-12-01-20:26:38-root-INFO: Loss Change: 161.460 -> 155.771
2024-12-01-20:26:38-root-INFO: Regularization Change: 0.000 -> 2.759
2024-12-01-20:26:38-root-INFO: Learning rate of xt decay: 0.13813 -> 0.13978.
2024-12-01-20:26:38-root-INFO: Coefficient of regularization decay: 0.00050 -> 0.00051.
2024-12-01-20:26:38-root-INFO: step: 86 lr_xt 0.07571301
2024-12-01-20:26:38-root-INFO: grad norm: 10.439 10.342 1.414
2024-12-01-20:26:38-root-INFO: grad norm: 10.126 10.008 1.539
2024-12-01-20:26:39-root-INFO: grad norm: 9.919 9.810 1.464
2024-12-01-20:26:39-root-INFO: grad norm: 9.779 9.665 1.490
2024-12-01-20:26:40-root-INFO: grad norm: 9.664 9.555 1.447
2024-12-01-20:26:40-root-INFO: Loss Change: 154.607 -> 150.623
2024-12-01-20:26:40-root-INFO: Regularization Change: 0.000 -> 1.943
2024-12-01-20:26:40-root-INFO: Learning rate of xt decay: 0.13978 -> 0.14146.
2024-12-01-20:26:40-root-INFO: Coefficient of regularization decay: 0.00051 -> 0.00051.
2024-12-01-20:26:41-root-INFO: step: 85 lr_xt 0.07769664
2024-12-01-20:26:41-root-INFO: grad norm: 12.113 11.946 2.008
2024-12-01-20:26:41-root-INFO: grad norm: 11.686 11.562 1.699
2024-12-01-20:26:42-root-INFO: grad norm: 11.301 11.175 1.686
2024-12-01-20:26:42-root-INFO: grad norm: 10.937 10.819 1.599
2024-12-01-20:26:43-root-INFO: grad norm: 10.608 10.491 1.572
2024-12-01-20:26:43-root-INFO: Loss Change: 151.598 -> 147.512
2024-12-01-20:26:43-root-INFO: Regularization Change: 0.000 -> 1.990
2024-12-01-20:26:43-root-INFO: Learning rate of xt decay: 0.14146 -> 0.14316.
2024-12-01-20:26:43-root-INFO: Coefficient of regularization decay: 0.00051 -> 0.00052.
2024-12-01-20:26:43-root-INFO: step: 84 lr_xt 0.07971945
2024-12-01-20:26:43-root-INFO: grad norm: 8.622 8.539 1.194
2024-12-01-20:26:44-root-INFO: grad norm: 8.335 8.241 1.249
2024-12-01-20:26:44-root-INFO: grad norm: 8.110 8.021 1.197
2024-12-01-20:26:45-root-INFO: grad norm: 7.942 7.851 1.198
2024-12-01-20:26:45-root-INFO: grad norm: 7.795 7.709 1.156
2024-12-01-20:26:45-root-INFO: Loss Change: 146.723 -> 143.603
2024-12-01-20:26:45-root-INFO: Regularization Change: 0.000 -> 1.530
2024-12-01-20:26:45-root-INFO: Learning rate of xt decay: 0.14316 -> 0.14488.
2024-12-01-20:26:45-root-INFO: Coefficient of regularization decay: 0.00052 -> 0.00052.
2024-12-01-20:26:46-root-INFO: step: 83 lr_xt 0.08178179
2024-12-01-20:26:46-root-INFO: grad norm: 10.203 10.064 1.679
2024-12-01-20:26:46-root-INFO: grad norm: 9.728 9.628 1.391
2024-12-01-20:26:47-root-INFO: grad norm: 9.340 9.241 1.360
2024-12-01-20:26:47-root-INFO: grad norm: 8.985 8.892 1.286
2024-12-01-20:26:48-root-INFO: grad norm: 8.670 8.580 1.252
2024-12-01-20:26:48-root-INFO: Loss Change: 144.497 -> 141.046
2024-12-01-20:26:48-root-INFO: Regularization Change: 0.000 -> 1.650
2024-12-01-20:26:48-root-INFO: Learning rate of xt decay: 0.14488 -> 0.14661.
2024-12-01-20:26:48-root-INFO: Coefficient of regularization decay: 0.00052 -> 0.00053.
2024-12-01-20:26:48-root-INFO: step: 82 lr_xt 0.08388403
2024-12-01-20:26:48-root-INFO: grad norm: 6.920 6.864 0.880
2024-12-01-20:26:49-root-INFO: grad norm: 6.622 6.553 0.956
2024-12-01-20:26:49-root-INFO: grad norm: 6.402 6.339 0.895
2024-12-01-20:26:50-root-INFO: grad norm: 6.243 6.174 0.923
2024-12-01-20:26:50-root-INFO: grad norm: 6.098 6.035 0.872
2024-12-01-20:26:51-root-INFO: Loss Change: 140.641 -> 137.931
2024-12-01-20:26:51-root-INFO: Regularization Change: 0.000 -> 1.303
2024-12-01-20:26:51-root-INFO: Learning rate of xt decay: 0.14661 -> 0.14837.
2024-12-01-20:26:51-root-INFO: Coefficient of regularization decay: 0.00053 -> 0.00053.
2024-12-01-20:26:51-root-INFO: step: 81 lr_xt 0.08602650
2024-12-01-20:26:51-root-INFO: grad norm: 8.259 8.141 1.390
2024-12-01-20:26:51-root-INFO: grad norm: 7.801 7.726 1.084
2024-12-01-20:26:52-root-INFO: grad norm: 7.477 7.397 1.090
2024-12-01-20:26:52-root-INFO: grad norm: 7.200 7.131 0.988
2024-12-01-20:26:53-root-INFO: grad norm: 6.953 6.881 0.994
2024-12-01-20:26:53-root-INFO: Loss Change: 138.489 -> 135.527
2024-12-01-20:26:53-root-INFO: Regularization Change: 0.000 -> 1.424
2024-12-01-20:26:53-root-INFO: Learning rate of xt decay: 0.14837 -> 0.15015.
2024-12-01-20:26:53-root-INFO: Coefficient of regularization decay: 0.00053 -> 0.00054.
2024-12-01-20:26:53-root-INFO: step: 80 lr_xt 0.08820955
2024-12-01-20:26:53-root-INFO: grad norm: 4.786 4.735 0.694
2024-12-01-20:26:54-root-INFO: grad norm: 4.435 4.385 0.667
2024-12-01-20:26:54-root-INFO: grad norm: 4.303 4.260 0.605
2024-12-01-20:26:55-root-INFO: grad norm: 4.231 4.182 0.640
2024-12-01-20:26:55-root-INFO: grad norm: 4.175 4.132 0.603
2024-12-01-20:26:56-root-INFO: Loss Change: 135.113 -> 132.656
2024-12-01-20:26:56-root-INFO: Regularization Change: 0.000 -> 1.147
2024-12-01-20:26:56-root-INFO: Undo step: 80
2024-12-01-20:26:56-root-INFO: Undo step: 81
2024-12-01-20:26:56-root-INFO: Undo step: 82
2024-12-01-20:26:56-root-INFO: Undo step: 83
2024-12-01-20:26:56-root-INFO: Undo step: 84
2024-12-01-20:26:56-root-INFO: step: 85 lr_xt 0.07769664
2024-12-01-20:26:56-root-INFO: grad norm: 41.387 40.929 6.135
2024-12-01-20:26:57-root-INFO: grad norm: 22.266 21.841 4.329
2024-12-01-20:26:57-root-INFO: grad norm: 16.187 15.828 3.392
2024-12-01-20:26:57-root-INFO: grad norm: 12.987 12.694 2.742
2024-12-01-20:26:58-root-INFO: grad norm: 11.143 10.919 2.225
2024-12-01-20:26:58-root-INFO: Loss Change: 308.903 -> 164.243
2024-12-01-20:26:58-root-INFO: Regularization Change: 0.000 -> 43.022
2024-12-01-20:26:58-root-INFO: Learning rate of xt decay: 0.14146 -> 0.14316.
2024-12-01-20:26:58-root-INFO: Coefficient of regularization decay: 0.00051 -> 0.00052.
2024-12-01-20:26:58-root-INFO: step: 84 lr_xt 0.07971945
2024-12-01-20:26:59-root-INFO: grad norm: 10.705 10.489 2.138
2024-12-01-20:26:59-root-INFO: grad norm: 9.869 9.710 1.765
2024-12-01-20:27:00-root-INFO: grad norm: 9.268 9.113 1.688
2024-12-01-20:27:00-root-INFO: grad norm: 8.911 8.788 1.474
2024-12-01-20:27:01-root-INFO: grad norm: 8.648 8.524 1.461
2024-12-01-20:27:01-root-INFO: Loss Change: 164.221 -> 150.095
2024-12-01-20:27:01-root-INFO: Regularization Change: 0.000 -> 5.997
2024-12-01-20:27:01-root-INFO: Learning rate of xt decay: 0.14316 -> 0.14488.
2024-12-01-20:27:01-root-INFO: Coefficient of regularization decay: 0.00052 -> 0.00052.
2024-12-01-20:27:01-root-INFO: step: 83 lr_xt 0.08178179
2024-12-01-20:27:01-root-INFO: grad norm: 7.113 7.027 1.101
2024-12-01-20:27:02-root-INFO: grad norm: 6.666 6.571 1.121
2024-12-01-20:27:02-root-INFO: grad norm: 6.463 6.381 1.024
2024-12-01-20:27:03-root-INFO: grad norm: 6.352 6.265 1.046
2024-12-01-20:27:03-root-INFO: grad norm: 6.295 6.218 0.982
2024-12-01-20:27:03-root-INFO: Loss Change: 149.441 -> 143.038
2024-12-01-20:27:03-root-INFO: Regularization Change: 0.000 -> 2.815
2024-12-01-20:27:03-root-INFO: Learning rate of xt decay: 0.14488 -> 0.14661.
2024-12-01-20:27:03-root-INFO: Coefficient of regularization decay: 0.00052 -> 0.00053.
2024-12-01-20:27:03-root-INFO: step: 82 lr_xt 0.08388403
2024-12-01-20:27:04-root-INFO: grad norm: 8.100 7.984 1.369
2024-12-01-20:27:04-root-INFO: grad norm: 8.056 7.972 1.160
2024-12-01-20:27:04-root-INFO: grad norm: 8.113 8.025 1.192
2024-12-01-20:27:05-root-INFO: grad norm: 8.144 8.063 1.146
2024-12-01-20:27:06-root-INFO: grad norm: 8.196 8.114 1.158
2024-12-01-20:27:06-root-INFO: Loss Change: 143.621 -> 139.562
2024-12-01-20:27:06-root-INFO: Regularization Change: 0.000 -> 2.167
2024-12-01-20:27:06-root-INFO: Learning rate of xt decay: 0.14661 -> 0.14837.
2024-12-01-20:27:06-root-INFO: Coefficient of regularization decay: 0.00053 -> 0.00053.
2024-12-01-20:27:06-root-INFO: step: 81 lr_xt 0.08602650
2024-12-01-20:27:06-root-INFO: grad norm: 6.428 6.378 0.806
2024-12-01-20:27:07-root-INFO: grad norm: 6.235 6.169 0.909
2024-12-01-20:27:07-root-INFO: grad norm: 6.231 6.172 0.854
2024-12-01-20:27:08-root-INFO: grad norm: 6.316 6.251 0.902
2024-12-01-20:27:08-root-INFO: grad norm: 6.352 6.291 0.881
2024-12-01-20:27:08-root-INFO: Loss Change: 138.768 -> 135.406
2024-12-01-20:27:08-root-INFO: Regularization Change: 0.000 -> 1.684
2024-12-01-20:27:08-root-INFO: Learning rate of xt decay: 0.14837 -> 0.15015.
2024-12-01-20:27:08-root-INFO: Coefficient of regularization decay: 0.00053 -> 0.00054.
2024-12-01-20:27:08-root-INFO: step: 80 lr_xt 0.08820955
2024-12-01-20:27:09-root-INFO: grad norm: 9.493 9.373 1.505
2024-12-01-20:27:09-root-INFO: grad norm: 8.924 8.848 1.160
2024-12-01-20:27:10-root-INFO: grad norm: 8.334 8.263 1.091
2024-12-01-20:27:10-root-INFO: grad norm: 8.092 8.028 1.021
2024-12-01-20:27:11-root-INFO: grad norm: 7.975 7.909 1.022
2024-12-01-20:27:11-root-INFO: Loss Change: 136.499 -> 133.091
2024-12-01-20:27:11-root-INFO: Regularization Change: 0.000 -> 1.806
2024-12-01-20:27:11-root-INFO: Learning rate of xt decay: 0.15015 -> 0.15196.
2024-12-01-20:27:11-root-INFO: Coefficient of regularization decay: 0.00054 -> 0.00054.
2024-12-01-20:27:11-root-INFO: step: 79 lr_xt 0.09043348
2024-12-01-20:27:11-root-INFO: grad norm: 6.364 6.318 0.762
2024-12-01-20:27:12-root-INFO: grad norm: 6.162 6.106 0.829
2024-12-01-20:27:12-root-INFO: grad norm: 6.084 6.032 0.796
2024-12-01-20:27:13-root-INFO: grad norm: 6.115 6.060 0.815
2024-12-01-20:27:13-root-INFO: grad norm: 6.048 5.993 0.813
2024-12-01-20:27:13-root-INFO: Loss Change: 132.464 -> 129.651
2024-12-01-20:27:13-root-INFO: Regularization Change: 0.000 -> 1.457
2024-12-01-20:27:13-root-INFO: Learning rate of xt decay: 0.15196 -> 0.15378.
2024-12-01-20:27:13-root-INFO: Coefficient of regularization decay: 0.00054 -> 0.00055.
2024-12-01-20:27:14-root-INFO: step: 78 lr_xt 0.09269861
2024-12-01-20:27:14-root-INFO: grad norm: 7.981 7.888 1.216
2024-12-01-20:27:14-root-INFO: grad norm: 7.532 7.469 0.965
2024-12-01-20:27:15-root-INFO: grad norm: 6.987 6.927 0.916
2024-12-01-20:27:15-root-INFO: grad norm: 6.823 6.768 0.866
2024-12-01-20:27:16-root-INFO: grad norm: 6.904 6.847 0.883
2024-12-01-20:27:16-root-INFO: Loss Change: 130.417 -> 127.725
2024-12-01-20:27:16-root-INFO: Regularization Change: 0.000 -> 1.556
2024-12-01-20:27:16-root-INFO: Learning rate of xt decay: 0.15378 -> 0.15562.
2024-12-01-20:27:16-root-INFO: Coefficient of regularization decay: 0.00055 -> 0.00055.
2024-12-01-20:27:16-root-INFO: step: 77 lr_xt 0.09500525
2024-12-01-20:27:16-root-INFO: grad norm: 5.296 5.256 0.652
2024-12-01-20:27:17-root-INFO: grad norm: 4.982 4.937 0.666
2024-12-01-20:27:17-root-INFO: grad norm: 4.897 4.852 0.662
2024-12-01-20:27:18-root-INFO: grad norm: 4.973 4.930 0.652
2024-12-01-20:27:18-root-INFO: grad norm: 4.842 4.794 0.680
2024-12-01-20:27:18-root-INFO: Loss Change: 127.033 -> 124.422
2024-12-01-20:27:18-root-INFO: Regularization Change: 0.000 -> 1.291
2024-12-01-20:27:18-root-INFO: Learning rate of xt decay: 0.15562 -> 0.15749.
2024-12-01-20:27:18-root-INFO: Coefficient of regularization decay: 0.00055 -> 0.00056.
2024-12-01-20:27:18-root-INFO: step: 76 lr_xt 0.09735366
2024-12-01-20:27:19-root-INFO: grad norm: 7.184 7.097 1.112
2024-12-01-20:27:19-root-INFO: grad norm: 6.081 6.024 0.831
2024-12-01-20:27:20-root-INFO: grad norm: 5.122 5.077 0.675
2024-12-01-20:27:20-root-INFO: grad norm: 4.724 4.684 0.619
2024-12-01-20:27:20-root-INFO: grad norm: 4.465 4.426 0.586
2024-12-01-20:27:21-root-INFO: Loss Change: 124.978 -> 122.053
2024-12-01-20:27:21-root-INFO: Regularization Change: 0.000 -> 1.326
2024-12-01-20:27:21-root-INFO: Learning rate of xt decay: 0.15749 -> 0.15938.
2024-12-01-20:27:21-root-INFO: Coefficient of regularization decay: 0.00056 -> 0.00056.
2024-12-01-20:27:21-root-INFO: step: 75 lr_xt 0.09974414
2024-12-01-20:27:21-root-INFO: grad norm: 3.423 3.379 0.545
2024-12-01-20:27:22-root-INFO: grad norm: 3.084 3.047 0.474
2024-12-01-20:27:22-root-INFO: grad norm: 2.997 2.961 0.460
2024-12-01-20:27:22-root-INFO: grad norm: 3.034 2.999 0.463
2024-12-01-20:27:23-root-INFO: grad norm: 3.183 3.145 0.489
2024-12-01-20:27:23-root-INFO: Loss Change: 121.856 -> 119.676
2024-12-01-20:27:23-root-INFO: Regularization Change: 0.000 -> 1.150
2024-12-01-20:27:23-root-INFO: Undo step: 75
2024-12-01-20:27:23-root-INFO: Undo step: 76
2024-12-01-20:27:23-root-INFO: Undo step: 77
2024-12-01-20:27:23-root-INFO: Undo step: 78
2024-12-01-20:27:23-root-INFO: Undo step: 79
2024-12-01-20:27:23-root-INFO: step: 80 lr_xt 0.08820955
2024-12-01-20:27:24-root-INFO: grad norm: 37.131 36.831 4.706
2024-12-01-20:27:24-root-INFO: grad norm: 19.205 18.967 3.012
2024-12-01-20:27:24-root-INFO: grad norm: 13.477 13.251 2.460
2024-12-01-20:27:25-root-INFO: grad norm: 11.069 10.898 1.940
2024-12-01-20:27:25-root-INFO: grad norm: 9.923 9.774 1.712
2024-12-01-20:27:26-root-INFO: Loss Change: 273.187 -> 147.524
2024-12-01-20:27:26-root-INFO: Regularization Change: 0.000 -> 42.993
2024-12-01-20:27:26-root-INFO: Learning rate of xt decay: 0.15015 -> 0.15196.
2024-12-01-20:27:26-root-INFO: Coefficient of regularization decay: 0.00054 -> 0.00054.
2024-12-01-20:27:26-root-INFO: step: 79 lr_xt 0.09043348
2024-12-01-20:27:26-root-INFO: grad norm: 11.099 10.955 1.780
2024-12-01-20:27:26-root-INFO: grad norm: 10.827 10.720 1.518
2024-12-01-20:27:27-root-INFO: grad norm: 10.678 10.567 1.533
2024-12-01-20:27:27-root-INFO: grad norm: 10.575 10.479 1.420
2024-12-01-20:27:28-root-INFO: grad norm: 10.474 10.373 1.456
2024-12-01-20:27:28-root-INFO: Loss Change: 147.840 -> 136.644
2024-12-01-20:27:28-root-INFO: Regularization Change: 0.000 -> 5.983
2024-12-01-20:27:28-root-INFO: Learning rate of xt decay: 0.15196 -> 0.15378.
2024-12-01-20:27:28-root-INFO: Coefficient of regularization decay: 0.00054 -> 0.00055.
2024-12-01-20:27:28-root-INFO: step: 78 lr_xt 0.09269861
2024-12-01-20:27:28-root-INFO: grad norm: 8.979 8.914 1.078
2024-12-01-20:27:29-root-INFO: grad norm: 8.880 8.794 1.234
2024-12-01-20:27:29-root-INFO: grad norm: 8.839 8.764 1.146
2024-12-01-20:27:30-root-INFO: grad norm: 8.873 8.790 1.212
2024-12-01-20:27:30-root-INFO: grad norm: 8.856 8.779 1.165
2024-12-01-20:27:31-root-INFO: Loss Change: 136.048 -> 130.278
2024-12-01-20:27:31-root-INFO: Regularization Change: 0.000 -> 3.270
2024-12-01-20:27:31-root-INFO: Learning rate of xt decay: 0.15378 -> 0.15562.
2024-12-01-20:27:31-root-INFO: Coefficient of regularization decay: 0.00055 -> 0.00055.
2024-12-01-20:27:31-root-INFO: step: 77 lr_xt 0.09500525
2024-12-01-20:27:31-root-INFO: grad norm: 11.009 10.884 1.657
2024-12-01-20:27:31-root-INFO: grad norm: 10.303 10.210 1.376
2024-12-01-20:27:32-root-INFO: grad norm: 9.447 9.362 1.264
2024-12-01-20:27:32-root-INFO: grad norm: 8.959 8.879 1.196
2024-12-01-20:27:33-root-INFO: grad norm: 8.703 8.626 1.154
2024-12-01-20:27:33-root-INFO: Loss Change: 130.944 -> 125.941
2024-12-01-20:27:33-root-INFO: Regularization Change: 0.000 -> 2.728
2024-12-01-20:27:33-root-INFO: Learning rate of xt decay: 0.15562 -> 0.15749.
2024-12-01-20:27:33-root-INFO: Coefficient of regularization decay: 0.00055 -> 0.00056.
2024-12-01-20:27:33-root-INFO: step: 76 lr_xt 0.09735366
2024-12-01-20:27:33-root-INFO: grad norm: 6.748 6.699 0.813
2024-12-01-20:27:34-root-INFO: grad norm: 6.475 6.416 0.874
2024-12-01-20:27:34-root-INFO: grad norm: 6.338 6.283 0.835
2024-12-01-20:27:35-root-INFO: grad norm: 6.326 6.270 0.842
2024-12-01-20:27:35-root-INFO: grad norm: 6.242 6.185 0.836
2024-12-01-20:27:36-root-INFO: Loss Change: 125.184 -> 121.659
2024-12-01-20:27:36-root-INFO: Regularization Change: 0.000 -> 1.908
2024-12-01-20:27:36-root-INFO: Learning rate of xt decay: 0.15749 -> 0.15938.
2024-12-01-20:27:36-root-INFO: Coefficient of regularization decay: 0.00056 -> 0.00056.
2024-12-01-20:27:36-root-INFO: step: 75 lr_xt 0.09974414
2024-12-01-20:27:36-root-INFO: grad norm: 8.123 8.027 1.245
2024-12-01-20:27:36-root-INFO: grad norm: 7.598 7.533 0.992
2024-12-01-20:27:37-root-INFO: grad norm: 6.981 6.920 0.923
2024-12-01-20:27:37-root-INFO: grad norm: 6.770 6.713 0.880
2024-12-01-20:27:38-root-INFO: grad norm: 6.833 6.777 0.873
2024-12-01-20:27:38-root-INFO: Loss Change: 122.308 -> 119.232
2024-12-01-20:27:38-root-INFO: Regularization Change: 0.000 -> 1.890
2024-12-01-20:27:38-root-INFO: Learning rate of xt decay: 0.15938 -> 0.16129.
2024-12-01-20:27:38-root-INFO: Coefficient of regularization decay: 0.00056 -> 0.00057.
2024-12-01-20:27:38-root-INFO: step: 74 lr_xt 0.10217692
2024-12-01-20:27:39-root-INFO: grad norm: 5.332 5.295 0.625
2024-12-01-20:27:39-root-INFO: grad norm: 4.983 4.939 0.658
2024-12-01-20:27:40-root-INFO: grad norm: 4.969 4.926 0.649
2024-12-01-20:27:40-root-INFO: grad norm: 5.151 5.109 0.660
2024-12-01-20:27:40-root-INFO: grad norm: 5.034 4.989 0.675
2024-12-01-20:27:41-root-INFO: Loss Change: 118.800 -> 115.984
2024-12-01-20:27:41-root-INFO: Regularization Change: 0.000 -> 1.508
2024-12-01-20:27:41-root-INFO: Learning rate of xt decay: 0.16129 -> 0.16323.
2024-12-01-20:27:41-root-INFO: Coefficient of regularization decay: 0.00057 -> 0.00058.
2024-12-01-20:27:41-root-INFO: step: 73 lr_xt 0.10465226
2024-12-01-20:27:41-root-INFO: grad norm: 6.832 6.741 1.106
2024-12-01-20:27:42-root-INFO: grad norm: 6.167 6.114 0.802
2024-12-01-20:27:42-root-INFO: grad norm: 5.371 5.321 0.729
2024-12-01-20:27:42-root-INFO: grad norm: 5.251 5.207 0.682
2024-12-01-20:27:43-root-INFO: grad norm: 5.577 5.532 0.704
2024-12-01-20:27:43-root-INFO: Loss Change: 116.473 -> 113.943
2024-12-01-20:27:43-root-INFO: Regularization Change: 0.000 -> 1.602
2024-12-01-20:27:43-root-INFO: Learning rate of xt decay: 0.16323 -> 0.16519.
2024-12-01-20:27:43-root-INFO: Coefficient of regularization decay: 0.00058 -> 0.00058.
2024-12-01-20:27:43-root-INFO: step: 72 lr_xt 0.10717038
2024-12-01-20:27:44-root-INFO: grad norm: 4.457 4.422 0.559
2024-12-01-20:27:44-root-INFO: grad norm: 4.080 4.042 0.555
2024-12-01-20:27:45-root-INFO: grad norm: 4.166 4.130 0.546
2024-12-01-20:27:45-root-INFO: grad norm: 4.544 4.509 0.566
2024-12-01-20:27:46-root-INFO: grad norm: 4.339 4.300 0.585
2024-12-01-20:27:46-root-INFO: Loss Change: 113.546 -> 110.980
2024-12-01-20:27:46-root-INFO: Regularization Change: 0.000 -> 1.365
2024-12-01-20:27:46-root-INFO: Learning rate of xt decay: 0.16519 -> 0.16717.
2024-12-01-20:27:46-root-INFO: Coefficient of regularization decay: 0.00058 -> 0.00059.
2024-12-01-20:27:46-root-INFO: step: 71 lr_xt 0.10973151
2024-12-01-20:27:46-root-INFO: grad norm: 4.976 4.919 0.749
2024-12-01-20:27:47-root-INFO: grad norm: 4.744 4.701 0.637
2024-12-01-20:27:47-root-INFO: grad norm: 4.566 4.526 0.605
2024-12-01-20:27:48-root-INFO: grad norm: 4.509 4.468 0.612
2024-12-01-20:27:48-root-INFO: grad norm: 4.519 4.481 0.579
2024-12-01-20:27:48-root-INFO: Loss Change: 111.279 -> 109.252
2024-12-01-20:27:48-root-INFO: Regularization Change: 0.000 -> 1.390
2024-12-01-20:27:48-root-INFO: Learning rate of xt decay: 0.16717 -> 0.16918.
2024-12-01-20:27:48-root-INFO: Coefficient of regularization decay: 0.00059 -> 0.00059.
2024-12-01-20:27:48-root-INFO: step: 70 lr_xt 0.11233583
2024-12-01-20:27:49-root-INFO: grad norm: 3.902 3.857 0.594
2024-12-01-20:27:49-root-INFO: grad norm: 3.761 3.726 0.510
2024-12-01-20:27:50-root-INFO: grad norm: 3.737 3.704 0.490
2024-12-01-20:27:50-root-INFO: grad norm: 3.813 3.782 0.489
2024-12-01-20:27:51-root-INFO: grad norm: 3.787 3.752 0.514
2024-12-01-20:27:51-root-INFO: Loss Change: 108.852 -> 106.496
2024-12-01-20:27:51-root-INFO: Regularization Change: 0.000 -> 1.318
2024-12-01-20:27:51-root-INFO: Undo step: 70
2024-12-01-20:27:51-root-INFO: Undo step: 71
2024-12-01-20:27:51-root-INFO: Undo step: 72
2024-12-01-20:27:51-root-INFO: Undo step: 73
2024-12-01-20:27:51-root-INFO: Undo step: 74
2024-12-01-20:27:51-root-INFO: step: 75 lr_xt 0.09974414
2024-12-01-20:27:51-root-INFO: grad norm: 39.444 39.145 4.848
2024-12-01-20:27:52-root-INFO: grad norm: 17.569 17.340 2.832
2024-12-01-20:27:52-root-INFO: grad norm: 11.222 11.010 2.173
2024-12-01-20:27:53-root-INFO: grad norm: 8.557 8.399 1.635
2024-12-01-20:27:53-root-INFO: grad norm: 6.824 6.684 1.377
2024-12-01-20:27:53-root-INFO: Loss Change: 259.917 -> 131.329
2024-12-01-20:27:53-root-INFO: Regularization Change: 0.000 -> 47.011
2024-12-01-20:27:53-root-INFO: Learning rate of xt decay: 0.15938 -> 0.16129.
2024-12-01-20:27:53-root-INFO: Coefficient of regularization decay: 0.00056 -> 0.00057.
2024-12-01-20:27:54-root-INFO: step: 74 lr_xt 0.10217692
2024-12-01-20:27:54-root-INFO: grad norm: 6.394 6.260 1.304
2024-12-01-20:27:54-root-INFO: grad norm: 5.510 5.400 1.097
2024-12-01-20:27:55-root-INFO: grad norm: 4.970 4.870 0.992
2024-12-01-20:27:55-root-INFO: grad norm: 4.617 4.528 0.901
2024-12-01-20:27:56-root-INFO: grad norm: 4.393 4.312 0.843
2024-12-01-20:27:56-root-INFO: Loss Change: 131.320 -> 120.589
2024-12-01-20:27:56-root-INFO: Regularization Change: 0.000 -> 5.555
2024-12-01-20:27:56-root-INFO: Learning rate of xt decay: 0.16129 -> 0.16323.
2024-12-01-20:27:56-root-INFO: Coefficient of regularization decay: 0.00057 -> 0.00058.
2024-12-01-20:27:56-root-INFO: step: 73 lr_xt 0.10465226
2024-12-01-20:27:56-root-INFO: grad norm: 4.388 4.293 0.907
2024-12-01-20:27:57-root-INFO: grad norm: 4.202 4.135 0.743
2024-12-01-20:27:57-root-INFO: grad norm: 4.677 4.621 0.726
2024-12-01-20:27:58-root-INFO: grad norm: 4.526 4.468 0.723
2024-12-01-20:27:58-root-INFO: grad norm: 4.300 4.250 0.659
2024-12-01-20:27:59-root-INFO: Loss Change: 120.430 -> 115.311
2024-12-01-20:27:59-root-INFO: Regularization Change: 0.000 -> 2.925
2024-12-01-20:27:59-root-INFO: Learning rate of xt decay: 0.16323 -> 0.16519.
2024-12-01-20:27:59-root-INFO: Coefficient of regularization decay: 0.00058 -> 0.00058.
2024-12-01-20:27:59-root-INFO: step: 72 lr_xt 0.10717038
2024-12-01-20:27:59-root-INFO: grad norm: 4.775 4.715 0.756
2024-12-01-20:27:59-root-INFO: grad norm: 4.801 4.759 0.633
2024-12-01-20:28:00-root-INFO: grad norm: 4.608 4.565 0.631
2024-12-01-20:28:00-root-INFO: grad norm: 4.357 4.319 0.571
2024-12-01-20:28:01-root-INFO: grad norm: 4.357 4.316 0.594
2024-12-01-20:28:01-root-INFO: Loss Change: 115.171 -> 111.229
2024-12-01-20:28:01-root-INFO: Regularization Change: 0.000 -> 2.173
2024-12-01-20:28:01-root-INFO: Learning rate of xt decay: 0.16519 -> 0.16717.
2024-12-01-20:28:01-root-INFO: Coefficient of regularization decay: 0.00058 -> 0.00059.
2024-12-01-20:28:01-root-INFO: step: 71 lr_xt 0.10973151
2024-12-01-20:28:02-root-INFO: grad norm: 5.161 5.111 0.718
2024-12-01-20:28:02-root-INFO: grad norm: 4.219 4.175 0.605
2024-12-01-20:28:02-root-INFO: grad norm: 2.920 2.877 0.496
2024-12-01-20:28:03-root-INFO: grad norm: 2.890 2.848 0.486
2024-12-01-20:28:03-root-INFO: grad norm: 3.301 3.265 0.487
2024-12-01-20:28:04-root-INFO: Loss Change: 111.368 -> 108.232
2024-12-01-20:28:04-root-INFO: Regularization Change: 0.000 -> 1.775
2024-12-01-20:28:04-root-INFO: Learning rate of xt decay: 0.16717 -> 0.16918.
2024-12-01-20:28:04-root-INFO: Coefficient of regularization decay: 0.00059 -> 0.00059.
2024-12-01-20:28:04-root-INFO: step: 70 lr_xt 0.11233583
2024-12-01-20:28:04-root-INFO: grad norm: 4.188 4.120 0.749
2024-12-01-20:28:04-root-INFO: grad norm: 4.500 4.467 0.550
2024-12-01-20:28:05-root-INFO: grad norm: 4.172 4.139 0.523
2024-12-01-20:28:05-root-INFO: grad norm: 3.698 3.667 0.480
2024-12-01-20:28:06-root-INFO: grad norm: 3.890 3.857 0.507
2024-12-01-20:28:06-root-INFO: Loss Change: 108.030 -> 105.297
2024-12-01-20:28:06-root-INFO: Regularization Change: 0.000 -> 1.607
2024-12-01-20:28:06-root-INFO: Learning rate of xt decay: 0.16918 -> 0.17121.
2024-12-01-20:28:06-root-INFO: Coefficient of regularization decay: 0.00059 -> 0.00060.
2024-12-01-20:28:06-root-INFO: step: 69 lr_xt 0.11498353
2024-12-01-20:28:06-root-INFO: grad norm: 5.243 5.193 0.727
2024-12-01-20:28:07-root-INFO: grad norm: 3.844 3.803 0.559
2024-12-01-20:28:07-root-INFO: grad norm: 2.400 2.360 0.434
2024-12-01-20:28:08-root-INFO: grad norm: 2.245 2.207 0.409
2024-12-01-20:28:08-root-INFO: grad norm: 2.365 2.329 0.410
2024-12-01-20:28:09-root-INFO: Loss Change: 105.477 -> 102.781
2024-12-01-20:28:09-root-INFO: Regularization Change: 0.000 -> 1.376
2024-12-01-20:28:09-root-INFO: Learning rate of xt decay: 0.17121 -> 0.17326.
2024-12-01-20:28:09-root-INFO: Coefficient of regularization decay: 0.00060 -> 0.00061.
2024-12-01-20:28:09-root-INFO: step: 68 lr_xt 0.11767478
2024-12-01-20:28:09-root-INFO: grad norm: 5.274 5.182 0.982
2024-12-01-20:28:09-root-INFO: grad norm: 4.211 4.168 0.604
2024-12-01-20:28:10-root-INFO: grad norm: 2.759 2.714 0.492
2024-12-01-20:28:10-root-INFO: grad norm: 2.857 2.821 0.454
2024-12-01-20:28:11-root-INFO: grad norm: 3.928 3.895 0.511
2024-12-01-20:28:11-root-INFO: Loss Change: 102.931 -> 100.762
2024-12-01-20:28:11-root-INFO: Regularization Change: 0.000 -> 1.551
2024-12-01-20:28:11-root-INFO: Learning rate of xt decay: 0.17326 -> 0.17534.
2024-12-01-20:28:11-root-INFO: Coefficient of regularization decay: 0.00061 -> 0.00061.
2024-12-01-20:28:11-root-INFO: step: 67 lr_xt 0.12040972
2024-12-01-20:28:12-root-INFO: grad norm: 3.889 3.858 0.487
2024-12-01-20:28:12-root-INFO: grad norm: 4.137 4.106 0.509
2024-12-01-20:28:12-root-INFO: Loss too large (99.784->99.818)! Learning rate decreased to 0.09633.
2024-12-01-20:28:13-root-INFO: grad norm: 3.705 3.674 0.477
2024-12-01-20:28:13-root-INFO: grad norm: 3.092 3.062 0.432
2024-12-01-20:28:14-root-INFO: grad norm: 3.266 3.236 0.443
2024-12-01-20:28:14-root-INFO: Loss Change: 100.563 -> 98.381
2024-12-01-20:28:14-root-INFO: Regularization Change: 0.000 -> 1.043
2024-12-01-20:28:14-root-INFO: Learning rate of xt decay: 0.17534 -> 0.17745.
2024-12-01-20:28:14-root-INFO: Coefficient of regularization decay: 0.00061 -> 0.00062.
2024-12-01-20:28:14-root-INFO: step: 66 lr_xt 0.12318848
2024-12-01-20:28:14-root-INFO: grad norm: 4.668 4.618 0.683
2024-12-01-20:28:14-root-INFO: Loss too large (98.605->98.674)! Learning rate decreased to 0.09855.
2024-12-01-20:28:15-root-INFO: grad norm: 3.841 3.809 0.492
2024-12-01-20:28:15-root-INFO: grad norm: 2.819 2.787 0.423
2024-12-01-20:28:16-root-INFO: grad norm: 3.048 3.018 0.427
2024-12-01-20:28:16-root-INFO: grad norm: 3.530 3.503 0.435
2024-12-01-20:28:17-root-INFO: Loss Change: 98.605 -> 96.915
2024-12-01-20:28:17-root-INFO: Regularization Change: 0.000 -> 0.935
2024-12-01-20:28:17-root-INFO: Learning rate of xt decay: 0.17745 -> 0.17957.
2024-12-01-20:28:17-root-INFO: Coefficient of regularization decay: 0.00062 -> 0.00062.
2024-12-01-20:28:17-root-INFO: step: 65 lr_xt 0.12601118
2024-12-01-20:28:17-root-INFO: grad norm: 3.712 3.671 0.549
2024-12-01-20:28:17-root-INFO: grad norm: 5.158 5.133 0.511
2024-12-01-20:28:17-root-INFO: Loss too large (96.502->96.698)! Learning rate decreased to 0.10081.
2024-12-01-20:28:18-root-INFO: grad norm: 3.826 3.797 0.471
2024-12-01-20:28:18-root-INFO: grad norm: 2.136 2.104 0.364
2024-12-01-20:28:19-root-INFO: grad norm: 2.309 2.279 0.371
2024-12-01-20:28:19-root-INFO: Loss Change: 96.842 -> 94.847
2024-12-01-20:28:19-root-INFO: Regularization Change: 0.000 -> 0.988
2024-12-01-20:28:19-root-INFO: Undo step: 65
2024-12-01-20:28:19-root-INFO: Undo step: 66
2024-12-01-20:28:19-root-INFO: Undo step: 67
2024-12-01-20:28:19-root-INFO: Undo step: 68
2024-12-01-20:28:19-root-INFO: Undo step: 69
2024-12-01-20:28:19-root-INFO: step: 70 lr_xt 0.11233583
2024-12-01-20:28:20-root-INFO: grad norm: 33.960 33.666 4.461
2024-12-01-20:28:20-root-INFO: grad norm: 17.495 17.270 2.800
2024-12-01-20:28:21-root-INFO: grad norm: 11.163 10.954 2.154
2024-12-01-20:28:21-root-INFO: grad norm: 8.490 8.330 1.640
2024-12-01-20:28:22-root-INFO: grad norm: 6.947 6.801 1.417
2024-12-01-20:28:22-root-INFO: Loss Change: 245.807 -> 119.584
2024-12-01-20:28:22-root-INFO: Regularization Change: 0.000 -> 52.567
2024-12-01-20:28:22-root-INFO: Learning rate of xt decay: 0.16918 -> 0.17121.
2024-12-01-20:28:22-root-INFO: Coefficient of regularization decay: 0.00059 -> 0.00060.
2024-12-01-20:28:22-root-INFO: step: 69 lr_xt 0.11498353
2024-12-01-20:28:22-root-INFO: grad norm: 6.454 6.344 1.188
2024-12-01-20:28:23-root-INFO: grad norm: 5.654 5.549 1.085
2024-12-01-20:28:23-root-INFO: grad norm: 5.136 5.051 0.931
2024-12-01-20:28:24-root-INFO: grad norm: 4.737 4.650 0.899
2024-12-01-20:28:24-root-INFO: grad norm: 4.477 4.408 0.788
2024-12-01-20:28:24-root-INFO: Loss Change: 119.712 -> 109.178
2024-12-01-20:28:24-root-INFO: Regularization Change: 0.000 -> 6.143
2024-12-01-20:28:24-root-INFO: Learning rate of xt decay: 0.17121 -> 0.17326.
2024-12-01-20:28:24-root-INFO: Coefficient of regularization decay: 0.00060 -> 0.00061.
2024-12-01-20:28:25-root-INFO: step: 68 lr_xt 0.11767478
2024-12-01-20:28:25-root-INFO: grad norm: 4.144 4.068 0.790
2024-12-01-20:28:25-root-INFO: grad norm: 3.635 3.572 0.674
2024-12-01-20:28:26-root-INFO: grad norm: 3.434 3.373 0.643
2024-12-01-20:28:26-root-INFO: grad norm: 3.363 3.309 0.601
2024-12-01-20:28:27-root-INFO: grad norm: 3.334 3.279 0.606
2024-12-01-20:28:27-root-INFO: Loss Change: 108.729 -> 103.465
2024-12-01-20:28:27-root-INFO: Regularization Change: 0.000 -> 3.149
2024-12-01-20:28:27-root-INFO: Learning rate of xt decay: 0.17326 -> 0.17534.
2024-12-01-20:28:27-root-INFO: Coefficient of regularization decay: 0.00061 -> 0.00061.
2024-12-01-20:28:27-root-INFO: step: 67 lr_xt 0.12040972
2024-12-01-20:28:27-root-INFO: grad norm: 4.113 4.059 0.665
2024-12-01-20:28:28-root-INFO: grad norm: 3.975 3.926 0.624
2024-12-01-20:28:28-root-INFO: grad norm: 4.028 3.990 0.557
2024-12-01-20:28:29-root-INFO: grad norm: 3.929 3.883 0.604
2024-12-01-20:28:29-root-INFO: grad norm: 3.807 3.772 0.519
2024-12-01-20:28:29-root-INFO: Loss Change: 103.391 -> 99.882
2024-12-01-20:28:29-root-INFO: Regularization Change: 0.000 -> 2.328
2024-12-01-20:28:29-root-INFO: Learning rate of xt decay: 0.17534 -> 0.17745.
2024-12-01-20:28:29-root-INFO: Coefficient of regularization decay: 0.00061 -> 0.00062.
2024-12-01-20:28:30-root-INFO: step: 66 lr_xt 0.12318848
2024-12-01-20:28:30-root-INFO: grad norm: 3.646 3.606 0.537
2024-12-01-20:28:30-root-INFO: grad norm: 3.646 3.613 0.486
2024-12-01-20:28:31-root-INFO: grad norm: 3.707 3.666 0.551
2024-12-01-20:28:31-root-INFO: grad norm: 3.832 3.801 0.483
2024-12-01-20:28:32-root-INFO: grad norm: 3.868 3.826 0.566
2024-12-01-20:28:32-root-INFO: Loss Change: 99.812 -> 96.876
2024-12-01-20:28:32-root-INFO: Regularization Change: 0.000 -> 1.937
2024-12-01-20:28:32-root-INFO: Learning rate of xt decay: 0.17745 -> 0.17957.
2024-12-01-20:28:32-root-INFO: Coefficient of regularization decay: 0.00062 -> 0.00062.
2024-12-01-20:28:32-root-INFO: step: 65 lr_xt 0.12601118
2024-12-01-20:28:32-root-INFO: grad norm: 5.212 5.155 0.768
2024-12-01-20:28:33-root-INFO: grad norm: 4.423 4.379 0.626
2024-12-01-20:28:33-root-INFO: grad norm: 3.468 3.434 0.482
2024-12-01-20:28:34-root-INFO: grad norm: 3.629 3.587 0.547
2024-12-01-20:28:34-root-INFO: grad norm: 4.040 4.010 0.485
2024-12-01-20:28:35-root-INFO: Loss Change: 97.061 -> 94.377
2024-12-01-20:28:35-root-INFO: Regularization Change: 0.000 -> 1.877
2024-12-01-20:28:35-root-INFO: Learning rate of xt decay: 0.17957 -> 0.18173.
2024-12-01-20:28:35-root-INFO: Coefficient of regularization decay: 0.00062 -> 0.00063.
2024-12-01-20:28:35-root-INFO: step: 64 lr_xt 0.12887791
2024-12-01-20:28:35-root-INFO: grad norm: 4.351 4.309 0.605
2024-12-01-20:28:35-root-INFO: grad norm: 4.396 4.368 0.493
2024-12-01-20:28:36-root-INFO: grad norm: 4.212 4.173 0.570
2024-12-01-20:28:37-root-INFO: grad norm: 4.136 4.110 0.469
2024-12-01-20:28:37-root-INFO: grad norm: 4.080 4.042 0.553
2024-12-01-20:28:37-root-INFO: Loss Change: 94.268 -> 91.806
2024-12-01-20:28:37-root-INFO: Regularization Change: 0.000 -> 1.705
2024-12-01-20:28:37-root-INFO: Learning rate of xt decay: 0.18173 -> 0.18391.
2024-12-01-20:28:37-root-INFO: Coefficient of regularization decay: 0.00063 -> 0.00064.
2024-12-01-20:28:38-root-INFO: step: 63 lr_xt 0.13178874
2024-12-01-20:28:38-root-INFO: grad norm: 4.845 4.796 0.685
2024-12-01-20:28:38-root-INFO: grad norm: 4.351 4.311 0.587
2024-12-01-20:28:39-root-INFO: grad norm: 3.702 3.672 0.470
2024-12-01-20:28:39-root-INFO: grad norm: 3.866 3.829 0.535
2024-12-01-20:28:40-root-INFO: grad norm: 4.308 4.282 0.473
2024-12-01-20:28:40-root-INFO: Loss Change: 92.000 -> 89.913
2024-12-01-20:28:40-root-INFO: Regularization Change: 0.000 -> 1.734
2024-12-01-20:28:40-root-INFO: Learning rate of xt decay: 0.18391 -> 0.18612.
2024-12-01-20:28:40-root-INFO: Coefficient of regularization decay: 0.00064 -> 0.00064.
2024-12-01-20:28:40-root-INFO: step: 62 lr_xt 0.13474373
2024-12-01-20:28:40-root-INFO: grad norm: 4.512 4.466 0.641
2024-12-01-20:28:41-root-INFO: grad norm: 4.244 4.217 0.474
2024-12-01-20:28:41-root-INFO: grad norm: 4.054 4.021 0.518
2024-12-01-20:28:42-root-INFO: grad norm: 4.151 4.128 0.439
2024-12-01-20:28:42-root-INFO: grad norm: 4.034 4.000 0.520
2024-12-01-20:28:42-root-INFO: Loss Change: 89.624 -> 87.196
2024-12-01-20:28:42-root-INFO: Regularization Change: 0.000 -> 1.656
2024-12-01-20:28:42-root-INFO: Learning rate of xt decay: 0.18612 -> 0.18835.
2024-12-01-20:28:42-root-INFO: Coefficient of regularization decay: 0.00064 -> 0.00065.
2024-12-01-20:28:43-root-INFO: step: 61 lr_xt 0.13774291
2024-12-01-20:28:43-root-INFO: grad norm: 4.454 4.419 0.559
2024-12-01-20:28:43-root-INFO: grad norm: 4.105 4.070 0.540
2024-12-01-20:28:44-root-INFO: grad norm: 3.622 3.596 0.432
2024-12-01-20:28:44-root-INFO: grad norm: 3.792 3.759 0.501
2024-12-01-20:28:45-root-INFO: grad norm: 4.200 4.177 0.442
2024-12-01-20:28:45-root-INFO: Loss Change: 87.310 -> 85.532
2024-12-01-20:28:45-root-INFO: Regularization Change: 0.000 -> 1.663
2024-12-01-20:28:45-root-INFO: Learning rate of xt decay: 0.18835 -> 0.19061.
2024-12-01-20:28:45-root-INFO: Coefficient of regularization decay: 0.00065 -> 0.00066.
2024-12-01-20:28:45-root-INFO: step: 60 lr_xt 0.14078630
2024-12-01-20:28:45-root-INFO: grad norm: 4.152 4.119 0.527
2024-12-01-20:28:46-root-INFO: grad norm: 3.898 3.875 0.423
2024-12-01-20:28:46-root-INFO: grad norm: 3.956 3.926 0.485
2024-12-01-20:28:47-root-INFO: grad norm: 4.222 4.201 0.428
2024-12-01-20:28:47-root-INFO: grad norm: 4.057 4.025 0.505
2024-12-01-20:28:47-root-INFO: Loss Change: 85.473 -> 83.235
2024-12-01-20:28:47-root-INFO: Regularization Change: 0.000 -> 1.609
2024-12-01-20:28:47-root-INFO: Undo step: 60
2024-12-01-20:28:47-root-INFO: Undo step: 61
2024-12-01-20:28:47-root-INFO: Undo step: 62
2024-12-01-20:28:47-root-INFO: Undo step: 63
2024-12-01-20:28:47-root-INFO: Undo step: 64
2024-12-01-20:28:48-root-INFO: step: 65 lr_xt 0.12601118
2024-12-01-20:28:48-root-INFO: grad norm: 28.162 27.942 3.515
2024-12-01-20:28:48-root-INFO: grad norm: 13.713 13.518 2.304
2024-12-01-20:28:49-root-INFO: grad norm: 9.064 8.889 1.770
2024-12-01-20:28:49-root-INFO: grad norm: 6.912 6.776 1.366
2024-12-01-20:28:50-root-INFO: grad norm: 5.666 5.555 1.120
2024-12-01-20:28:50-root-INFO: Loss Change: 209.458 -> 104.926
2024-12-01-20:28:50-root-INFO: Regularization Change: 0.000 -> 50.573
2024-12-01-20:28:50-root-INFO: Learning rate of xt decay: 0.17957 -> 0.18173.
2024-12-01-20:28:50-root-INFO: Coefficient of regularization decay: 0.00062 -> 0.00063.
2024-12-01-20:28:50-root-INFO: step: 64 lr_xt 0.12887791
2024-12-01-20:28:50-root-INFO: grad norm: 5.064 4.979 0.927
2024-12-01-20:28:51-root-INFO: grad norm: 4.377 4.299 0.823
2024-12-01-20:28:51-root-INFO: grad norm: 3.976 3.910 0.721
2024-12-01-20:28:52-root-INFO: grad norm: 3.744 3.681 0.688
2024-12-01-20:28:52-root-INFO: grad norm: 3.716 3.662 0.628
2024-12-01-20:28:52-root-INFO: Loss Change: 104.754 -> 95.397
2024-12-01-20:28:52-root-INFO: Regularization Change: 0.000 -> 6.185
2024-12-01-20:28:52-root-INFO: Learning rate of xt decay: 0.18173 -> 0.18391.
2024-12-01-20:28:52-root-INFO: Coefficient of regularization decay: 0.00063 -> 0.00064.
2024-12-01-20:28:53-root-INFO: step: 63 lr_xt 0.13178874
2024-12-01-20:28:53-root-INFO: grad norm: 3.779 3.724 0.642
2024-12-01-20:28:53-root-INFO: grad norm: 3.744 3.703 0.552
2024-12-01-20:28:54-root-INFO: grad norm: 3.783 3.740 0.568
2024-12-01-20:28:54-root-INFO: grad norm: 4.011 3.973 0.549
2024-12-01-20:28:55-root-INFO: grad norm: 3.926 3.884 0.574
2024-12-01-20:28:55-root-INFO: Loss Change: 95.323 -> 90.574
2024-12-01-20:28:55-root-INFO: Regularization Change: 0.000 -> 3.290
2024-12-01-20:28:55-root-INFO: Learning rate of xt decay: 0.18391 -> 0.18612.
2024-12-01-20:28:55-root-INFO: Coefficient of regularization decay: 0.00064 -> 0.00064.
2024-12-01-20:28:55-root-INFO: step: 62 lr_xt 0.13474373
2024-12-01-20:28:55-root-INFO: grad norm: 5.174 5.091 0.927
2024-12-01-20:28:56-root-INFO: grad norm: 4.396 4.347 0.654
2024-12-01-20:28:56-root-INFO: grad norm: 3.492 3.447 0.558
2024-12-01-20:28:57-root-INFO: grad norm: 3.473 3.432 0.531
2024-12-01-20:28:57-root-INFO: grad norm: 3.633 3.597 0.517
2024-12-01-20:28:57-root-INFO: Loss Change: 90.595 -> 86.972
2024-12-01-20:28:57-root-INFO: Regularization Change: 0.000 -> 2.548
2024-12-01-20:28:57-root-INFO: Learning rate of xt decay: 0.18612 -> 0.18835.
2024-12-01-20:28:57-root-INFO: Coefficient of regularization decay: 0.00064 -> 0.00065.
2024-12-01-20:28:58-root-INFO: step: 61 lr_xt 0.13774291
2024-12-01-20:28:58-root-INFO: grad norm: 3.406 3.373 0.466
2024-12-01-20:28:58-root-INFO: grad norm: 3.383 3.351 0.464
2024-12-01-20:28:59-root-INFO: grad norm: 3.420 3.386 0.481
2024-12-01-20:28:59-root-INFO: grad norm: 3.525 3.493 0.476
2024-12-01-20:29:00-root-INFO: grad norm: 3.572 3.537 0.501
2024-12-01-20:29:00-root-INFO: Loss Change: 86.830 -> 84.092
2024-12-01-20:29:00-root-INFO: Regularization Change: 0.000 -> 2.022
2024-12-01-20:29:00-root-INFO: Learning rate of xt decay: 0.18835 -> 0.19061.
2024-12-01-20:29:00-root-INFO: Coefficient of regularization decay: 0.00065 -> 0.00066.
2024-12-01-20:29:00-root-INFO: step: 60 lr_xt 0.14078630
2024-12-01-20:29:00-root-INFO: grad norm: 4.881 4.808 0.841
2024-12-01-20:29:01-root-INFO: grad norm: 4.401 4.358 0.615
2024-12-01-20:29:01-root-INFO: grad norm: 3.901 3.858 0.577
2024-12-01-20:29:02-root-INFO: grad norm: 3.868 3.830 0.539
2024-12-01-20:29:02-root-INFO: grad norm: 3.875 3.839 0.528
2024-12-01-20:29:02-root-INFO: Loss Change: 84.351 -> 81.917
2024-12-01-20:29:02-root-INFO: Regularization Change: 0.000 -> 1.968
2024-12-01-20:29:02-root-INFO: Learning rate of xt decay: 0.19061 -> 0.19290.
2024-12-01-20:29:02-root-INFO: Coefficient of regularization decay: 0.00066 -> 0.00066.
2024-12-01-20:29:03-root-INFO: step: 59 lr_xt 0.14387389
2024-12-01-20:29:03-root-INFO: grad norm: 3.631 3.597 0.496
2024-12-01-20:29:03-root-INFO: grad norm: 3.603 3.572 0.472
2024-12-01-20:29:04-root-INFO: grad norm: 3.656 3.626 0.467
2024-12-01-20:29:04-root-INFO: grad norm: 3.768 3.737 0.482
2024-12-01-20:29:05-root-INFO: grad norm: 3.764 3.731 0.491
2024-12-01-20:29:05-root-INFO: Loss Change: 81.727 -> 79.480
2024-12-01-20:29:05-root-INFO: Regularization Change: 0.000 -> 1.745
2024-12-01-20:29:05-root-INFO: Learning rate of xt decay: 0.19290 -> 0.19521.
2024-12-01-20:29:05-root-INFO: Coefficient of regularization decay: 0.00066 -> 0.00067.
2024-12-01-20:29:05-root-INFO: step: 58 lr_xt 0.14700566
2024-12-01-20:29:05-root-INFO: grad norm: 4.722 4.661 0.755
2024-12-01-20:29:06-root-INFO: grad norm: 4.262 4.222 0.582
2024-12-01-20:29:06-root-INFO: grad norm: 3.702 3.665 0.520
2024-12-01-20:29:07-root-INFO: grad norm: 3.680 3.645 0.503
2024-12-01-20:29:07-root-INFO: grad norm: 3.720 3.689 0.484
2024-12-01-20:29:07-root-INFO: Loss Change: 79.563 -> 77.472
2024-12-01-20:29:07-root-INFO: Regularization Change: 0.000 -> 1.782
2024-12-01-20:29:07-root-INFO: Learning rate of xt decay: 0.19521 -> 0.19756.
2024-12-01-20:29:07-root-INFO: Coefficient of regularization decay: 0.00067 -> 0.00068.
2024-12-01-20:29:08-root-INFO: step: 57 lr_xt 0.15018154
2024-12-01-20:29:08-root-INFO: grad norm: 3.400 3.369 0.454
2024-12-01-20:29:08-root-INFO: grad norm: 3.386 3.360 0.417
2024-12-01-20:29:09-root-INFO: grad norm: 3.481 3.452 0.448
2024-12-01-20:29:09-root-INFO: grad norm: 3.664 3.636 0.446
2024-12-01-20:29:10-root-INFO: grad norm: 3.699 3.667 0.483
2024-12-01-20:29:10-root-INFO: Loss Change: 77.079 -> 75.149
2024-12-01-20:29:10-root-INFO: Regularization Change: 0.000 -> 1.632
2024-12-01-20:29:10-root-INFO: Learning rate of xt decay: 0.19756 -> 0.19993.
2024-12-01-20:29:10-root-INFO: Coefficient of regularization decay: 0.00068 -> 0.00068.
2024-12-01-20:29:10-root-INFO: step: 56 lr_xt 0.15340147
2024-12-01-20:29:10-root-INFO: grad norm: 4.570 4.513 0.723
2024-12-01-20:29:11-root-INFO: grad norm: 4.194 4.155 0.570
2024-12-01-20:29:11-root-INFO: grad norm: 3.784 3.751 0.505
2024-12-01-20:29:12-root-INFO: grad norm: 3.753 3.718 0.507
2024-12-01-20:29:12-root-INFO: grad norm: 3.745 3.715 0.469
2024-12-01-20:29:12-root-INFO: Loss Change: 75.333 -> 73.450
2024-12-01-20:29:12-root-INFO: Regularization Change: 0.000 -> 1.739
2024-12-01-20:29:12-root-INFO: Learning rate of xt decay: 0.19993 -> 0.20232.
2024-12-01-20:29:12-root-INFO: Coefficient of regularization decay: 0.00068 -> 0.00069.
2024-12-01-20:29:13-root-INFO: step: 55 lr_xt 0.15666536
2024-12-01-20:29:13-root-INFO: grad norm: 3.487 3.457 0.459
2024-12-01-20:29:13-root-INFO: grad norm: 3.461 3.436 0.417
2024-12-01-20:29:14-root-INFO: grad norm: 3.549 3.521 0.445
2024-12-01-20:29:14-root-INFO: grad norm: 3.703 3.677 0.441
2024-12-01-20:29:15-root-INFO: grad norm: 3.734 3.703 0.480
2024-12-01-20:29:15-root-INFO: Loss Change: 73.246 -> 71.425
2024-12-01-20:29:15-root-INFO: Regularization Change: 0.000 -> 1.628
2024-12-01-20:29:15-root-INFO: Undo step: 55
2024-12-01-20:29:15-root-INFO: Undo step: 56
2024-12-01-20:29:15-root-INFO: Undo step: 57
2024-12-01-20:29:15-root-INFO: Undo step: 58
2024-12-01-20:29:15-root-INFO: Undo step: 59
2024-12-01-20:29:15-root-INFO: step: 60 lr_xt 0.14078630
2024-12-01-20:29:15-root-INFO: grad norm: 25.085 24.824 3.611
2024-12-01-20:29:16-root-INFO: grad norm: 13.627 13.479 2.008
2024-12-01-20:29:16-root-INFO: grad norm: 9.272 9.120 1.673
2024-12-01-20:29:17-root-INFO: grad norm: 7.020 6.910 1.235
2024-12-01-20:29:17-root-INFO: grad norm: 6.019 5.915 1.113
2024-12-01-20:29:17-root-INFO: Loss Change: 184.222 -> 93.101
2024-12-01-20:29:17-root-INFO: Regularization Change: 0.000 -> 49.866
2024-12-01-20:29:17-root-INFO: Learning rate of xt decay: 0.19061 -> 0.19290.
2024-12-01-20:29:17-root-INFO: Coefficient of regularization decay: 0.00066 -> 0.00066.
2024-12-01-20:29:18-root-INFO: step: 59 lr_xt 0.14387389
2024-12-01-20:29:18-root-INFO: grad norm: 6.332 6.237 1.097
2024-12-01-20:29:18-root-INFO: grad norm: 5.328 5.250 0.904
2024-12-01-20:29:19-root-INFO: grad norm: 4.278 4.210 0.760
2024-12-01-20:29:19-root-INFO: grad norm: 4.091 4.032 0.691
2024-12-01-20:29:20-root-INFO: grad norm: 4.113 4.061 0.650
2024-12-01-20:29:20-root-INFO: Loss Change: 93.205 -> 83.947
2024-12-01-20:29:20-root-INFO: Regularization Change: 0.000 -> 6.817
2024-12-01-20:29:20-root-INFO: Learning rate of xt decay: 0.19290 -> 0.19521.
2024-12-01-20:29:20-root-INFO: Coefficient of regularization decay: 0.00066 -> 0.00067.
2024-12-01-20:29:20-root-INFO: step: 58 lr_xt 0.14700566
2024-12-01-20:29:20-root-INFO: grad norm: 3.894 3.850 0.585
2024-12-01-20:29:21-root-INFO: grad norm: 3.750 3.709 0.555
2024-12-01-20:29:21-root-INFO: grad norm: 3.757 3.716 0.551
2024-12-01-20:29:22-root-INFO: grad norm: 3.851 3.812 0.545
2024-12-01-20:29:22-root-INFO: grad norm: 3.836 3.797 0.551
2024-12-01-20:29:22-root-INFO: Loss Change: 83.626 -> 79.056
2024-12-01-20:29:22-root-INFO: Regularization Change: 0.000 -> 3.552
2024-12-01-20:29:22-root-INFO: Learning rate of xt decay: 0.19521 -> 0.19756.
2024-12-01-20:29:22-root-INFO: Coefficient of regularization decay: 0.00067 -> 0.00068.
2024-12-01-20:29:22-root-INFO: step: 57 lr_xt 0.15018154
2024-12-01-20:29:23-root-INFO: grad norm: 4.887 4.818 0.818
2024-12-01-20:29:23-root-INFO: grad norm: 4.284 4.238 0.630
2024-12-01-20:29:24-root-INFO: grad norm: 3.640 3.597 0.556
2024-12-01-20:29:24-root-INFO: grad norm: 3.633 3.595 0.523
2024-12-01-20:29:25-root-INFO: grad norm: 3.704 3.668 0.515
2024-12-01-20:29:25-root-INFO: Loss Change: 79.067 -> 75.738
2024-12-01-20:29:25-root-INFO: Regularization Change: 0.000 -> 2.690
2024-12-01-20:29:25-root-INFO: Learning rate of xt decay: 0.19756 -> 0.19993.
2024-12-01-20:29:25-root-INFO: Coefficient of regularization decay: 0.00068 -> 0.00068.
2024-12-01-20:29:25-root-INFO: step: 56 lr_xt 0.15340147
2024-12-01-20:29:25-root-INFO: grad norm: 3.606 3.576 0.465
2024-12-01-20:29:26-root-INFO: grad norm: 3.497 3.467 0.458
2024-12-01-20:29:26-root-INFO: grad norm: 3.577 3.545 0.473
2024-12-01-20:29:27-root-INFO: grad norm: 3.706 3.675 0.476
2024-12-01-20:29:27-root-INFO: grad norm: 3.731 3.697 0.502
2024-12-01-20:29:28-root-INFO: Loss Change: 75.609 -> 73.039
2024-12-01-20:29:28-root-INFO: Regularization Change: 0.000 -> 2.187
2024-12-01-20:29:28-root-INFO: Learning rate of xt decay: 0.19993 -> 0.20232.
2024-12-01-20:29:28-root-INFO: Coefficient of regularization decay: 0.00068 -> 0.00069.
2024-12-01-20:29:28-root-INFO: step: 55 lr_xt 0.15666536
2024-12-01-20:29:28-root-INFO: grad norm: 4.807 4.738 0.809
2024-12-01-20:29:29-root-INFO: grad norm: 4.338 4.294 0.617
2024-12-01-20:29:29-root-INFO: grad norm: 3.839 3.800 0.546
2024-12-01-20:29:30-root-INFO: grad norm: 3.801 3.764 0.528
2024-12-01-20:29:30-root-INFO: grad norm: 3.798 3.764 0.504
2024-12-01-20:29:30-root-INFO: Loss Change: 73.245 -> 70.870
2024-12-01-20:29:30-root-INFO: Regularization Change: 0.000 -> 2.101
2024-12-01-20:29:30-root-INFO: Learning rate of xt decay: 0.20232 -> 0.20475.
2024-12-01-20:29:30-root-INFO: Coefficient of regularization decay: 0.00069 -> 0.00070.
2024-12-01-20:29:31-root-INFO: step: 54 lr_xt 0.15997308
2024-12-01-20:29:31-root-INFO: grad norm: 3.674 3.645 0.462
2024-12-01-20:29:31-root-INFO: grad norm: 3.561 3.532 0.455
2024-12-01-20:29:32-root-INFO: grad norm: 3.594 3.564 0.462
2024-12-01-20:29:32-root-INFO: grad norm: 3.707 3.677 0.470
2024-12-01-20:29:33-root-INFO: grad norm: 3.728 3.695 0.494
2024-12-01-20:29:33-root-INFO: Loss Change: 70.624 -> 68.540
2024-12-01-20:29:33-root-INFO: Regularization Change: 0.000 -> 1.887
2024-12-01-20:29:33-root-INFO: Learning rate of xt decay: 0.20475 -> 0.20721.
2024-12-01-20:29:33-root-INFO: Coefficient of regularization decay: 0.00070 -> 0.00070.
2024-12-01-20:29:33-root-INFO: step: 53 lr_xt 0.16332449
2024-12-01-20:29:33-root-INFO: grad norm: 4.658 4.600 0.733
2024-12-01-20:29:34-root-INFO: grad norm: 4.279 4.235 0.607
2024-12-01-20:29:34-root-INFO: grad norm: 3.872 3.836 0.529
2024-12-01-20:29:35-root-INFO: grad norm: 3.838 3.801 0.532
2024-12-01-20:29:35-root-INFO: grad norm: 3.807 3.774 0.496
2024-12-01-20:29:36-root-INFO: Loss Change: 68.768 -> 66.773
2024-12-01-20:29:36-root-INFO: Regularization Change: 0.000 -> 1.919
2024-12-01-20:29:36-root-INFO: Learning rate of xt decay: 0.20721 -> 0.20970.
2024-12-01-20:29:36-root-INFO: Coefficient of regularization decay: 0.00070 -> 0.00071.
2024-12-01-20:29:36-root-INFO: step: 52 lr_xt 0.16671942
2024-12-01-20:29:36-root-INFO: grad norm: 3.568 3.542 0.430
2024-12-01-20:29:37-root-INFO: grad norm: 3.468 3.442 0.425
2024-12-01-20:29:37-root-INFO: grad norm: 3.512 3.482 0.455
2024-12-01-20:29:38-root-INFO: grad norm: 3.603 3.576 0.440
2024-12-01-20:29:38-root-INFO: grad norm: 3.637 3.605 0.480
2024-12-01-20:29:38-root-INFO: Loss Change: 66.570 -> 64.746
2024-12-01-20:29:38-root-INFO: Regularization Change: 0.000 -> 1.776
2024-12-01-20:29:38-root-INFO: Learning rate of xt decay: 0.20970 -> 0.21221.
2024-12-01-20:29:38-root-INFO: Coefficient of regularization decay: 0.00071 -> 0.00072.
2024-12-01-20:29:39-root-INFO: step: 51 lr_xt 0.17015769
2024-12-01-20:29:39-root-INFO: grad norm: 4.641 4.576 0.774
2024-12-01-20:29:39-root-INFO: grad norm: 4.293 4.252 0.594
2024-12-01-20:29:40-root-INFO: grad norm: 3.942 3.907 0.526
2024-12-01-20:29:40-root-INFO: grad norm: 3.866 3.831 0.519
2024-12-01-20:29:41-root-INFO: grad norm: 3.794 3.763 0.485
2024-12-01-20:29:41-root-INFO: Loss Change: 64.928 -> 63.031
2024-12-01-20:29:41-root-INFO: Regularization Change: 0.000 -> 1.903
2024-12-01-20:29:41-root-INFO: Learning rate of xt decay: 0.21221 -> 0.21476.
2024-12-01-20:29:41-root-INFO: Coefficient of regularization decay: 0.00072 -> 0.00072.
2024-12-01-20:29:41-root-INFO: step: 50 lr_xt 0.17363908
2024-12-01-20:29:41-root-INFO: grad norm: 3.586 3.561 0.426
2024-12-01-20:29:42-root-INFO: grad norm: 3.473 3.448 0.420
2024-12-01-20:29:42-root-INFO: grad norm: 3.479 3.452 0.434
2024-12-01-20:29:43-root-INFO: grad norm: 3.559 3.533 0.432
2024-12-01-20:29:43-root-INFO: grad norm: 3.594 3.564 0.463
2024-12-01-20:29:44-root-INFO: Loss Change: 62.624 -> 60.890
2024-12-01-20:29:44-root-INFO: Regularization Change: 0.000 -> 1.777
2024-12-01-20:29:44-root-INFO: Undo step: 50
2024-12-01-20:29:44-root-INFO: Undo step: 51
2024-12-01-20:29:44-root-INFO: Undo step: 52
2024-12-01-20:29:44-root-INFO: Undo step: 53
2024-12-01-20:29:44-root-INFO: Undo step: 54
2024-12-01-20:29:44-root-INFO: step: 55 lr_xt 0.15666536
2024-12-01-20:29:44-root-INFO: grad norm: 23.355 23.229 2.422
2024-12-01-20:29:44-root-INFO: grad norm: 12.277 12.080 2.189
2024-12-01-20:29:45-root-INFO: grad norm: 8.171 8.069 1.287
2024-12-01-20:29:45-root-INFO: grad norm: 6.300 6.190 1.173
2024-12-01-20:29:46-root-INFO: grad norm: 5.171 5.086 0.935
2024-12-01-20:29:46-root-INFO: Loss Change: 169.607 -> 81.633
2024-12-01-20:29:46-root-INFO: Regularization Change: 0.000 -> 53.981
2024-12-01-20:29:46-root-INFO: Learning rate of xt decay: 0.20232 -> 0.20475.
2024-12-01-20:29:46-root-INFO: Coefficient of regularization decay: 0.00069 -> 0.00070.
2024-12-01-20:29:46-root-INFO: step: 54 lr_xt 0.15997308
2024-12-01-20:29:47-root-INFO: grad norm: 4.551 4.468 0.863
2024-12-01-20:29:47-root-INFO: grad norm: 3.872 3.807 0.705
2024-12-01-20:29:48-root-INFO: grad norm: 3.447 3.388 0.636
2024-12-01-20:29:48-root-INFO: grad norm: 3.127 3.071 0.590
2024-12-01-20:29:49-root-INFO: grad norm: 2.886 2.836 0.536
2024-12-01-20:29:49-root-INFO: Loss Change: 81.285 -> 72.634
2024-12-01-20:29:49-root-INFO: Regularization Change: 0.000 -> 6.917
2024-12-01-20:29:49-root-INFO: Learning rate of xt decay: 0.20475 -> 0.20721.
2024-12-01-20:29:49-root-INFO: Coefficient of regularization decay: 0.00070 -> 0.00070.
2024-12-01-20:29:49-root-INFO: step: 53 lr_xt 0.16332449
2024-12-01-20:29:49-root-INFO: grad norm: 2.968 2.900 0.635
2024-12-01-20:29:50-root-INFO: grad norm: 2.633 2.589 0.479
2024-12-01-20:29:50-root-INFO: grad norm: 2.487 2.442 0.473
2024-12-01-20:29:51-root-INFO: grad norm: 2.412 2.374 0.425
2024-12-01-20:29:51-root-INFO: grad norm: 2.412 2.374 0.428
2024-12-01-20:29:52-root-INFO: Loss Change: 72.564 -> 68.278
2024-12-01-20:29:52-root-INFO: Regularization Change: 0.000 -> 3.568
2024-12-01-20:29:52-root-INFO: Learning rate of xt decay: 0.20721 -> 0.20970.
2024-12-01-20:29:52-root-INFO: Coefficient of regularization decay: 0.00070 -> 0.00071.
2024-12-01-20:29:52-root-INFO: step: 52 lr_xt 0.16671942
2024-12-01-20:29:52-root-INFO: grad norm: 2.485 2.444 0.447
2024-12-01-20:29:52-root-INFO: grad norm: 2.342 2.311 0.380
2024-12-01-20:29:53-root-INFO: grad norm: 2.437 2.408 0.370
2024-12-01-20:29:53-root-INFO: grad norm: 2.704 2.677 0.381
2024-12-01-20:29:54-root-INFO: grad norm: 2.957 2.930 0.398
2024-12-01-20:29:54-root-INFO: Loss Change: 68.121 -> 65.307
2024-12-01-20:29:54-root-INFO: Regularization Change: 0.000 -> 2.615
2024-12-01-20:29:54-root-INFO: Learning rate of xt decay: 0.20970 -> 0.21221.
2024-12-01-20:29:54-root-INFO: Coefficient of regularization decay: 0.00071 -> 0.00072.
2024-12-01-20:29:54-root-INFO: step: 51 lr_xt 0.17015769
2024-12-01-20:29:55-root-INFO: grad norm: 4.274 4.210 0.736
2024-12-01-20:29:55-root-INFO: grad norm: 4.029 3.992 0.542
2024-12-01-20:29:56-root-INFO: grad norm: 3.815 3.780 0.515
2024-12-01-20:29:56-root-INFO: grad norm: 3.786 3.752 0.502
2024-12-01-20:29:57-root-INFO: grad norm: 3.731 3.700 0.478
2024-12-01-20:29:57-root-INFO: Loss Change: 65.396 -> 63.000
2024-12-01-20:29:57-root-INFO: Regularization Change: 0.000 -> 2.453
2024-12-01-20:29:57-root-INFO: Learning rate of xt decay: 0.21221 -> 0.21476.
2024-12-01-20:29:57-root-INFO: Coefficient of regularization decay: 0.00072 -> 0.00072.
2024-12-01-20:29:57-root-INFO: step: 50 lr_xt 0.17363908
2024-12-01-20:29:57-root-INFO: grad norm: 3.464 3.438 0.421
2024-12-01-20:29:58-root-INFO: grad norm: 3.368 3.343 0.409
2024-12-01-20:29:58-root-INFO: grad norm: 3.414 3.387 0.423
2024-12-01-20:29:59-root-INFO: grad norm: 3.482 3.457 0.418
2024-12-01-20:29:59-root-INFO: grad norm: 3.498 3.470 0.444
2024-12-01-20:30:00-root-INFO: Loss Change: 62.528 -> 60.290
2024-12-01-20:30:00-root-INFO: Regularization Change: 0.000 -> 2.135
2024-12-01-20:30:00-root-INFO: Learning rate of xt decay: 0.21476 -> 0.21734.
2024-12-01-20:30:00-root-INFO: Coefficient of regularization decay: 0.00072 -> 0.00073.
2024-12-01-20:30:00-root-INFO: step: 49 lr_xt 0.17716334
2024-12-01-20:30:00-root-INFO: grad norm: 4.562 4.503 0.734
2024-12-01-20:30:01-root-INFO: grad norm: 4.036 3.996 0.561
2024-12-01-20:30:01-root-INFO: grad norm: 3.484 3.454 0.461
2024-12-01-20:30:02-root-INFO: grad norm: 3.375 3.345 0.451
2024-12-01-20:30:02-root-INFO: grad norm: 3.339 3.313 0.421
2024-12-01-20:30:02-root-INFO: Loss Change: 60.556 -> 58.326
2024-12-01-20:30:02-root-INFO: Regularization Change: 0.000 -> 2.133
2024-12-01-20:30:02-root-INFO: Learning rate of xt decay: 0.21734 -> 0.21994.
2024-12-01-20:30:02-root-INFO: Coefficient of regularization decay: 0.00073 -> 0.00074.
2024-12-01-20:30:03-root-INFO: step: 48 lr_xt 0.18073022
2024-12-01-20:30:03-root-INFO: grad norm: 3.145 3.124 0.368
2024-12-01-20:30:03-root-INFO: grad norm: 3.007 2.985 0.358
2024-12-01-20:30:04-root-INFO: grad norm: 3.062 3.037 0.383
2024-12-01-20:30:04-root-INFO: grad norm: 3.176 3.154 0.375
2024-12-01-20:30:05-root-INFO: grad norm: 3.258 3.232 0.414
2024-12-01-20:30:05-root-INFO: Loss Change: 58.102 -> 56.266
2024-12-01-20:30:05-root-INFO: Regularization Change: 0.000 -> 1.895
2024-12-01-20:30:05-root-INFO: Learning rate of xt decay: 0.21994 -> 0.22258.
2024-12-01-20:30:05-root-INFO: Coefficient of regularization decay: 0.00074 -> 0.00075.
2024-12-01-20:30:05-root-INFO: step: 47 lr_xt 0.18433941
2024-12-01-20:30:05-root-INFO: grad norm: 4.318 4.258 0.713
2024-12-01-20:30:06-root-INFO: grad norm: 4.006 3.971 0.528
2024-12-01-20:30:06-root-INFO: grad norm: 3.699 3.669 0.467
2024-12-01-20:30:07-root-INFO: grad norm: 3.611 3.582 0.458
2024-12-01-20:30:07-root-INFO: grad norm: 3.575 3.548 0.439
2024-12-01-20:30:07-root-INFO: Loss Change: 56.480 -> 54.614
2024-12-01-20:30:07-root-INFO: Regularization Change: 0.000 -> 2.036
2024-12-01-20:30:07-root-INFO: Learning rate of xt decay: 0.22258 -> 0.22525.
2024-12-01-20:30:07-root-INFO: Coefficient of regularization decay: 0.00075 -> 0.00075.
2024-12-01-20:30:08-root-INFO: step: 46 lr_xt 0.18799060
2024-12-01-20:30:08-root-INFO: grad norm: 3.281 3.252 0.434
2024-12-01-20:30:08-root-INFO: grad norm: 3.150 3.125 0.397
2024-12-01-20:30:09-root-INFO: grad norm: 3.185 3.157 0.421
2024-12-01-20:30:09-root-INFO: grad norm: 3.264 3.238 0.411
2024-12-01-20:30:10-root-INFO: grad norm: 3.300 3.270 0.442
2024-12-01-20:30:10-root-INFO: Loss Change: 54.370 -> 52.668
2024-12-01-20:30:10-root-INFO: Regularization Change: 0.000 -> 1.862
2024-12-01-20:30:10-root-INFO: Learning rate of xt decay: 0.22525 -> 0.22796.
2024-12-01-20:30:10-root-INFO: Coefficient of regularization decay: 0.00075 -> 0.00076.
2024-12-01-20:30:10-root-INFO: step: 45 lr_xt 0.19168344
2024-12-01-20:30:10-root-INFO: grad norm: 4.082 4.030 0.649
2024-12-01-20:30:11-root-INFO: grad norm: 3.759 3.725 0.506
2024-12-01-20:30:11-root-INFO: grad norm: 3.445 3.418 0.430
2024-12-01-20:30:12-root-INFO: grad norm: 3.336 3.307 0.439
2024-12-01-20:30:12-root-INFO: grad norm: 3.301 3.276 0.408
2024-12-01-20:30:12-root-INFO: Loss Change: 52.715 -> 50.915
2024-12-01-20:30:12-root-INFO: Regularization Change: 0.000 -> 1.968
2024-12-01-20:30:12-root-INFO: Undo step: 45
2024-12-01-20:30:12-root-INFO: Undo step: 46
2024-12-01-20:30:12-root-INFO: Undo step: 47
2024-12-01-20:30:12-root-INFO: Undo step: 48
2024-12-01-20:30:12-root-INFO: Undo step: 49
2024-12-01-20:30:13-root-INFO: step: 50 lr_xt 0.17363908
2024-12-01-20:30:13-root-INFO: grad norm: 21.349 21.196 2.551
2024-12-01-20:30:13-root-INFO: grad norm: 12.492 12.368 1.754
2024-12-01-20:30:14-root-INFO: grad norm: 8.568 8.448 1.429
2024-12-01-20:30:14-root-INFO: grad norm: 5.896 5.802 1.050
2024-12-01-20:30:15-root-INFO: grad norm: 5.253 5.176 0.897
2024-12-01-20:30:15-root-INFO: Loss Change: 151.226 -> 71.435
2024-12-01-20:30:15-root-INFO: Regularization Change: 0.000 -> 54.263
2024-12-01-20:30:15-root-INFO: Learning rate of xt decay: 0.21476 -> 0.21734.
2024-12-01-20:30:15-root-INFO: Coefficient of regularization decay: 0.00072 -> 0.00073.
2024-12-01-20:30:15-root-INFO: step: 49 lr_xt 0.17716334
2024-12-01-20:30:15-root-INFO: grad norm: 6.047 5.983 0.881
2024-12-01-20:30:16-root-INFO: grad norm: 5.334 5.278 0.771
2024-12-01-20:30:16-root-INFO: grad norm: 4.648 4.600 0.665
2024-12-01-20:30:17-root-INFO: grad norm: 4.585 4.537 0.660
2024-12-01-20:30:17-root-INFO: grad norm: 4.613 4.573 0.611
2024-12-01-20:30:17-root-INFO: Loss Change: 71.466 -> 62.922
2024-12-01-20:30:17-root-INFO: Regularization Change: 0.000 -> 8.115
2024-12-01-20:30:17-root-INFO: Learning rate of xt decay: 0.21734 -> 0.21994.
2024-12-01-20:30:18-root-INFO: Coefficient of regularization decay: 0.00073 -> 0.00074.
2024-12-01-20:30:18-root-INFO: step: 48 lr_xt 0.18073022
2024-12-01-20:30:18-root-INFO: grad norm: 4.430 4.385 0.630
2024-12-01-20:30:18-root-INFO: grad norm: 4.232 4.194 0.569
2024-12-01-20:30:19-root-INFO: grad norm: 4.183 4.137 0.619
2024-12-01-20:30:19-root-INFO: grad norm: 4.157 4.120 0.558
2024-12-01-20:30:20-root-INFO: grad norm: 4.106 4.060 0.612
2024-12-01-20:30:20-root-INFO: Loss Change: 62.708 -> 58.164
2024-12-01-20:30:20-root-INFO: Regularization Change: 0.000 -> 4.405
2024-12-01-20:30:20-root-INFO: Learning rate of xt decay: 0.21994 -> 0.22258.
2024-12-01-20:30:20-root-INFO: Coefficient of regularization decay: 0.00074 -> 0.00075.
2024-12-01-20:30:20-root-INFO: step: 47 lr_xt 0.18433941
2024-12-01-20:30:20-root-INFO: grad norm: 4.830 4.769 0.768
2024-12-01-20:30:21-root-INFO: grad norm: 4.399 4.351 0.645
2024-12-01-20:30:21-root-INFO: grad norm: 3.970 3.935 0.531
2024-12-01-20:30:22-root-INFO: grad norm: 3.843 3.803 0.557
2024-12-01-20:30:22-root-INFO: grad norm: 3.736 3.704 0.489
2024-12-01-20:30:23-root-INFO: Loss Change: 58.314 -> 55.037
2024-12-01-20:30:23-root-INFO: Regularization Change: 0.000 -> 3.299
2024-12-01-20:30:23-root-INFO: Learning rate of xt decay: 0.22258 -> 0.22525.
2024-12-01-20:30:23-root-INFO: Coefficient of regularization decay: 0.00075 -> 0.00075.
2024-12-01-20:30:23-root-INFO: step: 46 lr_xt 0.18799060
2024-12-01-20:30:23-root-INFO: grad norm: 3.485 3.444 0.535
2024-12-01-20:30:23-root-INFO: grad norm: 3.411 3.379 0.471
2024-12-01-20:30:24-root-INFO: grad norm: 3.464 3.424 0.524
2024-12-01-20:30:24-root-INFO: grad norm: 3.558 3.524 0.484
2024-12-01-20:30:25-root-INFO: grad norm: 3.602 3.561 0.542
2024-12-01-20:30:25-root-INFO: Loss Change: 54.765 -> 52.372
2024-12-01-20:30:25-root-INFO: Regularization Change: 0.000 -> 2.594
2024-12-01-20:30:25-root-INFO: Learning rate of xt decay: 0.22525 -> 0.22796.
2024-12-01-20:30:25-root-INFO: Coefficient of regularization decay: 0.00075 -> 0.00076.
2024-12-01-20:30:25-root-INFO: step: 45 lr_xt 0.19168344
2024-12-01-20:30:26-root-INFO: grad norm: 4.400 4.343 0.710
2024-12-01-20:30:26-root-INFO: grad norm: 4.053 4.008 0.602
2024-12-01-20:30:26-root-INFO: grad norm: 3.684 3.651 0.495
2024-12-01-20:30:27-root-INFO: grad norm: 3.560 3.522 0.518
2024-12-01-20:30:27-root-INFO: grad norm: 3.451 3.420 0.457
2024-12-01-20:30:28-root-INFO: Loss Change: 52.414 -> 50.122
2024-12-01-20:30:28-root-INFO: Regularization Change: 0.000 -> 2.442
2024-12-01-20:30:28-root-INFO: Learning rate of xt decay: 0.22796 -> 0.23069.
2024-12-01-20:30:28-root-INFO: Coefficient of regularization decay: 0.00076 -> 0.00077.
2024-12-01-20:30:28-root-INFO: step: 44 lr_xt 0.19541757
2024-12-01-20:30:28-root-INFO: grad norm: 3.293 3.251 0.526
2024-12-01-20:30:29-root-INFO: grad norm: 3.193 3.160 0.462
2024-12-01-20:30:29-root-INFO: grad norm: 3.228 3.191 0.488
2024-12-01-20:30:30-root-INFO: grad norm: 3.294 3.262 0.459
2024-12-01-20:30:30-root-INFO: grad norm: 3.332 3.295 0.494
2024-12-01-20:30:30-root-INFO: Loss Change: 49.962 -> 48.091
2024-12-01-20:30:30-root-INFO: Regularization Change: 0.000 -> 2.145
2024-12-01-20:30:30-root-INFO: Learning rate of xt decay: 0.23069 -> 0.23346.
2024-12-01-20:30:30-root-INFO: Coefficient of regularization decay: 0.00077 -> 0.00078.
2024-12-01-20:30:31-root-INFO: step: 43 lr_xt 0.19919257
2024-12-01-20:30:31-root-INFO: grad norm: 4.040 3.988 0.642
2024-12-01-20:30:31-root-INFO: grad norm: 3.732 3.693 0.537
2024-12-01-20:30:32-root-INFO: grad norm: 3.442 3.412 0.451
2024-12-01-20:30:32-root-INFO: grad norm: 3.310 3.277 0.465
2024-12-01-20:30:33-root-INFO: grad norm: 3.193 3.166 0.412
2024-12-01-20:30:33-root-INFO: Loss Change: 48.024 -> 46.069
2024-12-01-20:30:33-root-INFO: Regularization Change: 0.000 -> 2.140
2024-12-01-20:30:33-root-INFO: Learning rate of xt decay: 0.23346 -> 0.23626.
2024-12-01-20:30:33-root-INFO: Coefficient of regularization decay: 0.00078 -> 0.00078.
2024-12-01-20:30:33-root-INFO: step: 42 lr_xt 0.20300803
2024-12-01-20:30:33-root-INFO: grad norm: 3.056 3.022 0.453
2024-12-01-20:30:34-root-INFO: grad norm: 2.942 2.915 0.396
2024-12-01-20:30:34-root-INFO: grad norm: 2.947 2.917 0.420
2024-12-01-20:30:35-root-INFO: grad norm: 2.980 2.955 0.387
2024-12-01-20:30:35-root-INFO: grad norm: 3.006 2.976 0.420
2024-12-01-20:30:36-root-INFO: Loss Change: 45.879 -> 44.230
2024-12-01-20:30:36-root-INFO: Regularization Change: 0.000 -> 1.940
2024-12-01-20:30:36-root-INFO: Learning rate of xt decay: 0.23626 -> 0.23910.
2024-12-01-20:30:36-root-INFO: Coefficient of regularization decay: 0.00078 -> 0.00079.
2024-12-01-20:30:36-root-INFO: step: 41 lr_xt 0.20721469
2024-12-01-20:30:36-root-INFO: grad norm: 4.033 3.972 0.701
2024-12-01-20:30:36-root-INFO: grad norm: 3.565 3.530 0.498
2024-12-01-20:30:37-root-INFO: grad norm: 3.181 3.157 0.395
2024-12-01-20:30:37-root-INFO: grad norm: 3.011 2.984 0.398
2024-12-01-20:30:38-root-INFO: grad norm: 2.889 2.868 0.348
2024-12-01-20:30:38-root-INFO: Loss Change: 44.405 -> 42.419
2024-12-01-20:30:38-root-INFO: Regularization Change: 0.000 -> 2.081
2024-12-01-20:30:38-root-INFO: Learning rate of xt decay: 0.23910 -> 0.24197.
2024-12-01-20:30:38-root-INFO: Coefficient of regularization decay: 0.00079 -> 0.00080.
2024-12-01-20:30:38-root-INFO: step: 40 lr_xt 0.21110784
2024-12-01-20:30:38-root-INFO: grad norm: 2.618 2.589 0.393
2024-12-01-20:30:39-root-INFO: grad norm: 2.398 2.376 0.320
2024-12-01-20:30:39-root-INFO: grad norm: 2.394 2.371 0.324
2024-12-01-20:30:40-root-INFO: grad norm: 2.441 2.421 0.310
2024-12-01-20:30:40-root-INFO: grad norm: 2.494 2.471 0.334
2024-12-01-20:30:41-root-INFO: Loss Change: 42.186 -> 40.618
2024-12-01-20:30:41-root-INFO: Regularization Change: 0.000 -> 1.829
2024-12-01-20:30:41-root-INFO: Undo step: 40
2024-12-01-20:30:41-root-INFO: Undo step: 41
2024-12-01-20:30:41-root-INFO: Undo step: 42
2024-12-01-20:30:41-root-INFO: Undo step: 43
2024-12-01-20:30:41-root-INFO: Undo step: 44
2024-12-01-20:30:41-root-INFO: step: 45 lr_xt 0.19168344
2024-12-01-20:30:41-root-INFO: grad norm: 20.598 20.432 2.611
2024-12-01-20:30:41-root-INFO: grad norm: 11.588 11.452 1.770
2024-12-01-20:30:42-root-INFO: grad norm: 7.994 7.917 1.103
2024-12-01-20:30:42-root-INFO: grad norm: 6.091 6.020 0.926
2024-12-01-20:30:43-root-INFO: grad norm: 5.333 5.276 0.781
2024-12-01-20:30:43-root-INFO: Loss Change: 145.018 -> 61.332
2024-12-01-20:30:43-root-INFO: Regularization Change: 0.000 -> 63.195
2024-12-01-20:30:43-root-INFO: Learning rate of xt decay: 0.22796 -> 0.23069.
2024-12-01-20:30:43-root-INFO: Coefficient of regularization decay: 0.00076 -> 0.00077.
2024-12-01-20:30:43-root-INFO: step: 44 lr_xt 0.19541757
2024-12-01-20:30:43-root-INFO: grad norm: 4.798 4.750 0.682
2024-12-01-20:30:44-root-INFO: grad norm: 4.506 4.463 0.621
2024-12-01-20:30:44-root-INFO: grad norm: 4.300 4.260 0.580
2024-12-01-20:30:45-root-INFO: grad norm: 4.125 4.088 0.549
2024-12-01-20:30:45-root-INFO: grad norm: 3.991 3.956 0.524
2024-12-01-20:30:46-root-INFO: Loss Change: 61.034 -> 53.134
2024-12-01-20:30:46-root-INFO: Regularization Change: 0.000 -> 8.081
2024-12-01-20:30:46-root-INFO: Learning rate of xt decay: 0.23069 -> 0.23346.
2024-12-01-20:30:46-root-INFO: Coefficient of regularization decay: 0.00077 -> 0.00078.
2024-12-01-20:30:46-root-INFO: step: 43 lr_xt 0.19919257
2024-12-01-20:30:46-root-INFO: grad norm: 4.475 4.416 0.722
2024-12-01-20:30:46-root-INFO: grad norm: 4.088 4.051 0.550
2024-12-01-20:30:47-root-INFO: grad norm: 3.767 3.733 0.503
2024-12-01-20:30:47-root-INFO: grad norm: 3.641 3.609 0.476
2024-12-01-20:30:48-root-INFO: grad norm: 3.528 3.498 0.454
2024-12-01-20:30:48-root-INFO: Loss Change: 52.990 -> 48.705
2024-12-01-20:30:48-root-INFO: Regularization Change: 0.000 -> 4.517
2024-12-01-20:30:48-root-INFO: Learning rate of xt decay: 0.23346 -> 0.23626.
2024-12-01-20:30:48-root-INFO: Coefficient of regularization decay: 0.00078 -> 0.00078.
2024-12-01-20:30:48-root-INFO: step: 42 lr_xt 0.20300803
2024-12-01-20:30:49-root-INFO: grad norm: 3.274 3.252 0.374
2024-12-01-20:30:49-root-INFO: grad norm: 3.151 3.129 0.372
2024-12-01-20:30:49-root-INFO: grad norm: 3.134 3.110 0.382
2024-12-01-20:30:50-root-INFO: grad norm: 3.133 3.111 0.371
2024-12-01-20:30:50-root-INFO: grad norm: 3.129 3.105 0.386
2024-12-01-20:30:51-root-INFO: Loss Change: 48.423 -> 45.578
2024-12-01-20:30:51-root-INFO: Regularization Change: 0.000 -> 3.186
2024-12-01-20:30:51-root-INFO: Learning rate of xt decay: 0.23626 -> 0.23910.
2024-12-01-20:30:51-root-INFO: Coefficient of regularization decay: 0.00078 -> 0.00079.
2024-12-01-20:30:51-root-INFO: step: 41 lr_xt 0.20721469
2024-12-01-20:30:51-root-INFO: grad norm: 4.142 4.072 0.761
2024-12-01-20:30:51-root-INFO: grad norm: 3.688 3.653 0.507
2024-12-01-20:30:52-root-INFO: grad norm: 3.371 3.343 0.432
2024-12-01-20:30:52-root-INFO: grad norm: 3.196 3.169 0.415
2024-12-01-20:30:53-root-INFO: grad norm: 3.055 3.032 0.373
2024-12-01-20:30:53-root-INFO: Loss Change: 45.727 -> 43.008
2024-12-01-20:30:53-root-INFO: Regularization Change: 0.000 -> 2.856
2024-12-01-20:30:53-root-INFO: Learning rate of xt decay: 0.23910 -> 0.24197.
2024-12-01-20:30:53-root-INFO: Coefficient of regularization decay: 0.00079 -> 0.00080.
2024-12-01-20:30:53-root-INFO: step: 40 lr_xt 0.21110784
2024-12-01-20:30:54-root-INFO: grad norm: 2.616 2.597 0.313
2024-12-01-20:30:54-root-INFO: grad norm: 2.399 2.384 0.265
2024-12-01-20:30:55-root-INFO: grad norm: 2.381 2.365 0.280
2024-12-01-20:30:55-root-INFO: grad norm: 2.404 2.389 0.269
2024-12-01-20:30:55-root-INFO: grad norm: 2.443 2.425 0.295
2024-12-01-20:30:56-root-INFO: Loss Change: 42.685 -> 40.693
2024-12-01-20:30:56-root-INFO: Regularization Change: 0.000 -> 2.275
2024-12-01-20:30:56-root-INFO: Learning rate of xt decay: 0.24197 -> 0.24487.
2024-12-01-20:30:56-root-INFO: Coefficient of regularization decay: 0.00080 -> 0.00081.
2024-12-01-20:30:56-root-INFO: step: 39 lr_xt 0.21503976
2024-12-01-20:30:56-root-INFO: grad norm: 3.125 3.081 0.524
2024-12-01-20:30:57-root-INFO: grad norm: 2.943 2.917 0.389
2024-12-01-20:30:57-root-INFO: grad norm: 2.855 2.835 0.339
2024-12-01-20:30:57-root-INFO: grad norm: 2.783 2.760 0.353
2024-12-01-20:30:58-root-INFO: grad norm: 2.719 2.701 0.312
2024-12-01-20:30:58-root-INFO: Loss Change: 40.661 -> 38.792
2024-12-01-20:30:58-root-INFO: Regularization Change: 0.000 -> 2.188
2024-12-01-20:30:58-root-INFO: Learning rate of xt decay: 0.24487 -> 0.24781.
2024-12-01-20:30:58-root-INFO: Coefficient of regularization decay: 0.00081 -> 0.00082.
2024-12-01-20:30:58-root-INFO: step: 38 lr_xt 0.21900989
2024-12-01-20:30:59-root-INFO: grad norm: 2.436 2.419 0.287
2024-12-01-20:30:59-root-INFO: grad norm: 2.213 2.200 0.236
2024-12-01-20:31:00-root-INFO: grad norm: 2.186 2.172 0.246
2024-12-01-20:31:00-root-INFO: grad norm: 2.193 2.180 0.240
2024-12-01-20:31:01-root-INFO: grad norm: 2.214 2.199 0.261
2024-12-01-20:31:01-root-INFO: Loss Change: 38.470 -> 36.805
2024-12-01-20:31:01-root-INFO: Regularization Change: 0.000 -> 1.953
2024-12-01-20:31:01-root-INFO: Learning rate of xt decay: 0.24781 -> 0.25078.
2024-12-01-20:31:01-root-INFO: Coefficient of regularization decay: 0.00082 -> 0.00082.
2024-12-01-20:31:01-root-INFO: step: 37 lr_xt 0.22301766
2024-12-01-20:31:01-root-INFO: grad norm: 3.064 3.018 0.528
2024-12-01-20:31:02-root-INFO: grad norm: 2.776 2.751 0.372
2024-12-01-20:31:02-root-INFO: grad norm: 2.612 2.594 0.302
2024-12-01-20:31:03-root-INFO: grad norm: 2.489 2.469 0.314
2024-12-01-20:31:03-root-INFO: grad norm: 2.388 2.373 0.268
2024-12-01-20:31:03-root-INFO: Loss Change: 36.834 -> 35.096
2024-12-01-20:31:03-root-INFO: Regularization Change: 0.000 -> 1.980
2024-12-01-20:31:03-root-INFO: Learning rate of xt decay: 0.25078 -> 0.25379.
2024-12-01-20:31:03-root-INFO: Coefficient of regularization decay: 0.00082 -> 0.00083.
2024-12-01-20:31:04-root-INFO: step: 36 lr_xt 0.22706247
2024-12-01-20:31:04-root-INFO: grad norm: 2.126 2.111 0.252
2024-12-01-20:31:04-root-INFO: grad norm: 1.927 1.916 0.205
2024-12-01-20:31:05-root-INFO: grad norm: 1.891 1.879 0.213
2024-12-01-20:31:05-root-INFO: grad norm: 1.889 1.878 0.204
2024-12-01-20:31:06-root-INFO: grad norm: 1.901 1.888 0.223
2024-12-01-20:31:06-root-INFO: Loss Change: 34.846 -> 33.366
2024-12-01-20:31:06-root-INFO: Regularization Change: 0.000 -> 1.766
2024-12-01-20:31:06-root-INFO: Learning rate of xt decay: 0.25379 -> 0.25684.
2024-12-01-20:31:06-root-INFO: Coefficient of regularization decay: 0.00083 -> 0.00084.
2024-12-01-20:31:06-root-INFO: step: 35 lr_xt 0.23114370
2024-12-01-20:31:06-root-INFO: grad norm: 2.647 2.607 0.457
2024-12-01-20:31:07-root-INFO: grad norm: 2.401 2.379 0.322
2024-12-01-20:31:07-root-INFO: grad norm: 2.270 2.256 0.255
2024-12-01-20:31:08-root-INFO: grad norm: 2.177 2.160 0.271
2024-12-01-20:31:08-root-INFO: grad norm: 2.099 2.087 0.228
2024-12-01-20:31:09-root-INFO: Loss Change: 33.380 -> 31.839
2024-12-01-20:31:09-root-INFO: Regularization Change: 0.000 -> 1.818
2024-12-01-20:31:09-root-INFO: Undo step: 35
2024-12-01-20:31:09-root-INFO: Undo step: 36
2024-12-01-20:31:09-root-INFO: Undo step: 37
2024-12-01-20:31:09-root-INFO: Undo step: 38
2024-12-01-20:31:09-root-INFO: Undo step: 39
2024-12-01-20:31:09-root-INFO: step: 40 lr_xt 0.21110784
2024-12-01-20:31:09-root-INFO: grad norm: 17.311 17.139 2.434
2024-12-01-20:31:09-root-INFO: grad norm: 9.471 9.391 1.232
2024-12-01-20:31:10-root-INFO: grad norm: 6.645 6.569 1.001
2024-12-01-20:31:10-root-INFO: grad norm: 5.121 5.064 0.764
2024-12-01-20:31:11-root-INFO: grad norm: 4.320 4.273 0.637
2024-12-01-20:31:11-root-INFO: Loss Change: 120.958 -> 50.647
2024-12-01-20:31:11-root-INFO: Regularization Change: 0.000 -> 59.414
2024-12-01-20:31:11-root-INFO: Learning rate of xt decay: 0.24197 -> 0.24487.
2024-12-01-20:31:11-root-INFO: Coefficient of regularization decay: 0.00080 -> 0.00081.
2024-12-01-20:31:11-root-INFO: step: 39 lr_xt 0.21503976
2024-12-01-20:31:11-root-INFO: grad norm: 4.215 4.157 0.697
2024-12-01-20:31:12-root-INFO: grad norm: 3.692 3.652 0.540
2024-12-01-20:31:12-root-INFO: grad norm: 3.326 3.292 0.479
2024-12-01-20:31:13-root-INFO: grad norm: 3.045 3.014 0.430
2024-12-01-20:31:13-root-INFO: grad norm: 2.840 2.812 0.398
2024-12-01-20:31:14-root-INFO: Loss Change: 50.497 -> 42.706
2024-12-01-20:31:14-root-INFO: Regularization Change: 0.000 -> 8.396
2024-12-01-20:31:14-root-INFO: Learning rate of xt decay: 0.24487 -> 0.24781.
2024-12-01-20:31:14-root-INFO: Coefficient of regularization decay: 0.00081 -> 0.00082.
2024-12-01-20:31:14-root-INFO: step: 38 lr_xt 0.21900989
2024-12-01-20:31:14-root-INFO: grad norm: 2.643 2.617 0.371
2024-12-01-20:31:14-root-INFO: grad norm: 2.340 2.320 0.307
2024-12-01-20:31:15-root-INFO: grad norm: 2.232 2.213 0.291
2024-12-01-20:31:15-root-INFO: grad norm: 2.174 2.155 0.284
2024-12-01-20:31:16-root-INFO: grad norm: 2.142 2.123 0.281
2024-12-01-20:31:16-root-INFO: Loss Change: 42.351 -> 38.512
2024-12-01-20:31:16-root-INFO: Regularization Change: 0.000 -> 4.296
2024-12-01-20:31:16-root-INFO: Learning rate of xt decay: 0.24781 -> 0.25078.
2024-12-01-20:31:16-root-INFO: Coefficient of regularization decay: 0.00082 -> 0.00082.
2024-12-01-20:31:16-root-INFO: step: 37 lr_xt 0.22301766
2024-12-01-20:31:16-root-INFO: grad norm: 2.869 2.822 0.519
2024-12-01-20:31:17-root-INFO: grad norm: 2.639 2.613 0.368
2024-12-01-20:31:17-root-INFO: grad norm: 2.559 2.538 0.325
2024-12-01-20:31:18-root-INFO: grad norm: 2.493 2.472 0.326
2024-12-01-20:31:18-root-INFO: grad norm: 2.437 2.418 0.298
2024-12-01-20:31:19-root-INFO: Loss Change: 38.435 -> 35.731
2024-12-01-20:31:19-root-INFO: Regularization Change: 0.000 -> 3.166
2024-12-01-20:31:19-root-INFO: Learning rate of xt decay: 0.25078 -> 0.25379.
2024-12-01-20:31:19-root-INFO: Coefficient of regularization decay: 0.00082 -> 0.00083.
2024-12-01-20:31:19-root-INFO: step: 36 lr_xt 0.22706247
2024-12-01-20:31:19-root-INFO: grad norm: 2.237 2.219 0.279
2024-12-01-20:31:19-root-INFO: grad norm: 2.038 2.024 0.233
2024-12-01-20:31:20-root-INFO: grad norm: 2.001 1.987 0.238
2024-12-01-20:31:20-root-INFO: grad norm: 1.995 1.981 0.235
2024-12-01-20:31:21-root-INFO: grad norm: 1.997 1.982 0.246
2024-12-01-20:31:21-root-INFO: Loss Change: 35.458 -> 33.344
2024-12-01-20:31:21-root-INFO: Regularization Change: 0.000 -> 2.491
2024-12-01-20:31:21-root-INFO: Learning rate of xt decay: 0.25379 -> 0.25684.
2024-12-01-20:31:21-root-INFO: Coefficient of regularization decay: 0.00083 -> 0.00084.
2024-12-01-20:31:21-root-INFO: step: 35 lr_xt 0.23114370
2024-12-01-20:31:21-root-INFO: grad norm: 2.753 2.709 0.489
2024-12-01-20:31:22-root-INFO: grad norm: 2.489 2.465 0.345
2024-12-01-20:31:22-root-INFO: grad norm: 2.327 2.309 0.287
2024-12-01-20:31:23-root-INFO: grad norm: 2.223 2.204 0.285
2024-12-01-20:31:23-root-INFO: grad norm: 2.125 2.110 0.252
2024-12-01-20:31:24-root-INFO: Loss Change: 33.341 -> 31.421
2024-12-01-20:31:24-root-INFO: Regularization Change: 0.000 -> 2.262
2024-12-01-20:31:24-root-INFO: Learning rate of xt decay: 0.25684 -> 0.25992.
2024-12-01-20:31:24-root-INFO: Coefficient of regularization decay: 0.00084 -> 0.00085.
2024-12-01-20:31:24-root-INFO: step: 34 lr_xt 0.23526068
2024-12-01-20:31:24-root-INFO: grad norm: 1.913 1.898 0.244
2024-12-01-20:31:25-root-INFO: grad norm: 1.668 1.658 0.182
2024-12-01-20:31:25-root-INFO: grad norm: 1.612 1.601 0.189
2024-12-01-20:31:25-root-INFO: grad norm: 1.585 1.575 0.180
2024-12-01-20:31:26-root-INFO: grad norm: 1.571 1.559 0.193
2024-12-01-20:31:26-root-INFO: Loss Change: 31.156 -> 29.537
2024-12-01-20:31:26-root-INFO: Regularization Change: 0.000 -> 1.915
2024-12-01-20:31:26-root-INFO: Learning rate of xt decay: 0.25992 -> 0.26304.
2024-12-01-20:31:26-root-INFO: Coefficient of regularization decay: 0.00085 -> 0.00086.
2024-12-01-20:31:26-root-INFO: step: 33 lr_xt 0.23941272
2024-12-01-20:31:26-root-INFO: grad norm: 2.251 2.208 0.439
2024-12-01-20:31:27-root-INFO: grad norm: 2.001 1.983 0.270
2024-12-01-20:31:27-root-INFO: grad norm: 1.897 1.882 0.238
2024-12-01-20:31:28-root-INFO: grad norm: 1.829 1.815 0.228
2024-12-01-20:31:28-root-INFO: grad norm: 1.768 1.755 0.208
2024-12-01-20:31:29-root-INFO: Loss Change: 29.327 -> 27.800
2024-12-01-20:31:29-root-INFO: Regularization Change: 0.000 -> 1.850
2024-12-01-20:31:29-root-INFO: Learning rate of xt decay: 0.26304 -> 0.26620.
2024-12-01-20:31:29-root-INFO: Coefficient of regularization decay: 0.00086 -> 0.00087.
2024-12-01-20:31:29-root-INFO: step: 32 lr_xt 0.24359912
2024-12-01-20:31:29-root-INFO: grad norm: 1.677 1.654 0.275
2024-12-01-20:31:30-root-INFO: grad norm: 1.318 1.309 0.152
2024-12-01-20:31:30-root-INFO: grad norm: 1.246 1.238 0.145
2024-12-01-20:31:31-root-INFO: grad norm: 1.220 1.212 0.142
2024-12-01-20:31:31-root-INFO: grad norm: 1.206 1.197 0.149
2024-12-01-20:31:31-root-INFO: Loss Change: 27.600 -> 26.194
2024-12-01-20:31:31-root-INFO: Regularization Change: 0.000 -> 1.656
2024-12-01-20:31:31-root-INFO: Learning rate of xt decay: 0.26620 -> 0.26939.
2024-12-01-20:31:31-root-INFO: Coefficient of regularization decay: 0.00087 -> 0.00088.
2024-12-01-20:31:31-root-INFO: step: 31 lr_xt 0.24781911
2024-12-01-20:31:32-root-INFO: grad norm: 1.783 1.748 0.352
2024-12-01-20:31:32-root-INFO: grad norm: 1.555 1.540 0.213
2024-12-01-20:31:33-root-INFO: grad norm: 1.498 1.487 0.184
2024-12-01-20:31:33-root-INFO: grad norm: 1.468 1.456 0.185
2024-12-01-20:31:34-root-INFO: grad norm: 1.442 1.432 0.167
2024-12-01-20:31:34-root-INFO: Loss Change: 26.088 -> 24.797
2024-12-01-20:31:34-root-INFO: Regularization Change: 0.000 -> 1.611
2024-12-01-20:31:34-root-INFO: Learning rate of xt decay: 0.26939 -> 0.27262.
2024-12-01-20:31:34-root-INFO: Coefficient of regularization decay: 0.00088 -> 0.00088.
2024-12-01-20:31:34-root-INFO: step: 30 lr_xt 0.25207194
2024-12-01-20:31:34-root-INFO: grad norm: 1.472 1.449 0.255
2024-12-01-20:31:35-root-INFO: grad norm: 1.164 1.156 0.143
2024-12-01-20:31:35-root-INFO: grad norm: 1.103 1.095 0.133
2024-12-01-20:31:36-root-INFO: grad norm: 1.077 1.070 0.128
2024-12-01-20:31:36-root-INFO: grad norm: 1.062 1.053 0.133
2024-12-01-20:31:36-root-INFO: Loss Change: 24.568 -> 23.332
2024-12-01-20:31:36-root-INFO: Regularization Change: 0.000 -> 1.505
2024-12-01-20:31:36-root-INFO: Undo step: 30
2024-12-01-20:31:36-root-INFO: Undo step: 31
2024-12-01-20:31:36-root-INFO: Undo step: 32
2024-12-01-20:31:36-root-INFO: Undo step: 33
2024-12-01-20:31:36-root-INFO: Undo step: 34
2024-12-01-20:31:37-root-INFO: step: 35 lr_xt 0.23114370
2024-12-01-20:31:37-root-INFO: grad norm: 15.280 15.175 1.789
2024-12-01-20:31:37-root-INFO: grad norm: 8.451 8.375 1.130
2024-12-01-20:31:38-root-INFO: grad norm: 5.873 5.816 0.817
2024-12-01-20:31:38-root-INFO: grad norm: 4.567 4.522 0.638
2024-12-01-20:31:39-root-INFO: grad norm: 3.761 3.722 0.540
2024-12-01-20:31:39-root-INFO: Loss Change: 104.226 -> 41.660
2024-12-01-20:31:39-root-INFO: Regularization Change: 0.000 -> 58.649
2024-12-01-20:31:39-root-INFO: Learning rate of xt decay: 0.25684 -> 0.25992.
2024-12-01-20:31:39-root-INFO: Coefficient of regularization decay: 0.00084 -> 0.00085.
2024-12-01-20:31:39-root-INFO: step: 34 lr_xt 0.23526068
2024-12-01-20:31:39-root-INFO: grad norm: 3.678 3.639 0.531
2024-12-01-20:31:40-root-INFO: grad norm: 3.280 3.249 0.449
2024-12-01-20:31:40-root-INFO: grad norm: 3.009 2.984 0.389
2024-12-01-20:31:41-root-INFO: grad norm: 2.832 2.806 0.384
2024-12-01-20:31:41-root-INFO: grad norm: 2.694 2.672 0.346
2024-12-01-20:31:42-root-INFO: Loss Change: 41.385 -> 34.263
2024-12-01-20:31:42-root-INFO: Regularization Change: 0.000 -> 8.621
2024-12-01-20:31:42-root-INFO: Learning rate of xt decay: 0.25992 -> 0.26304.
2024-12-01-20:31:42-root-INFO: Coefficient of regularization decay: 0.00085 -> 0.00086.
2024-12-01-20:31:42-root-INFO: step: 33 lr_xt 0.23941272
2024-12-01-20:31:42-root-INFO: grad norm: 2.456 2.435 0.322
2024-12-01-20:31:42-root-INFO: grad norm: 2.220 2.204 0.265
2024-12-01-20:31:43-root-INFO: grad norm: 2.147 2.130 0.273
2024-12-01-20:31:43-root-INFO: grad norm: 2.111 2.096 0.258
2024-12-01-20:31:44-root-INFO: grad norm: 2.083 2.066 0.272
2024-12-01-20:31:44-root-INFO: Loss Change: 33.741 -> 30.165
2024-12-01-20:31:44-root-INFO: Regularization Change: 0.000 -> 4.408
2024-12-01-20:31:44-root-INFO: Learning rate of xt decay: 0.26304 -> 0.26620.
2024-12-01-20:31:44-root-INFO: Coefficient of regularization decay: 0.00086 -> 0.00087.
2024-12-01-20:31:44-root-INFO: step: 32 lr_xt 0.24359912
2024-12-01-20:31:44-root-INFO: grad norm: 2.857 2.811 0.507
2024-12-01-20:31:45-root-INFO: grad norm: 2.545 2.520 0.358
2024-12-01-20:31:45-root-INFO: grad norm: 2.334 2.314 0.305
2024-12-01-20:31:46-root-INFO: grad norm: 2.203 2.183 0.300
2024-12-01-20:31:46-root-INFO: grad norm: 2.083 2.065 0.269
2024-12-01-20:31:47-root-INFO: Loss Change: 30.128 -> 27.549
2024-12-01-20:31:47-root-INFO: Regularization Change: 0.000 -> 3.170
2024-12-01-20:31:47-root-INFO: Learning rate of xt decay: 0.26620 -> 0.26939.
2024-12-01-20:31:47-root-INFO: Coefficient of regularization decay: 0.00087 -> 0.00088.
2024-12-01-20:31:47-root-INFO: step: 31 lr_xt 0.24781911
2024-12-01-20:31:47-root-INFO: grad norm: 1.898 1.881 0.258
2024-12-01-20:31:47-root-INFO: grad norm: 1.655 1.643 0.196
2024-12-01-20:31:48-root-INFO: grad norm: 1.592 1.580 0.198
2024-12-01-20:31:48-root-INFO: grad norm: 1.555 1.543 0.190
2024-12-01-20:31:49-root-INFO: grad norm: 1.527 1.514 0.196
2024-12-01-20:31:49-root-INFO: Loss Change: 27.263 -> 25.338
2024-12-01-20:31:49-root-INFO: Regularization Change: 0.000 -> 2.389
2024-12-01-20:31:49-root-INFO: Learning rate of xt decay: 0.26939 -> 0.27262.
2024-12-01-20:31:49-root-INFO: Coefficient of regularization decay: 0.00088 -> 0.00088.
2024-12-01-20:31:49-root-INFO: step: 30 lr_xt 0.25207194
2024-12-01-20:31:50-root-INFO: grad norm: 2.205 2.166 0.411
2024-12-01-20:31:50-root-INFO: grad norm: 1.933 1.914 0.274
2024-12-01-20:31:51-root-INFO: grad norm: 1.790 1.774 0.236
2024-12-01-20:31:51-root-INFO: grad norm: 1.700 1.684 0.230
2024-12-01-20:31:51-root-INFO: grad norm: 1.609 1.596 0.207
2024-12-01-20:31:52-root-INFO: Loss Change: 25.214 -> 23.541
2024-12-01-20:31:52-root-INFO: Regularization Change: 0.000 -> 2.097
2024-12-01-20:31:52-root-INFO: Learning rate of xt decay: 0.27262 -> 0.27589.
2024-12-01-20:31:52-root-INFO: Coefficient of regularization decay: 0.00088 -> 0.00089.
2024-12-01-20:31:52-root-INFO: step: 29 lr_xt 0.25635679
2024-12-01-20:31:52-root-INFO: grad norm: 1.561 1.538 0.264
2024-12-01-20:31:53-root-INFO: grad norm: 1.238 1.230 0.143
2024-12-01-20:31:53-root-INFO: grad norm: 1.173 1.164 0.140
2024-12-01-20:31:54-root-INFO: grad norm: 1.139 1.131 0.134
2024-12-01-20:31:54-root-INFO: grad norm: 1.115 1.106 0.138
2024-12-01-20:31:54-root-INFO: Loss Change: 23.324 -> 21.879
2024-12-01-20:31:54-root-INFO: Regularization Change: 0.000 -> 1.794
2024-12-01-20:31:54-root-INFO: Learning rate of xt decay: 0.27589 -> 0.27921.
2024-12-01-20:31:54-root-INFO: Coefficient of regularization decay: 0.00089 -> 0.00090.
2024-12-01-20:31:54-root-INFO: step: 28 lr_xt 0.26067283
2024-12-01-20:31:55-root-INFO: grad norm: 1.814 1.778 0.363
2024-12-01-20:31:55-root-INFO: grad norm: 1.504 1.489 0.211
2024-12-01-20:31:56-root-INFO: grad norm: 1.392 1.381 0.181
2024-12-01-20:31:56-root-INFO: grad norm: 1.325 1.314 0.175
2024-12-01-20:31:57-root-INFO: grad norm: 1.262 1.252 0.157
2024-12-01-20:31:57-root-INFO: Loss Change: 21.650 -> 20.308
2024-12-01-20:31:57-root-INFO: Regularization Change: 0.000 -> 1.696
2024-12-01-20:31:57-root-INFO: Learning rate of xt decay: 0.27921 -> 0.28256.
2024-12-01-20:31:57-root-INFO: Coefficient of regularization decay: 0.00090 -> 0.00091.
2024-12-01-20:31:57-root-INFO: step: 27 lr_xt 0.26501920
2024-12-01-20:31:57-root-INFO: grad norm: 1.319 1.297 0.240
2024-12-01-20:31:58-root-INFO: grad norm: 1.029 1.022 0.122
2024-12-01-20:31:58-root-INFO: grad norm: 0.975 0.968 0.118
2024-12-01-20:31:59-root-INFO: grad norm: 0.949 0.942 0.111
2024-12-01-20:31:59-root-INFO: grad norm: 0.929 0.922 0.115
2024-12-01-20:32:00-root-INFO: Loss Change: 20.132 -> 18.947
2024-12-01-20:32:00-root-INFO: Regularization Change: 0.000 -> 1.515
2024-12-01-20:32:00-root-INFO: Learning rate of xt decay: 0.28256 -> 0.28595.
2024-12-01-20:32:00-root-INFO: Coefficient of regularization decay: 0.00091 -> 0.00092.
2024-12-01-20:32:00-root-INFO: step: 26 lr_xt 0.26939500
2024-12-01-20:32:00-root-INFO: grad norm: 1.542 1.509 0.317
2024-12-01-20:32:00-root-INFO: grad norm: 1.225 1.212 0.173
2024-12-01-20:32:01-root-INFO: grad norm: 1.140 1.130 0.147
2024-12-01-20:32:01-root-INFO: grad norm: 1.090 1.080 0.143
2024-12-01-20:32:02-root-INFO: grad norm: 1.046 1.038 0.129
2024-12-01-20:32:02-root-INFO: Loss Change: 18.827 -> 17.683
2024-12-01-20:32:02-root-INFO: Regularization Change: 0.000 -> 1.479
2024-12-01-20:32:02-root-INFO: Learning rate of xt decay: 0.28595 -> 0.28938.
2024-12-01-20:32:02-root-INFO: Coefficient of regularization decay: 0.00092 -> 0.00093.
2024-12-01-20:32:02-root-INFO: step: 25 lr_xt 0.27379933
2024-12-01-20:32:02-root-INFO: grad norm: 1.263 1.237 0.256
2024-12-01-20:32:03-root-INFO: grad norm: 0.921 0.914 0.113
2024-12-01-20:32:03-root-INFO: grad norm: 0.866 0.860 0.104
2024-12-01-20:32:04-root-INFO: grad norm: 0.842 0.836 0.099
2024-12-01-20:32:04-root-INFO: grad norm: 0.825 0.819 0.098
2024-12-01-20:32:05-root-INFO: Loss Change: 17.400 -> 16.333
2024-12-01-20:32:05-root-INFO: Regularization Change: 0.000 -> 1.389
2024-12-01-20:32:05-root-INFO: Undo step: 25
2024-12-01-20:32:05-root-INFO: Undo step: 26
2024-12-01-20:32:05-root-INFO: Undo step: 27
2024-12-01-20:32:05-root-INFO: Undo step: 28
2024-12-01-20:32:05-root-INFO: Undo step: 29
2024-12-01-20:32:05-root-INFO: step: 30 lr_xt 0.25207194
2024-12-01-20:32:05-root-INFO: grad norm: 14.148 14.069 1.492
2024-12-01-20:32:05-root-INFO: grad norm: 7.932 7.887 0.843
2024-12-01-20:32:06-root-INFO: grad norm: 5.243 5.204 0.641
2024-12-01-20:32:06-root-INFO: grad norm: 4.083 4.051 0.515
2024-12-01-20:32:07-root-INFO: grad norm: 3.380 3.349 0.454
2024-12-01-20:32:07-root-INFO: Loss Change: 92.219 -> 33.531
2024-12-01-20:32:07-root-INFO: Regularization Change: 0.000 -> 60.195
2024-12-01-20:32:07-root-INFO: Learning rate of xt decay: 0.27262 -> 0.27589.
2024-12-01-20:32:07-root-INFO: Coefficient of regularization decay: 0.00088 -> 0.00089.
2024-12-01-20:32:07-root-INFO: step: 29 lr_xt 0.25635679
2024-12-01-20:32:07-root-INFO: grad norm: 3.380 3.341 0.510
2024-12-01-20:32:08-root-INFO: grad norm: 3.059 3.032 0.407
2024-12-01-20:32:08-root-INFO: grad norm: 2.866 2.845 0.347
2024-12-01-20:32:09-root-INFO: grad norm: 2.735 2.713 0.349
2024-12-01-20:32:09-root-INFO: grad norm: 2.590 2.572 0.307
2024-12-01-20:32:10-root-INFO: Loss Change: 33.283 -> 26.507
2024-12-01-20:32:10-root-INFO: Regularization Change: 0.000 -> 8.977
2024-12-01-20:32:10-root-INFO: Learning rate of xt decay: 0.27589 -> 0.27921.
2024-12-01-20:32:10-root-INFO: Coefficient of regularization decay: 0.00089 -> 0.00090.
2024-12-01-20:32:10-root-INFO: step: 28 lr_xt 0.26067283
2024-12-01-20:32:10-root-INFO: grad norm: 2.332 2.311 0.314
2024-12-01-20:32:11-root-INFO: grad norm: 2.026 2.013 0.230
2024-12-01-20:32:11-root-INFO: grad norm: 1.888 1.874 0.230
2024-12-01-20:32:11-root-INFO: grad norm: 1.801 1.789 0.212
2024-12-01-20:32:12-root-INFO: grad norm: 1.722 1.709 0.215
2024-12-01-20:32:12-root-INFO: Loss Change: 25.966 -> 22.580
2024-12-01-20:32:12-root-INFO: Regularization Change: 0.000 -> 4.447
2024-12-01-20:32:12-root-INFO: Learning rate of xt decay: 0.27921 -> 0.28256.
2024-12-01-20:32:12-root-INFO: Coefficient of regularization decay: 0.00090 -> 0.00091.
2024-12-01-20:32:12-root-INFO: step: 27 lr_xt 0.26501920
2024-12-01-20:32:13-root-INFO: grad norm: 2.166 2.130 0.392
2024-12-01-20:32:13-root-INFO: grad norm: 1.879 1.862 0.255
2024-12-01-20:32:13-root-INFO: grad norm: 1.722 1.708 0.216
2024-12-01-20:32:14-root-INFO: grad norm: 1.618 1.603 0.216
2024-12-01-20:32:14-root-INFO: grad norm: 1.548 1.536 0.194
2024-12-01-20:32:15-root-INFO: Loss Change: 22.452 -> 20.178
2024-12-01-20:32:15-root-INFO: Regularization Change: 0.000 -> 3.002
2024-12-01-20:32:15-root-INFO: Learning rate of xt decay: 0.28256 -> 0.28595.
2024-12-01-20:32:15-root-INFO: Coefficient of regularization decay: 0.00091 -> 0.00092.
2024-12-01-20:32:15-root-INFO: step: 26 lr_xt 0.26939500
2024-12-01-20:32:15-root-INFO: grad norm: 1.561 1.537 0.271
2024-12-01-20:32:15-root-INFO: grad norm: 1.257 1.248 0.152
2024-12-01-20:32:16-root-INFO: grad norm: 1.193 1.183 0.154
2024-12-01-20:32:16-root-INFO: grad norm: 1.168 1.159 0.142
2024-12-01-20:32:17-root-INFO: grad norm: 1.151 1.140 0.154
2024-12-01-20:32:17-root-INFO: Loss Change: 19.906 -> 18.208
2024-12-01-20:32:17-root-INFO: Regularization Change: 0.000 -> 2.250
2024-12-01-20:32:17-root-INFO: Learning rate of xt decay: 0.28595 -> 0.28938.
2024-12-01-20:32:17-root-INFO: Coefficient of regularization decay: 0.00092 -> 0.00093.
2024-12-01-20:32:17-root-INFO: step: 25 lr_xt 0.27379933
2024-12-01-20:32:17-root-INFO: grad norm: 1.757 1.722 0.346
2024-12-01-20:32:18-root-INFO: grad norm: 1.475 1.459 0.214
2024-12-01-20:32:18-root-INFO: grad norm: 1.361 1.349 0.184
2024-12-01-20:32:19-root-INFO: grad norm: 1.302 1.289 0.185
2024-12-01-20:32:19-root-INFO: grad norm: 1.254 1.243 0.165
2024-12-01-20:32:20-root-INFO: Loss Change: 17.945 -> 16.525
2024-12-01-20:32:20-root-INFO: Regularization Change: 0.000 -> 1.919
2024-12-01-20:32:20-root-INFO: Learning rate of xt decay: 0.28938 -> 0.29285.
2024-12-01-20:32:20-root-INFO: Coefficient of regularization decay: 0.00093 -> 0.00094.
2024-12-01-20:32:20-root-INFO: step: 24 lr_xt 0.27823123
2024-12-01-20:32:20-root-INFO: grad norm: 1.359 1.335 0.254
2024-12-01-20:32:20-root-INFO: grad norm: 1.019 1.011 0.124
2024-12-01-20:32:21-root-INFO: grad norm: 0.960 0.953 0.118
2024-12-01-20:32:21-root-INFO: grad norm: 0.940 0.933 0.113
2024-12-01-20:32:22-root-INFO: grad norm: 0.928 0.921 0.119
2024-12-01-20:32:22-root-INFO: Loss Change: 16.362 -> 15.137
2024-12-01-20:32:22-root-INFO: Regularization Change: 0.000 -> 1.639
2024-12-01-20:32:22-root-INFO: Learning rate of xt decay: 0.29285 -> 0.29636.
2024-12-01-20:32:22-root-INFO: Coefficient of regularization decay: 0.00094 -> 0.00095.
2024-12-01-20:32:22-root-INFO: step: 23 lr_xt 0.28268972
2024-12-01-20:32:22-root-INFO: grad norm: 1.502 1.471 0.305
2024-12-01-20:32:23-root-INFO: grad norm: 1.176 1.164 0.172
2024-12-01-20:32:23-root-INFO: grad norm: 1.108 1.099 0.141
2024-12-01-20:32:24-root-INFO: grad norm: 1.071 1.060 0.147
2024-12-01-20:32:24-root-INFO: grad norm: 1.040 1.032 0.128
2024-12-01-20:32:25-root-INFO: Loss Change: 14.910 -> 13.806
2024-12-01-20:32:25-root-INFO: Regularization Change: 0.000 -> 1.509
2024-12-01-20:32:25-root-INFO: Learning rate of xt decay: 0.29636 -> 0.29992.
2024-12-01-20:32:25-root-INFO: Coefficient of regularization decay: 0.00095 -> 0.00096.
2024-12-01-20:32:25-root-INFO: step: 22 lr_xt 0.28717380
2024-12-01-20:32:25-root-INFO: grad norm: 1.244 1.221 0.240
2024-12-01-20:32:25-root-INFO: grad norm: 0.893 0.886 0.109
2024-12-01-20:32:26-root-INFO: grad norm: 0.832 0.827 0.098
2024-12-01-20:32:26-root-INFO: grad norm: 0.809 0.803 0.094
2024-12-01-20:32:27-root-INFO: grad norm: 0.794 0.789 0.095
2024-12-01-20:32:27-root-INFO: Loss Change: 13.640 -> 12.642
2024-12-01-20:32:27-root-INFO: Regularization Change: 0.000 -> 1.357
2024-12-01-20:32:27-root-INFO: Learning rate of xt decay: 0.29992 -> 0.30352.
2024-12-01-20:32:27-root-INFO: Coefficient of regularization decay: 0.00096 -> 0.00097.
2024-12-01-20:32:27-root-INFO: step: 21 lr_xt 0.29168243
2024-12-01-20:32:28-root-INFO: grad norm: 1.353 1.326 0.268
2024-12-01-20:32:28-root-INFO: grad norm: 1.026 1.016 0.143
2024-12-01-20:32:28-root-INFO: grad norm: 0.972 0.965 0.114
2024-12-01-20:32:29-root-INFO: grad norm: 0.946 0.938 0.121
2024-12-01-20:32:29-root-INFO: grad norm: 0.929 0.923 0.106
2024-12-01-20:32:30-root-INFO: Loss Change: 12.505 -> 11.574
2024-12-01-20:32:30-root-INFO: Regularization Change: 0.000 -> 1.305
2024-12-01-20:32:30-root-INFO: Learning rate of xt decay: 0.30352 -> 0.30716.
2024-12-01-20:32:30-root-INFO: Coefficient of regularization decay: 0.00097 -> 0.00098.
2024-12-01-20:32:30-root-INFO: step: 20 lr_xt 0.29621455
2024-12-01-20:32:30-root-INFO: grad norm: 1.241 1.216 0.246
2024-12-01-20:32:30-root-INFO: grad norm: 0.824 0.818 0.096
2024-12-01-20:32:31-root-INFO: grad norm: 0.761 0.757 0.081
2024-12-01-20:32:31-root-INFO: grad norm: 0.740 0.736 0.078
2024-12-01-20:32:32-root-INFO: grad norm: 0.728 0.724 0.078
2024-12-01-20:32:32-root-INFO: Loss Change: 11.440 -> 10.547
2024-12-01-20:32:32-root-INFO: Regularization Change: 0.000 -> 1.226
2024-12-01-20:32:32-root-INFO: Undo step: 20
2024-12-01-20:32:32-root-INFO: Undo step: 21
2024-12-01-20:32:32-root-INFO: Undo step: 22
2024-12-01-20:32:32-root-INFO: Undo step: 23
2024-12-01-20:32:32-root-INFO: Undo step: 24
2024-12-01-20:32:32-root-INFO: step: 25 lr_xt 0.27379933
2024-12-01-20:32:33-root-INFO: grad norm: 13.696 13.629 1.355
2024-12-01-20:32:33-root-INFO: grad norm: 7.325 7.279 0.825
2024-12-01-20:32:34-root-INFO: grad norm: 5.077 5.040 0.615
2024-12-01-20:32:34-root-INFO: grad norm: 3.879 3.850 0.473
2024-12-01-20:32:35-root-INFO: grad norm: 3.188 3.162 0.408
2024-12-01-20:32:35-root-INFO: Loss Change: 85.700 -> 25.990
2024-12-01-20:32:35-root-INFO: Regularization Change: 0.000 -> 66.583
2024-12-01-20:32:35-root-INFO: Learning rate of xt decay: 0.28938 -> 0.29285.
2024-12-01-20:32:35-root-INFO: Coefficient of regularization decay: 0.00093 -> 0.00094.
2024-12-01-20:32:35-root-INFO: step: 24 lr_xt 0.27823123
2024-12-01-20:32:35-root-INFO: grad norm: 2.991 2.962 0.419
2024-12-01-20:32:36-root-INFO: grad norm: 2.511 2.490 0.321
2024-12-01-20:32:36-root-INFO: grad norm: 2.228 2.211 0.274
2024-12-01-20:32:36-root-INFO: grad norm: 2.018 2.002 0.255
2024-12-01-20:32:37-root-INFO: grad norm: 1.892 1.878 0.231
2024-12-01-20:32:37-root-INFO: Loss Change: 25.690 -> 19.192
2024-12-01-20:32:37-root-INFO: Regularization Change: 0.000 -> 9.103
2024-12-01-20:32:37-root-INFO: Learning rate of xt decay: 0.29285 -> 0.29636.
2024-12-01-20:32:37-root-INFO: Coefficient of regularization decay: 0.00094 -> 0.00095.
2024-12-01-20:32:37-root-INFO: step: 23 lr_xt 0.28268972
2024-12-01-20:32:38-root-INFO: grad norm: 1.937 1.912 0.310
2024-12-01-20:32:38-root-INFO: grad norm: 1.612 1.600 0.192
2024-12-01-20:32:38-root-INFO: grad norm: 1.504 1.494 0.180
2024-12-01-20:32:39-root-INFO: grad norm: 1.542 1.532 0.174
2024-12-01-20:32:39-root-INFO: grad norm: 1.452 1.441 0.179
2024-12-01-20:32:40-root-INFO: Loss Change: 18.742 -> 15.767
2024-12-01-20:32:40-root-INFO: Regularization Change: 0.000 -> 4.222
2024-12-01-20:32:40-root-INFO: Learning rate of xt decay: 0.29636 -> 0.29992.
2024-12-01-20:32:40-root-INFO: Coefficient of regularization decay: 0.00095 -> 0.00096.
2024-12-01-20:32:40-root-INFO: step: 22 lr_xt 0.28717380
2024-12-01-20:32:40-root-INFO: grad norm: 1.872 1.844 0.323
2024-12-01-20:32:41-root-INFO: grad norm: 1.616 1.602 0.211
2024-12-01-20:32:41-root-INFO: grad norm: 1.772 1.760 0.208
2024-12-01-20:32:41-root-INFO: grad norm: 1.585 1.571 0.216
2024-12-01-20:32:42-root-INFO: grad norm: 1.422 1.411 0.175
2024-12-01-20:32:42-root-INFO: Loss Change: 15.590 -> 13.711
2024-12-01-20:32:42-root-INFO: Regularization Change: 0.000 -> 2.719
2024-12-01-20:32:42-root-INFO: Learning rate of xt decay: 0.29992 -> 0.30352.
2024-12-01-20:32:42-root-INFO: Coefficient of regularization decay: 0.00096 -> 0.00097.
2024-12-01-20:32:42-root-INFO: step: 21 lr_xt 0.29168243
2024-12-01-20:32:43-root-INFO: grad norm: 1.486 1.464 0.256
2024-12-01-20:32:43-root-INFO: grad norm: 1.199 1.191 0.141
2024-12-01-20:32:43-root-INFO: grad norm: 1.189 1.180 0.141
2024-12-01-20:32:44-root-INFO: grad norm: 1.460 1.453 0.151
2024-12-01-20:32:44-root-INFO: grad norm: 1.286 1.275 0.167
2024-12-01-20:32:45-root-INFO: Loss Change: 13.437 -> 12.084
2024-12-01-20:32:45-root-INFO: Regularization Change: 0.000 -> 1.995
2024-12-01-20:32:45-root-INFO: Learning rate of xt decay: 0.30352 -> 0.30716.
2024-12-01-20:32:45-root-INFO: Coefficient of regularization decay: 0.00097 -> 0.00098.
2024-12-01-20:32:45-root-INFO: step: 20 lr_xt 0.29621455
2024-12-01-20:32:45-root-INFO: grad norm: 1.782 1.754 0.315
2024-12-01-20:32:45-root-INFO: grad norm: 1.365 1.354 0.170
2024-12-01-20:32:46-root-INFO: grad norm: 1.626 1.617 0.171
2024-12-01-20:32:46-root-INFO: grad norm: 1.314 1.303 0.168
2024-12-01-20:32:47-root-INFO: grad norm: 1.116 1.108 0.127
2024-12-01-20:32:47-root-INFO: Loss Change: 11.979 -> 10.775
2024-12-01-20:32:47-root-INFO: Regularization Change: 0.000 -> 1.670
2024-12-01-20:32:47-root-INFO: Learning rate of xt decay: 0.30716 -> 0.31085.
2024-12-01-20:32:47-root-INFO: Coefficient of regularization decay: 0.00098 -> 0.00099.
2024-12-01-20:32:47-root-INFO: step: 19 lr_xt 0.30076908
2024-12-01-20:32:47-root-INFO: grad norm: 1.219 1.200 0.213
2024-12-01-20:32:48-root-INFO: grad norm: 0.860 0.855 0.096
2024-12-01-20:32:48-root-INFO: grad norm: 0.796 0.792 0.083
2024-12-01-20:32:49-root-INFO: grad norm: 0.791 0.787 0.081
2024-12-01-20:32:49-root-INFO: grad norm: 0.844 0.840 0.087
2024-12-01-20:32:50-root-INFO: Loss Change: 10.553 -> 9.619
2024-12-01-20:32:50-root-INFO: Regularization Change: 0.000 -> 1.386
2024-12-01-20:32:50-root-INFO: Learning rate of xt decay: 0.31085 -> 0.31458.
2024-12-01-20:32:50-root-INFO: Coefficient of regularization decay: 0.00099 -> 0.00100.
2024-12-01-20:32:50-root-INFO: step: 18 lr_xt 0.30534490
2024-12-01-20:32:50-root-INFO: grad norm: 2.174 2.149 0.327
2024-12-01-20:32:50-root-INFO: grad norm: 1.324 1.313 0.166
2024-12-01-20:32:51-root-INFO: grad norm: 1.033 1.027 0.111
2024-12-01-20:32:51-root-INFO: grad norm: 0.915 0.910 0.100
2024-12-01-20:32:52-root-INFO: grad norm: 0.846 0.842 0.082
2024-12-01-20:32:52-root-INFO: Loss Change: 9.579 -> 8.647
2024-12-01-20:32:52-root-INFO: Regularization Change: 0.000 -> 1.311
2024-12-01-20:32:52-root-INFO: Learning rate of xt decay: 0.31458 -> 0.31835.
2024-12-01-20:32:52-root-INFO: Coefficient of regularization decay: 0.00100 -> 0.00101.
2024-12-01-20:32:52-root-INFO: step: 17 lr_xt 0.30994086
2024-12-01-20:32:52-root-INFO: grad norm: 1.143 1.124 0.209
2024-12-01-20:32:53-root-INFO: grad norm: 0.753 0.749 0.080
2024-12-01-20:32:53-root-INFO: grad norm: 0.704 0.701 0.066
2024-12-01-20:32:54-root-INFO: grad norm: 0.718 0.714 0.067
2024-12-01-20:32:54-root-INFO: grad norm: 0.965 0.962 0.076
2024-12-01-20:32:55-root-INFO: Loss Change: 8.531 -> 7.801
2024-12-01-20:32:55-root-INFO: Regularization Change: 0.000 -> 1.124
2024-12-01-20:32:55-root-INFO: Learning rate of xt decay: 0.31835 -> 0.32217.
2024-12-01-20:32:55-root-INFO: Coefficient of regularization decay: 0.00101 -> 0.00102.
2024-12-01-20:32:55-root-INFO: step: 16 lr_xt 0.31455579
2024-12-01-20:32:55-root-INFO: grad norm: 1.234 1.216 0.210
2024-12-01-20:32:55-root-INFO: grad norm: 0.775 0.771 0.082
2024-12-01-20:32:56-root-INFO: grad norm: 0.728 0.725 0.063
2024-12-01-20:32:56-root-INFO: grad norm: 0.784 0.780 0.072
2024-12-01-20:32:57-root-INFO: grad norm: 1.232 1.229 0.087
2024-12-01-20:32:57-root-INFO: Loss Change: 7.723 -> 7.060
2024-12-01-20:32:57-root-INFO: Regularization Change: 0.000 -> 1.040
2024-12-01-20:32:57-root-INFO: Learning rate of xt decay: 0.32217 -> 0.32604.
2024-12-01-20:32:57-root-INFO: Coefficient of regularization decay: 0.00102 -> 0.00103.
2024-12-01-20:32:57-root-INFO: step: 15 lr_xt 0.31918850
2024-12-01-20:32:58-root-INFO: grad norm: 1.211 1.192 0.212
2024-12-01-20:32:58-root-INFO: grad norm: 0.746 0.742 0.073
2024-12-01-20:32:59-root-INFO: grad norm: 0.645 0.642 0.054
2024-12-01-20:32:59-root-INFO: grad norm: 0.639 0.637 0.051
2024-12-01-20:32:59-root-INFO: grad norm: 0.712 0.710 0.057
2024-12-01-20:33:00-root-INFO: Loss Change: 6.990 -> 6.264
2024-12-01-20:33:00-root-INFO: Regularization Change: 0.000 -> 1.068
2024-12-01-20:33:00-root-INFO: Undo step: 15
2024-12-01-20:33:00-root-INFO: Undo step: 16
2024-12-01-20:33:00-root-INFO: Undo step: 17
2024-12-01-20:33:00-root-INFO: Undo step: 18
2024-12-01-20:33:00-root-INFO: Undo step: 19
2024-12-01-20:33:00-root-INFO: step: 20 lr_xt 0.29621455
2024-12-01-20:33:00-root-INFO: grad norm: 12.692 12.644 1.110
2024-12-01-20:33:01-root-INFO: grad norm: 6.762 6.723 0.720
2024-12-01-20:33:01-root-INFO: grad norm: 4.574 4.549 0.479
2024-12-01-20:33:01-root-INFO: grad norm: 3.517 3.496 0.384
2024-12-01-20:33:02-root-INFO: grad norm: 2.897 2.880 0.317
2024-12-01-20:33:02-root-INFO: Loss Change: 75.299 -> 19.471
2024-12-01-20:33:02-root-INFO: Regularization Change: 0.000 -> 66.774
2024-12-01-20:33:02-root-INFO: Learning rate of xt decay: 0.30716 -> 0.31085.
2024-12-01-20:33:02-root-INFO: Coefficient of regularization decay: 0.00098 -> 0.00099.
2024-12-01-20:33:02-root-INFO: step: 19 lr_xt 0.30076908
2024-12-01-20:33:02-root-INFO: grad norm: 2.646 2.627 0.320
2024-12-01-20:33:03-root-INFO: grad norm: 2.212 2.198 0.244
2024-12-01-20:33:03-root-INFO: grad norm: 1.958 1.947 0.210
2024-12-01-20:33:04-root-INFO: grad norm: 1.784 1.773 0.194
2024-12-01-20:33:04-root-INFO: grad norm: 1.792 1.783 0.179
2024-12-01-20:33:05-root-INFO: Loss Change: 18.946 -> 13.250
2024-12-01-20:33:05-root-INFO: Regularization Change: 0.000 -> 8.749
2024-12-01-20:33:05-root-INFO: Learning rate of xt decay: 0.31085 -> 0.31458.
2024-12-01-20:33:05-root-INFO: Coefficient of regularization decay: 0.00099 -> 0.00100.
2024-12-01-20:33:05-root-INFO: step: 18 lr_xt 0.30534490
2024-12-01-20:33:05-root-INFO: grad norm: 1.958 1.939 0.272
2024-12-01-20:33:05-root-INFO: grad norm: 1.593 1.582 0.184
2024-12-01-20:33:06-root-INFO: grad norm: 1.528 1.520 0.151
2024-12-01-20:33:06-root-INFO: grad norm: 1.405 1.396 0.154
2024-12-01-20:33:07-root-INFO: grad norm: 1.281 1.274 0.131
2024-12-01-20:33:07-root-INFO: Loss Change: 12.930 -> 10.337
2024-12-01-20:33:07-root-INFO: Regularization Change: 0.000 -> 3.898
2024-12-01-20:33:07-root-INFO: Learning rate of xt decay: 0.31458 -> 0.31835.
2024-12-01-20:33:07-root-INFO: Coefficient of regularization decay: 0.00100 -> 0.00101.
2024-12-01-20:33:07-root-INFO: step: 17 lr_xt 0.30994086
2024-12-01-20:33:07-root-INFO: grad norm: 1.451 1.434 0.226
2024-12-01-20:33:08-root-INFO: grad norm: 1.188 1.182 0.127
2024-12-01-20:33:08-root-INFO: grad norm: 1.530 1.526 0.121
2024-12-01-20:33:09-root-INFO: grad norm: 1.079 1.073 0.108
2024-12-01-20:33:09-root-INFO: grad norm: 0.953 0.948 0.092
2024-12-01-20:33:10-root-INFO: Loss Change: 10.087 -> 8.598
2024-12-01-20:33:10-root-INFO: Regularization Change: 0.000 -> 2.309
2024-12-01-20:33:10-root-INFO: Learning rate of xt decay: 0.31835 -> 0.32217.
2024-12-01-20:33:10-root-INFO: Coefficient of regularization decay: 0.00101 -> 0.00102.
2024-12-01-20:33:10-root-INFO: step: 16 lr_xt 0.31455579
2024-12-01-20:33:10-root-INFO: grad norm: 1.368 1.351 0.218
2024-12-01-20:33:11-root-INFO: grad norm: 0.973 0.967 0.111
2024-12-01-20:33:11-root-INFO: grad norm: 0.891 0.888 0.083
2024-12-01-20:33:11-root-INFO: grad norm: 0.976 0.973 0.086
2024-12-01-20:33:12-root-INFO: grad norm: 0.915 0.911 0.080
2024-12-01-20:33:12-root-INFO: Loss Change: 8.437 -> 7.324
2024-12-01-20:33:12-root-INFO: Regularization Change: 0.000 -> 1.640
2024-12-01-20:33:12-root-INFO: Learning rate of xt decay: 0.32217 -> 0.32604.
2024-12-01-20:33:12-root-INFO: Coefficient of regularization decay: 0.00102 -> 0.00103.
2024-12-01-20:33:12-root-INFO: step: 15 lr_xt 0.31918850
2024-12-01-20:33:13-root-INFO: grad norm: 1.445 1.423 0.252
2024-12-01-20:33:13-root-INFO: grad norm: 0.991 0.985 0.110
2024-12-01-20:33:13-root-INFO: grad norm: 0.793 0.790 0.071
2024-12-01-20:33:14-root-INFO: grad norm: 0.724 0.720 0.068
2024-12-01-20:33:14-root-INFO: grad norm: 0.734 0.731 0.059
2024-12-01-20:33:15-root-INFO: Loss Change: 7.224 -> 6.348
2024-12-01-20:33:15-root-INFO: Regularization Change: 0.000 -> 1.297
2024-12-01-20:33:15-root-INFO: Learning rate of xt decay: 0.32604 -> 0.32995.
2024-12-01-20:33:15-root-INFO: Coefficient of regularization decay: 0.00103 -> 0.00104.
2024-12-01-20:33:15-root-INFO: step: 14 lr_xt 0.32383775
2024-12-01-20:33:15-root-INFO: grad norm: 1.739 1.722 0.241
2024-12-01-20:33:16-root-INFO: grad norm: 0.894 0.889 0.093
2024-12-01-20:33:16-root-INFO: grad norm: 0.721 0.718 0.061
2024-12-01-20:33:16-root-INFO: grad norm: 0.700 0.697 0.063
2024-12-01-20:33:17-root-INFO: grad norm: 0.664 0.662 0.051
2024-12-01-20:33:17-root-INFO: Loss Change: 6.310 -> 5.531
2024-12-01-20:33:17-root-INFO: Regularization Change: 0.000 -> 1.079
2024-12-01-20:33:17-root-INFO: Learning rate of xt decay: 0.32995 -> 0.33391.
2024-12-01-20:33:17-root-INFO: Coefficient of regularization decay: 0.00104 -> 0.00105.
2024-12-01-20:33:17-root-INFO: step: 13 lr_xt 0.32850231
2024-12-01-20:33:18-root-INFO: grad norm: 1.380 1.362 0.224
2024-12-01-20:33:18-root-INFO: grad norm: 0.840 0.835 0.090
2024-12-01-20:33:18-root-INFO: grad norm: 0.726 0.724 0.054
2024-12-01-20:33:19-root-INFO: grad norm: 0.863 0.862 0.054
2024-12-01-20:33:19-root-INFO: grad norm: 0.700 0.698 0.054
2024-12-01-20:33:20-root-INFO: Loss Change: 5.529 -> 4.860
2024-12-01-20:33:20-root-INFO: Regularization Change: 0.000 -> 0.945
2024-12-01-20:33:20-root-INFO: Learning rate of xt decay: 0.33391 -> 0.33792.
2024-12-01-20:33:20-root-INFO: Coefficient of regularization decay: 0.00105 -> 0.00106.
2024-12-01-20:33:20-root-INFO: step: 12 lr_xt 0.33318090
2024-12-01-20:33:20-root-INFO: grad norm: 1.141 1.124 0.195
2024-12-01-20:33:21-root-INFO: grad norm: 0.742 0.737 0.078
2024-12-01-20:33:21-root-INFO: grad norm: 1.041 1.039 0.064
2024-12-01-20:33:21-root-INFO: grad norm: 0.682 0.679 0.058
2024-12-01-20:33:22-root-INFO: grad norm: 0.679 0.678 0.045
2024-12-01-20:33:22-root-INFO: Loss Change: 4.868 -> 4.298
2024-12-01-20:33:22-root-INFO: Regularization Change: 0.000 -> 0.847
2024-12-01-20:33:22-root-INFO: Learning rate of xt decay: 0.33792 -> 0.34197.
2024-12-01-20:33:22-root-INFO: Coefficient of regularization decay: 0.00106 -> 0.00107.
2024-12-01-20:33:22-root-INFO: step: 11 lr_xt 0.33787222
2024-12-01-20:33:23-root-INFO: grad norm: 1.378 1.361 0.214
2024-12-01-20:33:23-root-INFO: grad norm: 0.769 0.766 0.075
2024-12-01-20:33:24-root-INFO: grad norm: 0.666 0.665 0.043
2024-12-01-20:33:24-root-INFO: grad norm: 0.816 0.815 0.043
2024-12-01-20:33:25-root-INFO: grad norm: 0.664 0.662 0.048
2024-12-01-20:33:25-root-INFO: Loss Change: 4.369 -> 3.791
2024-12-01-20:33:25-root-INFO: Regularization Change: 0.000 -> 0.790
2024-12-01-20:33:25-root-INFO: Learning rate of xt decay: 0.34197 -> 0.34608.
2024-12-01-20:33:25-root-INFO: Coefficient of regularization decay: 0.00107 -> 0.00108.
2024-12-01-20:33:25-root-INFO: step: 10 lr_xt 0.34257494
2024-12-01-20:33:25-root-INFO: grad norm: 1.218 1.200 0.208
2024-12-01-20:33:26-root-INFO: grad norm: 0.845 0.842 0.076
2024-12-01-20:33:26-root-INFO: grad norm: 1.043 1.042 0.061
2024-12-01-20:33:27-root-INFO: grad norm: 0.656 0.654 0.051
2024-12-01-20:33:27-root-INFO: grad norm: 0.560 0.559 0.034
2024-12-01-20:33:27-root-INFO: Loss Change: 3.894 -> 3.374
2024-12-01-20:33:27-root-INFO: Regularization Change: 0.000 -> 0.750
2024-12-01-20:33:27-root-INFO: Undo step: 10
2024-12-01-20:33:27-root-INFO: Undo step: 11
2024-12-01-20:33:27-root-INFO: Undo step: 12
2024-12-01-20:33:27-root-INFO: Undo step: 13
2024-12-01-20:33:27-root-INFO: Undo step: 14
2024-12-01-20:33:28-root-INFO: step: 15 lr_xt 0.31918850
2024-12-01-20:33:28-root-INFO: grad norm: 12.706 12.675 0.883
2024-12-01-20:33:28-root-INFO: grad norm: 6.315 6.291 0.542
2024-12-01-20:33:29-root-INFO: grad norm: 4.220 4.203 0.385
2024-12-01-20:33:29-root-INFO: grad norm: 3.202 3.187 0.309
2024-12-01-20:33:30-root-INFO: grad norm: 2.591 2.578 0.255
2024-12-01-20:33:30-root-INFO: Loss Change: 69.067 -> 13.904
2024-12-01-20:33:30-root-INFO: Regularization Change: 0.000 -> 70.223
2024-12-01-20:33:30-root-INFO: Learning rate of xt decay: 0.32604 -> 0.32995.
2024-12-01-20:33:30-root-INFO: Coefficient of regularization decay: 0.00103 -> 0.00104.
2024-12-01-20:33:30-root-INFO: step: 14 lr_xt 0.32383775
2024-12-01-20:33:30-root-INFO: grad norm: 2.410 2.397 0.256
2024-12-01-20:33:31-root-INFO: grad norm: 1.965 1.955 0.199
2024-12-01-20:33:31-root-INFO: grad norm: 1.708 1.700 0.167
2024-12-01-20:33:32-root-INFO: grad norm: 1.519 1.512 0.153
2024-12-01-20:33:32-root-INFO: grad norm: 1.375 1.368 0.136
2024-12-01-20:33:33-root-INFO: Loss Change: 13.386 -> 8.441
2024-12-01-20:33:33-root-INFO: Regularization Change: 0.000 -> 7.983
2024-12-01-20:33:33-root-INFO: Learning rate of xt decay: 0.32995 -> 0.33391.
2024-12-01-20:33:33-root-INFO: Coefficient of regularization decay: 0.00104 -> 0.00105.
2024-12-01-20:33:33-root-INFO: step: 13 lr_xt 0.32850231
2024-12-01-20:33:33-root-INFO: grad norm: 1.612 1.598 0.211
2024-12-01-20:33:33-root-INFO: grad norm: 1.304 1.297 0.133
2024-12-01-20:33:34-root-INFO: grad norm: 1.515 1.511 0.113
2024-12-01-20:33:34-root-INFO: grad norm: 1.089 1.084 0.105
2024-12-01-20:33:35-root-INFO: grad norm: 0.998 0.994 0.089
2024-12-01-20:33:35-root-INFO: Loss Change: 8.155 -> 6.173
2024-12-01-20:33:35-root-INFO: Regularization Change: 0.000 -> 3.233
2024-12-01-20:33:35-root-INFO: Learning rate of xt decay: 0.33391 -> 0.33792.
2024-12-01-20:33:35-root-INFO: Coefficient of regularization decay: 0.00105 -> 0.00106.
2024-12-01-20:33:35-root-INFO: step: 12 lr_xt 0.33318090
2024-12-01-20:33:35-root-INFO: grad norm: 1.285 1.273 0.180
2024-12-01-20:33:36-root-INFO: grad norm: 0.942 0.937 0.093
2024-12-01-20:33:36-root-INFO: grad norm: 1.036 1.033 0.076
2024-12-01-20:33:37-root-INFO: grad norm: 0.909 0.906 0.081
2024-12-01-20:33:37-root-INFO: grad norm: 0.745 0.743 0.061
2024-12-01-20:33:37-root-INFO: Loss Change: 5.995 -> 4.870
2024-12-01-20:33:37-root-INFO: Regularization Change: 0.000 -> 1.794
2024-12-01-20:33:37-root-INFO: Learning rate of xt decay: 0.33792 -> 0.34197.
2024-12-01-20:33:37-root-INFO: Coefficient of regularization decay: 0.00106 -> 0.00107.
2024-12-01-20:33:38-root-INFO: step: 11 lr_xt 0.33787222
2024-12-01-20:33:38-root-INFO: grad norm: 1.161 1.147 0.180
2024-12-01-20:33:38-root-INFO: grad norm: 0.734 0.731 0.066
2024-12-01-20:33:39-root-INFO: grad norm: 0.667 0.665 0.049
2024-12-01-20:33:39-root-INFO: grad norm: 0.775 0.773 0.048
2024-12-01-20:33:40-root-INFO: grad norm: 0.838 0.835 0.061
2024-12-01-20:33:40-root-INFO: Loss Change: 4.786 -> 4.050
2024-12-01-20:33:40-root-INFO: Regularization Change: 0.000 -> 1.203
2024-12-01-20:33:40-root-INFO: Learning rate of xt decay: 0.34197 -> 0.34608.
2024-12-01-20:33:40-root-INFO: Coefficient of regularization decay: 0.00107 -> 0.00108.
2024-12-01-20:33:40-root-INFO: step: 10 lr_xt 0.34257494
2024-12-01-20:33:40-root-INFO: grad norm: 1.522 1.506 0.226
2024-12-01-20:33:41-root-INFO: grad norm: 0.875 0.871 0.081
2024-12-01-20:33:41-root-INFO: grad norm: 0.604 0.602 0.043
2024-12-01-20:33:42-root-INFO: grad norm: 0.518 0.517 0.038
2024-12-01-20:33:42-root-INFO: grad norm: 0.491 0.490 0.033
2024-12-01-20:33:43-root-INFO: Loss Change: 4.089 -> 3.404
2024-12-01-20:33:43-root-INFO: Regularization Change: 0.000 -> 0.929
2024-12-01-20:33:43-root-INFO: Learning rate of xt decay: 0.34608 -> 0.35023.
2024-12-01-20:33:43-root-INFO: Coefficient of regularization decay: 0.00108 -> 0.00109.
2024-12-01-20:33:43-root-INFO: step: 9 lr_xt 0.34728771
2024-12-01-20:33:43-root-INFO: grad norm: 1.146 1.132 0.179
2024-12-01-20:33:43-root-INFO: grad norm: 0.868 0.865 0.069
2024-12-01-20:33:44-root-INFO: grad norm: 0.862 0.861 0.053
2024-12-01-20:33:44-root-INFO: grad norm: 0.795 0.793 0.058
2024-12-01-20:33:45-root-INFO: grad norm: 0.705 0.704 0.041
2024-12-01-20:33:45-root-INFO: Loss Change: 3.457 -> 2.983
2024-12-01-20:33:45-root-INFO: Regularization Change: 0.000 -> 0.758
2024-12-01-20:33:45-root-INFO: Learning rate of xt decay: 0.35023 -> 0.35443.
2024-12-01-20:33:45-root-INFO: Coefficient of regularization decay: 0.00109 -> 0.00110.
2024-12-01-20:33:45-root-INFO: step: 8 lr_xt 0.35200918
2024-12-01-20:33:45-root-INFO: grad norm: 1.080 1.070 0.145
2024-12-01-20:33:46-root-INFO: grad norm: 0.676 0.675 0.039
2024-12-01-20:33:46-root-INFO: grad norm: 0.624 0.623 0.035
2024-12-01-20:33:47-root-INFO: grad norm: 0.605 0.604 0.033
2024-12-01-20:33:47-root-INFO: grad norm: 0.600 0.599 0.038
2024-12-01-20:33:48-root-INFO: Loss Change: 3.056 -> 2.631
2024-12-01-20:33:48-root-INFO: Regularization Change: 0.000 -> 0.660
2024-12-01-20:33:48-root-INFO: Learning rate of xt decay: 0.35443 -> 0.35869.
2024-12-01-20:33:48-root-INFO: Coefficient of regularization decay: 0.00110 -> 0.00111.
2024-12-01-20:33:48-root-INFO: step: 7 lr_xt 0.35673794
2024-12-01-20:33:48-root-INFO: grad norm: 1.173 1.159 0.176
2024-12-01-20:33:48-root-INFO: grad norm: 0.666 0.664 0.046
2024-12-01-20:33:49-root-INFO: grad norm: 0.549 0.548 0.037
2024-12-01-20:33:49-root-INFO: grad norm: 0.530 0.529 0.031
2024-12-01-20:33:50-root-INFO: grad norm: 0.499 0.498 0.028
2024-12-01-20:33:50-root-INFO: Loss Change: 2.775 -> 2.273
2024-12-01-20:33:50-root-INFO: Regularization Change: 0.000 -> 0.675
2024-12-01-20:33:50-root-INFO: Learning rate of xt decay: 0.35869 -> 0.36299.
2024-12-01-20:33:50-root-INFO: Coefficient of regularization decay: 0.00111 -> 0.00112.
2024-12-01-20:33:50-root-INFO: step: 6 lr_xt 0.36147257
2024-12-01-20:33:50-root-INFO: grad norm: 0.941 0.932 0.133
2024-12-01-20:33:51-root-INFO: grad norm: 0.443 0.442 0.033
2024-12-01-20:33:51-root-INFO: grad norm: 0.364 0.363 0.028
2024-12-01-20:33:52-root-INFO: grad norm: 0.334 0.333 0.027
2024-12-01-20:33:52-root-INFO: grad norm: 0.314 0.313 0.026
2024-12-01-20:33:53-root-INFO: Loss Change: 2.406 -> 2.035
2024-12-01-20:33:53-root-INFO: Regularization Change: 0.000 -> 0.544
2024-12-01-20:33:53-root-INFO: Learning rate of xt decay: 0.36299 -> 0.36735.
2024-12-01-20:33:53-root-INFO: Coefficient of regularization decay: 0.00112 -> 0.00113.
2024-12-01-20:33:53-root-INFO: step: 5 lr_xt 0.36621164
2024-12-01-20:33:53-root-INFO: grad norm: 0.918 0.909 0.130
2024-12-01-20:33:53-root-INFO: grad norm: 0.432 0.431 0.035
2024-12-01-20:33:54-root-INFO: grad norm: 0.350 0.349 0.032
2024-12-01-20:33:54-root-INFO: grad norm: 0.314 0.313 0.029
2024-12-01-20:33:55-root-INFO: grad norm: 0.292 0.291 0.029
2024-12-01-20:33:55-root-INFO: Loss Change: 2.192 -> 1.847
2024-12-01-20:33:55-root-INFO: Regularization Change: 0.000 -> 0.507
2024-12-01-20:33:55-root-INFO: Undo step: 5
2024-12-01-20:33:55-root-INFO: Undo step: 6
2024-12-01-20:33:55-root-INFO: Undo step: 7
2024-12-01-20:33:55-root-INFO: Undo step: 8
2024-12-01-20:33:55-root-INFO: Undo step: 9
2024-12-01-20:33:55-root-INFO: step: 10 lr_xt 0.34257494
2024-12-01-20:33:55-root-INFO: grad norm: 13.477 13.458 0.714
2024-12-01-20:33:56-root-INFO: grad norm: 5.804 5.786 0.454
2024-12-01-20:33:56-root-INFO: grad norm: 4.009 4.000 0.270
2024-12-01-20:33:57-root-INFO: grad norm: 2.931 2.923 0.224
2024-12-01-20:33:57-root-INFO: grad norm: 2.194 2.187 0.171
2024-12-01-20:33:58-root-INFO: Loss Change: 60.024 -> 8.593
2024-12-01-20:33:58-root-INFO: Regularization Change: 0.000 -> 69.440
2024-12-01-20:33:58-root-INFO: Learning rate of xt decay: 0.34608 -> 0.35023.
2024-12-01-20:33:58-root-INFO: Coefficient of regularization decay: 0.00108 -> 0.00109.
2024-12-01-20:33:58-root-INFO: step: 9 lr_xt 0.34728771
2024-12-01-20:33:58-root-INFO: grad norm: 2.035 2.028 0.169
2024-12-01-20:33:58-root-INFO: grad norm: 1.615 1.611 0.122
2024-12-01-20:33:59-root-INFO: grad norm: 1.393 1.389 0.099
2024-12-01-20:33:59-root-INFO: grad norm: 1.263 1.260 0.088
2024-12-01-20:34:00-root-INFO: grad norm: 1.197 1.193 0.092
2024-12-01-20:34:00-root-INFO: Loss Change: 8.159 -> 4.703
2024-12-01-20:34:00-root-INFO: Regularization Change: 0.000 -> 6.012
2024-12-01-20:34:00-root-INFO: Learning rate of xt decay: 0.35023 -> 0.35443.
2024-12-01-20:34:00-root-INFO: Coefficient of regularization decay: 0.00109 -> 0.00110.
2024-12-01-20:34:00-root-INFO: step: 8 lr_xt 0.35200918
2024-12-01-20:34:00-root-INFO: grad norm: 1.608 1.597 0.188
2024-12-01-20:34:01-root-INFO: grad norm: 1.114 1.111 0.089
2024-12-01-20:34:01-root-INFO: grad norm: 0.850 0.848 0.055
2024-12-01-20:34:02-root-INFO: grad norm: 0.822 0.820 0.060
2024-12-01-20:34:02-root-INFO: grad norm: 0.857 0.856 0.049
2024-12-01-20:34:03-root-INFO: Loss Change: 4.552 -> 3.258
2024-12-01-20:34:03-root-INFO: Regularization Change: 0.000 -> 2.202
2024-12-01-20:34:03-root-INFO: Learning rate of xt decay: 0.35443 -> 0.35869.
2024-12-01-20:34:03-root-INFO: Coefficient of regularization decay: 0.00110 -> 0.00111.
2024-12-01-20:34:03-root-INFO: step: 7 lr_xt 0.35673794
2024-12-01-20:34:03-root-INFO: grad norm: 1.134 1.128 0.118
2024-12-01-20:34:03-root-INFO: grad norm: 0.783 0.782 0.042
2024-12-01-20:34:04-root-INFO: grad norm: 0.735 0.734 0.043
2024-12-01-20:34:04-root-INFO: grad norm: 0.705 0.704 0.039
2024-12-01-20:34:05-root-INFO: grad norm: 0.667 0.665 0.043
2024-12-01-20:34:05-root-INFO: Loss Change: 3.174 -> 2.526
2024-12-01-20:34:05-root-INFO: Regularization Change: 0.000 -> 1.105
2024-12-01-20:34:05-root-INFO: Learning rate of xt decay: 0.35869 -> 0.36299.
2024-12-01-20:34:05-root-INFO: Coefficient of regularization decay: 0.00111 -> 0.00112.
2024-12-01-20:34:05-root-INFO: step: 6 lr_xt 0.36147257
2024-12-01-20:34:05-root-INFO: grad norm: 1.126 1.116 0.150
2024-12-01-20:34:06-root-INFO: grad norm: 0.648 0.647 0.040
2024-12-01-20:34:06-root-INFO: grad norm: 0.522 0.521 0.030
2024-12-01-20:34:07-root-INFO: grad norm: 0.440 0.439 0.027
2024-12-01-20:34:07-root-INFO: grad norm: 0.402 0.401 0.025
2024-12-01-20:34:08-root-INFO: Loss Change: 2.583 -> 2.103
2024-12-01-20:34:08-root-INFO: Regularization Change: 0.000 -> 0.713
2024-12-01-20:34:08-root-INFO: Learning rate of xt decay: 0.36299 -> 0.36735.
2024-12-01-20:34:08-root-INFO: Coefficient of regularization decay: 0.00112 -> 0.00113.
2024-12-01-20:34:08-root-INFO: step: 5 lr_xt 0.36621164
2024-12-01-20:34:08-root-INFO: grad norm: 0.885 0.877 0.118
2024-12-01-20:34:08-root-INFO: grad norm: 0.449 0.448 0.031
2024-12-01-20:34:09-root-INFO: grad norm: 0.363 0.363 0.027
2024-12-01-20:34:09-root-INFO: grad norm: 0.334 0.333 0.025
2024-12-01-20:34:10-root-INFO: grad norm: 0.315 0.314 0.024
2024-12-01-20:34:10-root-INFO: Loss Change: 2.194 -> 1.846
2024-12-01-20:34:10-root-INFO: Regularization Change: 0.000 -> 0.531
2024-12-01-20:34:10-root-INFO: Learning rate of xt decay: 0.36735 -> 0.37175.
2024-12-01-20:34:10-root-INFO: Coefficient of regularization decay: 0.00113 -> 0.00114.
2024-12-01-20:34:10-root-INFO: step: 4 lr_xt 0.37095370
2024-12-01-20:34:10-root-INFO: grad norm: 0.812 0.806 0.097
2024-12-01-20:34:11-root-INFO: grad norm: 0.410 0.409 0.032
2024-12-01-20:34:11-root-INFO: grad norm: 0.329 0.328 0.028
2024-12-01-20:34:12-root-INFO: grad norm: 0.298 0.296 0.027
2024-12-01-20:34:12-root-INFO: grad norm: 0.278 0.276 0.026
2024-12-01-20:34:13-root-INFO: Loss Change: 1.958 -> 1.664
2024-12-01-20:34:13-root-INFO: Regularization Change: 0.000 -> 0.452
2024-12-01-20:34:13-root-INFO: Learning rate of xt decay: 0.37175 -> 0.37621.
2024-12-01-20:34:13-root-INFO: Coefficient of regularization decay: 0.00114 -> 0.00116.
2024-12-01-20:34:13-root-INFO: step: 3 lr_xt 0.37569726
2024-12-01-20:34:13-root-INFO: grad norm: 0.783 0.778 0.081
2024-12-01-20:34:13-root-INFO: grad norm: 0.390 0.389 0.034
2024-12-01-20:34:14-root-INFO: grad norm: 0.309 0.307 0.031
2024-12-01-20:34:14-root-INFO: grad norm: 0.277 0.275 0.030
2024-12-01-20:34:15-root-INFO: grad norm: 0.257 0.255 0.030
2024-12-01-20:34:15-root-INFO: Loss Change: 1.798 -> 1.523
2024-12-01-20:34:15-root-INFO: Regularization Change: 0.000 -> 0.422
2024-12-01-20:34:15-root-INFO: Learning rate of xt decay: 0.37621 -> 0.38073.
2024-12-01-20:34:15-root-INFO: Coefficient of regularization decay: 0.00116 -> 0.00117.
2024-12-01-20:34:15-root-INFO: step: 2 lr_xt 0.38044082
2024-12-01-20:34:15-root-INFO: grad norm: 0.742 0.739 0.064
2024-12-01-20:34:16-root-INFO: grad norm: 0.378 0.377 0.034
2024-12-01-20:34:16-root-INFO: grad norm: 0.324 0.322 0.034
2024-12-01-20:34:17-root-INFO: grad norm: 0.269 0.267 0.033
2024-12-01-20:34:17-root-INFO: grad norm: 0.237 0.234 0.032
2024-12-01-20:34:18-root-INFO: Loss Change: 1.654 -> 1.404
2024-12-01-20:34:18-root-INFO: Regularization Change: 0.000 -> 0.390
2024-12-01-20:34:18-root-INFO: Learning rate of xt decay: 0.38073 -> 0.38530.
2024-12-01-20:34:18-root-INFO: Coefficient of regularization decay: 0.00117 -> 0.00118.
2024-12-01-20:34:18-root-INFO: step: 1 lr_xt 0.38518288
2024-12-01-20:34:18-root-INFO: grad norm: 0.731 0.728 0.058
2024-12-01-20:34:19-root-INFO: grad norm: 0.358 0.357 0.032
2024-12-01-20:34:19-root-INFO: grad norm: 0.284 0.282 0.029
2024-12-01-20:34:19-root-INFO: grad norm: 0.254 0.252 0.028
2024-12-01-20:34:20-root-INFO: grad norm: 0.242 0.240 0.028
2024-12-01-20:34:20-root-INFO: Loss Change: 1.523 -> 1.281
2024-12-01-20:34:20-root-INFO: Regularization Change: 0.000 -> 0.385
2024-12-01-20:34:20-root-INFO: Learning rate of xt decay: 0.38530 -> 0.38992.
2024-12-01-20:34:20-root-INFO: Coefficient of regularization decay: 0.00118 -> 0.00119.
2024-12-01-20:34:20-root-INFO: step: 0 lr_xt 0.38992188
2024-12-01-20:34:21-root-INFO: grad norm: 0.831 0.827 0.078
2024-12-01-20:34:21-root-INFO: grad norm: 0.513 0.512 0.024
2024-12-01-20:34:22-root-INFO: grad norm: 0.408 0.407 0.029
2024-12-01-20:34:22-root-INFO: grad norm: 0.357 0.354 0.041
2024-12-01-20:34:23-root-INFO: grad norm: 0.329 0.325 0.048
2024-12-01-20:34:23-root-INFO: Loss Change: 1.423 -> 0.974
2024-12-01-20:34:23-root-INFO: Regularization Change: 0.000 -> 0.797
2024-12-01-20:34:23-root-INFO: Undo step: 0
2024-12-01-20:34:23-root-INFO: Undo step: 1
2024-12-01-20:34:23-root-INFO: Undo step: 2
2024-12-01-20:34:23-root-INFO: Undo step: 3
2024-12-01-20:34:23-root-INFO: Undo step: 4
2024-12-01-20:34:23-root-INFO: step: 5 lr_xt 0.36621164
2024-12-01-20:34:23-root-INFO: grad norm: 12.424 12.417 0.394
2024-12-01-20:34:24-root-INFO: grad norm: 5.617 5.614 0.185
2024-12-01-20:34:24-root-INFO: grad norm: 3.630 3.627 0.129
2024-12-01-20:34:25-root-INFO: grad norm: 2.182 2.180 0.087
2024-12-01-20:34:25-root-INFO: grad norm: 1.616 1.614 0.084
2024-12-01-20:34:26-root-INFO: Loss Change: 37.810 -> 4.073
2024-12-01-20:34:26-root-INFO: Regularization Change: 0.000 -> 48.181
2024-12-01-20:34:26-root-INFO: Learning rate of xt decay: 0.36735 -> 0.37175.
2024-12-01-20:34:26-root-INFO: Coefficient of regularization decay: 0.00113 -> 0.00114.
2024-12-01-20:34:26-root-INFO: step: 4 lr_xt 0.37095370
2024-12-01-20:34:26-root-INFO: grad norm: 1.451 1.449 0.075
2024-12-01-20:34:26-root-INFO: grad norm: 1.053 1.052 0.046
2024-12-01-20:34:27-root-INFO: grad norm: 0.823 0.822 0.039
2024-12-01-20:34:27-root-INFO: grad norm: 0.753 0.752 0.037
2024-12-01-20:34:28-root-INFO: grad norm: 1.408 1.408 0.034
2024-12-01-20:34:28-root-INFO: Loss Change: 3.874 -> 2.257
2024-12-01-20:34:28-root-INFO: Regularization Change: 0.000 -> 2.876
2024-12-01-20:34:28-root-INFO: Learning rate of xt decay: 0.37175 -> 0.37621.
2024-12-01-20:34:28-root-INFO: Coefficient of regularization decay: 0.00114 -> 0.00116.
2024-12-01-20:34:28-root-INFO: step: 3 lr_xt 0.37569726
2024-12-01-20:34:29-root-INFO: grad norm: 0.912 0.909 0.066
2024-12-01-20:34:29-root-INFO: grad norm: 0.549 0.548 0.031
2024-12-01-20:34:29-root-INFO: grad norm: 0.460 0.459 0.028
2024-12-01-20:34:30-root-INFO: grad norm: 0.407 0.406 0.028
2024-12-01-20:34:30-root-INFO: grad norm: 0.367 0.366 0.027
2024-12-01-20:34:31-root-INFO: Loss Change: 2.248 -> 1.750
2024-12-01-20:34:31-root-INFO: Regularization Change: 0.000 -> 0.868
2024-12-01-20:34:31-root-INFO: Learning rate of xt decay: 0.37621 -> 0.38073.
2024-12-01-20:34:31-root-INFO: Coefficient of regularization decay: 0.00116 -> 0.00117.
2024-12-01-20:34:31-root-INFO: step: 2 lr_xt 0.38044082
2024-12-01-20:34:31-root-INFO: grad norm: 0.761 0.758 0.070
2024-12-01-20:34:32-root-INFO: grad norm: 0.437 0.435 0.037
2024-12-01-20:34:32-root-INFO: grad norm: 0.367 0.366 0.033
2024-12-01-20:34:33-root-INFO: grad norm: 0.314 0.312 0.031
2024-12-01-20:34:33-root-INFO: grad norm: 0.284 0.283 0.029
2024-12-01-20:34:33-root-INFO: Loss Change: 1.823 -> 1.500
2024-12-01-20:34:33-root-INFO: Regularization Change: 0.000 -> 0.538
2024-12-01-20:34:33-root-INFO: Learning rate of xt decay: 0.38073 -> 0.38530.
2024-12-01-20:34:33-root-INFO: Coefficient of regularization decay: 0.00117 -> 0.00118.
2024-12-01-20:34:33-root-INFO: step: 1 lr_xt 0.38518288
2024-12-01-20:34:34-root-INFO: grad norm: 0.714 0.710 0.084
2024-12-01-20:34:34-root-INFO: grad norm: 0.377 0.376 0.035
2024-12-01-20:34:35-root-INFO: grad norm: 0.299 0.297 0.027
2024-12-01-20:34:35-root-INFO: grad norm: 0.262 0.261 0.022
2024-12-01-20:34:36-root-INFO: grad norm: 0.255 0.254 0.023
2024-12-01-20:34:36-root-INFO: Loss Change: 1.589 -> 1.332
2024-12-01-20:34:36-root-INFO: Regularization Change: 0.000 -> 0.419
2024-12-01-20:34:36-root-INFO: Learning rate of xt decay: 0.38530 -> 0.38992.
2024-12-01-20:34:36-root-INFO: Coefficient of regularization decay: 0.00118 -> 0.00119.
2024-12-01-20:34:36-root-INFO: loss_sample0_0: 1.3319721221923828
2024-12-01-20:34:36-root-INFO: It takes 1825.050 seconds for image sample0
2024-12-01-20:34:36-root-INFO: lpips_score_sample0: 0.126
2024-12-01-20:34:36-root-INFO: psnr_score_sample0: 17.754
2024-12-01-20:34:36-root-INFO: ssim_score_sample0: 0.721
2024-12-01-20:34:36-root-INFO: mean_lpips: 0.12564265727996826
2024-12-01-20:34:36-root-INFO: best_mean_lpips: 0.12564265727996826
2024-12-01-20:34:36-root-INFO: mean_psnr: 17.753713607788086
2024-12-01-20:34:36-root-INFO: best_mean_psnr: 17.753713607788086
2024-12-01-20:34:36-root-INFO: mean_ssim: 0.7205359935760498
2024-12-01-20:34:36-root-INFO: best_mean_ssim: 0.7205359935760498
2024-12-01-20:34:36-root-INFO: final_loss: 1.3319721221923828
2024-12-01-20:34:36-root-INFO: mean time: 1825.0502910614014
2024-12-01-20:34:36-root-INFO: Your samples are ready and waiting for you here: 
./hyperparam_eval/results/celebahq_o_ddim_jump5_sample2_iter5_lr0.02_10009 
 
Enjoy.
