{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {   \n",
    "        \"dataset\": \"ImageNet\",\n",
    "        \"mask_type\": \"expand\",\n",
    "        \"algorithm\": \"Copaint\"\n",
    "        \"mean_lpips\": 0.503011167049408,\n",
    "        \"mean_psnr\": 17.135379791259766,\n",
    "        \"mean_ssim\": 0.5807474851608276,\n",
    "        \"final_loss\": 1.5211669206619263,\n",
    "        \"mean time\": 244.44522905349731\n",
    "    },\n",
    "\n",
    "    {   \n",
    "        \"dataset\": \"ImageNet\",\n",
    "        \"mask_type\": \"half\",\n",
    "        \"algorithm\": \"Copaint\"\n",
    "        \"mean_lpips\": 0.18792548775672913,\n",
    "        \"mean_psnr\": 20.609283447265625,\n",
    "        \"mean_ssim\": 0.7838151454925537,\n",
    "        \"final_loss\": 9.873313903808594,\n",
    "        \"mean time\": 277.57729959487915\n",
    "    },\n",
    "\n",
    "    {   \n",
    "        \"dataset\": \"ImageNet\",\n",
    "        \"mask_type\": \"line\",\n",
    "        \"algorithm\": \"Copaint\"\n",
    "        \"mean_lpips\": 0.034693643450737,\n",
    "        \"mean_psnr\": 38.161407470703125,\n",
    "        \"mean_ssim\": 0.9552620649337769,\n",
    "        \"final_loss\": 13.067879676818848,\n",
    "        \"mean time\": 253.88609099388123\n",
    "    },\n",
    "\n",
    "    {   \n",
    "        \"dataset\": \"ImageNet\",\n",
    "        \"mask_type\": \"sr2\",\n",
    "        \"algorithm\": \"Copaint\"\n",
    "        \"mean_lpips\": 0.05219435691833496,\n",
    "        \"mean_psnr\": 37.041473388671875,\n",
    "        \"mean_ssim\": 0.9436663389205933,\n",
    "        \"final_loss\": 7.975658416748047,\n",
    "        \"mean time\": 244.29270911216736\n",
    "    },\n",
    "\n",
    "    {   \n",
    "        \"dataset\": \"ImageNet\",\n",
    "        \"mask_type\": \"expand\",\n",
    "        \"algorithm\": \"Copaint\"\n",
    "        \"mean_lpips\": 0.503011167049408,\n",
    "        \"mean_psnr\": 17.135379791259766,\n",
    "        \"mean_ssim\": 0.5807474851608276,\n",
    "        \"final_loss\": 1.5211669206619263,\n",
    "        \"mean time\": 244.44522905349731\n",
    "    },\n",
    "\n",
    "    {   \n",
    "        \"dataset\": \"ImageNet\",\n",
    "        \"mask_type\": \"expand\",\n",
    "        \"algorithm\": \"Copaint\"\n",
    "        \"mean_lpips\": 0.503011167049408,\n",
    "        \"mean_psnr\": 17.135379791259766,\n",
    "        \"mean_ssim\": 0.5807474851608276,\n",
    "        \"final_loss\": 1.5211669206619263,\n",
    "        \"mean time\": 244.44522905349731\n",
    "    },\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Directory where result files are stored\n",
    "base_dir = 'train_results'\n",
    "\n",
    "# Function to parse result files and extract the metrics\n",
    "def extract_metrics_from_result(file_path):\n",
    "    metrics = {}\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                # Try loading each line as a JSON object\n",
    "                data = json.loads(line)\n",
    "                # Extract relevant metrics from the JSON data\n",
    "                if 'mean_lpips' in data:\n",
    "                    metrics['mean_lpips'] = data['mean_lpips']\n",
    "                elif 'mean_psnr' in data:\n",
    "                    metrics['mean_psnr'] = data['mean_psnr']\n",
    "                elif 'mean_ssim' in data:\n",
    "                    metrics['mean_ssim'] = data['mean_ssim']\n",
    "                elif 'final_loss' in data:\n",
    "                    metrics['final_loss'] = data['final_loss']\n",
    "                elif 'mean time' in data:\n",
    "                    metrics['mean_time'] = data['mean time']\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "    return metrics\n",
    "\n",
    "# Prepare lists to hold the data for plotting\n",
    "datasets = []\n",
    "mask_types = []\n",
    "algorithms = []\n",
    "metrics_data = {\n",
    "    \"mean_lpips\": [],\n",
    "    \"mean_psnr\": [],\n",
    "    \"mean_ssim\": [],\n",
    "    \"final_loss\": [],\n",
    "    \"mean_time\": []\n",
    "}\n",
    "\n",
    "# Walk through the directory and collect data\n",
    "for algo in os.listdir(base_dir):\n",
    "    algo_dir = os.path.join(base_dir, algo)\n",
    "    if not os.path.isdir(algo_dir):\n",
    "        continue\n",
    "    \n",
    "    for dataset in os.listdir(algo_dir):\n",
    "        dataset_dir = os.path.join(algo_dir, dataset)\n",
    "        if not os.path.isdir(dataset_dir):\n",
    "            continue\n",
    "        \n",
    "        for mask in os.listdir(dataset_dir):\n",
    "            mask_dir = os.path.join(dataset_dir, mask)\n",
    "            if not os.path.isdir(mask_dir):\n",
    "                continue\n",
    "\n",
    "            # Get all .result files in the mask folder\n",
    "            result_files = [f for f in os.listdir(mask_dir) if f.endswith('.result')]\n",
    "            if len(result_files) < 2:\n",
    "                continue  # If there are less than 2 result files, skip this mask\n",
    "\n",
    "            # Sort result files to pick the second one\n",
    "            result_files.sort()\n",
    "            second_result_file = os.path.join(mask_dir, result_files[1])\n",
    "\n",
    "            # Extract metrics from the second result file\n",
    "            metrics = extract_metrics_from_result(second_result_file)\n",
    "            \n",
    "            if metrics:\n",
    "                # Store the dataset, mask, algorithm and corresponding metrics\n",
    "                datasets.append(dataset)\n",
    "                mask_types.append(mask)\n",
    "                algorithms.append(algo)\n",
    "\n",
    "                for metric in metrics_data:\n",
    "                    metrics_data[metric].append(metrics.get(metric, None))\n",
    "\n",
    "# Plot the data\n",
    "bar_width = 0.2\n",
    "x = np.arange(len(datasets))  # x-axis positions for bars\n",
    "\n",
    "# Plot each metric\n",
    "for metric in metrics_data:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for m_idx, mask in enumerate(mask_types):\n",
    "        for a_idx, algo in enumerate(algorithms):\n",
    "            # Calculate bar positions\n",
    "            positions = x + (m_idx * len(algorithms) + a_idx) * bar_width\n",
    "            # Plot bars for each algorithm\n",
    "            plt.bar(positions, metrics_data[metric], bar_width,\n",
    "                    label=f'{mask} - {algo}')\n",
    "    \n",
    "    # Set plot details\n",
    "    plt.xlabel('Datasets')\n",
    "    plt.ylabel(metric.replace('_', ' ').title())\n",
    "    plt.title(f'{metric.replace(\"_\", \" \").title()} Across Datasets, Mask Types, and Algorithms')\n",
    "    plt.xticks(x + bar_width * (len(mask_types) * len(algorithms) - 1) / 2, datasets)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
